好的，我们来详细解释一下“正交化”的定义和过程。
[[向量的正交]]
### 核心定义

**正交化 (Orthogonalization)** 是一个数学过程，指的是将一组**线性无关**的向量 $(\alpha_1, \alpha_2, ..., \alpha_n)$ 转换为一组**两两正交**的向量 $(\beta_1, \beta_2, ..., \beta_n)$，并且转换后的这组新向量所张成的线性空间与原始向量组所张成的线性空间是**完全相同**的。

简单来说，就是把一组“歪斜”的基向量，变成一组“垂直”的基向量，但它们描述的是同一个空间。

在正交化的基础上，如果再将每个向量的长度都调整为1，这个过程就叫做**标准正交化 (Orthonormalization)**。

### 关键概念

要理解正交化，首先需要明确两个基本概念：

1.  **向量的内积（点积）**：对于两个向量 $\alpha = (a_1, a_2, ..., a_n)^T$ 和 $\beta = (b_1, b_2, ..., b_n)^T$，它们的内积（或点积）定义为：
    $\alpha \cdot \beta = \alpha^T \beta = a_1b_1 + a_2b_2 + ... + a_n b_n$

2.  **向量的正交 (Orthogonal)**：如果两个非零向量的内积为0，我们就称这两个向量是**正交**的。
    $\alpha \perp \beta \iff \alpha \cdot \beta = 0$
    在二维或三维空间中，这和我们几何直观上的“垂直”是同一个概念。

### 如何进行正交化？—— 施密特正交化 (Gram-Schmidt Process)

最常用的正交化方法是**施密特正交化**。它的思想是：从向量组中一个一个地处理向量，每处理一个新向量，就把它在已经正交化的向量方向上的分量（投影）全部减掉，剩下的部分自然就与前面的所有向量都正交了。

假设我们有一组线性无关的向量 $\{\alpha_1, \alpha_2, ..., \alpha_m\}$，我们想得到一组正交向量 $\{\beta_1, \beta_2, ..., \beta_m\}$。

**步骤如下：**

1.  **第一个向量**：直接取第一个向量作为新基的第一个向量。
    $\beta_1 = \alpha_1$

2.  **第二个向量**：取第二个原始向量 $\alpha_2$，减去它在 $\beta_1$ 方向上的投影。
    $\beta_2 = \alpha_2 - \text{proj}_{\beta_1}(\alpha_2) = \alpha_2 - \frac{\alpha_2 \cdot \beta_1}{\beta_1 \cdot \beta_1} \beta_1$
    这里的 $\frac{\alpha_2 \cdot \beta_1}{\beta_1 \cdot \beta_1} \beta_1$ 就是向量 $\alpha_2$ 在向量 $\beta_1$ 上的投影向量。减去这个投影后，剩下的 $\beta_2$ 就与 $\beta_1$ 正交了。

3.  **第三个向量**：取第三个原始向量 $\alpha_3$，减去它在 $\beta_1$ 和 $\beta_2$ 方向上的所有投影。
    $\beta_3 = \alpha_3 - \text{proj}_{\beta_1}(\alpha_3) - \text{proj}_{\beta_2}(\alpha_3) = \alpha_3 - \frac{\alpha_3 \cdot \beta_1}{\beta_1 \cdot \beta_1} \beta_1 - \frac{\alpha_3 \cdot \beta_2}{\beta_2 \cdot \beta_2} \beta_2$
    这样得到的 $\beta_3$ 就同时与 $\beta_1$ 和 $\beta_2$ 正交。

4.  **推广到第 k 个向量**：
    $\beta_k = \alpha_k - \sum_{j=1}^{k-1} \frac{\alpha_k \cdot \beta_j}{\beta_j \cdot \beta_j} \beta_j$

通过这个迭代过程，我们就能得到一组两两正交的向量 $\{\beta_1, \beta_2, ..., \beta_m\}$。

### 从正交化到标准正交化

得到正交向量组 $\{\beta_1, \beta_2, ..., \beta_m\}$ 后，我们再对每个向量进行**单位化 (Normalization)**，即将每个向量除以它自身的长度（范数），就可以得到一个**标准正交向量组** $\{e_1, e_2, ..., e_m\}$。

向量 $\beta_i$ 的长度（范数）为 $||\beta_i|| = \sqrt{\beta_i \cdot \beta_i}$。
单位化操作为：
$e_i = \frac{\beta_i}{||\beta_i||}$

### 为什么正交化很重要？

正交（特别是标准正交）的向量组具有非常优美的性质，极大地简化了线性代数中的计算和理论：

1.  **坐标计算简单**：在一个由标准正交基 $\{e_1, ..., e_n\}$ 张成的空间里，任何向量 $v$ 的坐标可以非常容易地通过内积得到：$v = (v \cdot e_1)e_1 + (v \cdot e_2)e_2 + ... + (v \cdot e_n)e_n$。
2.  **构建正交矩阵**：将一组标准正交向量作为列（或行）可以构建一个**正交矩阵** $Q$。正交矩阵满足 $Q^T Q = E$（即 $Q^{-1} = Q^T$），这使得求逆运算变得极其简单。
3.  **理论应用**：在题目中，将对称矩阵 $A$ 对角化的过程就需要找到一组标准正交的特征向量来构成正交矩阵 $Q$，从而实现 $Q^T A Q = \Lambda$。这在二次型化简、主成分分析（PCA）等领域是核心步骤。

回到你给的题目，当特征值 $\lambda = -1$ 是一个二重根时，我们找到了两个线性无关的特征向量 $\xi_1$ 和 $\xi_2$。但它们俩之间并不正交，所以必须使用施密特正交化过程，将它们转换为正交的 $\eta_1, \eta_2$，然后再单位化为 $e_1, e_2$，才能用于构建正交矩阵 $Q$。