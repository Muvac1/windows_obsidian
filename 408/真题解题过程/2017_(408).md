![[2017-exam-paper-ocr.pdf#page=1&rect=70,596,549,705|2017-exam-paper-ocr, p.1]]
[[Pasted image 20250930043154.png]]

[[时间复杂度分析]] 
[[时间复杂度等价]]
**1. 分析代码**

```c
int func(int n) {
    int i=0, sum=0;
    while(sum < n) {
        sum += ++i;
    }
    return i;
}
```

*   **初始化**：`i` 和 `sum` 都从0开始。
*   **循环条件**：循环持续的条件是 `sum < n`。当 `sum >= n` 时，循环终止。
*   **循环体**：`sum += ++i;`。这是一个关键操作。`++i` 是前置自增，意味着先将 `i` 的值加1，然后用新的 `i` 值参与运算。
    *   它等价于：
        ```c
        i = i + 1;
        sum = sum + i;
        ```
2. 
	*   **第1次循环**：`i` 变为1，`sum` = 0 + 1 = 1。
	*   **第2次循环**：`i` 变为2，`sum` = 1 + 2 = 3。
	*   **第3次循环**：`i` 变为3，`sum` = 3 + 3 = 6。
	*   ...
	*   **第k次循环**：`i` 变为 `k`，`sum` 的值是 $1 + 2 + 3 + \dots + k$。
3. $sum = \frac{k(k+1)}{2}$ 
	1. $\frac{k(k+1)}{2} \approx n$ 
	2. $k(k+1) \approx 2n$
		$k^2 + k \approx 2n$
	3. $k^2 \approx 2n$ 
	4. $k \approx \sqrt{2n} = \sqrt{2} \cdot \sqrt{n}$ 
4. 所以，循环的执行次数 `k` 与 $\sqrt{n}$ (即 $n^{1/2}$) 成正比  
5.  B. $O(n^{1/2})$ 

- 衍生    [[时间复杂度分析]]
	- [[++i vs. i++ 的时间复杂度影响]] 
		- 如果原题中的 `sum += ++i;` 改为 `sum += i++;`，时间复杂度会变吗？
			- **结论**：在渐近分析中，$k^2-k$ 和 $k^2+k$ 的主导项都是 $k^2$。因此，求解后得到的复杂度依然是 $O(\sqrt{n})$。在时间复杂度的大O分析层面，这两者没有区别，但这可能作为一个细节题来考察对自增运算符的理解。

![[2017-exam-paper-ocr.pdf#page=1&rect=76,509,503,599|2017-exam-paper-ocr, p.1]]
[[Pasted image 20250930043159.png]]


[[栈]] 
#函数调用栈    
- 1 错误 
- I. 采用非递归的方式重写递归程序时必须用栈
	- 这个说法的关键在于“必须” (must) 这个词，过于绝对。虽然栈是实现递归转非递归的一种通用且强大的方法，因为它能完美模拟函数调用栈的行为（保存局部变量、返回地址等），但并非所有情况都必须用栈。
*   **反例：**
    1.  #尾递归  尾递归是一种特殊的递归形式，递归调用是函数的最后一步操作。这种递归可以被编译器优化，直接转换成一个简单的循环，完全不需要栈。
    2.  #简单递归 ： 像题目解析中提到的计算斐波那契数列或阶乘，虽然有递归定义，但它们的迭代版本（非递归）只需要几个变量和一个循环就可以实现，并不需要显式地使用一个栈结构。
- 2 正确    
	- II. 函数调用时，系统要用栈保存必要的信息[[堆栈帧]]
	3.  每当一个函数被调用时，系统会创建一个称为“栈帧” 或“活动记录”的数据块，并将其压入一个特定的内存区域，这个区域就是 #调用栈
		1. #栈帧 中保存了函数的参数、局部变量、返回地址 #堆栈帧
		2. [[递归与栈的关系]] 
- 衍生 
	- [[栈的应用]] 




![[2017-exam-paper-ocr.pdf#page=1&rect=75,462,436,509|2017-exam-paper-ocr, p.1]]
[[Pasted image 20250930043205.png]]

 #稀疏矩阵  [[邻接矩阵，邻接表 ，稀疏图，稠密图]]  
#压缩存储   #不同的压缩存储方式   [[压缩存储]]
三元组表和十字链表是两种专门为压缩存储稀疏矩阵而设计的数据结构。邻接矩阵不属于压缩存储，而二叉链表则用于完全不同的数据类型。因此，正确答案是 **A**  
#三元组表  #十字链表  
- 衍生
	- [[稀疏矩阵的转置运算]]  #转置运算   
		- 原矩阵每一列的非零元个数，然后计算每一列第一个非零元在转置后三元组表中的起始位置。时间复杂度可以优化到 $O(n+t)$。这是面试和考试中的高频考点
	- [[稀疏矩阵的加法和乘法运算]] 
	- [[树和森林的存储结构]] 
	



![[2017-exam-paper-ocr.pdf#page=1&rect=75,424,517,460|2017-exam-paper-ocr, p.1]]
[[Pasted image 20250930043209.png]]

#结点的度  #非叶结点   #先序序列   [[遍历序列的基本性质]]  [[序列相同的条件]] 
1. 推理过程 
	1. 用 `R` 代表根结点，`L` 代表左子树的遍历序列，`R_sub` 代表右子树的遍历序列。
		*   那么，这棵树的先序序列可以表示为：`R, L, R_sub`
		*   这棵树的中序序列可以表示为：`L, R, R_sub`
		
		*   要使这两个序列相同，即 `R, L, R_sub` = `L, R, R_sub`，我们来比较它们的第一个元素。
		*   在先序序列中，第一个元素永远是根结点 `R`。
		*   在中序序列中，第一个元素是左子树遍历序列 `L` 的第一个元素。
		*   为了让两个序列的第一个元素相同，中序序列的第一个元素也必须是根结点 `R`。这种情况只有在左子树的遍历序列 `L` 为**空**时才会发生。
		
		*   如果左子树为空，那么：
		    *   先序序列变为：`R, R_sub`
		    *   中序序列变为：`R, R_sub`
		    *   此时，两个序列就相同了。
		
		*   这个逻辑是**递归**的。也就是说，对于树中的**任意一个结点**（把它看作一个子树的根），要使其子树的先序和中序遍历相同，这个结点都**不能有左孩子**。
	2. 题目要求是“所有非叶结点须满足的条件”。非叶结点就是有孩子的结点。根据我们的推导，这些结点都不能有左孩子，所以它们只能有右孩子 
		1. 正确答案是 **B. 只有右子树**

	*   **A. 只有左子树：** 如果一个结点 `R` 只有左子树 `L`，那么先序是 `R, L`，中序是 `L, R`。这两个序列显然是相反的，不可能相同（除非树只有一个结点）。
	*   **C. 结点的度均为1：** 这个条件太宽泛。一个结点的度为1，意味着它要么只有左孩子，要么只有右孩子。如果存在一个结点只有左孩子，那么条件就不满足了。所以C是错误的。
	*   **D. 结点的度均为2：** 如果结点的度为2，意味着它既有左孩子又有右孩子，这直接违反了我们推导出的“左子树必须为空”的结论。

- 衍生 
	- [[序列相同的条件]] 
	-  [[根据遍历序列重建二叉树]] 
	- [[二叉树的性质]] 
		- 对于任意一棵非空二叉树，如果叶结点的数量为$n_0$，度为2的结点数量为$n_2$，那么它们之间存在一个恒定的关系：
				$n_0 = n_2 + 1$
	- [[层次遍历]]    
		- 除了深度优先的三种遍历，还有一种广度优先的遍历方式，即层次遍历 ， 通常使用**队列**数据结构来实现

![[Pasted image 20250930043248.png]]
[[Pasted image 20250930043226.png]]
 - 
#后序序列  #二叉树的后序遍历  
1. 后序遍历的规则是：**先遍历左子树，再遍历右子树，最后访问根结点** 
	1. 后序遍历序列的一个显著特点是，序列的最后一个元素一定是整棵树（或子树）的根结点
	2. B 
- 衍生 
	- [[线索二叉树]] 
		- 为了利用二叉树中大量的空指针域，将它们改造为指向结点前驱或后继的线索，从而方便遍历 




![[Pasted image 20251015110858.png]]
[[Pasted image 20250930043324.png]]

[[哈夫曼编码]]  
#字符集
1.  **性质**：哈夫曼编码是 #前缀编码 ，即任何一个字符的编码都不是另一个字符编码的前缀，这保证了编码在解码时不会产生歧义。
2.     `0100` -> 匹配成功！这是字符 **a** 的编码。
    *   剩余序列: `011001001011110101`
    *   `011` -> 匹配成功！这是字符 **g** 的编码。
    *   剩余序列: `001001011110101`
    *   `001` -> 匹配成功！这是字符 **e** 的编码。
    *   剩余序列: `001011110101`
    *   `001` -> 再次匹配成功！这是字符 **e** 的编码。
    *   剩余序列: `011110101`
	将解码出的字符拼接起来，得到的结果是 **`ageeghd`** 

- 衍生 
	- #计算WPL 
		- 在构建完哈夫曼树后，要求计算其带权路径长度。这既考察了建树过程，也考察了对最优性概念的理解 
	- #哈夫曼树的性质  [[哈夫曼树]]  
		- #编码的非唯一性 在构建树时，如果出现两个或以上权重相同的最小节点，选择哪两个进行合并是任意的，这可能导致构造出不同形态的哈夫曼树。 在为分支分配0和1时，左0右1或左1右0都是可以的。
		    *   因此，对于同一组权重，可能存在不同的哈夫曼编码方案，但它们的**WPL一定是相同且最小的**。

![[2017-exam-paper-ocr.pdf#page=1&rect=76,283,531,326|2017-exam-paper-ocr, p.1]]
[[Pasted image 20250930043328.png]]

#顶点的度      

- [[握手定理（有无向图）]]  
	**无向图:** 所有顶点的度之和等于边数的两倍。 
	$\sum_{i=1}^{n} d(v_i) = 2|E|$

1. 根据握手定理，图中所有顶点的度数之和为：
	$\sum \text{deg}(v) = 2 \times |E| = 2 \times 16 = 32$
2. 计算已知顶点的度数和 
	 3 个度为 4 的顶点，它们的度数和为：$3 \times 4 = 12$
	*   4 个度为 3 的顶点，它们的度数和为：$4 \times 3 = 12$
	*   这些已知顶点的度数总和为：$12 + 12 = 24$
3. 计算剩余顶点的度数和
	1. 所有顶点的总度数和是 32，而已知顶点的度数和是 24。因此，剩下的“其他顶点”的度数总和必须是：
		$32 - 24 = 8$ 
4. 求解最少的顶点数 
	1. 用一些顶点来凑成 8 这个度数和。题目的约束是，这些“其他顶点”的度数都必须小于 3（即度数只能是 0, 1, 2）  
	2. 使顶点的数量**最少**，我们应该让每个新增加的顶点的度数**最大**。在小于 3 的度数中，最大的是 2 
5.   为了让 $x$ 最小，我们应该给这 $x$ 个顶点尽可能高的度数，即都设为 2。
	*   设这 $x$ 个顶点的度数均为 2，它们的度数和为 $2x$。
	*   所以，我们需要满足 $2x = 8$。
	*   解得 $x = 4$。
		* 我们至少需要 4 个“其他顶点”（这4个顶点的度数都为2）才能满足剩余的度数和为 8
6.  计算总顶点数 
	1. 现在把所有顶点数量加起来：
		*   度为 4 的顶点数：3
		*   度为 3 的顶点数：4
		*   其他顶点（度为2）的最少数：4
		*   总的最小顶点数 = $3 + 4 + 4 = 11$
- 衍生 
	- #奇数度顶点的性质 
		- 在任何无向图中，度数为奇数的顶点个数永远是**偶数**
			-  **考题形式：** “一个图有7个顶点，它们的度数分别是1, 2, 3, 3, 4, 4, x，求x的可能值”，或者“判断一个度数序列是否可能构成一个简单图”
	- #有向图的度数定理  
		对于有向图，每个顶点有**入度 (in-degree)** 和**出度 (out-degree)**。
		*   **定理：** 在任何有向图中，所有顶点的入度之和等于所有顶点的出度之和，且它们都等于图的边数。
		*   **公式：** $\sum_{v \in V} \text{deg}^-(v) = \sum_{v \in V} \text{deg}^+(v) = |E|$
	- [[图]] 

![[2017-exam-paper-ocr.pdf#page=1&rect=73,141,450,280|2017-exam-paper-ocr, p.1]]
![[Pasted image 20250930043334.png]]  

[[二分查找]]  
#折半查找判定树  #二叉树入门题目 
假设要构建的树是基于有序序列 `[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]` 
  1.   第一步：为选项中的树节点赋值
	1. 对每个选项的树结构进行 #中序遍历 ，并依次填上 1 到 10 
	2. 中序遍历得到的节点顺序是 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 
2. 第二步：逐一验证每个选项是否符合单一的构建规则
	1.  验证选项 A 
		1. **根节点**: 6
			*   **初始序列**: `[1, 10]`
			*   要得到根节点 6，中间下标的计算必须是：$mid = \lceil \frac{1+10}{2} \rceil = \lceil 5.5 \rceil = 6$
			* 因此，我们假设选项 A 是基于**向上取整**规则构建的，并验证其所有子树 
			    *   **左子树 (节点 3)**: 根为 6，左子树的序列范围是 `[1, 5]`。
			        *   $mid = \lceil \frac{1+5}{2} \rceil = \lceil 3 \rceil = 3$。与图中节点 3 匹配。**规则一致**。
			    *   **右子树 (节点 9)**: 根为 6，右子树的序列范围是 `[7, 10]`。
			        *   $mid = \lceil \frac{7+10}{2} \rceil = \lceil 8.5 \rceil = 9$。与图中节点 9 匹配。**规则一致**。
			    *   **节点 3 的右子树 (节点 5)**: 序列范围是 `[4, 5]`。
			        *   $mid = \lceil \frac{4+5}{2} \rceil = \lceil 4.5 \rceil = 5$。与图中节点 5 匹配。**规则一致**。
			    *   **节点 9 的左子树 (节点 8)**: 序列范围是 `[7, 8]`。
			        *   $mid = \lceil \frac{7+8}{2} \rceil = \lceil 7.5 \rceil = 8$。与图中节点 8 匹配。**规则一致**。
			
			经过验证，选项 A 的所有节点都符合**向上取整**这一单一规则。因此，**A 是一个有效的折半查找判定树**
	2. 验证选项 B
			**根节点**: 6。同样，这要求使用**向上取整**规则。
		*   我们来查找矛盾点（即不符合向上取整规则的地方）。
		    *   **节点 3 的右子树 (节点 5)**: 序列范围 `[4, 5]`。
		        *   $mid = \lceil \frac{4+5}{2} \rceil = 5$。匹配。
		    *   **节点 9 的左子树 (节点 7)**: 序列范围 `[7, 8]`。
		        *   根据向上取整规则，中间值应为 $mid = \lceil \frac{7+8}{2} \rceil = 8$。
		        *   但图 B 中该节点的值是 7，这实际上是向下取整 $mid = \lfloor \frac{7+8}{2} \rfloor = 7$ 的结果。
		*   在构建过程中，既使用了向上取整（如节点5），又使用了向下取整（如节点7），规则不一致。因此，B 错误。
	3. 验证选项 C
		**根节点**: 5
		*   **初始序列**: `[1, 10]`
		*   要得到根节点 5，中间下标的计算必须是：$mid = \lfloor \frac{1+10}{2} \rfloor = \lfloor 5.5 \rfloor = 5$。
		*   因此，我们假设选项 C 是基于**向下取整**规则构建的，并查找矛盾点。
		    *   **节点 2 的右子树 (节点 4)**: 序列范围 `[3, 4]`。
		        *   根据向下取整规则，中间值应为 $mid = \lfloor \frac{3+4}{2} \rfloor = \lfloor 3.5 \rfloor = 3$。
		        *   但图 C 中该节点的值是 4，这实际上是向上取整 $mid = \lceil \frac{3+4}{2} \rceil = 4$ 的结果。
		*   规则不一致。因此，C 错误。
	4. 验证选项 D 
		  **根节点**: 5。同样，这要求使用**向下取整**规则。
		*   **左子树 (节点 3)**: 根为 5，左子树的序列范围是 `[1, 4]`。
		    *   根据向下取整规则，中间值应为 $mid = \lfloor \frac{1+4}{2} \rfloor = \lfloor 2.5 \rfloor = 2$。
		    *   但图 D 中该节点的值是 3。
		*   在第一层子树构建时就出现了矛盾。因此，D 错误。
		
		**结论**: 只有选项 A 完全符合单一的构建规则（向上取整）。
		
- 衍生 
	- #平均查找长度ASL    [[平均查找长度 (ASL)]]
		-  **计算**: $ASL_{成功} = \frac{\sum_{i=1}^{n} C_i}{n}$，其中 $C_i$ 是查找第 $i$ 个元素的比较次数（即该节点所在的层数）。
	    *   **考点**: 给你一棵折半查找判定树，计算其成功查找的平均查找长度。对于本题的树 A，ASL = (1×1 + 2×2 + 4×3 + 3×4) / 10 = 2.9。
	    *   **延伸**: 查找失败的 ASL 计算。这需要考虑外部节点（查找失败时终止的位置）
	-  #最优二叉查找树   
		-  **考点**: 这是一个动态规划的经典问题。可能会要求理解其概念，或者解决一个小规模的最优二叉查找树构建问题。
	- #平衡二叉树AVL  **考点**:
        *   AVL 树的定义（任何节点的左右子树高度差不超过1）及其旋转调整操作（LL, RR, LR, RL）。
        *   红黑树的 5 条性质及其插入/删除时的颜色调整和旋转。
        *   比较不同类型查找树的性能和适用场景。





![[2017-exam-paper-ocr.pdf#page=1&rect=70,86,456,143|2017-exam-paper-ocr, p.1]]
[[Pasted image 20250930043340.png]]

[[B树和B+树的区别]]  
#B➕树 
B+树 特别适合处理存储在磁盘等外部设备上的 大量数据，特别是需要进行范围查询和精确查找 的场景，  因为每次磁盘的IO成本很高，B+树通过降低树的高度，最大限度的减少了磁盘读取的次数

1. A #编译器中的语法分析   #语法分析  主要是讲源代码字符串转换层一系列的记号，这个过程通常使用 #有限自动机  来实现，他通过 #状态转换 来识别关键字、标识符、运算符等，这个场景与B+树形索引结构关系不大
2. B  关系数据库系统中的索引 #数据库索引  ，数据库的数据量非常庞大， 无法一次性全部加载到磁盘上， #数据库索引的目的 就是为了加速查询 B+树的特性完美契合这个需求
	1. 减少磁盘IO 
	2. 高效的范围查询 
		1. 由于叶子节点是相连的有序链表， 当需要查询一个范围时， 只需定位到起始的叶子节点， 然后沿着链表顺序遍历即可， 无需再从树的根节点开始查找， 效率极高
		2. 因此， B+树是关系型 数据库 （如MySQL 的 innoDB引擎）中最核心和最常用的索引结构
3. C  网络中的 #路由表查询   路由表查找的核心是 #最长前缀匹配  ，虽然可以用树形结构， 但更高效和常用的数据结构是 #字典树Trie树  或其变体， 如 #基数树  
4. D 操作系统的磁盘 #空闲块管理 [[磁盘空闲空间管理]]  
	1.  #空闲链表法   将所有空闲块用链表连接起来
	2. #位图法  用一个二进制位图来表示所有磁盘块， 0代表以占用 ，1 代表空闲
	3. 这些方法实现简单，开销小， 比维护一个复杂的B+树更合适
- 结论： 综合分析， 只有 #关系数据库 中的索引 是 #B➕树的应用场景 
- 衍生 
	- B+树的高度与性能计算 #B➕树的性能
	- [[数据库索引类型]] 
	- [[索引结构的选择B+树vs哈希索引]] 


![[2017-exam-paper-ocr.pdf#page=1&rect=76,31,495,91|2017-exam-paper-ocr, p.1]]
[[Pasted image 20250930043345.png]]

#归并排序   #插入排序  [[排序算法]]
#归并排序与插入排序对比  [[各类内部排序算法的时间复杂与空间复杂度]]    [[内部排序和外部排序]] 


1. 归并排序的程序代码更短
	1.  #插入排序 实现非常简单， 通常由两层循环构成，外层循环遍历待排序的元素，内层循环为当前元素在已排序部分找到合适的位置并插入。代码简单
	2. #归并排序 基于 #分治思想  ，需要一个递归函数来不断地将数组对半分割，还需要以恶搞额外的合并函数，用于将两个已排序的子数组和 
2. 陈述 II：归并排序的占用空间更少 
	1.   **插入排序**：它是一个 **原地排序 (in-place)** 算法。在排序过程中，它只需要一个额外的变量来临时存储待插入的元素，其所需的额外空间是固定的，与待排序数据量 $n$ 无关。因此，其空间复杂度为 $O(1)$。
	2.   **归并排序**：在合并两个有序子数组时，通常需要一个临时的辅助数组来存放合并后的结果，这个辅助数组的大小与待合并的数据量成正比。对于一个长度为 $n$ 的数组，它需要一个大小为 $n$ 的辅助数组。因此，其空间复杂度为 $O(n)$ 
	3.   **结论**：归并排序占用的空间（$O(n)$）比插入排序（$O(1)$）要**多**。所以陈述 II **错误**
3. 陈述 III：归并排序的运行效率更高
	**时间复杂度 (Time Complexity)** 是衡量算法执行时间随数据规模增长而增长的趋势。这通常是选择排序算法时最重要的考量因素。
	*   **插入排序**：
	    *   最坏情况（数组逆序）：时间复杂度为 $O(n^2)$。
	    *   平均情况：时间复杂度为 $O(n^2)$。
	    *   最好情况（数组已有序）：时间复杂度为 $O(n)$。
	*   **归并排序**：
	    *   无论是最好、最坏还是平均情况，归并排序都需要稳定地执行“分解”和“合并”操作。其时间复杂度始终为 $O(n\log n)$。
	* **比较**：当数据规模 $n$ 很大时，$O(n\log n)$ 的增长速度远慢于 $O(n^2)$。因此，对于大规模、无序的数据，归并排序的运行效率远高于插入排序 
	* **结论**：在通常情况下（尤其是在处理大规模数据时），归并排序的运行效率更高。陈述 III **正确** 



- 衍生 
	- [[各类内部排序算法的时间复杂与空间复杂度]]   
	- 何时选择插入排序？ 
		- 但在某些特定场景下，插入排序反而更具优势：
			*   **数据规模小**：当 $n$ 很小时， $O(n^2)$ 算法的常数项和低阶项可能使其比 $O(n\log n)$ 算法更快。因为归并排序的递归和合并操作有额外的开销。
			*   **数据基本有序**：当数据已经接近有序时，插入排序的时间复杂度接近 $O(n)$，效率非常高。
			*   **混合排序算法**：一些高级排序算法（如 Timsort，Python 的内置排序）会结合使用多种排序。例如，当待排序的子数组规模小于某个阈值时，就切换到插入排序，以提高效率。

لإ


لإ


![[2017-exam-paper-ocr.pdf#page=2&rect=74,770,510,822|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930043350.png]]

[[存储器的四种主要存取方式]]    [[存储结构]]
#存储方式对排序算法的影响   #顺序存储   #链式存储     [[顺序存储与链式存储]] 
1.  I. 插入排序 
	1. **访问方式**：在已排序区中，它需要与其前面的元素逐一比较。这种“访问相邻前一个元素”的操作，无论是数组还是链表都可以高效完成。 
	2. **效率变化**：在数组中，找到位置后需要移动元素，这很耗时。在链表中，找到位置后插入节点的操作是$O(1)$，效率更高。但是，查找插入位置的过程无论是数组还是链表，都需要顺序比较，平均时间复杂度都是$O(n)$。因此，对于整个算法而言，总的时间复杂度量级不变，仍然是$O(n^2)$。效率没有降低
2.  II. 选择排序 
	1. **访问方式**：它的主要操作是在未排序区中进行顺序扫描以找到最值。这种顺序扫描对数组和链表都同样适用。 
	2. 效率变化 找到最值后，需要将其与未排序区的第一个元素交换。在数组中，交换是$O(1)$。在链表中，交换两个节点（尤其是非相邻节点）需要修改多个指针，稍微复杂一些，但也可以在$O(1)$时间内完成（如果维护了指向前驱节点的指针）。算法的瓶颈在于$n-1$次扫描，每次扫描的成本是线性的。因此，总的时间复杂度量级不变，仍然是$O(n^2)$。效率没有降低。 
3. 气泡排序 
	1.  **访问方式**：只涉及对**相邻元素**的访问和比较。
		*   **效率变化**：在数组中，访问`A[i]`和`A[i+1]`是$O(1)$。在链表中，访问当前节点和它的后继节点也是$O(1)$。因此，核心操作的效率没有变化。总的时间复杂度量级不变，仍然是$O(n^2)$。效率没有降低。 
4.  IV. 希尔排序 
	1. **访问方式**：希尔排序的关键在于它需要跳跃式地访问元素，例如比较`A[i]`和`A[i+gap]` 
	2.  **效率变化**：在数组中，由于支持随机访问，访问`A[i]`和`A[i+gap]`都是$O(1)$操作。但在链表中，要从第`i`个节点找到第`i+gap`个节点，必须向后遍历`gap`次，这是一个$O(gap)$的操作。这使得内层循环的成本大大增加，导致算法的整体时间效率**显著降低**
5.  V. 堆排序 
	1. **访问方式**：堆通常用数组来实现。因为在完全二叉树中，父节点和子节点的位置存在固定的数学关系。对于一个下标为`i`的节点：
	    *   其父节点下标为 $\lfloor(i-1)/2\rfloor$
	    *   其左子节点下标为 $2i+1$
	    *   其右子节点下标为 $2i+2$
	    这种通过下标计算直接定位到父子节点的方式，完全依赖于数组的**随机访问**特性。
	*   **效率变化**：如果用链表来表示堆，就无法通过下标计算来快速定位父子节点。每次调整堆时，寻找父子节点都需要通过指针遍历，效率远低于数组的$O(1)$访问。因此，堆排序的效率会**显著降低**

- 衍生 
	- [[原地排序]] 
	-  [[数据结构对排序算法的适应性]]  

![[2017-exam-paper-ocr.pdf#page=2&rect=75,708,522,774|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930043355.png]]

[[计算机性能评测的四个指标]]  
#指令集体系结构ISA    #CPU执行时间   [[CPU时间占比（CPU利用率）]] 
1. $CPU_{时间} = 指令数 \times CPI \times 时钟周期时间$ 
	1. $CPU_{时间} = \frac{指令数 \times CPI}{主频}$ 
2. 计算运行时间 
	1. M1 的运行时间 $T_{M1}$:
	    $T_{M1} = \frac{IC \times CPI_1}{f_1} = \frac{IC \times 2}{1.5}$
	2. M2 的运行时间 $T_{M2}$:
	    $T_{M2} = \frac{IC \times CPI_2}{f_2} = \frac{IC \times 1}{1.2}$
3. 要求的是 M1 和 M2 运行时间的比值，即 $T_{M1} / T_{M2}$ 
	1. $\frac{T_{M1}}{T_{M2}} = \frac{\frac{IC \times 2}{1.5}}{\frac{IC \times 1}{1.2}}$ 
4. 计算比值时，相同的指令数 $IC$ 可以被约掉 
	1. $\frac{T_{M1}}{T_{M2}} = \frac{2/1.5}{1/1.2} = \frac{2}{1.5} \times \frac{1.2}{1} = \frac{2.4}{1.5}$
	2. $\frac{24}{15} = \frac{8}{5} = 1.6$ 

- 衍生 
	- #MIPS每秒执行百万条指令数  **考点**: 可能会让你计算M1和M2的MIPS值，并比较它们。例如，
        $MIPS_{M1} = \frac{1.5 \times 10^9}{2 \times 10^6} = 750$
        $MIPS_{M2} = \frac{1.2 \times 10^9}{1 \times 10^6} = 1200$
        这里会发现，虽然M2的运行速度比M1快（运行时间短），但M2的MIPS值也更高，这符合直觉。但MIPS有其局限性（MIPS陷阱），因为它没有考虑指令的功能强弱
	 - [[计算流水线加速比]] 
	 - #Amdahl定律   
		 - 当只对系统的某一部分进行优化时，Amdahl定律可以用来计算整个系统的性能提升上限。 
	    *   **公式**: $S_{overall} = \frac{1}{(1 - F_{enhanced}) + \frac{F_{enhanced}}{S_{enhanced}}}$
	    *   $F_{enhanced}$ 是可被优化的部分所占原执行时间的比例。
	    *   $S_{enhanced}$ 是该部分获得的加速比。
	    *   **考点**: 可能会给出一个程序的运行时间构成，比如“程序P有40%是浮点运算，60%是其他运算。现将浮点运算单元的性能提升3倍，求整个程序的加速比。”
	        解：$F_{enhanced} = 0.4$, $S_{enhanced} = 3$
	        $S_{overall} = \frac{1}{(1 - 0.4) + \frac{0.4}{3}} = \frac{1}{0.6 + 0.133} = \frac{1}{0.733} \approx 1.36$
	        #整体加速比 约为1.36倍



![[2017-exam-paper-ocr.pdf#page=2&rect=76,643,527,707|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930043359.png]]
[[Pasted image 20250930043403.png]]
#交叉编址 
  #计算周期数  [[高位交叉编址vs低位交叉编址]] 

1. 步骤一：确定起始芯片编号 
	1. 知道 `double` 变量 `x` 的第一个字节存储在哪个芯片上。这由它的起始地址 `804001AH` 的最低两位决定 
	2. 将地址的最后一位十六进制数 `A` 转换为二进制。
	    $A_{16} = 1010_2$
	3.  所以，地址 `804001AH` 的二进制表示的最后四位是 `1010`。
	4.  地址的最低两位是 `10`。
	5.  根据我们的映射关系，`10` 对应的是**芯片 2**。
	    所以，`double` 变量 `x` 的第一个字节存储在芯片 2 中
2. 步骤二：分析数据在芯片间的分布 
	1. `double` 变量共 8 个字节。由于是交叉编址，这 8 个字节会依次存储在芯片 2, 3, 0, 1, 2, 3, 0, 1 中 
		*   字节 1: 芯片 2
		*   字节 2: 芯片 3
		*   字节 3: 芯片 0
		*   字节 4: 芯片 1
		*   字节 5: 芯片 2
		*   字节 6: 芯片 3
		*   字节 7: 芯片 0
		*   字节 8: 芯片 1
3. 步骤三：计算所需的 #存储周期 数 
	1. 一个存储周期可以从 4 个芯片中各读取 1 个字节，总共 4 个字节 
	2. 第一个存储周期 
		1.  CPU 发出读请求，起始地址为 `804001AH`（指向芯片 2）。
		    *   #存储控制器 会读取一个与 #总线宽度 对齐的 4 字节 #数据块 。这个数据块包含了地址 `...10`（芯片 2）和 `...11`（芯片 3）的数据。
		    *   在此周期中，我们成功读取了 `x` 的**第 1 个字节（来自芯片 2）**和**第 2 个字节（来自芯片 3）**。
		    *   本周期获得字节数：2
	3. 第二个存储周期 
		1. 存储控制器接着读取下一个 4 字节的数据块。
		    *   这个数据块会同时从芯片 0、芯片 1、芯片 2、芯片 3 中各读取一个字节。
		    *   在此周期中，我们成功读取了 `x` 的**第 3、4、5、6 个字节**。
		    *   本周期获得字节数：4。
		    *   累计获得字节数：2 + 4 = 6
	4. 第三个存储周期 
		1. 此时我们还需要读取 2 个字节（第 7 和第 8 字节）。
		    *   存储控制器再次读取下一个 4 字节的数据块。
		    *   在此周期中，我们成功读取了 `x` 的**第 7 个字节（来自芯片 0）**和**第 8 个字节（来自芯片 1）**。
		    *   至此，8 个字节全部读取完毕
	5. 总共需要 **3** 个存储周期。因此，答案是 **C**
4. #存储周期数通用公式    
	1. 对于这类问题，我们可以推导一个通用公式。
		假设：
		*   要读取的数据块大小为 $N$ 字节。
		*   交叉存储的模块数量为 $m$。
		*   起始地址对应的起始模块（芯片）编号为 $S$（编号从 0 到 $m-1$）。
		
		1.  第一个存储周期可以读取的字节数是 $m-S$。
		2.  剩余需要读取的字节数是 $N - (m-S)$。
		3.  之后每个存储周期可以读取 $m$ 个字节。所以，读取剩余字节需要的周期数是 $\lceil \frac{N - (m-S)}{m} \rceil$。（这里 $\lceil \cdot \rceil$ 表示向上取整）
		4.  总的存储周期数 $T = 1 + \lceil \frac{N - (m-S)}{m} \rceil$
		将本题数据代入公式：
		*   $N=8$ (double 占 8 字节)
		*   $m=4$ (4 个芯片)
		*   $S=2$ (起始芯片编号为 2)
		$T = 1 + \lceil \frac{8 - (4-2)}{4} \rceil = 1 + \lceil \frac{6}{4} \rceil = 1 + \lceil 1.5 \rceil = 1 + 2 = 3$ 


- 衍生 
	-  [[高位交叉编址vs低位交叉编址]] 
		- **考点**: 可能会问在某个地址的连续数据块是否会跨模块，或者这种编址方式的优缺点（优点是便于系统扩充，缺点是无法实现并行存取，不利于提高带宽） 
	- 存储器带宽计算
		- **概念**: 带宽是衡量数据传输速率的指标，单位通常是 MB/s 或 GB/s。
	    *   **公式**: 带宽 = (总线宽度 / 8) / 存储周期。
	    *   **交叉编址下的带宽**: 对于低位交叉存储器，在连续读写时，其理论峰值带宽可以达到单个模块带宽的 $m$ 倍。
		- **考点**: 给出存储周期时间、总线宽度和模块数，计算单个模块的带宽和整个存储系统的最大带宽。例如，若存储周期为 10ns，总线宽度 32 位，则带宽为 $(32/8) / (10 \times 10^{-9}) = 400 \text{ MB/s}$。 
	- #地址映射与译码   #地址映射核心思想 [[地址映射]]
		- 概念： 如何将一个完整的逻辑地址或物理地址分解成不同的部分，用于选择芯片、片内行地址和列地址。
		-   **考点**: 给定一个存储系统的总容量、芯片规格和组织方式，要求画出地址的分配图。例如，一个 1GB 的主存由 8 片 $128M \times 8$ 位的芯片构成，地址线共有 30 根 ($2^{30} = 1G$)，如何将这 30 根地址线分配给片选信号和片内地址 


![[2017-exam-paper-ocr.pdf#page=2&rect=80,509,533,646|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930043409.png]]
#访问局部性   #时间局部性    #局部性原理 
1.   操作系统利用了 #局部性原理  （Principle of Locality）[[缓存的工作原理 ，局部性原理]]
	    *   **时间局部性**：如果一个数据项被访问，那么在不久的将来它很可能再次被访问。
	    *   **空间局部性**：如果一个数据项被访问，那么与它地址相邻的数据项也很可能很快被访问。
2. 分析题目中的代码
	1.  **空间局部性分析**:
	    观察内层循环 `for(j=0; j<=i; j++)`。在这个循环中，数组 `a` 的元素被依次访问：`a[0]`, `a[1]`, `a[2]`, ..., `a[i]`。在C语言中，数组的元素在内存中是连续存放的。因此，当程序访问 `a[j]` 后，紧接着就会访问 `a[j+1]`，这两个元素在内存中的地址是相邻的。这完全符合空间局部性的定义。
	    **结论：对数组 `a` 的访问具有良好的空间局部性。**
	2. **时间局部性分析**:
	    观察外层循环 `for(i=0; i<=9; i++)`。我们追踪一下特定元素的访问情况：
	    *   当 `i = 0` 时，访问 `a[0]`。
	    *   当 `i = 1` 时，访问 `a[0]`, `a[1]`。
	    *   当 `i = 2` 时，访问 `a[0]`, `a[1]`, `a[2]`。
	    *   ...
	    *   当 `i = 9` 时，访问 `a[0]`, `a[1]`, ..., `a[9]`。
	我们可以看到，元素 `a[0]` 在外层循环的每一次迭代中都被访问了。元素 `a[1]` 在 `i` 从1到9的迭代中也都被访问了。对于任意元素 `a[k]`，它会在 `i` 从 `k` 到 9 的所有迭代中被重复访问。这些重复访问之间只隔了内层循环的执行时间，在整个程序的执行过程中，这个时间间隔很短。这完全符合时间局部性的定义。
    **结论：对数组 `a` 的访问具有良好的时间局部性。**
A 
- 衍生 
	- #二维数组的遍历顺序 
		- 非常经典的考点，用于考察对 #空间局部性 的理解。
			在C/C++/Java等语言中，二维数组是按**行主序 (Row-Major Order)** 存储的。这意味着，同一行的元素在内存中是连续的。
	- **示例代码1：按行遍历 (空间局部性好)**
```c
int matrix[100][100];
for (int i = 0; i < 100; i++) {
    for (int j = 0; j < 100; j++) {
        sum += matrix[i][j]; // 访问顺序: matrix[0][0], matrix[0][1], ...
    }
}
```
这种访问方式与内存存储顺序一致，空间局部性极好，缓存命中率高。
- 示例代码2： #按列遍历 (空间局部性差)
```c
int matrix[100][100];
for (int j = 0; j < 100; j++) {
    for (int i = 0; i < 100; i++) {
        sum += matrix[i][j]; // 访问顺序: matrix[0][0], matrix[1][0], ...
    }
}
```
这种访问方式会导致内存地址的“跳跃”。访问 `matrix[i][j]` 之后，下一个访问的是 `matrix[i+1][j]`，它们在内存中相隔了一整行的距离。这破坏了空间局部性，会导致大量的缓存缺失，性能远低于按行遍历。

-   [[数组和链表的区别]]  


![[2017-exam-paper-ocr.pdf#page=2&rect=77,476,478,517|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044146.png]]
- 
		#寻址模式方式  [[寻址方法的比较]]  
	#访问方法#下标顺序访问 
	
1. 这道题的核心是理解不同寻址方式的原理和应用场景，特别是它们如何计算 #操作数的有效地址  #计算有效地址  [[计算有效地址]]
	1. 访问一维数组 `Array` 的第 `i` 个元素 `Array[i]` 时，其内存地址可以表示为：
		`地址(Array[i]) = 数组的基地址 + i * 每个元素的大小` 
		1. 需要找到一种寻址方式，其计算有效地址的模式与这个公式最匹配
2. 分析 变址寻址 
	1.  $EA = A + (IX)$ 
		*   `A` 是指令中给出的地址部分。
		*   `(IX)` 是变址寄存器中的内容。
	2.  **如何匹配数组访问：**
		*   我们可以将数组的**基地址**（首地址）存放在指令的地址字段 `A` 中。
		*   将数组的**下标** `i` 存放在变址寄存器 `IX` 中。
		*   当需要按顺序访问数组时（例如在 `for` 循环中），我们只需要不断地增加变址寄存器 `IX` 的值（`i++`），而指令本身可以保持不变。CPU 每次都会自动计算出 $A + (IX)$，从而定位到下一个数组元素。
	*   **结论：** 变址寻址的机制完美契合了“基地址+偏移量”的数组访问模式，因此是最适合的
3. A. 相对寻址
	2. **公式：** $EA = (PC) + A$
        *   `(PC)` 是程序计数器 (Program Counter) 的内容，即当前指令的地址。
        *   这种方式的基准是当前指令的位置，主要用于实现程序的跳转和分支，使得代码可以被加载到内存的任何位置（位置无关代码），而不适用于访问数据结构
4. B. 寄存器寻址 
	*   **操作数直接在寄存器中**，而不是在内存里。指令中直接指定了存放操作数的寄存器编号。
	*   这种方式速度最快，因为它不访问内存。但它根本不涉及内存地址的计算，所以无法用来访问存储在内存中的数组。
5. C. 直接寻址  
	*   **公式：** $EA = A$
	*   指令的地址字段 `A` 直接给出了操作数在内存中的有效地址。
	*   这种方式只能访问一个固定的内存单元。如果要访问数组 `Array[0]`, `Array[1]`, `Array[2]`...，你需要为每个元素编写一条地址不同的指令，这非常低效和不灵活。


- 衍生 
	- [[变址寻址与基址选址的对比]]  
		- **考题形式：** 可能会问“为了让程序能在内存中任意位置运行，应采用哪种寻址方式？”（答案：基址寻址或相对寻址） 
	- [[寻址方式的执行效率比较]] 
		- **考题形式：** “下列寻址方式中，执行速度最快的是？”（答案：寄存器寻址）


![[2017-exam-paper-ocr.pdf#page=2&rect=77,426,527,477|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044151.png]]
- 这道题的核心是考察在 #固定指令字长  的前提下，如何利用 #扩展操作码技术  来设计包含多种不同地址格式指令的指令系统，并结合 #字节编址 的物理约束来确定最终的指令长度
#指令字长 
#指令格式  
1. 分析指令结构   #地址指令 
	*   **三地址指令**：`[操作码 OP | 地址1 A1 | 地址2 A2 | 地址3 A3]`
    *   **二地址指令**：`[操作码 OP | 地址1 A1 | 地址2 A2]` 
	1. 由于指令字长是固定的，这个长度必须能容纳下最长的指令格式，也就是三地址指令。
2.  确定 #操作码(Opcode)的最小长度 [[指令格式]]
	1. 定义多少条不同的指令,若操作码有 $n$ 位，则最多可以表示 $2^n$ 种不同的状态，即最多定义 $2^n$ 条指令。
	2. 题目中有 29 条三地址指令和 107 条二地址指令。我们首先需要确定一个基础的操作码长度 $k$，这个长度必须能区分开三地址指令，并为二地址指令留出扩展空
	3. 为了能表示 29 条三地址指令，操作码长度 $k$ 必须满足：
	4. $2^k \ge 29$ 
		1. 操作码字段的**最小长度**为 **5 位**
3. 计算满足逻辑需求的 #最小指令字长
	1. 我们以最长的三地址指令格式和刚算出的最小操作码长度来计算指令字长： 
		*   操作码 (OP) 长度 = 5 位
	    *   每个地址字段 (A1, A2, A3) 长度 = 6 位 (题目已知)
	2. 最小指令字长 = (操作码长度) + (地址1长度) + (地址2长度) + (地址3长度)
	    最小指令字长 = $5 + 6 + 6 + 6 = 23$ 位
4. 验证该设计是否能容纳所有指令（ #扩展操作码检验 ）
	1. 验证这个 23 位的指令长度设计是否也足够容纳 107 条二地址指令。这里就要用到扩展操作码技术 
	2. 当操作码为 5 位时，总共有 $2^5=32$ 种可能的编码。
	    *   其中 29 种编码被用于三地址指令。
	    *   剩余的编码数量为 $32 - 29 = 3$ 种。这 3 种编码可以作为“扩展标志”或“转义码”，用来表示“这不是一条三地址指令，而是一条二地址指令”
	3. 对于二地址指令，其格式为 `[OP | A1 | A2]`。在固定的 23 位长度下，它会多出一个原本属于 A3 的 6 位空间。这个空间可以用来 #扩展操作码 。
	   因此， #二地址指令的可用编码数量  = (剩余的转义码数量) × (扩展字段能表示的状态数)
	    *   可支持的 #二地址指令  数量 = $3 \times 2^6 = 3 \times 64 = 192$ 条
	题目要求支持 107 条二地址指令，而我们的设计可以支持 192 条。因为 $192 > 107$，所以这个设计在逻辑上是成立的。最小的逻辑指令长度确实是 23 位
5. 结合物理约束（字节编址） 
	1. 题目中有一个关键条件：“某计算机按字节编址”。
	    *   **字节编址 (Byte-addressable)** 意味着内存的最小可寻址单位是一个字节（Byte）。
	    *   1 字节 = 8 位 (bit)。
	    *   为了方便CPU取指和内存管理，指令字长通常设计为字节的整数倍
	2. 我们的计算得出的最小逻辑长度是 23 位，但它不是 8 的倍数。因此，我们需要找到大于或等于 23 的最小的 8 的倍数 
		1. 24 是大于等于 23 的最小的 8 的倍数。所以，指令字长至少应该是 **24 位** 


- 衍生 
	- [[指令格式]]  
		- 一条指令通常由**操作码(Opcode)**和**地址码(Operand/Address)**组成。操作码指出要执行什么操作（如加、减、存取），地址码指出操作数或操作数的地址。
	-  #N地址指令 
		- 根据指令中包含的地址码数量，分为三地址、二地址、一地址和零地址指令。
	- #指令字长 
		- 一条指令的总位数。可以是固定的（如本题），也可以是可变的（如 Intel x86 架构）。固定字长便于硬件译码和流水线处理，但可能浪费空间；可变字长节省空间，但译码复杂。
	- [[扩展操作码技术]] 
		- **示例**：如本题，5位的操作码有32种组合。用`00000`到`11100`（共29个）代表三地址指令。用`11101`, `11110`, `11111`（共3个）作为前缀，表示这是一条二地址指令，此时，原本A3字段的6位将被视为扩展操作码，从而可以定义 $3 \times 2^6$ 条二地址指令
	- 反向计算 
		- 告诉你指令字长、地址字段长度和指令种类，让你计算在采用扩展操作码技术后，最多能支持多少条某种格式的指令。
	    *   例 ：指令长32位，地址字段8位。若已有15条三地址指令和240条二地址指令，最多还能支持多少条一地址指令？
	* 可变长指令设计  #指令字长与哈夫曼编码 
		* 题目条件变为“指令字长可变”，通常会结合 #哈夫曼编码 （Huffman Coding）的思想，让使用频率高的指令长度更短，以优化程序总长度。 
	* #寻址方式   
		* 本题默认地址字段是直接寻址内存。考题可能引入多种寻址方式（如寄存器寻址、立即数寻址、间接寻址），这会影响地址字段的解释和长度设计。
	    *   *例*：若地址字段的某一位用于区分是寄存器寻址还是内存寻址，那么实际可用的地址位数就会减少
	* 与存储容量的关系 
		* 地址字段的位数直接决定了可寻址的内存空间大小。
		    *   例 ： 本题地址字段为6位，若按字寻址，则可寻址 $2^6=64$ 个字。若按字节寻址，则可寻址 $2^6=64$ 个字节。题目可能会问该指令系统支持的最大内存容量是多少。



![[2017-exam-paper-ocr.pdf#page=2&rect=75,354,471,427|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044156.png]]


[[流水线技术]]     [[超标量技术]]
#流水线特性 #超标量
1. 能缩短流水线功能段的处理时间 
	1. 流水线技术是将一条指令的执行过程划分为多个阶段（功能段），例如：取指(IF)、译码(ID)、执行(EX)、访存(MEM)、写回(WB)。每个阶段的处理时间取决于该阶段硬件电路的延迟 
	2. #超标量技术的核心思想 是“空间换时间” 
		1. 即通过增加硬件资源（如增加多条流水线、多个执行单元）来并行处理多条指令，而不是去改变单个功能段（如ALU的加法运算）本身的处理速度
		2. 缩短流水线功能段的处理时间通常是通过改进电路设计、使用更快的半导体工艺等方式实现的，这与是否采用超标量架构没有直接关系 
2.  II: "能在一个时钟周期内同时发射多条指令"
	1. 这是**超标量最核心、最本质的特征**。传统的标量流水线（Scalar Pipeline）在一个时钟周期最多只能发射（Issue）一条指令
	2.  为了实现并行执行，超标量处理器配备了多套指令译码、分派逻辑和多个功能单元（如多个整数运算单元、浮点运算单元等）。这使得它能够在同一个时钟周期内，从指令队列中取出多条没有依赖关系的指令，并将它们“发射”到不同的执行流水线中去
		1. 例如，一个4-way超标量处理器理论上可以在一个时钟周期内同时发射4条指令。
		*   因此，叙述 II 是**正确**的
3.  III: "能结合 #动态调度技术 提高指令执行并行性"  
	1. #动态调度与乱序执行   
		1. 如Tomasulo算法或Scoreboarding，允许处理器在运行时检查指令间的数据依赖关系，对指令进行乱序执行（Out-of-Order Execution, OoOE）。处理器可以越过正在等待数据的指令，先执行后面准备就绪的无关指令，从而最大限度地填充并行的执行单元，挖掘指令级并行性
		2.  现代的超标量处理器几乎都与复杂的动态调度、乱序执行和分支预测技术紧密结合，以实现高性能

- 衍生 
	- 

![[2017-exam-paper-ocr.pdf#page=2&rect=78,275,463,357|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044202.png]]


#总线与主存技术   #控制存储器   





![[2017-exam-paper-ocr.pdf#page=2&rect=76,226,510,281|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044207.png]]


[[指令流水线与冲突]]  



![[2017-exam-paper-ocr.pdf#page=2&rect=75,177,477,228|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044221.png]]


[[系统总线结构（数据线，地址线，控制总线）]]  


#多总线结构




![[2017-exam-paper-ocr.pdf#page=2&rect=76,128,456,181|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044227.png]]


#数据传送  [[IO接口和IO端口]]  [[IO 结构与控制]]  




![[2017-exam-paper-ocr.pdf#page=2&rect=75,47,344,133|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044233.png]]
[[Pasted image 20250930044239.png]]

#多重中断系统  #中断系统设计的基本原则   

![[Pasted image 20251015111201.png]]
![[2017-exam-paper-ocr.pdf#page=3&rect=68,682,525,822|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044245.png]]

[[磁盘调度算法]]





![[2017-exam-paper-ocr.pdf#page=3&rect=74,608,505,683|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044251.png]]


[[系统调用的过程]]
C
 



![[2017-exam-paper-ocr.pdf#page=3&rect=72,500,527,608|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044257.png]]

#最佳适应算法 
[[动态分区存储管理（动态分区分配算法）]]  
	  **策略**: 遍历整个空闲分区链表，找到**所有**能满足大小要求的分区中，**尺寸最小**的那一个。 
	  #起始地址 





![[2017-exam-paper-ocr.pdf#page=3&rect=77,450,533,505|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044302.png]]


#簇  [[文件分配表FAT]]




![[2017-exam-paper-ocr.pdf#page=3&rect=74,377,415,457|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044309.png]]

#时间片轮转算法  [[常见进程调度算法与优先级关系]]

[





![[2017-exam-paper-ocr.pdf#page=3&rect=73,323,513,381|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044315.png]]


#多道批处理系统  D
 





![[2017-exam-paper-ocr.pdf#page=3&rect=75,238,498,329|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044321.png]]
[[逻辑地址到物理地址的转换]]

#逻辑格式化




![[2017-exam-paper-ocr.pdf#page=3&rect=74,151,528,242|2017-exam-paper-ocr, p.3]][[Pasted image 20250930044405.png]]


[[文件控制块FCB]] 
[[计算所有位数]]  
#描述文件权限的位数 








![[2017-exam-paper-ocr.pdf#page=3&rect=73,67,530,148|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044410.png]]

[[文件描述符、打开文件表和FCB(inode)的关系]] 















![[2017-exam-paper-ocr.pdf#page=4&rect=80,741,499,818|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044415.png]]

#数据读取 
#DMA工作流程  
#数据传输过程   
[[总线与主存技术]]










![[2017-exam-paper-ocr.pdf#page=4&rect=79,692,526,743|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044421.png]]

[[OSI七层模型]]
[[数据封装过程]]
[[TCP-IP 协议栈封装与解封装]]  

#数据传输效率  
#应用层 



![[2017-exam-paper-ocr.pdf#page=4&rect=76,643,516,691|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044425.png]]


[[香农定理]] 
#信噪比SNR   [[信噪比]]




![[2017-exam-paper-ocr.pdf#page=4&rect=76,459,528,642|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044432.png]]
[[IP分组的生命周期]]  [[IP头部略讲]] 
[[以太网帧结构]]  






![[2017-exam-paper-ocr.pdf#page=4&rect=73,421,500,458|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044440.png]]


#判断IP地址的合法性   
#目的IP地址  
#判读源IP地址和目标IP地址  [[IP




![[2017-exam-paper-ocr.pdf#page=4&rect=79,387,506,424|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044451.png]]
[[数据封装过程]]





![[2017-exam-paper-ocr.pdf#page=4&rect=78,339,521,389|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044457.png]]

[[IP子网划分]]  
[[IP地址与子网掩码]]  





![[2017-exam-paper-ocr.pdf#page=4&rect=75,291,526,340|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044502.png]]


#发送窗口   
[[TCP的两个窗口机制]]  




![[2017-exam-paper-ocr.pdf#page=4&rect=73,216,344,301|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044507.png]]
#FTP文件传输协议   

![[2017-exam-paper-ocr.pdf#page=5&rect=70,523,539,830|2017-exam-paper-ocr, p.5]][[Pasted image 20250930044523.png]]
[[表达式转换（前中后缀）]]  
#表达式树   




![[2017-exam-paper-ocr.pdf#page=6&rect=75,617,528,823|2017-exam-paper-ocr, p.6]]
[[Pasted image 20250930044624.png]]
[[Pasted image 20250930044632.png]]

#Prim算法   


![[2017-exam-paper-ocr.pdf#page=7&rect=77,563,539,823|2017-exam-paper-ocr, p.7]]
[[Pasted image 20250930044646.png]]
[[Pasted image 20250930044653.png]]
[[Pasted image 20250930044700.png]]
[[Pasted image 20250930044710.png]]

[[数据类型转换]]  

[[IEEE 754 标准]]  
















![[2017-exam-paper-ocr.pdf#page=7&rect=63,270,551,573|2017-exam-paper-ocr, p.7]]
[[Pasted image 20250930044722.png]]

[[RISC 和CISC的区别]]  
[[指令格式]] 
#机器指令  










![[2017-exam-paper-ocr.pdf#page=7&rect=65,136,536,273|2017-exam-paper-ocr, p.7]]
[[Pasted image 20250930044741.png]]
[








![[2017-exam-paper-ocr.pdf#page=8&rect=70,565,532,824|2017-exam-paper-ocr, p.8]]
[[Pasted image 20250930044751.png]]


[[临界区问题]]  





![[2017-exam-paper-ocr.pdf#page=8&rect=75,127,536,568|2017-exam-paper-ocr, p.8]]
[[Pasted image 20250930044759.png]]
[[Pasted image 20250930044804.png]]

[[后退N帧协议GBN]]    [[数据帧]]  #数据帧   
1.  [[数据帧











