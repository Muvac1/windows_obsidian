![[2017-exam-paper-ocr.pdf#page=1&rect=70,596,549,705|2017-exam-paper-ocr, p.1]]
[[Pasted image 20250930043154.png]]

[[时间复杂度分析]] 
[[时间复杂度等价]]
**1. 分析代码**

```c
int func(int n) {
    int i=0, sum=0;
    while(sum < n) {
        sum += ++i;
    }
    return i;
}
```

*   **初始化**：`i` 和 `sum` 都从0开始。
*   **循环条件**：循环持续的条件是 `sum < n`。当 `sum >= n` 时，循环终止。
*   **循环体**：`sum += ++i;`。这是一个关键操作。`++i` 是前置自增，意味着先将 `i` 的值加1，然后用新的 `i` 值参与运算。
    *   它等价于：
        ```c
        i = i + 1;
        sum = sum + i;
        ```
2. 
	*   **第1次循环**：`i` 变为1，`sum` = 0 + 1 = 1。
	*   **第2次循环**：`i` 变为2，`sum` = 1 + 2 = 3。
	*   **第3次循环**：`i` 变为3，`sum` = 3 + 3 = 6。
	*   ...
	*   **第k次循环**：`i` 变为 `k`，`sum` 的值是 $1 + 2 + 3 + \dots + k$。
3. $sum = \frac{k(k+1)}{2}$ 
	1. $\frac{k(k+1)}{2} \approx n$ 
	2. $k(k+1) \approx 2n$
		$k^2 + k \approx 2n$
	3. $k^2 \approx 2n$ 
	4. $k \approx \sqrt{2n} = \sqrt{2} \cdot \sqrt{n}$ 
4. 所以，循环的执行次数 `k` 与 $\sqrt{n}$ (即 $n^{1/2}$) 成正比  
5.  B. $O(n^{1/2})$ 

- 衍生    [[时间复杂度分析]]
	- [[++i vs. i++ 的时间复杂度影响]] 
		- 如果原题中的 `sum += ++i;` 改为 `sum += i++;`，时间复杂度会变吗？
			- **结论**：在渐近分析中，$k^2-k$ 和 $k^2+k$ 的主导项都是 $k^2$。因此，求解后得到的复杂度依然是 $O(\sqrt{n})$。在时间复杂度的大O分析层面，这两者没有区别，但这可能作为一个细节题来考察对自增运算符的理解。

![[2017-exam-paper-ocr.pdf#page=1&rect=76,509,503,599|2017-exam-paper-ocr, p.1]]
[[Pasted image 20250930043159.png]]


[[栈]] 
#函数调用栈    
- 1 错误 
- I. 采用非递归的方式重写递归程序时必须用栈
	- 这个说法的关键在于“必须” (must) 这个词，过于绝对。虽然栈是实现递归转非递归的一种通用且强大的方法，因为它能完美模拟函数调用栈的行为（保存局部变量、返回地址等），但并非所有情况都必须用栈。
*   **反例：**
    1.  #尾递归  尾递归是一种特殊的递归形式，递归调用是函数的最后一步操作。这种递归可以被编译器优化，直接转换成一个简单的循环，完全不需要栈。
    2.  #简单递归 ： 像题目解析中提到的计算斐波那契数列或阶乘，虽然有递归定义，但它们的迭代版本（非递归）只需要几个变量和一个循环就可以实现，并不需要显式地使用一个栈结构。
- 2 正确    
	- II. 函数调用时，系统要用栈保存必要的信息[[堆栈帧]]
	3.  每当一个函数被调用时，系统会创建一个称为“栈帧” 或“活动记录”的数据块，并将其压入一个特定的内存区域，这个区域就是 #调用栈
		1. #栈帧 中保存了函数的参数、局部变量、返回地址 #堆栈帧
		2. [[递归与栈的关系]] 
- 衍生 
	- [[栈的应用]] 




![[2017-exam-paper-ocr.pdf#page=1&rect=75,462,436,509|2017-exam-paper-ocr, p.1]]
[[Pasted image 20250930043205.png]]

 #稀疏矩阵  [[邻接矩阵，邻接表 ，稀疏图，稠密图]]  
#压缩存储   #不同的压缩存储方式   [[压缩存储]]
三元组表和十字链表是两种专门为压缩存储稀疏矩阵而设计的数据结构。邻接矩阵不属于压缩存储，而二叉链表则用于完全不同的数据类型。因此，正确答案是 **A**  
#三元组表  #十字链表  
- 衍生
	- [[稀疏矩阵的转置运算]]  #转置运算   
		- 原矩阵每一列的非零元个数，然后计算每一列第一个非零元在转置后三元组表中的起始位置。时间复杂度可以优化到 $O(n+t)$。这是面试和考试中的高频考点
	- [[稀疏矩阵的加法和乘法运算]] 
	- [[树和森林的存储结构]] 
	



![[2017-exam-paper-ocr.pdf#page=1&rect=75,424,517,460|2017-exam-paper-ocr, p.1]]
[[Pasted image 20250930043209.png]]

#结点的度  #非叶结点   #先序序列   [[遍历序列的基本性质]]  [[序列相同的条件]] 
1. 推理过程 
	1. 用 `R` 代表根结点，`L` 代表左子树的遍历序列，`R_sub` 代表右子树的遍历序列。
		*   那么，这棵树的先序序列可以表示为：`R, L, R_sub`
		*   这棵树的中序序列可以表示为：`L, R, R_sub`
		
		*   要使这两个序列相同，即 `R, L, R_sub` = `L, R, R_sub`，我们来比较它们的第一个元素。
		*   在先序序列中，第一个元素永远是根结点 `R`。
		*   在中序序列中，第一个元素是左子树遍历序列 `L` 的第一个元素。
		*   为了让两个序列的第一个元素相同，中序序列的第一个元素也必须是根结点 `R`。这种情况只有在左子树的遍历序列 `L` 为**空**时才会发生。
		
		*   如果左子树为空，那么：
		    *   先序序列变为：`R, R_sub`
		    *   中序序列变为：`R, R_sub`
		    *   此时，两个序列就相同了。
		
		*   这个逻辑是**递归**的。也就是说，对于树中的**任意一个结点**（把它看作一个子树的根），要使其子树的先序和中序遍历相同，这个结点都**不能有左孩子**。
	2. 题目要求是“所有非叶结点须满足的条件”。非叶结点就是有孩子的结点。根据我们的推导，这些结点都不能有左孩子，所以它们只能有右孩子 
		1. 正确答案是 **B. 只有右子树**

	*   **A. 只有左子树：** 如果一个结点 `R` 只有左子树 `L`，那么先序是 `R, L`，中序是 `L, R`。这两个序列显然是相反的，不可能相同（除非树只有一个结点）。
	*   **C. 结点的度均为1：** 这个条件太宽泛。一个结点的度为1，意味着它要么只有左孩子，要么只有右孩子。如果存在一个结点只有左孩子，那么条件就不满足了。所以C是错误的。
	*   **D. 结点的度均为2：** 如果结点的度为2，意味着它既有左孩子又有右孩子，这直接违反了我们推导出的“左子树必须为空”的结论。

- 衍生 
	- [[序列相同的条件]] 
	-  [[根据遍历序列重建二叉树]] 
	- [[二叉树的性质]] 
		- 对于任意一棵非空二叉树，如果叶结点的数量为$n_0$，度为2的结点数量为$n_2$，那么它们之间存在一个恒定的关系：
				$n_0 = n_2 + 1$
	- [[层次遍历]]    
		- 除了深度优先的三种遍历，还有一种广度优先的遍历方式，即层次遍历 ， 通常使用**队列**数据结构来实现

![[Pasted image 20250930043248.png]]
[[Pasted image 20250930043226.png]]
 - 
#后序序列  #二叉树的后序遍历  
1. 后序遍历的规则是：**先遍历左子树，再遍历右子树，最后访问根结点** 
	1. 后序遍历序列的一个显著特点是，序列的最后一个元素一定是整棵树（或子树）的根结点
	2. B 
- 衍生 
	- [[线索二叉树]] 
		- 为了利用二叉树中大量的空指针域，将它们改造为指向结点前驱或后继的线索，从而方便遍历 




![[Pasted image 20251015110858.png]]
[[Pasted image 20250930043324.png]]

[[哈夫曼编码]]  
#字符集
1.  **性质**：哈夫曼编码是 #前缀编码 ，即任何一个字符的编码都不是另一个字符编码的前缀，这保证了编码在解码时不会产生歧义。
2.     `0100` -> 匹配成功！这是字符 **a** 的编码。
    *   剩余序列: `011001001011110101`
    *   `011` -> 匹配成功！这是字符 **g** 的编码。
    *   剩余序列: `001001011110101`
    *   `001` -> 匹配成功！这是字符 **e** 的编码。
    *   剩余序列: `001011110101`
    *   `001` -> 再次匹配成功！这是字符 **e** 的编码。
    *   剩余序列: `011110101`
	将解码出的字符拼接起来，得到的结果是 **`ageeghd`** 

- 衍生 
	- #计算WPL 
		- 在构建完哈夫曼树后，要求计算其带权路径长度。这既考察了建树过程，也考察了对最优性概念的理解 
	- #哈夫曼树的性质  [[哈夫曼树]]  
		- #编码的非唯一性 在构建树时，如果出现两个或以上权重相同的最小节点，选择哪两个进行合并是任意的，这可能导致构造出不同形态的哈夫曼树。 在为分支分配0和1时，左0右1或左1右0都是可以的。
		    *   因此，对于同一组权重，可能存在不同的哈夫曼编码方案，但它们的**WPL一定是相同且最小的**。

![[2017-exam-paper-ocr.pdf#page=1&rect=76,283,531,326|2017-exam-paper-ocr, p.1]]
[[Pasted image 20250930043328.png]]

#顶点的度      

- [[握手定理（有无向图）]]  
	**无向图:** 所有顶点的度之和等于边数的两倍。 
	$\sum_{i=1}^{n} d(v_i) = 2|E|$

1. 根据握手定理，图中所有顶点的度数之和为：
	$\sum \text{deg}(v) = 2 \times |E| = 2 \times 16 = 32$
2. 计算已知顶点的度数和 
	 3 个度为 4 的顶点，它们的度数和为：$3 \times 4 = 12$
	*   4 个度为 3 的顶点，它们的度数和为：$4 \times 3 = 12$
	*   这些已知顶点的度数总和为：$12 + 12 = 24$
3. 计算剩余顶点的度数和
	1. 所有顶点的总度数和是 32，而已知顶点的度数和是 24。因此，剩下的“其他顶点”的度数总和必须是：
		$32 - 24 = 8$ 
4. 求解最少的顶点数 
	1. 用一些顶点来凑成 8 这个度数和。题目的约束是，这些“其他顶点”的度数都必须小于 3（即度数只能是 0, 1, 2）  
	2. 使顶点的数量**最少**，我们应该让每个新增加的顶点的度数**最大**。在小于 3 的度数中，最大的是 2 
5.   为了让 $x$ 最小，我们应该给这 $x$ 个顶点尽可能高的度数，即都设为 2。
	*   设这 $x$ 个顶点的度数均为 2，它们的度数和为 $2x$。
	*   所以，我们需要满足 $2x = 8$。
	*   解得 $x = 4$。
		* 我们至少需要 4 个“其他顶点”（这4个顶点的度数都为2）才能满足剩余的度数和为 8
6.  计算总顶点数 
	1. 现在把所有顶点数量加起来：
		*   度为 4 的顶点数：3
		*   度为 3 的顶点数：4
		*   其他顶点（度为2）的最少数：4
		*   总的最小顶点数 = $3 + 4 + 4 = 11$
- 衍生 
	- #奇数度顶点的性质 
		- 在任何无向图中，度数为奇数的顶点个数永远是**偶数**
			-  **考题形式：** “一个图有7个顶点，它们的度数分别是1, 2, 3, 3, 4, 4, x，求x的可能值”，或者“判断一个度数序列是否可能构成一个简单图”
	- #有向图的度数定理  
		对于有向图，每个顶点有**入度 (in-degree)** 和**出度 (out-degree)**。
		*   **定理：** 在任何有向图中，所有顶点的入度之和等于所有顶点的出度之和，且它们都等于图的边数。
		*   **公式：** $\sum_{v \in V} \text{deg}^-(v) = \sum_{v \in V} \text{deg}^+(v) = |E|$
	- [[图]] 

![[2017-exam-paper-ocr.pdf#page=1&rect=73,141,450,280|2017-exam-paper-ocr, p.1]]
![[Pasted image 20250930043334.png]]  

[[二分查找]]  
#折半查找判定树  #二叉树入门题目 
假设要构建的树是基于有序序列 `[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]` 
  1.   第一步：为选项中的树节点赋值
	1. 对每个选项的树结构进行 #中序遍历 ，并依次填上 1 到 10 
	2. 中序遍历得到的节点顺序是 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 
2. 第二步：逐一验证每个选项是否符合单一的构建规则
	1.  验证选项 A 
		1. **根节点**: 6
			*   **初始序列**: `[1, 10]`
			*   要得到根节点 6，中间下标的计算必须是：$mid = \lceil \frac{1+10}{2} \rceil = \lceil 5.5 \rceil = 6$
			* 因此，我们假设选项 A 是基于**向上取整**规则构建的，并验证其所有子树 
			    *   **左子树 (节点 3)**: 根为 6，左子树的序列范围是 `[1, 5]`。
			        *   $mid = \lceil \frac{1+5}{2} \rceil = \lceil 3 \rceil = 3$。与图中节点 3 匹配。**规则一致**。
			    *   **右子树 (节点 9)**: 根为 6，右子树的序列范围是 `[7, 10]`。
			        *   $mid = \lceil \frac{7+10}{2} \rceil = \lceil 8.5 \rceil = 9$。与图中节点 9 匹配。**规则一致**。
			    *   **节点 3 的右子树 (节点 5)**: 序列范围是 `[4, 5]`。
			        *   $mid = \lceil \frac{4+5}{2} \rceil = \lceil 4.5 \rceil = 5$。与图中节点 5 匹配。**规则一致**。
			    *   **节点 9 的左子树 (节点 8)**: 序列范围是 `[7, 8]`。
			        *   $mid = \lceil \frac{7+8}{2} \rceil = \lceil 7.5 \rceil = 8$。与图中节点 8 匹配。**规则一致**。
			
			经过验证，选项 A 的所有节点都符合**向上取整**这一单一规则。因此，**A 是一个有效的折半查找判定树**
	2. 验证选项 B
			**根节点**: 6。同样，这要求使用**向上取整**规则。
		*   我们来查找矛盾点（即不符合向上取整规则的地方）。
		    *   **节点 3 的右子树 (节点 5)**: 序列范围 `[4, 5]`。
		        *   $mid = \lceil \frac{4+5}{2} \rceil = 5$。匹配。
		    *   **节点 9 的左子树 (节点 7)**: 序列范围 `[7, 8]`。
		        *   根据向上取整规则，中间值应为 $mid = \lceil \frac{7+8}{2} \rceil = 8$。
		        *   但图 B 中该节点的值是 7，这实际上是向下取整 $mid = \lfloor \frac{7+8}{2} \rfloor = 7$ 的结果。
		*   在构建过程中，既使用了向上取整（如节点5），又使用了向下取整（如节点7），规则不一致。因此，B 错误。
	3. 验证选项 C
		**根节点**: 5
		*   **初始序列**: `[1, 10]`
		*   要得到根节点 5，中间下标的计算必须是：$mid = \lfloor \frac{1+10}{2} \rfloor = \lfloor 5.5 \rfloor = 5$。
		*   因此，我们假设选项 C 是基于**向下取整**规则构建的，并查找矛盾点。
		    *   **节点 2 的右子树 (节点 4)**: 序列范围 `[3, 4]`。
		        *   根据向下取整规则，中间值应为 $mid = \lfloor \frac{3+4}{2} \rfloor = \lfloor 3.5 \rfloor = 3$。
		        *   但图 C 中该节点的值是 4，这实际上是向上取整 $mid = \lceil \frac{3+4}{2} \rceil = 4$ 的结果。
		*   规则不一致。因此，C 错误。
	4. 验证选项 D 
		  **根节点**: 5。同样，这要求使用**向下取整**规则。
		*   **左子树 (节点 3)**: 根为 5，左子树的序列范围是 `[1, 4]`。
		    *   根据向下取整规则，中间值应为 $mid = \lfloor \frac{1+4}{2} \rfloor = \lfloor 2.5 \rfloor = 2$。
		    *   但图 D 中该节点的值是 3。
		*   在第一层子树构建时就出现了矛盾。因此，D 错误。
		
		**结论**: 只有选项 A 完全符合单一的构建规则（向上取整）。
		
- 衍生 
	- #平均查找长度ASL    [[平均查找长度 (ASL)]]
		-  **计算**: $ASL_{成功} = \frac{\sum_{i=1}^{n} C_i}{n}$，其中 $C_i$ 是查找第 $i$ 个元素的比较次数（即该节点所在的层数）。
	    *   **考点**: 给你一棵折半查找判定树，计算其成功查找的平均查找长度。对于本题的树 A，ASL = (1×1 + 2×2 + 4×3 + 3×4) / 10 = 2.9。
	    *   **延伸**: 查找失败的 ASL 计算。这需要考虑外部节点（查找失败时终止的位置）
	-  #最优二叉查找树   
		-  **考点**: 这是一个动态规划的经典问题。可能会要求理解其概念，或者解决一个小规模的最优二叉查找树构建问题。
	- #平衡二叉树AVL  **考点**:
        *   AVL 树的定义（任何节点的左右子树高度差不超过1）及其旋转调整操作（LL, RR, LR, RL）。
        *   红黑树的 5 条性质及其插入/删除时的颜色调整和旋转。
        *   比较不同类型查找树的性能和适用场景。





![[2017-exam-paper-ocr.pdf#page=1&rect=70,86,456,143|2017-exam-paper-ocr, p.1]]
[[Pasted image 20250930043340.png]]

[[B树和B+树的区别]]  
#B➕树 
B+树 特别适合处理存储在磁盘等外部设备上的 大量数据，特别是需要进行范围查询和精确查找 的场景，  因为每次磁盘的IO成本很高，B+树通过降低树的高度，最大限度的减少了磁盘读取的次数

1. A #编译器中的语法分析   #语法分析  主要是讲源代码字符串转换层一系列的记号，这个过程通常使用 #有限自动机  来实现，他通过 #状态转换 来识别关键字、标识符、运算符等，这个场景与B+树形索引结构关系不大
2. B  关系数据库系统中的索引 #数据库索引  ，数据库的数据量非常庞大， 无法一次性全部加载到磁盘上， #数据库索引的目的 就是为了加速查询 B+树的特性完美契合这个需求
	1. 减少磁盘IO 
	2. 高效的范围查询 
		1. 由于叶子节点是相连的有序链表， 当需要查询一个范围时， 只需定位到起始的叶子节点， 然后沿着链表顺序遍历即可， 无需再从树的根节点开始查找， 效率极高
		2. 因此， B+树是关系型 数据库 （如MySQL 的 innoDB引擎）中最核心和最常用的索引结构
3. C  网络中的 #路由表查询   路由表查找的核心是 #最长前缀匹配  ，虽然可以用树形结构， 但更高效和常用的数据结构是 #字典树Trie树  或其变体， 如 #基数树  
4. D 操作系统的磁盘 #空闲块管理 [[磁盘空闲空间管理]]  
	1.  #空闲链表法   将所有空闲块用链表连接起来
	2. #位图法  用一个二进制位图来表示所有磁盘块， 0代表以占用 ，1 代表空闲
	3. 这些方法实现简单，开销小， 比维护一个复杂的B+树更合适
- 结论： 综合分析， 只有 #关系数据库 中的索引 是 #B➕树的应用场景 
- 衍生 
	- B+树的高度与性能计算 #B➕树的性能
	- [[数据库索引类型]] 
	- [[索引结构的选择B+树vs哈希索引]] 


![[2017-exam-paper-ocr.pdf#page=1&rect=76,31,495,91|2017-exam-paper-ocr, p.1]]
[[Pasted image 20250930043345.png]]

#归并排序   #插入排序  [[排序算法]]
#归并排序与插入排序对比  [[各类内部排序算法的时间复杂与空间复杂度]]    [[内部排序和外部排序]] 


1. 归并排序的程序代码更短
	1.  #插入排序 实现非常简单， 通常由两层循环构成，外层循环遍历待排序的元素，内层循环为当前元素在已排序部分找到合适的位置并插入。代码简单
	2. #归并排序 基于 #分治思想  ，需要一个递归函数来不断地将数组对半分割，还需要以恶搞额外的合并函数，用于将两个已排序的子数组和 
2. 陈述 II：归并排序的占用空间更少 
	1.   **插入排序**：它是一个 **原地排序 (in-place)** 算法。在排序过程中，它只需要一个额外的变量来临时存储待插入的元素，其所需的额外空间是固定的，与待排序数据量 $n$ 无关。因此，其空间复杂度为 $O(1)$。
	2.   **归并排序**：在合并两个有序子数组时，通常需要一个临时的辅助数组来存放合并后的结果，这个辅助数组的大小与待合并的数据量成正比。对于一个长度为 $n$ 的数组，它需要一个大小为 $n$ 的辅助数组。因此，其空间复杂度为 $O(n)$ 
	3.   **结论**：归并排序占用的空间（$O(n)$）比插入排序（$O(1)$）要**多**。所以陈述 II **错误**
3. 陈述 III：归并排序的运行效率更高
	**时间复杂度 (Time Complexity)** 是衡量算法执行时间随数据规模增长而增长的趋势。这通常是选择排序算法时最重要的考量因素。
	*   **插入排序**：
	    *   最坏情况（数组逆序）：时间复杂度为 $O(n^2)$。
	    *   平均情况：时间复杂度为 $O(n^2)$。
	    *   最好情况（数组已有序）：时间复杂度为 $O(n)$。
	*   **归并排序**：
	    *   无论是最好、最坏还是平均情况，归并排序都需要稳定地执行“分解”和“合并”操作。其时间复杂度始终为 $O(n\log n)$。
	* **比较**：当数据规模 $n$ 很大时，$O(n\log n)$ 的增长速度远慢于 $O(n^2)$。因此，对于大规模、无序的数据，归并排序的运行效率远高于插入排序 
	* **结论**：在通常情况下（尤其是在处理大规模数据时），归并排序的运行效率更高。陈述 III **正确** 



- 衍生 
	- [[各类内部排序算法的时间复杂与空间复杂度]]   
	- 何时选择插入排序？ 
		- 但在某些特定场景下，插入排序反而更具优势：
			*   **数据规模小**：当 $n$ 很小时， $O(n^2)$ 算法的常数项和低阶项可能使其比 $O(n\log n)$ 算法更快。因为归并排序的递归和合并操作有额外的开销。
			*   **数据基本有序**：当数据已经接近有序时，插入排序的时间复杂度接近 $O(n)$，效率非常高。
			*   **混合排序算法**：一些高级排序算法（如 Timsort，Python 的内置排序）会结合使用多种排序。例如，当待排序的子数组规模小于某个阈值时，就切换到插入排序，以提高效率。

لإ


لإ


![[2017-exam-paper-ocr.pdf#page=2&rect=74,770,510,822|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930043350.png]]

[[存储器的四种主要存取方式]]    [[存储结构]]
#存储方式对排序算法的影响   #顺序存储   #链式存储     [[顺序存储与链式存储]] 
1.  I. 插入排序 
	1. **访问方式**：在已排序区中，它需要与其前面的元素逐一比较。这种“访问相邻前一个元素”的操作，无论是数组还是链表都可以高效完成。 
	2. **效率变化**：在数组中，找到位置后需要移动元素，这很耗时。在链表中，找到位置后插入节点的操作是$O(1)$，效率更高。但是，查找插入位置的过程无论是数组还是链表，都需要顺序比较，平均时间复杂度都是$O(n)$。因此，对于整个算法而言，总的时间复杂度量级不变，仍然是$O(n^2)$。效率没有降低
2.  II. 选择排序 
	1. **访问方式**：它的主要操作是在未排序区中进行顺序扫描以找到最值。这种顺序扫描对数组和链表都同样适用。 
	2. 效率变化 找到最值后，需要将其与未排序区的第一个元素交换。在数组中，交换是$O(1)$。在链表中，交换两个节点（尤其是非相邻节点）需要修改多个指针，稍微复杂一些，但也可以在$O(1)$时间内完成（如果维护了指向前驱节点的指针）。算法的瓶颈在于$n-1$次扫描，每次扫描的成本是线性的。因此，总的时间复杂度量级不变，仍然是$O(n^2)$。效率没有降低。 
3. 气泡排序 
	1.  **访问方式**：只涉及对**相邻元素**的访问和比较。
		*   **效率变化**：在数组中，访问`A[i]`和`A[i+1]`是$O(1)$。在链表中，访问当前节点和它的后继节点也是$O(1)$。因此，核心操作的效率没有变化。总的时间复杂度量级不变，仍然是$O(n^2)$。效率没有降低。 
4.  IV. 希尔排序 
	1. **访问方式**：希尔排序的关键在于它需要跳跃式地访问元素，例如比较`A[i]`和`A[i+gap]` 
	2.  **效率变化**：在数组中，由于支持随机访问，访问`A[i]`和`A[i+gap]`都是$O(1)$操作。但在链表中，要从第`i`个节点找到第`i+gap`个节点，必须向后遍历`gap`次，这是一个$O(gap)$的操作。这使得内层循环的成本大大增加，导致算法的整体时间效率**显著降低**
5.  V. 堆排序 
	1. **访问方式**：堆通常用数组来实现。因为在完全二叉树中，父节点和子节点的位置存在固定的数学关系。对于一个下标为`i`的节点：
	    *   其父节点下标为 $\lfloor(i-1)/2\rfloor$
	    *   其左子节点下标为 $2i+1$
	    *   其右子节点下标为 $2i+2$
	    这种通过下标计算直接定位到父子节点的方式，完全依赖于数组的**随机访问**特性。
	*   **效率变化**：如果用链表来表示堆，就无法通过下标计算来快速定位父子节点。每次调整堆时，寻找父子节点都需要通过指针遍历，效率远低于数组的$O(1)$访问。因此，堆排序的效率会**显著降低**

- 衍生 
	- [[原地排序]] 
	-  [[数据结构对排序算法的适应性]]  

![[2017-exam-paper-ocr.pdf#page=2&rect=75,708,522,774|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930043355.png]]

[[计算机性能评测的四个指标]]  
#指令集体系结构ISA    #CPU执行时间   [[CPU时间占比（CPU利用率）]] 
1. $CPU_{时间} = 指令数 \times CPI \times 时钟周期时间$ 
	1. $CPU_{时间} = \frac{指令数 \times CPI}{主频}$ 
2. 计算运行时间 
	1. M1 的运行时间 $T_{M1}$:
	    $T_{M1} = \frac{IC \times CPI_1}{f_1} = \frac{IC \times 2}{1.5}$
	2. M2 的运行时间 $T_{M2}$:
	    $T_{M2} = \frac{IC \times CPI_2}{f_2} = \frac{IC \times 1}{1.2}$
3. 要求的是 M1 和 M2 运行时间的比值，即 $T_{M1} / T_{M2}$ 
	1. $\frac{T_{M1}}{T_{M2}} = \frac{\frac{IC \times 2}{1.5}}{\frac{IC \times 1}{1.2}}$ 
4. 计算比值时，相同的指令数 $IC$ 可以被约掉 
	1. $\frac{T_{M1}}{T_{M2}} = \frac{2/1.5}{1/1.2} = \frac{2}{1.5} \times \frac{1.2}{1} = \frac{2.4}{1.5}$
	2. $\frac{24}{15} = \frac{8}{5} = 1.6$ 

- 衍生 
	- #MIPS每秒执行百万条指令数  **考点**: 可能会让你计算M1和M2的MIPS值，并比较它们。例如，
        $MIPS_{M1} = \frac{1.5 \times 10^9}{2 \times 10^6} = 750$
        $MIPS_{M2} = \frac{1.2 \times 10^9}{1 \times 10^6} = 1200$
        这里会发现，虽然M2的运行速度比M1快（运行时间短），但M2的MIPS值也更高，这符合直觉。但MIPS有其局限性（MIPS陷阱），因为它没有考虑指令的功能强弱
	 - [[计算流水线加速比]] 
	 - #Amdahl定律   
		 - 当只对系统的某一部分进行优化时，Amdahl定律可以用来计算整个系统的性能提升上限。 
	    *   **公式**: $S_{overall} = \frac{1}{(1 - F_{enhanced}) + \frac{F_{enhanced}}{S_{enhanced}}}$
	    *   $F_{enhanced}$ 是可被优化的部分所占原执行时间的比例。
	    *   $S_{enhanced}$ 是该部分获得的加速比。
	    *   **考点**: 可能会给出一个程序的运行时间构成，比如“程序P有40%是浮点运算，60%是其他运算。现将浮点运算单元的性能提升3倍，求整个程序的加速比。”
	        解：$F_{enhanced} = 0.4$, $S_{enhanced} = 3$
	        $S_{overall} = \frac{1}{(1 - 0.4) + \frac{0.4}{3}} = \frac{1}{0.6 + 0.133} = \frac{1}{0.733} \approx 1.36$
	        #整体加速比 约为1.36倍



![[2017-exam-paper-ocr.pdf#page=2&rect=76,643,527,707|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930043359.png]]
[[Pasted image 20250930043403.png]]
#交叉编址 
  #计算周期数  [[高位交叉编址vs低位交叉编址]] 

1. 步骤一：确定起始芯片编号 
	1. 知道 `double` 变量 `x` 的第一个字节存储在哪个芯片上。这由它的起始地址 `804001AH` 的最低两位决定 
	2. 将地址的最后一位十六进制数 `A` 转换为二进制。
	    $A_{16} = 1010_2$
	3.  所以，地址 `804001AH` 的二进制表示的最后四位是 `1010`。
	4.  地址的最低两位是 `10`。
	5.  根据我们的映射关系，`10` 对应的是**芯片 2**。
	    所以，`double` 变量 `x` 的第一个字节存储在芯片 2 中
2. 步骤二：分析数据在芯片间的分布 
	1. `double` 变量共 8 个字节。由于是交叉编址，这 8 个字节会依次存储在芯片 2, 3, 0, 1, 2, 3, 0, 1 中 
		*   字节 1: 芯片 2
		*   字节 2: 芯片 3
		*   字节 3: 芯片 0
		*   字节 4: 芯片 1
		*   字节 5: 芯片 2
		*   字节 6: 芯片 3
		*   字节 7: 芯片 0
		*   字节 8: 芯片 1
3. 步骤三：计算所需的 #存储周期 数 
	1. 一个存储周期可以从 4 个芯片中各读取 1 个字节，总共 4 个字节 
	2. 第一个存储周期 
		1.  CPU 发出读请求，起始地址为 `804001AH`（指向芯片 2）。
		    *   #存储控制器 会读取一个与 #总线宽度 对齐的 4 字节 #数据块 。这个数据块包含了地址 `...10`（芯片 2）和 `...11`（芯片 3）的数据。
		    *   在此周期中，我们成功读取了 `x` 的**第 1 个字节（来自芯片 2）**和**第 2 个字节（来自芯片 3）**。
		    *   本周期获得字节数：2
	3. 第二个存储周期 
		1. 存储控制器接着读取下一个 4 字节的数据块。
		    *   这个数据块会同时从芯片 0、芯片 1、芯片 2、芯片 3 中各读取一个字节。
		    *   在此周期中，我们成功读取了 `x` 的**第 3、4、5、6 个字节**。
		    *   本周期获得字节数：4。
		    *   累计获得字节数：2 + 4 = 6
	4. 第三个存储周期 
		1. 此时我们还需要读取 2 个字节（第 7 和第 8 字节）。
		    *   存储控制器再次读取下一个 4 字节的数据块。
		    *   在此周期中，我们成功读取了 `x` 的**第 7 个字节（来自芯片 0）**和**第 8 个字节（来自芯片 1）**。
		    *   至此，8 个字节全部读取完毕
	5. 总共需要 **3** 个存储周期。因此，答案是 **C**
4. #存储周期数通用公式    
	1. 对于这类问题，我们可以推导一个通用公式。
		假设：
		*   要读取的数据块大小为 $N$ 字节。
		*   交叉存储的模块数量为 $m$。
		*   起始地址对应的起始模块（芯片）编号为 $S$（编号从 0 到 $m-1$）。
		
		1.  第一个存储周期可以读取的字节数是 $m-S$。
		2.  剩余需要读取的字节数是 $N - (m-S)$。
		3.  之后每个存储周期可以读取 $m$ 个字节。所以，读取剩余字节需要的周期数是 $\lceil \frac{N - (m-S)}{m} \rceil$。（这里 $\lceil \cdot \rceil$ 表示向上取整）
		4.  总的存储周期数 $T = 1 + \lceil \frac{N - (m-S)}{m} \rceil$
		将本题数据代入公式：
		*   $N=8$ (double 占 8 字节)
		*   $m=4$ (4 个芯片)
		*   $S=2$ (起始芯片编号为 2)
		$T = 1 + \lceil \frac{8 - (4-2)}{4} \rceil = 1 + \lceil \frac{6}{4} \rceil = 1 + \lceil 1.5 \rceil = 1 + 2 = 3$ 


- 衍生 
	-  [[高位交叉编址vs低位交叉编址]] 
		- **考点**: 可能会问在某个地址的连续数据块是否会跨模块，或者这种编址方式的优缺点（优点是便于系统扩充，缺点是无法实现并行存取，不利于提高带宽） 
	- 存储器带宽计算
		- **概念**: 带宽是衡量数据传输速率的指标，单位通常是 MB/s 或 GB/s。
	    *   **公式**: 带宽 = (总线宽度 / 8) / 存储周期。
	    *   **交叉编址下的带宽**: 对于低位交叉存储器，在连续读写时，其理论峰值带宽可以达到单个模块带宽的 $m$ 倍。
		- **考点**: 给出存储周期时间、总线宽度和模块数，计算单个模块的带宽和整个存储系统的最大带宽。例如，若存储周期为 10ns，总线宽度 32 位，则带宽为 $(32/8) / (10 \times 10^{-9}) = 400 \text{ MB/s}$。 
	- #地址映射与译码   #地址映射核心思想 [[地址映射]]
		- 概念： 如何将一个完整的逻辑地址或物理地址分解成不同的部分，用于选择芯片、片内行地址和列地址。
		-   **考点**: 给定一个存储系统的总容量、芯片规格和组织方式，要求画出地址的分配图。例如，一个 1GB 的主存由 8 片 $128M \times 8$ 位的芯片构成，地址线共有 30 根 ($2^{30} = 1G$)，如何将这 30 根地址线分配给片选信号和片内地址 


![[2017-exam-paper-ocr.pdf#page=2&rect=80,509,533,646|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930043409.png]]
#访问局部性   #时间局部性    #局部性原理 
1.   操作系统利用了 #局部性原理  （Principle of Locality）[[缓存的工作原理 ，局部性原理]]
	    *   **时间局部性**：如果一个数据项被访问，那么在不久的将来它很可能再次被访问。
	    *   **空间局部性**：如果一个数据项被访问，那么与它地址相邻的数据项也很可能很快被访问。
2. 分析题目中的代码
	1.  **空间局部性分析**:
	    观察内层循环 `for(j=0; j<=i; j++)`。在这个循环中，数组 `a` 的元素被依次访问：`a[0]`, `a[1]`, `a[2]`, ..., `a[i]`。在C语言中，数组的元素在内存中是连续存放的。因此，当程序访问 `a[j]` 后，紧接着就会访问 `a[j+1]`，这两个元素在内存中的地址是相邻的。这完全符合空间局部性的定义。
	    **结论：对数组 `a` 的访问具有良好的空间局部性。**
	2. **时间局部性分析**:
	    观察外层循环 `for(i=0; i<=9; i++)`。我们追踪一下特定元素的访问情况：
	    *   当 `i = 0` 时，访问 `a[0]`。
	    *   当 `i = 1` 时，访问 `a[0]`, `a[1]`。
	    *   当 `i = 2` 时，访问 `a[0]`, `a[1]`, `a[2]`。
	    *   ...
	    *   当 `i = 9` 时，访问 `a[0]`, `a[1]`, ..., `a[9]`。
	我们可以看到，元素 `a[0]` 在外层循环的每一次迭代中都被访问了。元素 `a[1]` 在 `i` 从1到9的迭代中也都被访问了。对于任意元素 `a[k]`，它会在 `i` 从 `k` 到 9 的所有迭代中被重复访问。这些重复访问之间只隔了内层循环的执行时间，在整个程序的执行过程中，这个时间间隔很短。这完全符合时间局部性的定义。
    **结论：对数组 `a` 的访问具有良好的时间局部性。**
A 
- 衍生 
	- #二维数组的遍历顺序 
		- 非常经典的考点，用于考察对 #空间局部性 的理解。
			在C/C++/Java等语言中，二维数组是按**行主序 (Row-Major Order)** 存储的。这意味着，同一行的元素在内存中是连续的。
	- **示例代码1：按行遍历 (空间局部性好)**
```c
int matrix[100][100];
for (int i = 0; i < 100; i++) {
    for (int j = 0; j < 100; j++) {
        sum += matrix[i][j]; // 访问顺序: matrix[0][0], matrix[0][1], ...
    }
}
```
这种访问方式与内存存储顺序一致，空间局部性极好，缓存命中率高。
- 示例代码2： #按列遍历 (空间局部性差)
```c
int matrix[100][100];
for (int j = 0; j < 100; j++) {
    for (int i = 0; i < 100; i++) {
        sum += matrix[i][j]; // 访问顺序: matrix[0][0], matrix[1][0], ...
    }
}
```
这种访问方式会导致内存地址的“跳跃”。访问 `matrix[i][j]` 之后，下一个访问的是 `matrix[i+1][j]`，它们在内存中相隔了一整行的距离。这破坏了空间局部性，会导致大量的缓存缺失，性能远低于按行遍历。

-   [[数组和链表的区别]]  


![[2017-exam-paper-ocr.pdf#page=2&rect=77,476,478,517|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044146.png]]
- 
		#寻址模式方式  [[寻址方法的比较]]  
	#访问方法#下标顺序访问 
	
1. 这道题的核心是理解不同寻址方式的原理和应用场景，特别是它们如何计算 #操作数的有效地址  #计算有效地址  [[计算有效地址]]
	1. 访问一维数组 `Array` 的第 `i` 个元素 `Array[i]` 时，其内存地址可以表示为：
		`地址(Array[i]) = 数组的基地址 + i * 每个元素的大小` 
		1. 需要找到一种寻址方式，其计算有效地址的模式与这个公式最匹配
2. 分析 变址寻址 
	1.  $EA = A + (IX)$ 
		*   `A` 是指令中给出的地址部分。
		*   `(IX)` 是变址寄存器中的内容。
	2.  **如何匹配数组访问：**
		*   我们可以将数组的**基地址**（首地址）存放在指令的地址字段 `A` 中。
		*   将数组的**下标** `i` 存放在变址寄存器 `IX` 中。
		*   当需要按顺序访问数组时（例如在 `for` 循环中），我们只需要不断地增加变址寄存器 `IX` 的值（`i++`），而指令本身可以保持不变。CPU 每次都会自动计算出 $A + (IX)$，从而定位到下一个数组元素。
	*   **结论：** 变址寻址的机制完美契合了“基地址+偏移量”的数组访问模式，因此是最适合的
3. A. 相对寻址
	2. **公式：** $EA = (PC) + A$
        *   `(PC)` 是程序计数器 (Program Counter) 的内容，即当前指令的地址。
        *   这种方式的基准是当前指令的位置，主要用于实现程序的跳转和分支，使得代码可以被加载到内存的任何位置（位置无关代码），而不适用于访问数据结构
4. B. 寄存器寻址 
	*   **操作数直接在寄存器中**，而不是在内存里。指令中直接指定了存放操作数的寄存器编号。
	*   这种方式速度最快，因为它不访问内存。但它根本不涉及内存地址的计算，所以无法用来访问存储在内存中的数组。
5. C. 直接寻址  
	*   **公式：** $EA = A$
	*   指令的地址字段 `A` 直接给出了操作数在内存中的有效地址。
	*   这种方式只能访问一个固定的内存单元。如果要访问数组 `Array[0]`, `Array[1]`, `Array[2]`...，你需要为每个元素编写一条地址不同的指令，这非常低效和不灵活。


- 衍生 
	- [[变址寻址与基址选址的对比]]  
		- **考题形式：** 可能会问“为了让程序能在内存中任意位置运行，应采用哪种寻址方式？”（答案：基址寻址或相对寻址） 
	- [[寻址方式的执行效率比较]] 
		- **考题形式：** “下列寻址方式中，执行速度最快的是？”（答案：寄存器寻址）


![[2017-exam-paper-ocr.pdf#page=2&rect=77,426,527,477|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044151.png]]
- 这道题的核心是考察在 #固定指令字长  的前提下，如何利用 #扩展操作码技术  来设计包含多种不同地址格式指令的指令系统，并结合 #字节编址 的物理约束来确定最终的指令长度
#指令字长 
#指令格式  
1. 分析指令结构   #地址指令 
	*   **三地址指令**：`[操作码 OP | 地址1 A1 | 地址2 A2 | 地址3 A3]`
    *   **二地址指令**：`[操作码 OP | 地址1 A1 | 地址2 A2]` 
	1. 由于指令字长是固定的，这个长度必须能容纳下最长的指令格式，也就是三地址指令。
2.  确定 #操作码(Opcode)的最小长度 [[指令格式]]
	1. 定义多少条不同的指令,若操作码有 $n$ 位，则最多可以表示 $2^n$ 种不同的状态，即最多定义 $2^n$ 条指令。
	2. 题目中有 29 条三地址指令和 107 条二地址指令。我们首先需要确定一个基础的操作码长度 $k$，这个长度必须能区分开三地址指令，并为二地址指令留出扩展空
	3. 为了能表示 29 条三地址指令，操作码长度 $k$ 必须满足：
	4. $2^k \ge 29$ 
		1. 操作码字段的**最小长度**为 **5 位**
3. 计算满足逻辑需求的 #最小指令字长
	1. 我们以最长的三地址指令格式和刚算出的最小操作码长度来计算指令字长： 
		*   操作码 (OP) 长度 = 5 位
	    *   每个地址字段 (A1, A2, A3) 长度 = 6 位 (题目已知)
	2. 最小指令字长 = (操作码长度) + (地址1长度) + (地址2长度) + (地址3长度)
	    最小指令字长 = $5 + 6 + 6 + 6 = 23$ 位
4. 验证该设计是否能容纳所有指令（ #扩展操作码检验 ）
	1. 验证这个 23 位的指令长度设计是否也足够容纳 107 条二地址指令。这里就要用到扩展操作码技术 
	2. 当操作码为 5 位时，总共有 $2^5=32$ 种可能的编码。
	    *   其中 29 种编码被用于三地址指令。
	    *   剩余的编码数量为 $32 - 29 = 3$ 种。这 3 种编码可以作为“扩展标志”或“转义码”，用来表示“这不是一条三地址指令，而是一条二地址指令”
	3. 对于二地址指令，其格式为 `[OP | A1 | A2]`。在固定的 23 位长度下，它会多出一个原本属于 A3 的 6 位空间。这个空间可以用来 #扩展操作码 。
	   因此， #二地址指令的可用编码数量  = (剩余的转义码数量) × (扩展字段能表示的状态数)
	    *   可支持的 #二地址指令  数量 = $3 \times 2^6 = 3 \times 64 = 192$ 条
	题目要求支持 107 条二地址指令，而我们的设计可以支持 192 条。因为 $192 > 107$，所以这个设计在逻辑上是成立的。最小的逻辑指令长度确实是 23 位
5. 结合物理约束（字节编址） 
	1. 题目中有一个关键条件：“某计算机按字节编址”。
	    *   **字节编址 (Byte-addressable)** 意味着内存的最小可寻址单位是一个字节（Byte）。
	    *   1 字节 = 8 位 (bit)。
	    *   为了方便CPU取指和内存管理，指令字长通常设计为字节的整数倍
	2. 我们的计算得出的最小逻辑长度是 23 位，但它不是 8 的倍数。因此，我们需要找到大于或等于 23 的最小的 8 的倍数 
		1. 24 是大于等于 23 的最小的 8 的倍数。所以，指令字长至少应该是 **24 位** 


- 衍生 
	- [[指令格式]]  
		- 一条指令通常由**操作码(Opcode)**和**地址码(Operand/Address)**组成。操作码指出要执行什么操作（如加、减、存取），地址码指出操作数或操作数的地址。
	-  #N地址指令 
		- 根据指令中包含的地址码数量，分为三地址、二地址、一地址和零地址指令。
	- #指令字长 
		- 一条指令的总位数。可以是固定的（如本题），也可以是可变的（如 Intel x86 架构）。固定字长便于硬件译码和流水线处理，但可能浪费空间；可变字长节省空间，但译码复杂。
	- [[扩展操作码技术]] 
		- **示例**：如本题，5位的操作码有32种组合。用`00000`到`11100`（共29个）代表三地址指令。用`11101`, `11110`, `11111`（共3个）作为前缀，表示这是一条二地址指令，此时，原本A3字段的6位将被视为扩展操作码，从而可以定义 $3 \times 2^6$ 条二地址指令
	- 反向计算 
		- 告诉你指令字长、地址字段长度和指令种类，让你计算在采用扩展操作码技术后，最多能支持多少条某种格式的指令。
	    *   例 ：指令长32位，地址字段8位。若已有15条三地址指令和240条二地址指令，最多还能支持多少条一地址指令？
	* 可变长指令设计  #指令字长与哈夫曼编码 
		* 题目条件变为“指令字长可变”，通常会结合 #哈夫曼编码 （Huffman Coding）的思想，让使用频率高的指令长度更短，以优化程序总长度。 
	* #寻址方式   
		* 本题默认地址字段是直接寻址内存。考题可能引入多种寻址方式（如寄存器寻址、立即数寻址、间接寻址），这会影响地址字段的解释和长度设计。
	    *   *例*：若地址字段的某一位用于区分是寄存器寻址还是内存寻址，那么实际可用的地址位数就会减少
	* 与存储容量的关系 
		* 地址字段的位数直接决定了可寻址的内存空间大小。
		    *   例 ： 本题地址字段为6位，若按字寻址，则可寻址 $2^6=64$ 个字。若按字节寻址，则可寻址 $2^6=64$ 个字节。题目可能会问该指令系统支持的最大内存容量是多少。



![[2017-exam-paper-ocr.pdf#page=2&rect=75,354,471,427|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044156.png]]


[[流水线技术]]     [[超标量技术]]
#流水线特性 #超标量
1. 能缩短流水线功能段的处理时间 
	1. 流水线技术是将一条指令的执行过程划分为多个阶段（功能段），例如：取指(IF)、译码(ID)、执行(EX)、访存(MEM)、写回(WB)。每个阶段的处理时间取决于该阶段硬件电路的延迟 
	2. #超标量技术的核心思想 是“空间换时间” 
		1. 即通过增加硬件资源（如增加多条流水线、多个执行单元）来并行处理多条指令，而不是去改变单个功能段（如ALU的加法运算）本身的处理速度
		2. 缩短流水线功能段的处理时间通常是通过改进电路设计、使用更快的半导体工艺等方式实现的，这与是否采用超标量架构没有直接关系 
2.  II: "能在一个时钟周期内同时发射多条指令"
	1. 这是**超标量最核心、最本质的特征**。传统的标量流水线（Scalar Pipeline）在一个时钟周期最多只能发射（Issue）一条指令
	2.  为了实现并行执行，超标量处理器配备了多套指令译码、分派逻辑和多个功能单元（如多个整数运算单元、浮点运算单元等）。这使得它能够在同一个时钟周期内，从指令队列中取出多条没有依赖关系的指令，并将它们“发射”到不同的执行流水线中去
		1. 例如，一个4-way超标量处理器理论上可以在一个时钟周期内同时发射4条指令。
		*   因此，叙述 II 是**正确**的
3.  III: "能结合 #动态调度技术 提高指令执行并行性"  
	1. #动态调度与乱序执行   
		1. 如Tomasulo算法或Scoreboarding，允许处理器在运行时检查指令间的数据依赖关系，对指令进行乱序执行（Out-of-Order Execution, OoOE）。处理器可以越过正在等待数据的指令，先执行后面准备就绪的无关指令，从而最大限度地填充并行的执行单元，挖掘指令级并行性
		2.  现代的超标量处理器几乎都与复杂的动态调度、乱序执行和分支预测技术紧密结合，以实现高性能

- 衍生 
	-  [[超标量vs超长指令字VLIW]] 
	- [[超标量vs同时多线程（超线程）SMT]] 

![[2017-exam-paper-ocr.pdf#page=2&rect=78,275,463,357|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044202.png]]

1. #主存储器  #控制存储器 [[控制存储器容量的计算]] [[主存储器]]    [[控制存储器]] 
#总线与主存技术   #控制存储器   
2. A. MM 在 CPU 外，CS 在 CPU 内 
	1. **主存储器 (MM)**，也就是我们常说的内存条（RAM），是插在主板上的，位于 CPU 芯片的外部，通过系统总线与 CPU 进行通信。
    *   **控制存储器 (CS)** 是微程序控制器的一个核心部件，它存储了实现所有机器指令的微程序。微程序控制器本身是 CPU 内部的 控制器（Control Unit, CU）的一部分。因此，CS 位于 CPU 内部。
3. B. MM 按地址访问，CS 按内容访问 
	1.  **主存储器 (MM)** 的访问方式是按地址访问。每个存储单元都有一个唯一的地址。CPU 访问时，必须先给出地址。
    *   **控制存储器 (CS)** 存储的是微指令序列。**访问方式**：按地址访问。控制器内部有一个 #微程序计数器μPC  ，它提供下一条要执行的微指令在 CS 中的地址。
    *    “ #按内容访问”指的是 #相联存储器  的工作方式，用户给出内容，存储器返 回该内容所在的地址。这通常用于高速缓存（Cache）的地址映射或页表（TLB）中，而不是控制存储器。
4. C. MM 存储指令和数据，CS 存储微指令 
	1. **主存储器 (MM)** 的主要功能就是存放即将被 CPU 执行的程序（由机器指令构成）和程序处理的数据。
    *   **控制存储器 (CS)** 的功能是存放微程序，而微程序是由一系列**微指令**构成的，用于解释和执行每一条机器指令。
    *   这个叙述是**正确**的，准确地描述了二者的功能分工。
5. D. MM 用 RAM 和 ROM 实现，CS 用 ROM 实现 
	1. **主存储器 (MM)** 的绝大部分是由**RAM (Random-Access Memory)** 构成的，因为程序和数据在运行时需要被频繁读写。同时，主存中也包含一小部分 **ROM (Read-Only Memory)**，用于存放系统启动时所需的引导程序（如 BIOS/UEFI）和一些固化的子程序。
    *   **控制存储器 (CS)** 中存放的微程序是在 CPU 设计和制造时就固定下来的，在计算机运行时通常是只读不写的。因此，它通常由 **ROM** 来实现。
    *   这个叙述是**正确**的。

- 衍生 
	- [[存储器的层次结构]] 
	-  [[指令系统和微指令系统]]  [[微指令与微命令]] 
	-       [[相联存储器]] 






![[2017-exam-paper-ocr.pdf#page=2&rect=76,226,510,281|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044207.png]]
- 这道题的核心是理解计算机处理器中“ #数据通路 ”（Datapath）和“ #控制部件 ”（Control Unit）的根本区别。
1. A. 包含生成控制信号的控制部件  [[数据通路]]  [[控制部件和数据通路]] 
	1. 数据通路是执行数据操作的硬件集合，而控制部件是生成控制信号的独立单元。将两者混为一谈是概念上的错误。因此，这是本题的正确答案。
2. B. 包含算术逻辑运算部件 (ALU) 
	1. #算术逻辑单元ALU （Arithmetic Logic Unit）是数据通路的核心组件，负责执行加、减、与、或等算术和逻辑运算，是数据处理的主要场所
3. C. 包含通用寄存器组和取指部件 
	1. 这个说法是**正确**的。通用寄存器组（Register File）用于暂存操作数和运算结果，是数据流动过程中的关键存储单元。取指部件（通常包括程序计数器PC和指令存储器接口）负责从内存中获取指令，是数据（在这里是指令数据）进入处理器的入口。这些都属于数据通路 
4.  D. 由组合逻辑电路和时序逻辑电路组合而成
	1. 这个说法是**正确**的。数据通路是一个复杂的数字电路系统，它必然包含两类基本电路：
	    *   #组合逻辑电路 (Combinational Logic Circuits): 其输出仅取决于当前的输入，例如ALU、多路选择器（MUX）、加法器等。
	    *   #时序逻辑电路 (Sequential Logic Circuits): 其输出不仅取决于当前输入，还与电路之前的状态有关，具有记忆功能。例如程序计数器（PC）、通用寄存器、流水线寄存器等。
	
[[指令流水线与冲突]]  
[[微程序控制器和硬布线控制器的区别]] 


![[2017-exam-paper-ocr.pdf#page=2&rect=75,177,477,228|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044221.png]]

1.  D  [[突发传输]] 
2. [[CPU与总线]]  
3. [[总线桥]]  #总线桥 连接两条或多条总线的硬件设备 
[[系统总线结构（数据线，地址线，控制总线）]]  
#多总线结构

- 衍生 
	- [[总线带宽计算]] 


![[2017-exam-paper-ocr.pdf#page=2&rect=76,128,456,181|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044227.png]]
#IO操作  
1.  **I/O 操作的核心是什么？** I/O 操作指的是 CPU (中央处理器) 与外部设备（如键盘、硬盘、网卡）之间的数据交换。
2.  **CPU 如何与外部设备通信？** 解析中提到：“I/O 端口又称 I/O 接口，是 CPU 与设备之间的交接面。” 这说明 CPU 并不直接连接到 I/O 设备的复杂电路上，而是通过一个标准化的中间层——**I/O 端口**——来进行通信。这个端口起到了缓冲和转换的作用，解决了 CPU 和 I/O 设备之间速度与工作方式不匹配的问题。因此，选项 B（直接与 I/O 设备通信）是错误的。
3.  **数据在 CPU 内部暂存在哪里？** 当 CPU 执行指令时，需要处理的数据通常会先被加载到 CPU 内部的高速存储单元中，这些单元就是**寄存器**。对于 I/O 操作，数据要么从寄存器发送出去，要么被读取到寄存器中。
4.  **结合 I/O 指令的具体过程：** 解析中明确指出：“在执行一条指令时，CPU...使用数据总线在 **CPU 寄存器和端口之间**传输数据。” 这句话精确地描述了数据流动的路径。
    *   **输出操作 (OUT)**：CPU 将一个**通用寄存器**（如 x86 架构中的 `AL`, `AX`, `EAX` 寄存器）中的数据，通过数据总线发送到指定的 **I/O 端口**。
    *   **输入操作 (IN)**：CPU 从指定的 **I/O 端口**读取数据，通过数据总线存放到一个**通用寄存器**中。
5.  **结论：** 综上所述，由 I/O 指令直接引发的数据传送，发生在 CPU 的通用寄存器和 I/O 端口之间。这与选项 D 完全吻合。

**为什么其他选项是错误的？**
*   **A. I/O 设备和 I/O 端口之间：** 这个数据传送确实会发生，例如，键盘控制器将按键扫描码放入其端口的数据寄存器中。但这个过程是由 I/O 设备的控制器完成的，而不是由 CPU 执行的 "I/O 指令" *直接* 实现的。I/O 指令关心的是 CPU 与端口之间的数据交换。
*   **B. 通用寄存器和 I/O 设备之间：** 这是不准确的，因为 I/O 端口作为中介是必不可少的。
*   **C. I/O 端口和 I/O 端口之间：** 这种传送没有意义。数据流动的目的是在 CPU 和外部设备间交换，而不是在两个端口间打转。


#数据传送  [[IO接口和IO端口]]  [[1. IO 结构与控制]]  
- 衍生 
	- [[地址空间划分（IO编址方式）]]
		- **衍生考题**：可能会问“在内存映射 I/O 方式下，数据传送发生在何处？” 答案就变成了：“**通用寄存器和主存（中被映射为端口的单元）之间**”。
	- [[IO控制方式]]  
		- **衍生考题**：“在 DMA 方式下，数据传送发生在何处？” 答案是：“**I/O 设备和主存之间**”。

![[2017-exam-paper-ocr.pdf#page=2&rect=75,47,344,133|2017-exam-paper-ocr, p.2]]
[[Pasted image 20250930044233.png]]
[[Pasted image 20250930044239.png]]

#多重中断系统  #中断系统设计的基本原则   
1. A. 在一条指令执行结束时响应中断  [[（非）原子操作]]
	1.   **分析:** 这是正确的。CPU 执行指令是一个不可分割的 #原子操作 。为了保证当前指令的完整性，CPU 不会在指令执行到一半时去响应中断。它总是在执行完当前指令后，进入下一个“取指周期”之前，检查是否有中断请求。这个时间点被称为**中断检查点**。因此，中断响应发生在指令执行周期的末尾。
	    *   **结论:** A 叙述正确。
2. B. 中断处理期间 CPU 处于关中断状态  [[中断嵌套]]  [[单重中断系统与多重中断系统]] 
	1.   **分析:** 这是本题的关键。叙述中的“中断处理期间”是一个模糊的时间段。我们需要区分**单重中断系统**和**多重中断系统**。
        *   在**单重中断系统**中，为了防止中断处理程序自身被中断，CPU 在进入中断服务程序后会一直处于关中断状态（中断屏蔽），直到中断服务程序执行完毕返回主程序前才恢复中断。此时，这个叙述是正确的。
        *   然而，题目明确指出是**多重中断系统**（也称中断嵌套系统）。这种系统允许高优先级的中断请求打断正在处理的低优先级中断。为了实现这一点，CPU 的操作流程通常是：
            1.  响应中断后，硬件自动**关中断**。
            2.  执行一小段不可被再次中断的“入口”程序，用于**保护现场**（如程序计数器PC、程序状态字PSW等）。
            3.  在保护好现场之后，软件可以（也通常会）**开中断**（解除中断屏蔽）。
            4.  执行中断服务程序的主体部分。在此期间，如果来了更高优先级的中断，CPU 可以再次响应。
            5.  在中断服务程序即将结束时，再次**关中断**，以安全地**恢复现场**。
            6.  执行中断返回指令（如 `IRET`），返回到被打断的程序，并自动恢复中断状态。
    *   **结论:** 因为在多重中断系统的中断服务程序主体执行期间，CPU 是处于**开中断**状态以响应更高优先级的中断，所以“中断处理期间 CPU 处于关中断状态”这个说法是**错误**的
3. C. 中断请求的产生与当前指令的执行无关
	1. [[中断、异常和系统调用的区别与联系]]  题目中的“中断请求”通常指外部中断，其产生是异步的，与当前指令无关。C 叙述正确。 
4. D. CPU 通过采样中断请求信号检测中断请求 
	1.  CPU 并不会持续不断地监视中断请求线。如 A 选项所述，它只在特定的时间点——即每条指令执行周期的末尾——去“采样”或检查中断请求信号是否存在。如果检测到有效的中断请求并且CPU处于开中断状态，才会启动中断响应过程。

- 衍生 
	- [[中断向量与中断向量表]]  
		-   **考点：** CPU 如何找到对应的中断服务程序？
		    *   **详解：** 系统为每个中断源分配一个唯一的**中断类型号**。CPU 响应中断后，会根据这个类型号去内存中的一个固定区域——中断向量表——查找对应中断服务程序的入口地址。中断向量表本质上是一个存放中断服务程序入口地址的数组。
	- [[中断优先级排队器]] 
		-    **考点：** 当多个中断同时发生时，硬件如何决定响应哪一个？
	- [[中断屏蔽的规则（处理中断嵌套）]]  
		- **考点：** `CLI` (Clear Interrupt Flag) / `STI` (Set Interrupt Flag) 指令的作用是什么？ #中断屏蔽字的作用  （Interrupt Mask）的作用是什么？
			- **详解：** #关中断CLI 和 #开中断STI  是全局控制指令，用于控制 CPU 是否响应所有可屏蔽中断。而中断屏蔽字则提供了更精细的控制，它可以选择性地屏蔽某些中断源，而允许其他中断源。这对于实现复杂的中断优先级管理至关重要。

![[Pasted image 20251015111201.png]]
![[2017-exam-paper-ocr.pdf#page=3&rect=68,682,525,822|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044245.png]]

[[磁盘调度算法]]
1.  D  

*   **非抢占式 (本题默认)**: 一旦一个作业被选中运行，它就会一直运行直到完成或因 I/O 操作而阻塞，不会被其他作业中断。FCFS 和 SJF 都是典型的非抢占式算法。
*   **抢占式 (Preemptive)**: 正在运行的作业可能会被一个新到达的、优先级更高的作业中断。
    *   **衍生考点**: 如果题目中的“短作业优先”是**抢占式的**，它就变成了**最短剩余时间优先 (Shortest Remaining Time First, SRTF)** 算法。
    *   **举例**: 假设系统在 $t=2$ 时根据 SJF 选择了 J₃ (运行时间 2) 开始运行。J₃ 将在 $t=4$ 时完成。在 J₃ 运行期间的 $t=3$ 时刻，J₄ 到达了，它的运行时间是 1。
        *   在非抢占式 SJF 中，J₃ 会继续运行直到完成。
        *   在抢占式 SRTF 中，当 J₄ 在 $t=3$ 到达时，调度程序会比较 J₄ 的运行时间 (1) 和 J₃ 的*剩余*运行时间 (还剩 1)。如果出现平局，通常按先来先服务处理，所以 J₃ 会继续运行。但如果 J₄ 的运行时间是 0.5，那么 J₃ 就会被抢占，J₄ 开始运行。



![[2017-exam-paper-ocr.pdf#page=3&rect=74,608,505,683|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044251.png]]


[[系统调用的过程]]
C
- 衍生 
	 - 系统调用接口 (API vs. System Call)
		 -  **关系：** 程序员通常不直接使用 `trap` 指令进行系统调用，而是调用高级语言库函数（API），如C库中的 `printf()`、`malloc()`。
	    *   **封装：** 这些库函数内部会负责准备参数、执行 `trap` 指令等底层细节，为程序员提供了更方便、可移植的接口。例如，`printf()` 最终可能会调用 `write()` 这个系统调用。这种封装关系是常考点。
	- [[模式切换vs上下文切换]] 
		-   **联系：** 系统调用可能会 **引发** 上下文切换。例如，一个进程发起了一个读磁盘的系统调用，由于等待磁盘I/O需要很长时间，操作系统可能会将该进程置为阻塞态，并调度另一个就绪态的进程来运行，这时就发生了上下文切换 


![[2017-exam-paper-ocr.pdf#page=3&rect=72,500,527,608|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044257.png]]

#最佳适应算法 
[[动态分区存储管理（动态分区分配算法）]]  
	  **策略**: 遍历整个空闲分区链表，找到**所有**能满足大小要求的分区中，**尺寸最小**的那一个。 
	  #起始地址 
1. 第一步：分析初始状态 
	1. 列出系统当前的 #空闲分区链 （Free Partition List）信息。为了方便判断分区是否相邻，我们计算出每个分区的起始地址和结束地址。结束地址 = 起始地址 + 分区大小
		*   **分区1**: 起始地址 = 20K, 大小 = 40KB, 结束地址 = $20K + 40K = 60K$
		*   **分区2**: 起始地址 = 500K, 大小 = 80KB, 结束地址 = $500K + 80K = 580K$
		*   **分区3**: 起始地址 = 1000K, 大小 = 100KB, 结束地址 = $1000K + 100K = 1100K$
		*   **分区4**: 起始地址 = 200K, 大小 = 200KB, 结束地址 = $200K + 200K = 400K$
	2. 共有4个空闲分区 
2. 第二步：分析内存回收事件 #内存回收与合并  [[内存回收与合并]]
	1. 回收分区: 起始地址 = 60K, 大小 = 140KB, 结束地址 = $60K + 140K = 200K$ 
	2. #内存回收 的核心操作是**检查并合并相邻的空闲分区**。我们需要检查回收分区的上、下是否紧邻着已有的空闲分区。
	3. 检查下方（地址更低）是否相邻
		1. 回收分区的起始地址是 `60K`。我们查找空闲分区链中是否有分区的结束地址等于 `60K`。
		    *   分区1的结束地址是 `60K`。
		    *   因此，回收分区与分区1是**下方相邻**的。
	4. 检查上方（地址更高）是否相邻 
		1. 回收分区的结束地址是 `200K`。我们查找空闲分区链中是否有分区的起始地址等于 `200K`。
		    *   分区4的起始地址是 `200K`。
		    *   因此，回收分区与分区4是**上方相邻**的。
3. 第三步：执行合并操作 
	1. 回收分区同时与分区1和分区4相邻，这三个分区（分区1、回收分区、分区4）需要合并成一个大的连续空闲分区 
		*   **新分区的起始地址**: 取三个分区中最小的起始地址，即分区1的起始地址 `20K`。
		*   **新分区的大小**: 将三个分区的大小相加。
		    $Size_{new} = Size_{P1} + Size_{reclaimed} + Size_{P4} = 40KB + 140KB + 200KB = 380KB$
		*   **新分区的结束地址**: $20K + 380KB = 400K$。这也等于分区4的结束地址，验证了合并的正确性。
	2. 合并后，原来的分区1和分区4从空闲链中消失，取而代之的是这个新的大分区 
4. 第四步：更新空闲分区链并排序 
	1. 合并完成后，新的空闲分区链包含以下分区：
		*   **新合并分区**: 起始地址 = 20K, 大小 = 380KB
		*   **原分区2**: 起始地址 = 500K, 大小 = 80KB
		*   **原分区3**: 起始地址 = 1000K, 大小 = 100KB
	2. 现在系统中的空闲分区数量为 **3** 个 
	3. #最佳适应算法 
		[[动态分区存储管理（动态分区分配算法）]]  
			  **策略**: 遍历整个空闲分区链表，找到**所有**能满足大小要求的分区中，**尺寸最小**的那一个。 
		我们对更新后的空闲分区链进行排序：
		1.  分区 (500K, 80KB) -> 大小 80KB
		2.  分区 (1000K, 100KB) -> 大小 100KB
		3.  分区 (20K, 380KB) -> 大小 380KB
		
		排序后的空闲分区链为：
		*   **第1个分区**: 起始地址 = 500K, 大小 = 80KB
		*   **第2个分区**: 起始地址 = 1000K, 大小 = 100KB
		*   **第3个分区**: 起始地址 = 20K, 大小 = 380KB
1. 第五步：得出答案 
	1.   系统中空闲分区的数量：**3**
		*   空闲分区链第一个分区的起始地址：**500K**
		*   空闲分区链第一个分区的大小：**80KB** 
		* 这与选项 **B (3、500K、80KB)** 完全匹配。
- 衍生 
	- [[磁盘碎片整理]]   [[内存碎片管理]]  


![[2017-exam-paper-ocr.pdf#page=3&rect=77,450,533,505|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044302.png]]

1.  **单位换算:**
    首先，我们将所有单位统一为字节（B）。
    簇大小 = 1KB = 1024B。

2.  **计算所需簇的数量:**
    我们需要计算存放一个1026B的文件需要多少个1024B的簇。
    所需簇的数量 = $\lceil \frac{\text{文件大小}}{\text{簇大小}} \rceil$
    这里的 $\lceil ... \rceil$ 符号表示向上取整，因为即使只超出一点点，也必须分配一个完整的簇。

    代入数值：
    所需簇的数量 = $\lceil \frac{1026\text{B}}{1024\text{B}} \rceil = \lceil 1.00195... \rceil = 2$
    计算结果表明，存放这个文件需要2个簇。

3.  **计算总分配空间:**
    系统实际分配给该文件的磁盘空间是它所占用的簇的总大小。
    总分配空间 = 所需簇的数量 $\times$ 簇大小
    总分配空间 = $2 \times 1024\text{B} = 2048\text{B}$
    正确答案是 **D. 2048B**。
    
#簇  
- 衍生
	- [[文件分配表FAT]] 
		- **考点:** 可能会问一个大文件在FAT中是如何组织的，或者计算FAT表本身的大小。
	- *   **考点:** 解释为什么使用簇可以减少平均访问时间（因为簇内数据物理上连续，减少了寻道和旋转延迟）。或者直接给出转速、寻道时间等参数，计算平均访问时间。




![[2017-exam-paper-ocr.pdf#page=3&rect=74,377,415,457|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044309.png]]

#时间片轮转算法  [[常见进程调度算法与优先级关系]]

2. B. 当前进程的时间片用完后，该进程状态由执行态变为阻塞态 
	1.   **分析**：这个说法是**错误**的。
	*   **原因**：这是本题的核心考点，涉及进程的**三态模型**或**五态模型**。  [[进程状态模型]] 
	    *   **执行态 (Running)**：进程正在占用CPU运行。
	    *   **就绪态 (Ready)**：进程已经准备好运行，只等待CPU资源。
	    *   **阻塞态 (Blocked/Waiting)**：进程因等待某个事件（如I/O操作完成、等待一个信号量）而暂停执行，即使给它CPU，它也无法运行。
	*   **正确转换**：当一个进程的时间片用完，但它还没有完成任务时，它并没有在等待某个外部事件。它已经具备了继续运行的所有条件，只是CPU被调度程序分配给了其他进程。因此，它应该从**执行态 (Running)** 转换到 **就绪态 (Ready)**，排在就绪队列的末尾，等待下一轮调度。
	*   **何时变为阻塞态**：进程只有在主动请求并等待某个无法立即完成的资源或事件时，才会从执行态进入阻塞态。例如，当进程需要从硬盘读取一个文件时，它会发起一个系统调用，然后进入阻塞态，直到硬盘数据读取完毕
3. C. 时钟中断发生后，系统会修改当前进程在时间片内的剩余时间 
	1.  这个说法是**正确**的
		1. **原因**：时间片机制的实现依赖于硬件的**时钟（Timer）**。操作系统会设置一个定时器，每隔一个固定的时间（比如10毫秒）产生一次**时钟中断**。每次中断发生时，中断处理程序会运行，它会检查当前运行进程的时间片是否已经用完。具体来说，它会减少一个与时间片相关的计数器。当计数器减到0时，就意味着时间片耗尽，操作系统会触发一次进程调度。因此，时钟中断是实现时间片递减和调度的基础。
4. D. 影响时间片大小的主要因素包括响应时间、系统开销和进程数量等 
	1. 这个说法是**正确**的。
		*   **原因**：时间片大小的设定是一个权衡（Trade-off）的过程，需要考虑多个因素：
		    *   **响应时间 (Response Time)**：对于交互式系统（如桌面操作系统），用户希望操作能被快速响应。时间片越短，每个进程就能越快地得到再次执行的机会，用户的感觉就是系统响应很快。
		    *   **系统开销 (System Overhead)**：如A所述，时间片太短会导致频繁的上下文切换，系统开销增大，CPU的有效利用率下降。
		    *   **进程数量 (Number of Processes)**：如果就绪队列中的进程很多，为了保证每个进程在可接受的时间内（例如1秒内）至少被执行一次，时间片就不能设置得太长。
		*   **权衡**：
		    *   **时间片太大**：系统开销小，但响应时间变长。如果时间片大于大多数进程的执行时间，轮转调度就退化成了**先来先服务（FCFS）**调度。
		    *   **时间片太小**：响应时间短，但系统开销大，降低了整体的吞吐量。一个经验法则是，时间片的大小应该略大于一次典型的交互所需的时间，同时要保证上下文切换的开销占时间片的比例足够小（例如小于1%）。



![[2017-exam-paper-ocr.pdf#page=3&rect=73,323,513,381|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044315.png]]


#多道批处理系统  D
 





![[2017-exam-paper-ocr.pdf#page=3&rect=75,238,498,329|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044321.png]]
[[逻辑地址到物理地址的转换]]     [[磁盘使用前的三个步骤(低级格式化，分区，逻辑格式化)]] 
- 这道题的目的是考察您对磁盘投入使用前所需准备工作的理解，特别是要区分 #低级格式化 、 #分区 和 #逻辑格式化（高级格式化） 这三个不同的阶段。
#逻辑格式化
1. I. 对磁盘进行分区 
	1. 分区是将一个物理磁盘划分为一个或多个逻辑区域（如 C盘、D盘）的过程。这个操作是在逻辑格式化*之前*进行的。操作系统通常使用像 `fdisk` 或“磁盘管理”这样的工具来分区。逻辑格式化是针对一个*已经存在的分区*进行的。因此，I 不属于逻辑格式化的工作
2. II. 建立文件系统的根目录 
	1. 逻辑格式化的核心任务 就是在分区上“创建文件系统”。任何文件系统都需要一个起点来组织所有文件和文件夹，这个起点就是根目录（例如，Windows 中的 `C:\` 或 Linux 中的 `/`）。建立这个初始的、空的根目录是创建文件系统的关键一步。因此，II 是正确的
3. III. 确定磁盘扇区校验码所占位数 
	1. 这个操作属于 #低级格式化 
		1. 低级格式化在磁盘出厂时完成，它将磁盘盘面划分为磁道和扇区，并为每个扇区设置头部、数据区和尾部（包含校验码/ECC） 
			1. 这是硬件层面的操作，用于确保数据读写的物理可靠性，与操作系统建立文件系统无关。
4. IV. 对保存空闲磁盘块信息的数据结构进行初始化 ( 
	1. 文件系统必须能够跟踪哪些磁盘块是空闲的、哪些已经被文件占用。为此，文件系统会使用特定的数据结构，如 #位图 或 #空闲链表 。在逻辑格式化时，程序会初始化这个数据 结构，将分区内的所有磁盘块标记为“空闲”，为后续写入文件做准备。因此，IV 是正确的

  - 衍生 
	  - [[文件分配方式]]  
	  - [[磁盘空闲空间管理]] 
		  -   **考点：** 计算位图大小。例如，一个磁盘有 $N$ 个块，块大小为 $S$ 字节，那么位图需要 $N$ 位。占用的字节数为 $\lceil N/8 \rceil$ 字节，占用的磁盘块数为 $\lceil N/(8 \times S) \rceil$ 块。

![[2017-exam-paper-ocr.pdf#page=3&rect=74,151,528,242|2017-exam-paper-ocr, p.3]][[Pasted image 20250930044405.png]]


[[文件控制块FCB]] 
[[计算所有位数]]  
#描述文件权限的位数 
1. **表示方式 (Representation):** 使用二进制位串（bit string），即用 `1` 和 `0` 来表示。通常 `1` 代表“允许” (Grant/True)，`0` 代表“禁止” (Deny/False)。
	*   **作用对象 (Subjects):** 有4类不同的用户。
	    *   安全管理员
	    *   文件主
	    *   文件主的伙伴
	    *   其他用户
	*   **权限类型 (Permissions):** 有5种不同的访问权限。
	    *   完全控制
	    *   执行
	    *   修改
	    *   读取
	    *   写入
2. 我们需要为 **每一类用户** 都能独立地设置 **每一种权限**。这意味着，对于“安全管理员”这个用户类别，我们需要明确他是否拥有“完全控制”、“执行”、“修改”、“读取”、“写入”这五种权限。同样的过程也需要对“文件主”、“文件主的伙伴”和“其他用户”进行。 
	1. 可以将这个关系想象成一个二维表格或矩阵，行代表用户类别，列代表权限类型：

| 用户类别 (User Category) | 完全控制 (Full Control) | 执行 (Execute) | 修改 (Modify) | 读取 (Read) | 写入 (Write) |
| :--- | :---: | :---: | :---: | :---: | :---: |
| **安全管理员** | bit 1 | bit 2 | bit 3 | bit 4 | bit 5 |
| **文件主** | bit 6 | bit 7 | bit 8 | bit 9 | bit 10 |
| **文件主的伙伴** | bit 11 | bit 12 | bit 13 | bit 14 | bit 15 |
| **其他用户** | bit 16 | bit 17 | bit 18 | bit 19 | bit 20 |

在这个矩阵中，每一个单元格（cell）都代表一个独立的“是/否”决策（即该用户类别是否拥有该权限）。一个二进制位（bit）正好可以表示两种状态（0 或 1）。因此，每个单元格都需要1个bit来存储其状态。

因此，至少需要20个二进制位来描述一个文件的完整权限配置。
**结论：** 答案是 **20**，选择 **D**。

- 知识点介绍
	-  [[访问控制矩阵]] 
- 衍生 
	- [[访问控制矩阵的实现方式]] 
	-  经典的 #Unix/Linux #文件权限模型   
		*   **用户类别 (3类):**
		    *   文件主 (Owner/User, `u`)
		    *   文件主所在的组 (Group, `g`)
		    *   其他用户 (Others, `o`)
		*   **权限类型 (3种):**
		    *   读取 (Read, `r`)
		    *   写入 (Write, `w`)
		    *   执行 (Execute, `x`)
		
		如果题目背景换成标准的 Unix/Linux 模型，那么所需位数就是：
		$TotalBits = 3_{categories} \times 3_{permissions} = 9$
		这对应本题的 **选项B**。出题人很可能将此作为干扰项
	- 衍生考点:
	    *   **八进制表示法:** Unix权限常用3位八进制数表示，如 `755`。你需要知道 `r=4`, `w=2`, `x=1`，所以 `rwx` = $4+2+1=7$，`r-x` = $4+0+1=5$。`755` 就代表 `rwxr-xr-x`。
	    *   **特殊权限位:** 除了基本的9个权限位，还有 `SUID`, `SGID`, `Sticky Bit` 等特殊权限位，可能会一起考察。
	- #最小权限原则 
		- 这是安全设计的一个核心原则，即只授予主体完成其任务所必需的最小权限。考题可能会结合场景，让你判断如何设置权限才符合最小权限原则。
	 - #基于角色的访问控制RBAC 
		 - 这是比ACL更现代和灵活的模型。权限不直接授予用户，而是授予“角色”（如“数据库管理员”、“审计员”），然后将用户分配到不同的角色中。这样管理起来更方便，尤其是在大型组织中。
		*   **考点:** 可能会让你比较RBAC与ACL的异同和适用场景。

![[2017-exam-paper-ocr.pdf#page=3&rect=73,67,530,148|2017-exam-paper-ocr, p.3]]
[[Pasted image 20250930044410.png]]

[[文件描述符、打开文件表和FCB(inode)的关系]] 

1. 为了准确回答这个问题，我们需要理解 Unix/Linux 系统中文件打开的内部机制，这涉及到三个关键的数据结构：
	 -  #进程文件描述符表 (Per-Process File Descriptor Table)：每个进程独有。每个进程都有自己独立的一张表。这张表是一个数组，索引就是文件描述符 (file descriptor, fd)，例如 0, 1, 2, ...。表中的每个条目是一个指针，指向系统级的打开文件表中的一个条目
    *   #系统打开文件表 (System-Wide Open File Table)：整个系统共享。整个操作系统只有一张。当任何进程打开一个文件时，内核会在这张表中创建一个条目。这个条目包含了文件的状态信息，如读写模式（只读、读写等），以及最重要的—— 当前 #文件的读写偏移量（即读写指针） 
    *   #内存FCB/inode表 (In-Memory inode Table) ：作为磁盘上FCB/inode的缓存。整个操作系统也只有一张。它是在文件被访问时，从磁盘上的索引节点 (on-disk inode) 加载到内存中的副本。索引节点 (inode) 包含了文件的元数据，如文件大小、所有者、权限、时间戳以及指向文件数据块的指针等 
    *   关系：文件描述符 -> 进程表项 -> 系统表项 -> 内存inode -> 磁盘inode。
2. 叙述 I: `f1` 和 `f2` 的读写指针位置保持相同 
	1. 读写指针（或文件偏移量）是存放在 #系统打开文件表 的条目中的 
	2. 当进程1执行 `open("f1", ...)` 时，内核会在系统级打开文件表中创建一个**新的条目**，并将其中的读写指针初始化为0（通常情况下）。然后，进程1的文件描述符 `$fd1$` 会通过其进程级文件描述符表指向这个新创建的系统级条目。
		*   当进程2执行 `open("f2", ...)` 时，即使 `f2` 和 `f1` 指向同一个 inode，`open` 系统调用本身会为这次打开操作在系统级打开文件表中创建**另一个全新的条目**。这个新条目的读写指针同样被初始化为0。进程2的文件描述符 $fd2$ 会指向这个条目。
		*   因为 $fd1$ 和 $fd2$ 指向的是系统级打开文件表中**两个不同**的条目，所以它们各自拥有独立的读写指针。一个进程对文件进行读写操作，移动自己的读写指针，不会影响另一个进程的读写指针。
		*   **结论：** 叙述 I 是**错误**的
3. 叙述 II: f1 和 f2 共享同一个内存索引结点 
	1. #硬链接的本质 就是多个不同的文件名（目录条目）指向了磁盘上**同一个 inode**。inode 存储了文件的所有实际信息（除了文件名）。
		1. 当进程1打开 `f1` 时，内核会找到 `f1` 对应的 inode，并将其加载到内存索引节点表中。系统级打开文件表中的条目会包含一个指向这个内存 inode 的指针。
			*   当进程2打开 `f2` 时，内核会发现 `f2` 指向的 inode 和 `f1` 是同一个。如果这个 inode 已经在内存中了，内核就不会重复加载，而是让进程2对应的系统级打开文件表条目也指向这个**已经存在**的内存 inode。
			*   因此，通过 `f1` 和 `f2` 这两个不同的路径访问到的最终是同一个文件实体，它们共享同一个 inode。
			*   **结论：** 叙述 II 是**正确**的。
4. 叙述 III: `fd1` 和 `fd2` 分别指向各自的用户打开文件表中的一项。 
	1. 这是文件描述符的基本工作原理。文件描述符 $fd1$ 是进程1在其**自己的**进程级文件描述符表中的一个索引。文件描述符 $fd2$ 是进程2在其**自己的**进程级文件描述符表中的一个索引。
		*   每个进程都有一个独立的、私有的 #进程文件描述符表  。进程1无法直接访问进程2的文件描述符表，反之亦然。所以 $fd1$ 和 $fd2$ 必然指向各自进程的私有表项。
		*   **结论：** 叙述 III 是**正确**的。 
- [[软连接和硬连接]] 
- 衍生  
	- [[索引节点 (inode)]]
		-   inode 中包含哪些信息？不包含哪些信息？ 
			-    **包含：** 文件类型、权限、所有者ID、组ID、链接数、文件大小、时间戳（访问、修改、状态改变）、指向数据块的指针数组。
		    *   **不包含：** **文件名**。文件名是存储在目录文件的数据块中的，它和 inode 号构成一个映射关系。这也是为什么一个文件可以有多个名字（硬链接）。 
	* `dup()` 和 `dup2()` 系统调用
		* **考点：** 在一个进程内部，如何让不同的文件描述符指向同一个打开的文件？
	    *   **答案：** 使用 `dup()` 或 `dup2()`。例如 `new_fd = dup(old_fd)`。这会在进程的文件描述符表中创建一个新的条目 `$new_fd$`，但它指向的系统级打开文件表项与 `$old_fd$` 指向的**是同一个**。
	    *   **推论：** 在同一个进程中，通过 `dup()` 创建的两个文件描述符会共享同一个读写指针。这常用于实现I/O重定向。
			


![[2017-exam-paper-ocr.pdf#page=4&rect=80,741,499,818|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044415.png]]
B
#数据读取 
#DMA工作流程  [[DMA工作流程]]
#数据传输过程   
[[总线与主存技术]]

- [[DMA的传送方式]] 
	- DMA控制器在需要使用总线时，必须与CPU争夺总线控制权。根据DMAC如何占用总线，主要有三种传送方式
- [[DMA性能计算]]  考试中可能会出现计算DMA对CPU性能影响的题目。 
	- 假设某计算机CPU时钟频率为500MHz，每次总线访问需要1个时钟周期。一个磁盘设备采用DMA方式传输数据，数据传输率为2MB/s。每次DMA传输窃取1个总线周期来传送一个32位（4字节）的数据。请问DMA传输占用了多少CPU时间？ 
- #缓存一致性问题  
	- 这是一个更高级的考点。当DMA直接向内存写入数据时，如果CPU的缓存中存有该内存地址的旧数据副本，CPU将不会知道内存中的数据已被更新，从而导致数据不一致。解决这个问题需要特殊的硬件机制，如：
	*   #缓存刷新 (Cache Flushing)：在DMA传输前，将缓存中相关的“脏”数据写回内存；在DMA传输后，将缓存中相关的条目置为无效。
	*   #总线嗅探 (Bus Snooping) ：缓存控制器会“监听”总线上的活动。当它检测到有DMA操作正在写入某个内存地址，而这个地址的数据又存在于自己的缓存中时，它会自动将该缓存条目置为无效。









![[2017-exam-paper-ocr.pdf#page=4&rect=79,692,526,743|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044421.png]]

[[OSI七层模型]]
[[数据封装过程]]
[[TCP-IP 协议栈封装与解封装]]  
 [[数据传输效率]]
#数据传输效率  
#应用层 
这道题的目的是计算在OSI模型中，应用层数据的传输效率。解题步骤如下：

1.  **确定有效数据 (Useful Data):**
    题目中明确指出，应用层要发送的数据是 $400B$。这就是我们关心的“有效载荷”或“有用数据”。

2.  **确定额外开销 (Overhead):**
    *   OSI参考模型共有7层：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层。
    *   数据在发送时，从上到下逐层封装。每经过一层，通常会增加一个该层的“报头”（Header），这就是额外开销。
    *   题目规定：**应用层**（数据源头）和**物理层**（只处理比特流，不加报头）之外的**其他各层**都会增加开销。
    *   这些层包括：表示层、会话层、传输层、网络层、数据链路层。总共是 $7 - 2 = 5$ 层。
    *   每层增加的开销是 $20B$。
    *   所以，总的额外开销为：$总开销 = 5 \text{层} \times 20B/\text{层} = 100B$。

3.  **计算总传输数据 (Total Data):**
    实际在物理线路上传输的总数据量，是有效数据和所有额外开销的总和。
    $总数据 = 有效数据 + 总开销 = 400B + 100B = 500B$

4.  **计算传输效率 (Efficiency):**
    数据传输效率的定义是有效数据占总传输数据的比例。
    $效率 = \frac{有效数据}{总数据} \times 100\%$
    代入数值：
    $效率 = \frac{400B}{500B} \times 100\% = 0.8 \times 100\% = 80\%$

- 衍生
	- [[数据拆分]]  
	- 计算特定层的效率: 
		- 题目可能不问应用层效率，而是问**传输层**或**网络层**的传输效率。
	    *   **考点:** 如果问网络层的效率，那么“有效数据”就不仅仅是应用层的 $400B$，而是包括了上层（表示层、会话层、传输层）封装后的总数据。
	    *   **示例计算:** 在本题背景下，网络层的有效数据 = $400B + 20B_{表示层} + 20B_{会话层} + 20B_{传输层} = 460B$。总数据依然是 $500B$。则网络层的效率 = $\frac{460B}{500B} = 92\%$
	- 结合传输速率计算时间 
		- 题目可能给出信道带宽，要求计算总的传输时间。
		    *   **考点:** 需要先计算出总数据量（包含开销），然后除以传输速率。注意单位换算，通常带宽单位是 $bps$ (bits per second)，而数据大小是 $B$ (Byte)，需要乘以8。
		    *   **示例计算:** 假设信道带宽为 $100 Mbps$，传输本题的 $500B$ 数据需要的时间 = $\frac{500B \times 8 \text{ bit/B}}{100 \times 10^6 \text{ bit/s}} = \frac{4000}{10^8} s = 40 \mu s$。
			

![[2017-exam-paper-ocr.pdf#page=4&rect=76,643,516,691|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044425.png]]

1. [[奈氏准则]]  
	$C_{Nyquist} = 2W\log_2N$  
	*   $C_{Nyquist}$ 是极限数据传输速率，单位是比特/秒 (bps)。
	*   $W$ 是信道带宽，单位是赫兹 (Hz)。
	*   $N$ 是信号的状态数或离散电平数（例如，如果一个信号有4种不同的电压值，则 $N=4$）。
2. [[香农定理]] 
	1. $C_{Shannon} = W\log_2(1 + S/N)$ 
        *   $C_{Shannon}$ 是极限数据传输速率（信道容量），单位是比特/秒 (bps)。
        *   $W$ 是信道带宽，单位是赫兹 (Hz)。
        *   $S/N$ 是信噪比（Signal-to-Noise Ratio），即信号功率与噪声功率的比值。**注意：公式中的 $S/N$ 是一个线性比值，不是分贝(dB)
3.  #信噪比SNR   [[信噪比]] 
	1. 信噪比通常用分贝 (dB) 表示，其转换公式为：$SNR_{dB} = 10\log_{10}(S/N)$
    *   因此，从分贝值反算出线性比值 $S/N$ 的公式为：$S/N = 10^{(SNR_{dB}/10)}$
- 条件是：“无噪声情况下的极限数据传输速率 **不小于** 信噪比为 30dB 条件下的极限数据传输速率”  

1.  **将文字条件转换为数学不等式**：
    *   无噪声下的极限速率（使用奈氏准则）：$C_{Nyquist} = 2W\log_2N$
    *   有噪声下的极限速率（使用香农定理）：$C_{Shannon} = W\log_2(1 + S/N)$
    *   根据题意，我们得到不等式：$C_{Nyquist} \ge C_{Shannon}$
    *   代入公式：$2W\log_2N \ge W\log_2(1 + S/N)$

2.  **处理信噪比 (S/N)**：
    *   题目给出的信噪比是 $30$dB。我们需要将其转换为线性的 $S/N$ 值。
    *   使用转换公式：$30 = 10\log_{10}(S/N)$
    *   解这个方程：
        *   $3 = \log_{10}(S/N)$
        *   $S/N = 10^3 = 1000$

3.  **求解不等式**：
    *   将 $S/N = 1000$ 代入步骤1中的不等式：
        $2W\log_2N \ge W\log_2(1 + 1000)$
    *   假设带宽 $W > 0$，可以将 $W$ 从两边约掉：
        $2\log_2N \ge \log_2(1001)$
    *   利用对数运算法则 $a\log_b(x) = \log_b(x^a)$：
        $\log_2(N^2) \ge \log_2(1001)$
    *   由于对数函数 $\log_2(x)$ 是单调递增的，我们可以去掉两边的对数符号，不等式方向不变：
        $N^2 \ge 1001$
    *   求解 $N$：
        $N \ge \sqrt{1001}$
    *   我们知道 $31^2 = 961$ 且 $32^2 = 1024$。所以 $\sqrt{1001}$ 的值约等于 $31.64$。
    *   $N \ge 31.64$
    *   因为信号状态数 $N$ 必须是一个整数，所以满足该条件的最小整数 $N$ 是 **32**。

4.  **得出结论**：
    信号状态数至少是 32。因此，选择答案 **D**。


- 衍生 
	- #奈氏准则应用 给定带宽 $W$ 和信号状态数 $N$，求无噪声信道的极限速率。例如：带宽为 3kHz，采用 8 个相位进行调制的无噪声信道，最大数据速率是多少？
        *   解：$C = 2 \times 3000 \times \log_2(8) = 6000 \times 3 = 18000$ bps = 18 kbps。
    *   **香农定理应用**：给定带宽 $W$ 和信噪比 $S/N$（可能以 dB 形式给出），求信道的极限容量。例如：电话信道带宽为 3.1kHz，信噪比为 30dB，其最大数据传输速率是多少？
        *   解：$S/N = 10^{(30/10)} = 1000$。$C = 3100 \times \log_2(1 + 1000) \approx 3100 \times \log_2(1001) \approx 3100 \times 9.97 \approx 30900$ bps ≈ 30.9 kbps。
	- 奈氏准则 vs 香农定理 
		- 比较两者的异同。奈氏准则关注的是在无噪声情况下，通过增加信号状态数 $N$ 来提高速率；而香农定理指出，在有噪声的情况下，信噪比 $S/N$ 决定了速率的理论上限，即使信号状态数 $N$ 无限多，速率也不能超过香农容量。
	- #比特率与波特率的关系   
		-  波特率 (Baud Rate)：指码元（信号状态）每秒钟变化的次数，单位是波特 (Baud)。在奈氏准则中，最大码元速率是 $2W$。
        *   比特率 (Bit Rate)：指每秒钟传输的二进制比特数，单位是 bps。
        *   **关系**：比特率 = 波特率 $\times \log_2N$。这道题实际上就是在比较两个比特率。
	- 综合应用  
		- 考察在实际信道中，数据速率同时受到奈氏准则和香农定理的限制。一个信道的实际最大速率是两者计算出的较小值。
	    *   例如：一个带宽为 3kHz 的信道，信噪比为 20dB，采用 4 电平信号（$N=4$）传输，其实际能达到的最大速率是多少？
	        *   按奈氏准则：$C_{Nyquist} = 2 \times 3000 \times \log_2(4) = 12000$ bps = 12 kbps。
	        *   按香农定理：$S/N = 10^{(20/10)} = 100$。$C_{Shannon} = 3000 \times \log_2(1 + 100) \approx 3000 \times 6.65 \approx 19950$ bps = 19.95 kbps。
	        *   由于信号本身只有 4 个电平，其速率上限被奈氏准则限制在 12 kbps，远低于香农容量。因此，实际最大速率为 12 kbps



![[2017-exam-paper-ocr.pdf#page=4&rect=76,459,528,642|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044432.png]]
[[IP分组的生命周期]]  [[IP头部略讲]] 
[[以太网帧结构]]  
- 核心是理解在无线局域网（WLAN）中，当一个设备通过接入点（AP）与有线网络通信时，IEEE 802.11 数据帧的地址字段是如何被填充的  
1.     **路径:** 数据帧 F 从主机 H 发出，通过无线链路到达 AP。AP 收到后，再通过有线链路转发给路由器 R。 #IEEE802标准
	1.  **帧类型:** 题目明确指出是 IEEE 802.11 数据帧。数据从无线站点（Station）发送到分发系统（Distribution System, DS，可以理解为连接 AP 的有线网络），这属于 "To AP" 类型，更专业地说是 `To DS = 1`, `From DS = 0` 的情况。
2. 理解 IEEE 802.11 数据帧的地址字段 
	1. 只有 #源MAC地址  和 #目的MAC地址  两个地址的 #以太网帧 不同 ，标准的 #IEEE802-11数据帧头  包含三个或四个 #地址字段 。地址字段的含义取决于 #帧控制字段 （Frame Control）中的 `To DS` 和 `From DS` 两位

| To DS | From DS | 场景               | 地址1 (RA)  | 地址2 (TA) | 地址3    | 地址4     |
| :---: | :-----: | :--------------- | :-------- | :------- | :----- | :------ |
|   0   |    0    | Ad-hoc (IBSS)    | DA        | SA       | BSSID  | N/A     |
|   0   |    1    | From AP          | DA        | BSSID    | SA     | N/A     |
| **1** |  **0**  | **To AP (本题场景)** | **BSSID** | **SA**   | **DA** | **N/A** |
|   1   |    1    | WDS (无线桥接)       | RA        | TA       | DA     | SA      |
*   **RA (Receiver Address):** #接收地址RA 。无线链路上，直接接收该帧的设备的 MAC 地址。
*   **TA (Transmitter Address):** #发送地址TA 。无线链路上，直接发送该帧的设备的 MAC 地址。
*   **SA (Source Address):** #源地址SA 。整个数据传输路径中，最初发起通信的设备的 MAC 地址。
*   **DA (Destination Address):** #目的地址DA  。整个数据传输路径中，最终要到达的设备的 MAC 地址。
*   **BSSID (Basic Service Set Identifier):** #基本服务集标识符BSSID 。在基础设施模式下，它就是 AP 的 MAC 地址。

3. 应用到本题场景 (`To DS = 1`, `From DS = 0`)  
	1.  **地址1 (Address 1):** 对应 **RA (Receiver Address)**。在 H -> AP 这段无线链路上，谁是直接接收者？是 **AP**。因此，地址1是 AP 的 MAC 地址。在基础设施网络中，这个地址也同时是 **BSSID**。
	    *   地址1 = AP MAC = `00-12-34-56-78-9b`
	
	*   **地址2 (Address 2):** 对应 **SA (Source Address)**。谁是最初的数据发送者？是 **主机 H**。因此，地址2是 H 的 MAC 地址。
	    *   地址2 = H MAC = `00-12-34-56-78-9a`
	
	*   **地址3 (Address 3):** 对应 **DA (Destination Address)**。数据的最终目的地在 Internet 上，但 MAC 地址是工作在数据链路层的，它只能表示本局域网内的下一跳地址。数据要上 Internet，下一跳设备是**路由器 R**。因此，地址3是路由器 R 的 MAC 地址。
	    *   地址3 = R MAC = `00-12-34-56-78-9c`
4. 结论  
	*   地址1: `00-12-34-56-78-9b`
	*   地址2: `00-12-34-56-78-9a`
	*   地址3: `00-12-34-56-78-9c`
	1. 正确答案是 B 
5. 
6. [[IEEE802.11 帧格式与地址解析]] 
	1. 总结一下，Wi-Fi 地址复杂的根本原因：

	2.  **有一个“中间人” (AP):** 无线设备（手机、电脑）不能直接和路由器对话，它必须通过 AP 作为“翻译”和“桥梁”。AP 连接着**无线世界**和**有线世界 (DS)**。因此，一个数据帧必须同时说清楚两件事：
	    *   **在无线世界里，是谁发给谁？** (这就是 **TA** 和 **RA** 的作用)
	    *   **在整个网络旅程中，最初是谁发给最终谁？** (这就是 **SA** 和 **DA** 的作用)
	
	3.  **需要支持多种通信模式：** Wi-Fi 的设计者必须考虑到各种复杂场景，而不仅仅是你上网这一种。他们用一套地址规则，通过调整 `To DS` 和 `From DS` 两个标志位，就能完美适配所有情况：
	    *   **场景A (本题):** 你的电脑发数据给 AP，想上网。 (`To DS=1, From DS=0`)
	    *   **场景B:** AP 把从网上下载的数据发给你的电脑。 (`To DS=0, From DS=1`)
	    *   **场景C:** 两台笔记本电脑不用 AP，直接互传文件 (Ad-hoc 模式)。 (`To DS=0, From DS=0`)
	    *   **场景D:** 两个 AP 之间用无线连接来扩展信号 (WDS 桥接)。 (`To DS=1, From DS=1`)
	
	如果只用简单的“源/目的”两个地址，根本无法区分和处理这么多种复杂的场景。
		简单来说：
	*   **以太网的两个地址，回答的是：“最终谁发给最终谁？”**
	*   **Wi-Fi 的三个（或四个）地址，回答的是：“最终谁发给最终谁，其中在无线这段路上，具体是谁发给了谁？”**
- 衍生 
	- [[BSSIDvsESSID]] 
	- [[控制帧和管理帧]] 
	通过掌握 To DS 和 From DS 这两个比特位如何决定四个地址字段含义的核心规则，你就可以解决所有关于 802.11 数据帧地址的题目。
	
	
	

![[2017-exam-paper-ocr.pdf#page=4&rect=73,421,500,458|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044440.png]]


#判断IP地址的合法性   
#目的IP地址  
#判读源IP地址和目标IP地址  
1. A. 0.0.0.0 
	1. 这个地址在IP协议中被称为“未指定地址”（Unspecified Address）。它不能被用作目的地址 
	2. 作用  
		1. 它通常只在主机初始化阶段，还不知道自己IP地址时使用。最典型的场景是 #DHCP   当一台主机启动并希望从DHCP服务器获取IP地址时，它会发送一个DHCP发现报文（DHCPDISCOVER）。在这个报文的IP头部，源IP地址就是`0.0.0.0`，因为主机此时还“没有”IP地址。这个报文的目的地址通常是广播地址`255.255.255.255`。
    *   **结论**：`0.0.0.0`可以作为源地址，但不能作为目的地址。这完全符合题意
2. B. 127.0.0.1  
	1. 这是一个 #回环地址 （Loopback Address）。整个`127.0.0.0/8`网段都保留用于回环测试，但最常用的是`127.0.0.1`，通常与主机名`localhost`关联 
	2.   **作用**：当数据包的目的地址是回环地址时，协议栈会立即将数据包“环回”到本机，而不会将其发送到任何物理网络上。它主要用于测试本机的网络协议栈是否工作正常，或者用于本机上不同进程间的网络通信。
	    *   **结论**：它主要用作**目的地址**。一个数据包的源地址通常不会是`127.0.0.1`（尽管在某些特定情况下可能出现，但在网络通信中它不是一个有效的源地址）。因此，它不符合题意
3. C. 200.10.10.3  
	1. 这是一个普通的**C类单播地址**（Unicast Address）。
	    *   **作用**：这种地址用于唯一标识网络中的一台主机。它可以作为发送数据包的源地址，也可以作为接收数据包的目的地址。
	    *   **结论**：它可以同时作为源地址和目的地址，不符合题意。
4. D. 255.255.255.255 
	1. 这是一个**受限广播地址**（Limited Broadcast Address），也叫本地广播地址。
	    *   **作用**：当一个数据包的目的地址是`255.255.255.255`时，它会被发送到发送方所在的物理网段上的所有主机。路由器不会转发这种广播包。
	    *   **结论**：它只能用作**目的地址**，永远不能作为源地址（因为广播不是一台具体的主机，无法发起通信）。这与题意“只能作为源地址”正好相反。
- 综合以上分析，只有`0.0.0.0`满足“只能作为源IP地址但不能作为目的IP地址”的条件。  

  [[特殊地址计算（网络地址，广播地址）]]  [[回环地址]]  

- [[IPv4中的特殊地址]]   
-  衍生 
	- [[可用IP地址范围]]  [[IP地址分类]]  
	- #计算CIDR与子网划分    
		- 网络部分的计算重点，要求根据给定的IP地址和子网掩码（或CIDR前缀长度）计算出：
		    *   网络地址
		    *   广播地址
		    *   可用主机地址范围
		    *   可用主机数量
		- **计算公式：**
		    假设子网掩码中有$n$位网络位和$h$位主机位，其中$n+h=32$。
		    *   **子网数量**: 如果从原网络中借用$s$位主机位来划分子网，则可以划分出$2^s$个子网。
		    *   **每个子网的主机总数**: $2^h$
		    *   **每个子网的可用主机数**: $2^h-2$ (需要减去网络地址和广播地址)
		    **示例：**
		    计算IP地址 `192.168.50.130/27` 的网络地址、广播地址和可用主机数。
		    *   **/27** 表示子网掩码有27个1，即 `255.255.255.224`。
		    *   主机位有 $h = 32 - 27 = 5$ 位。
		    *   **网络地址**: 将IP地址与子网掩码进行**按位与**运算。
		        `130`的二进制是 `10000010`。`224`的二进制是 `11100000`。
		        `10000010` AND `11100000` = `10000000`，即十进制的`128`。
		        所以网络地址是 `192.168.50.128`。
		    *   **广播地址**: 将网络地址的主机位全部置为1。
		        网络地址的最后八位是`10000000`。将后5位主机位变为1，得到 `10011111`，即十进制的`159`。
		        所以广播地址是 `192.168.50.159`。
		    *   **可用主机数**: $2^5-2 = 32-2 = 30$。
		    *   **可用主机范围**: `192.168.50.129` 到 `192.168.50.158`。


![[2017-exam-paper-ocr.pdf#page=4&rect=79,387,506,424|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044451.png]]
[[数据封装过程]]
1. [[RIP协议]] 
	1. 它的工作方式是定期地（通常是每30秒）向邻居路由器广播自己的整个路由表。这种“发了就不管”的通信模式非常适合使用无连接的传输协议。
	    *   因此，RIP 选择使用 **UDP** (User Datagram Protocol) 来封装其报文。UDP 开销小，没有建立连接的延迟，非常适合 RIP 这种频繁、小数据量的广播通信。RIP 使用的 UDP 端口号是 520。
2. [[OSPF协议]]  
	1.   为了更精细地控制网络资源的利用和实现自己的可靠性机制（如确认和重传），OSPF 的设计者决定**直接使用 IP** 来封装其报文。它绕过了传输层，将 OSPF 报文直接放在 IP 数据报的数据部分。在 IP 协议头中，协议字段的值会被设置为 **89**，以表明上层协议是 OSPF。 
3. [[边界网关协议BGP]]  
	1.   为了保证这种高度的可靠性，BGP 选择了 **TCP** (Transmission Control Protocol) 作为其传输层协议。TCP 提供了面向连接、可靠的字节流服务，包括错误校验、重传、流量控制等机制，完美满足了 BGP 的需求。BGP 使用的 TCP 端口号是 **179**

**结论：**
*   RIP 使用 **UDP**
*   OSPF 使用 **IP**
*   BGP 使用 **TCP**
-   因此，正确的顺序是 UDP、IP、TCP。对应选项 **D**
- 知识点
	- [[路由协议中的汇总]]   [[路由协议分类]] 
	-  #传输层协议选择的原因
		*   **为什么 RIP 用 UDP？**
		    *   **简单高效：** RIP 报文小且发送频繁，UDP 的无连接特性和较小的头部开销使其非常高效。
		    *   **广播/组播支持：** RIP v1 使用广播，RIP v2 使用组播，UDP 都能很好地支持。
		    *   **自带可靠性机制：** RIP 自身通过周期性更新来保证路由信息的最终一致性，即使个别报文丢失，后续的更新也会纠正。
		
		*   **为什么 OSPF 直接用 IP？**
		    *   **控制权：** OSPF 是一个底层的网络控制协议，它需要对网络传输有更直接的控制，例如自己管理邻居关系、报文的确认和重传机制。使用 TCP/UDP 会增加不必要的开销和复杂性。
		    *   **效率：** 绕过传输层可以减少协议栈的处理开销。
		    *   **独立性：** OSPF 不依赖于传输层的功能，使其设计更加独立和健壮。
		
		*   **为什么 BGP 用 TCP？**
		    *   **可靠性：** BGP 承载着整个互联网的路由，其路由信息的交换必须是 100% 可靠的。TCP 的确认、重传和排序机制确保了这一点。
		    *   **数据量大：** 互联网的路由表非常庞大，BGP 需要传输大量数据。TCP 的滑动窗口和流量控制机制可以有效地处理大规模数据传输。
		    *   **会话管理：** BGP 路由器之间需要建立一个稳定的邻居关系（会话），TCP 的面向连接特性（三次握手、四次挥手）天然地支持了这种会-话的建立、维护和终止。
- 衍生 
	-  #度量值Metric 
	    *   #RIP的度量值 ： 跳数 (Hop Count)。最大有效跳数为 $15$，跳数 $16$ 表示目标网络不可达。这是 RIP 的一个主要限制。
	    *   #OSPF的度量值 ： 开销 (Cost)。Cost 是一个与接口带宽相关的计算值，带宽越高，Cost 越低。计算公式通常为：$Cost = \frac{参考带宽}{接口带宽}$。例如，如果参考带宽为 100 Mbps，一个 100 Mbps 接口的 Cost 就是 $1$，一个 10 Mbps 接口的 Cost 就是 $10$。路径的总 Cost 是路径上所有出接口 Cost 的累加。
	    *   #BGP的度量值 ： BGP 不使用单一的度量值，而是使用一系列复杂的**路径属性**（Path Attributes）来选择最佳路径，如 AS_PATH, LOCAL_PREF, MED 等。这使得 BGP 能够实现非常灵活的路由策略。
	- 问题与解决方案 
		-    #RIP的问题 ：
	        *   **慢收敛：** 网络拓扑变化后，需要较长时间才能传播到所有路由器。
	        *   **路由环路与无穷计数问题：** 距离向量算法的固有缺陷，可以通过水平分割、毒性反转、触发更新等机制来缓解。
	    *   #OSPF的区域 (Area) 概念：
	        *   为了解决大型网络中 OSPF 带来的巨大计算和通信开销，OSPF 引入了区域的概念。所有区域都必须连接到骨干区域 (Area 0)。这会考查不同类型的路由器，如 ABR (区域边界路由器) 和 ASBR (自治系统边界路由器)。
	    *   #BGP的邻居关系 ：
	        *   **iBGP (Internal BGP):** 在同一个 AS 内部的 BGP 邻居关系。
	        *   **eBGP (External BGP):** 在不同 AS 之间的 BGP 邻居关系。
	        *   iBGP 的水平分割规则：为了防止环路，从一个 iBGP 邻居学到的路由不会再通告给其他 iBGP 邻居。这引出了路由反射器 (Route Reflector) 和联邦 (Confederation) 等解决方案。
	[[协议与端口号]]
	


![[2017-exam-paper-ocr.pdf#page=4&rect=78,339,521,389|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044457.png]]

[[IP子网划分]]  
[[IP地址与子网掩码]]  
1. 第一步：分析初始网络状态  
	1. 初始网络地址为 `21.3.0.0/16`。
		*   根据 `/16`，我们知道网络号占16位，主机号占 $32 - 16 = 16$ 位。
		*   这16位主机号提供了 $2^{16}$ 个地址空间，我们将从这里开始划分。
2. 第二步： #计算子网号所需的位数 
	1. 要求将网络划分为 `128` 个子网。
		*   我们需要确定需要多少位才能表示 `128` 个不同的子网。这可以通过解方程 $2^n \ge 128$ 来得到，其中 $n$ 是子网号的位数 
	2. 知道 $2^7 = 128$，所以我们需要从主机号部分借用 **7位** 作为子网号  
3. 第三步：计算每个子网新的 #主机号位数  
	1. 从原来的16位主机号中借走了7位用作子网号。
		*   那么每个子网中剩下的用于表示主机的位数就是：
		    $h = \text{原主机号位数} - \text{子网号位数} = 16 - 7 = 9$ 位。
4. 第四步：计算每个子网可分配的 #最大IP地址数   #IP地址  
	1. 子网有9位主机号。
		*   因此，每个子网包含的总IP地址数是 $2^9$。
		    $2^9 = 512$ 个 
	2. 如前所述，每个子网中，主机号全为0的地址是网络地址，全为1的地址是广播地址。这两个地址不能分配给主机。
		*   所以，每个子网可分配的最大IP地址数是总地址数减2。
		    $\text{可分配地址数} = 2^h - 2 = 2^9 - 2 = 512 - 2 = 510$ 个。
	- **结论**: 每个子网可分配的最大IP地址个数是 `510`，所以选择答案 **C** 
- 衍生 
	- 计算新的子网掩码 
		- 原网络的掩码是 `/16`，即 `255.255.0.0`。
	    *   我们借用了7位，所以新的网络前缀长度是 $16 + 7 = 23$ 位，即 `/23`。
	    *   `/23` 对应的二进制掩码是前23个1，后面9个0：
	        `11111111.11111111.11111110.00000000`
	    *   转换为点分十进制就是 `255.255.254.0`。
	    *   **考题可能问**：划分后，新的子网掩码是什么？
	- 确定特定 #子网的地址范围 
		- **考题可能问**：请写出第3个子网的网络地址、广播地址以及可用的IP地址范围。
	    *   **解析**：
	        *   子网号是7位，主机号是9位。地址变化发生在第三个八位字节。
	        *   第1个子网的子网号是 `0000000` (二进制)。网络地址是 `21.3.0.0/23`。广播地址是 `21.3.1.255`。
	        *   第2个子网的子网号是 `0000001` (二进制)。网络地址是 `21.3.2.0/23`。广播地址是 `21.3.3.255`。
	        *   第3个子网的子网号是 `0000010` (二进制，十进制为2)。网络地址是 `21.3.4.0/23`。广播地址是 `21.3.5.255`。可用IP范围是 `21.3.4.1` 到 `21.3.5.254`。
	- 反向计算：根据主机数量确定子网划分 
		-    **考题可能问**：若网络 `21.3.0.0/16` 需要划分为多个子网，要求每个子网至少能容纳 `200` 台主机，最多可以划分出多少个这样的子网？
	    *   **解析**：
	        *   首先计算满足主机数要求所需的主机号位数 $h$。
	        *   公式为 $2^h - 2 \ge 200$。
	        *   $2^h \ge 202$。我们知道 $2^7 = 128$ (不够)，$2^8 = 256$ (满足)。所以需要 $h=8$ 位主机号。
	        *   原主机号有16位，保留8位给新主机号，则可以借用 $16 - 8 = 8$ 位作为子网号。
	        *   可划分的子网数量为 $2^8 = 256$ 个。

![[2017-exam-paper-ocr.pdf#page=4&rect=75,291,526,340|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044502.png]]


#发送窗口   
[[TCP的两个窗口机制]]  

1. 理解发送窗口
	1. TCP的发送方在任意时刻能够发送的数据量取决于两个因素：接收方的处理能力和网络的拥塞状况。这两个因素分别由 **接收窗口 (rwnd)** 和 **拥塞窗口 (cwnd)** 来量化。实际的发送窗口是这两者的最小值。
	    其数学公式为：
	    $W_{send} = \min(cwnd, rwnd)$
	2. 在本题中，接收窗口 $rwnd = 64 \text{KB}$。我们的目标是让发送窗口达到 $32 \text{KB}$。由于 $32 \text{KB} < 64 \text{KB}$，接收窗口在我们的目标范围内不是限制因素。因此，问题简化为：拥塞窗口 (cwnd) 从初始值增长到 $32 \text{KB}$ 需要多长时间？
2. 应用   #慢启动算法 [[TCP流量控制与拥塞控制]]
	1. 在连接刚刚建立时，拥塞窗口 $cwnd$ 的初始值通常设置为 $1 \text{ MSS}$。
	    *   在慢开始阶段，每经过一个 $RTT$（即发送方收到之前发送数据的ACK确认后），$cwnd$ 的大小就翻倍。
	2. 经过 5 个 #往返时延RTT  (时间 = $5 \times 5\text{ms} = 25\text{ms}$) 
		1.    时刻 0 (连接建立成功):
	        $cwnd = 1 \text{ MSS} = 1 \text{KB}$。
	        甲发送 $1 \text{KB}$ 的数据。
		*   **经过 1 个 RTT (时间 = $1 \times 5\text{ms} = 5\text{ms}$):**
			甲收到了对第一个 $1 \text{KB}$ 数据的ACK。
			根据慢开始算法，$cwnd$ 翻倍：$cwnd = 2 \times 1 \text{KB} = 2 \text{KB}$。
	
		*   **经过 2 个 RTT (时间 = $2 \times 5\text{ms} = 10\text{ms}$):**
			甲收到了对第二个 $2 \text{KB}$ 数据的ACK。
			$cwnd$ 再次翻倍：$cwnd = 2 \times 2 \text{KB} = 4 \text{KB}$。
	
		*   **经过 3 个 RTT (时间 = $3 \times 5\text{ms} = 15\text{ms}$):**
			甲收到了对 $4 \text{KB}$ 数据的ACK。
			$cwnd$ 翻倍：$cwnd = 2 \times 4 \text{KB} = 8 \text{KB}$。
	
		*   **经过 4 个 RTT (时间 = $4 \times 5\text{ms} = 20\text{ms}$):**
			甲收到了对 $8 \text{KB}$ 数据的ACK。
			$cwnd$ 翻倍：$cwnd = 2 \times 8 \text{KB} = 16 \text{KB}$。
	
		*   **经过 5 个 RTT (时间 = $5 \times 5\text{ms} = 25\text{ms}$):**
			甲收到了对 $16 \text{KB}$ 数据的ACK。
			$cwnd$ 翻倍：$cwnd = 2 \times 16 \text{KB} = 32 \text{KB}$。
$cwnd$ 已经达到了 $32 \text{KB}$。由于 $rwnd$ 是 $64 \text{KB}$，发送窗口 $W_{send} = \min(32\text{KB}, 64\text{KB}) = 32\text{KB}$。目标达成。

3.  **计算总时间**
    从连接建立成功到 $cwnd$ 达到 $32 \text{KB}$，总共经过了 5 个 $RTT$。
    总时间 = $5 \times RTT = 5 \times 5\text{ms} = 25\text{ms}$。

    因此，正确答案是 **A. 25ms**

- 衍生 
	- #慢开始阈值  #慢启动  这是一个非常重要的变量。当 $cwnd < ssthresh$ 时，TCP使用慢开始算法（指数增长）。当 $cwnd \ge ssthresh$ 时，TCP切换到拥塞避免算法（线性增长）。
    *   **衍生问题:** 如果初始的 $ssthresh$ 为 $16 \text{KB}$，那么发送窗口达到 $32 \text{KB}$ 需要多长时间？
        *   **解答:**
            *   前 4 个 RTT 和之前一样，慢开始阶段，$cwnd$ 增长到 $16 \text{KB}$。用时 $4 \times 5\text{ms} = 20\text{ms}$。
            *   此时 $cwnd = ssthresh$，进入拥塞避免阶段。
            *   在拥塞避免阶段，$cwnd$ 每个 RTT 只增加 1 MSS。
            *   从 $16 \text{KB}$ 增长到 $32 \text{KB}$，需要增加 $32 - 16 = 16 \text{KB}$，即 16 个 MSS。
            *   这需要 16 个 RTT。
            *   总时间 = $20\text{ms} + 16 \times 5\text{ms} = 20\text{ms} + 80\text{ms} = 100\text{ms}$。
	- [[不同的拥塞事件处理方式]]
	- #连接建立时间 
		- 从甲 **开始发起连接** 到发送窗口达到 $32 \text{KB}$ 需要多长时间？
	    *   **解答:** TCP建立连接需要三次握手。这个过程至少需要 1 个 RTT（SYN -> SYN+ACK -> ACK）。所以总时间需要加上这部分。
	        *   总时间 = 三次握手时间 + 慢启动时间 = $1 \times RTT + 25\text{ms} = 5\text{ms} + 25\text{ms} = 30\text{ms}$。


![[2017-exam-paper-ocr.pdf#page=4&rect=73,216,344,301|2017-exam-paper-ocr, p.4]]
[[Pasted image 20250930044507.png]]
#FTP文件传输协议   
[[FTP的双链接架构]] 
1. A. 数据连接在每次数据传输完毕后就关闭 
	1. 根据上述知识点，数据连接是为单次数据传输而建立的临时连接，传输完成后即关闭。这个描述是**正确**的
2.   **B. 控制连接在整个会话期间保持打开状态**
    *   根据上述知识点，控制连接负责整个会话的管理，从登录到注销一直存在。这个描述是**正确**的。
*   D. 客户端与服务器的 TCP 21 端口建立控制连接 
    *   这是FTP协议的标准。客户端主动发起连接，目标是服务器的熟知端口（Well-known Port）TCP 21。这个描述是**正确**的。 [[协议与端口号]]
*   C. 服务器与客户端的 TCP 20 端口建立数据连接
    *   这个描述是**错误**的，因为它不完整且具有误导性。它只在特定模式下部分正确，但作为一个普适性的描述是错的。这需要我们引入第二个关键知识点。

[[FTP的主动模式与被动模式]] 
总结选项C的错误之处：
1.  它没有区分主动模式和被动模式。在被动模式下，服务器的20端口根本不会被使用。
2.  即使在主动模式下，描述也是不准确的。是服务器**从**20端口发起连接，而连接的目标是客户端的一个随机高位端口，而不是客户端的20端口。

- 衍生 
	-  [[带内控制vs带外控制]]  
		-  考点：FTP属于哪种控制方式？
		    *   **详解**：FTP是典型的**带外控制 (Out-of-band control)**，因为它的控制信息（命令和响应）和数据在不同的连接上传输。
		    *   **对比**：像HTTP这样的协议是**带内控制 (In-band control)**，因为请求（控制信息）和响应（数据）都在同一个TCP连接中传输。
	- #FTP的状态性 
		-   **考点**：FTP是无状态协议还是有状态协议？
		    *   **详解**：FTP是**有状态协议 (Stateful Protocol)**。服务器需要为每个客户端维护一个会话状态，例如当前用户是谁、登录状态如何、当前工作目录在哪里等。
		    *   **对比**：HTTP/1.0是无状态协议，服务器处理完一个请求后不保留任何关于客户端的信息。
	- #FTP的安全性问题 
		- **考点**：标准FTP协议存在什么安全隐患？有哪些安全的替代方案？ 
	    *   **详解**：标准的FTP（端口21）在传输用户名、密码和文件内容时都是**明文传输**，容易被窃听。
	    *   **替代方案**：
	        *   **FTPS (FTP over SSL/TLS)**：使用SSL/TLS加密FTP的控制和数据连接，分为显式（Explicit）和隐式（Implicit）两种模式。
	        *   **SFTP (SSH File Transfer Protocol)**：它不是FTP的扩展，而是一个完全独立的协议，运行在SSH（Secure Shell）协议之上，提供文件传输和管理功能，所有数据都是加密的。它只使用一个连接（通常是TCP 22端口）。



![[2017-exam-paper-ocr.pdf#page=5&rect=70,523,539,830|2017-exam-paper-ocr, p.5]][[Pasted image 20250930044523.png]]
[[表达式转换（前中后缀）]]  
#表达式树   
1. 第一步：为什么选择中序遍历？  
	1. 对这棵树进行一次简单的中序遍历（左 -> 根 -> 右） 
		1. 从根节点 `*` 开始，先遍历其左子树。
		2.  进入左子树，根是 `+`。先遍历其左子树，即节点 `a`。`a` 是叶子节点，输出 `a`。
		3.  回到 `+`，输出根节点 `+`。
		4.  遍历 `+` 的右子树，即节点 `b`。`b` 是叶子节点，输出 `b`。
		5.  左子树 `+` 遍历完毕。回到根节点 `*`，输出根节点 `*`。
			1.  遍历 `*` 的右子树。
			2.  进入右子树，根是 `*`。先遍历其左子树，即节点 `c`。`c` 是叶子节点，输出 `c`。
			3.  回到 `*`，输出根节点 `*`。
			4.  遍历 `*` 的右子树，根是 `-`。它只有一个右孩子 `d`（代表取反）。
			5. 进入 `-`，它没有左子树。输出根节点 `-`。
			6. 遍历 `-` 的右子树，即节点 `d`。`d` 是叶子节点，输出 `d`。
2.  第二步： #为什么以及何时需要添加括号 
	1.  `a + b * c * - d` 是有歧义的。它可能被解释为 $a + (b*c) * (-d)$，也可能被解释为 $(a+b)*c*(-d)$。而原始树结构清晰地表达了运算次序是 $(a+b)$ 先算，$(c*(-d))$ 后算，最后两者相乘 
	2. 所以，简单的中序遍历是不够的，我们必须在适当的时候添加括号来维持正确的运算优先级
		1. #括号添加的规则
			1. 括号的作用是将一个子表达式“包裹”起来，使其成为一个整体，参与更高层次的运算。
				观察表达式 $(a+b)*(c*(-d))$：
				*   `a+b` 这个子表达式需要括号，因为它作为一个整体，是 `*` 运算的左操作数。
				*   `c*(-d)` 这个子表达式也需要括号。
				*   最外层的 `*` 运算，作为整个表达式的根，不需要括号。
				*   操作数（如 `a`, `b`, `c`, `d`）本身不需要括号。
			2. 由此我们得出基本设计思想
				1. 对一个以操作符为根的子树进行中序遍历时，如果这个子树**不是整个表达式树的根**，那么在遍历其内容（左子树、根、右子树）之前，需要输出一个左括号 `(`，在遍历完所有内容之后，需要输出一个右括号 `)`。
3. 第三步：如何用代码实现这个思想？ 
	1. 这就是参考答案中 `BtreeToExp(BTree *root, int deep)` 函数的精髓所在。它引入了一个参数 `deep` 来表示当前递归的深度
	2. `deep` 参数的作用  
		1. 我们让主函数调用时，传入的初始深度为 1 (`BtreeToExp(root, 1)`)。当递归进入子树时，深度加 1 (`deep+1`)。这样，只有当 `deep > 1` 时，才意味着当前处理的子树是一个**子表达式**，而不是顶层表达式。  
4. 我们来分析一下代码逻辑：
 #中序遍历  #中序遍历代码 
```c
void BtreeToExp(BTree *root, int deep)
{
    // 基本情况1：空树，直接返回
    if (root == NULL) return;

    // 基本情况2：叶子节点（操作数）
    else if (root->left == NULL && root->right == NULL) {
        printf("%s", root->data); // 直接输出操作数，不加括号
    }
    // 递归情况：内部节点（操作符）
    else {
        // 关键逻辑：如果不是顶层表达式 (deep > 1)，就加括号
        if (deep > 1) printf("(");

        // 中序遍历：左
        BtreeToExp(root->left, deep + 1);

        // 中序遍历：根
        printf("%s", root->data);

        // 中序遍历：右
        BtreeToExp(root->right, deep + 1);

        // 关键逻辑：与前面的左括号配对
        if (deep > 1) printf(")");
    }
}
```

代码逻辑详解：
1.  **处理叶子节点**：`if (root->left == NULL && root->right == NULL)` 判断当前节点是否为叶子节点。如果是，它代表一个操作数（如 `a`, `b`），直接打印出来即可。这是递归的终点。
2.  **处理内部节点（操作符）**：
    *   `if (deep > 1) printf("(");` 这是整个算法的核心。当函数被递归调用处理一个子树时（此时`deep`必然大于1），它首先打印一个左括号，将这个子表达式包裹起来。
    *   `BtreeToExp(root->left, deep + 1);` 递归处理左子树。
    *   `printf("%s", root->data);` 打印当前节点的操作符。
    *   `BtreeToExp(root->right, deep + 1);` 递归处理右子树。
    *   `if (deep > 1) printf(")");` 在子表达式完全处理完毕后，打印右括号，完成包裹。
**注意**：这个算法有一个小小的优化空间。严格来说，只有当子表达式的操作符优先级**低于**其父表达式的操作符时，才必须加括号。例如，在 $a+(b*c)$ 中，$b*c$ 就不需要括号。但题目给出的算法为了简单普适，为所有非顶层的子表达式都加上了括号，这在逻辑上是完全正确的，只是可能会产生一些冗余的括号，如 `(a*b)+(c*d)` 会被输出为 `((a*b)+(c*d))`（如果这是某个更大表达式的一部分）。对于本题的要求，这种“全部添加”的策略是满足条件的。
[[遍历二叉树的代码]] 


- 衍生 
	- [[表达式转换（前中后缀）]]
	- [[表达式树]] 
		- **由后缀或前缀表达式构建树**：这个过程相对简单。例如，从后往前读后缀表达式，遇到操作数就创建叶子节点并压栈，遇到操作符就出栈两个节点作为其左右孩子，然后将新生成的子树根节点压栈。
		- **由中缀表达式构建树**：这个过程最复杂，因为它涉及到操作符优先级和括号。通常需要结合两个栈（一个操作数栈，一个操作符栈）来完成，思路与调度场算法相似。
	- 算法的优化  
		-  **智能括号**：如前所述，设计一个更智能的算法，仅在必要时（根据操作符优先级）添加括号。例如，对于 $a+(b*c)$，在处理 `b*c` 这个子表达式时，发现其父节点是 `+`，由于 `*` 的优先级高于 `+`，所以可以不加括号。这就需要在递归时传递父节点的操作符信息。 

![[2017-exam-paper-ocr.pdf#page=6&rect=75,617,528,823|2017-exam-paper-ocr, p.6]]
[[Pasted image 20250930044624.png]]
[[Pasted image 20250930044632.png]]

#Prim算法   
1. [[最小生成树MST]]
	1. **核心思想**: “**加点法**”。从一个点开始，不断地把离当前这棵“小树”最近的点和边加进来，逐步扩大树的规模，直到覆盖所有顶点。
2.  `(A, D), (D, E), (C, E), (B, C)` 
- (2) 图 G 的 MST 是唯一的吗？ 
	1.  第 1 步：最小权值是 4，只有边 (A, D) 满足，选择是**唯一**的。
    2.  第 2 步：最小权值是 4，只有边 (D, E) 满足，选择是**唯一**的。
    3.  第 3 步：最小权值是 5，只有边 (E, C) 满足，选择是**唯一**的。
    4.  第 4 步：最小权值是 4，只有边 (B, C) 满足，选择是**唯一**的。

因为在从顶点 A 开始的 Prim 算法的每一步中，最小权值边的选择都是唯一的，所以生成的这棵 MST 是唯一的。


-  (3) 对任意的带权连通图，满足什么条件时，其 MST 是唯一的？

这是一个经典的理论问题。

**充分条件**:
如果一个 #带权连通图 中 所有边的权值都互不相同 ，那么它的最小生成树是唯一的。

**推导过程**:  
这个结论可以用  #MST的切割属性 (Cut Property)  来证明。
*   **切割属性**：对于图的任意一种顶点划分（一个“切分”），即将所有顶点分为两个不相交的集合 $S$ 和 $V-S$，连接这两个集合的所有边（称为“横切边”）中，权值最小的那条边必然属于图的任意一棵最小生成树。
*   **证明唯一性**：如果图中所有边的权值都不同，那么对于任何一个切分，权值最小的横切边都是**唯一**的。无论是 Prim 算法（每一步都是一个切分）还是 Kruskal 算法，在选择横切边时，都只会有一个唯一的选择。由于构成 MST 的所有边都是通过这种唯一选择得到的，因此最终的 MST 也是唯一的。 #最小生成树MST的唯一性 
	* #最小生成树MST的唯一性 ：
	    *   如果图中所有边的权重都**不相同**，那么最小生成树是**唯一**的。
	    *   如果存在权重相同的边，那么可能存在多棵不同的最小生成树，但它们的总权重一定是相同的。
	* 题目中说明“不要求回答充分必要条件”，因此回答“所有边的权值都互不相同时”是最标准、最安全的答案。

 
- 衍生    
	-  #MST性质
		-  #最小生成森林  
			- 如果图不连通，则无法生成一棵包含所有顶点的树。此时我们可以对每个连通分量分别求 MST，这些 MST 的集合就构成了最小生成森林。Kruskal 算法可以直接应用于不连通图求 MSF。
		- #次小生成树 
			- 求解权值第二小的生成树。通常的思路是先求出 MST，然后依次用一条不在 MST 上的边替换 MST 上的一条边（替换后要保证仍然是树），计算新树的权值，找到其中的最小值



![[2017-exam-paper-ocr.pdf#page=7&rect=77,563,539,823|2017-exam-paper-ocr, p.7]]
[[Pasted image 20250930044646.png]]
[[Pasted image 20250930044653.png]]
[[Pasted image 20250930044700.png]]
[[Pasted image 20250930044710.png]]

[[数据类型转换]]  

[[IEEE 754 标准]]   #较复杂  #数据类型转换入门题 
1. C函数`f1(n)`和`f2(n)`实际计算的是 $2^{n+1}-1$ 
	- 数据类型与表示 
	
- (1) `n=0` 时，`f1` 会出现死循环，为什么？若将 `i` 和 `n` 都改为 `int` 型，还会吗？ 
	1.  在`f1`中，`n`是`unsigned int`类型。当调用`f1(0)`时，`n=0`。
		1.  循环条件是`i <= n - 1`。这里的`n-1`是无符号数`0`减`1`。
		2.  无符号整数运算会“回绕”。$0 - 1$ 在模 $2^{32}$ 运算下，结果是 $2^{32}-1$ (即十六进制的`0xFFFFFFFF`)，这是`unsigned int`能表示的最大值。
		3.  因此，循环条件变为`i <= 4294967295`。
		4.  循环变量`i`也是`unsigned int`，从0开始递增。它永远都会满足`i <= 2^{32}-1`（当`i`达到最大值后，再加1会回绕到0），所以循环无法终止，形成死循环
	2. 改为 `int` 型
		1. `i`和`n`都是`int`类型。当`n=0`时，`n-1`的结果是`-1`
		2.  循环条件是`i <= -1` 
		3.  `i`的初始值是`0`。`0 <= -1`这个条件为假 
		4. 循环体一次都不会执行，函数直接返回初始值`sum=1`。不会出现死循环 
- **衍生考点**：
	*   **无符号数与有符号数比较**：例如，`if (-1 > 0U)` 这个条件在C语言中是真的，因为`-1`会被转换成无符号大数`0xFFFFFFFF`，它比`0U`大。这常常是安全漏洞的来源。
	*   #整数溢出/下溢 ：在进行长度或内存分配计算时，如果使用无符号数并发生下溢，可能导致分配一个巨大的、非预期的内存块，引发安全问题。

- (2) `f1(23)`与`f2(23)`的返回值是否相等？机器数各是什么？ 
	1. `int` 和 `float` 的表示范围与 #精度 
	2. 计算目标值 
		1.  我们需要计算 $f(23) = 2^{23+1} - 1 = 2^{24}-1$ 
	3. `f1(23)` (int) 
		*   $2^{24}-1$ 的二进制表示是24个1。
	    *   这个值远小于32位`int`的最大值$2^{31}-1$，所以可以精确表示，不会溢出。
	    *   其32位二进制机器数是 `0000 0000 1111 1111 1111 1111 1111 1111`。
	    *   转换为十六进制为 $00FFFFFFH$。
	4. `f2(23)` (float)
		1. 我们需要判断 $2^{24}-1$ 能否被`float`精确表示。
		    *   `float`的尾数有24位有效数字。
		    *   $2^{24}-1$ 的二进制是24个1，它恰好需要24位有效数字来表示。
		    *   因此，$2^{24}-1$ 可以被`float`精确表示，没有精度损失。
		    *   **机器数计算**:
		        *   符号S=0 (正数)。
		        *   值 $V = 2^{24}-1$。将其规格化：$V = (2^{24}-1) = (1.11...1)_2 \times 2^{23}$ (小数点后有23个1)。
		        *   阶码 $E = 23 + 127(\text{bias}) = 150 = (10010110)_2$。
		        *   尾数 $M$ 是小数点后的部分，即23个1。
		        *   组合起来 `S EEEEEEEE MMM...` 为 `0 10010110 11111111111111111111111`。
		        *   转换为十六进制为 $4B7FFFFFH$
	5. 结论 
		1.  返回值**相等**，因为`int`和`float`都能精确表示$2^{24}-1$这个值。
			*   `f1(23)`的机器数是 $00FFFFFFH$。
			*   f2(23)的机器数是 $4B7FFFFFH$。
- 衍生
	-  **浮点数精度限制**：哪些整数可以被`float`精确表示？所有绝对值小于等于$2^{24}$的整数都可以。大于$2^{24}$的整数，只有部分（那些尾数部分末尾是0的）可以。
	*   `double`类型的表示：64位，11位阶码，52位尾数，精度和范围远大于`float`
*  (3) `f1(24)`和`f2(24)`的返回值分别为...，为什么不相等？ 
	* 核心知识点： #浮点数舍入(Rounding)  #舍入 
	1. 计算目标值
		1.  $f(24) = 2^{24+1} - 1 = 2^{25}-1$
	2. `f1(24)` (int) 
		*   $2^{25}-1$ 仍然小于`int`最大值$2^{31}-1$，可以精确表示。
	    *   $2^{25}-1 = 33554432 - 1 = 33554431$。
	3. `f2(24)` (float) 
		1.   $2^{25}-1$ 的二进制表示是25个1。
		    *   `float`只有24位有效数字，无法精确表示25位有效数字的 $2^{25}-1$。必须进行舍入。
		    *   $2^{25}-1$ 的规格化形式是 $(1.11...1)_2 \times 2^{24}$ (小数点后有24个1)。
		    *   `float`的尾数只能存储小数点后的23位，即前23个1。第24个1是需要被舍入的位。
		    *   根据“舍入到最近”规则，由于第24位是1，需要向上舍入。
		    *   将`1.11...1` (23个1) 向上舍入，会发生进位，最终变为 `10.0`。
		    *   因此，舍入后的值变为 $(10.0)_2 \times 2^{24} = 2 \times 2^{24} = 2^{25} = 33554432.0$
		2. 结论
			*   `f1(24)`返回精确值`33554431`。
			*   `f2(24)`因精度限制和舍入，返回`33554432.0`。
			*   两者不相等，`f2(24)`比`f1(24)`大。
- 衍生 
	- 浮点数比较的陷阱永远不要用  $==$  直接比较两个浮点数是否相等，因为舍入误差可能导致它们有微小差异。应该比较它们的差的绝对值是否在一个很小的范围内，如 `if (fabs(a - b) < epsilon)`。
	*   **不同的舍入模式**：IEEE 754定义了多种舍入模式，如向零舍入、向正无穷舍入、向负无穷舍入。
- (4) $f(31) = 2^{32}-1$，而`f1(31)`的返回值却为-1，为什么？若使`f1(n)`的返回值与`f(n)`相等，则最大的n是多少？ 
	- 有符号整数的 #溢出 和 #二进制补码表示 
	1.  `f1(31)`的返回值 
		1.  `f1(31)`计算 $2^{31+1}-1 = 2^{32}-1$。
		    *   $2^{32}-1$ 的32位二进制表示是32个1：`1111 1111 ... 1111`。
		    *   `f1`的返回类型是`int`（32位有符号整数），它使用二进制补码。
		    *   在补码表示中，`1111 1111 ... 1111` 这个位模式代表的值是`-1`。
		    *   因此，计算结果发生了溢出，最终返回`-1`
		2. 使`f1(n)`的返回值与`f(n)`相等，最大的n 
			1. 问题是问，在不发生溢出的情况下，`f1(n)`能计算的最大`n`是多少。
			    *   我们需要 $f1(n)$ 的计算结果 $2^{n+1}-1$ 不超过`int`能表示的最大正数 $2^{31}-1$。
			    *   即 $2^{n+1}-1 \le 2^{31}-1$。
			    *   化简得 $2^{n+1} \le 2^{31}$。
			    *   两边取对数，得 $n+1 \le 31$。
			    *   解得 $n \le 30$。
			    *   所以，最大的`n`是`30`
- 衍生 
	-   **C语言中溢出的行为**：无符号整数溢出是明确定义的（回绕），而有符号整数溢出在C标准中是“ #未定义行为”，意味着编译器可以做任何处理，尽管在大多数平台上表现为补码的回绕。
	*   **二进制补码**：如何快速计算一个负数的补码（符号位不变，其余位取反加一），以及如何从补码反推原值。
		
-  (5) `f2(127)`的机器数为`7F80 0000H`，对应的值是什么？若使`f2(n)`的结果不溢出，则最大的n是多少？若使`f2(n)`的结果精确（无舍入），则最大的n是多少？ 
	1. `7F80 0000H` 对应的值 
		1. 将`7F80 0000H`转换为二进制：`0 11111111 00000000000000000000000`  
		2. **符号位 S = 0** (正)。
		    *   **阶码 E = 11111111** (全1)。
		    *   **尾数 M = 000...0** (全0)。
			*   根据IEEE 754标准，当阶码全为1且尾数全为0时，表示无穷大。因为符号位是0，所以它表示**正无穷大** ($+\infty$) 
	2. `f2(n)`不溢出的最大n
		1.    “ #不溢出”意味着结果不能是无穷大 
			1. `float`能表示的最大正规数的阶码是`11111110` (二进制)，即十进制的254。对应的实际指数是 $254-127=127$。
			    *   所以，`float`能表示的最大值约为 $2 \times 2^{127} = 2^{128}$。
			    *   我们需要 $f2(n)$ 的计算结果 $2^{n+1}-1$ 小于等于这个最大值。
			    *   $2^{n+1}-1 \le (2-2^{-23}) \times 2^{127}$。
				- 测试临界值：
			        *   当 $n=126$ 时，计算 $2^{127}-1$。规格化后为 $(1.1...1)_2 \times 2^{126}$。实际指数是126，小于127，可以表示（虽然会舍入）。
			        *   当 $n=127$ 时，计算 $2^{128}-1$。这个值非常接近 $2^{128}$。当它被舍入到最近的`float`数时，结果就是 $2^{128}$。
			        *   要表示 $2^{128}$，规格化为 $1.0 \times 2^{128}$。实际指数是128。对应的阶码是 $128+127=255$，即`11111111` (全1)。
			        *   如上所述，阶码全1是特殊值。由于尾数是0，这正好是无穷大的表示。因此，当$n=127$时，计算结果会溢出为正无穷大。
			    *   所以，不溢出的最大`n`是`126`
	3.   **`f2(n)`结果精确的最大n**:
	    *   “精确”意味着计算结果 $2^{n+1}-1$ 不需要舍入。
	    *   $2^{n+1}-1$ 的二进制表示是 $n+1$ 个连续的1。
	    *   `float`的有效数字是24位。
	    *   为了精确表示，所需位数 $n+1$ 必须小于或等于24。
	    *   $n+1 \le 24$。
	    *   解得 $n \le 23$。
	    *   所以，结果精确的最大`n`是`23`。
- 衍生 
	- #NaN (Not a Number)：当阶码全1，尾数不为0时，表示NaN。例如 `0/0` 或 `sqrt(-1)` 的结果。
	*   #非规格化数 ：当阶码全0时，用于表示非常接近0的数，填补了0和最小规格化数之间的空隙，实现了“渐进下溢”。
		
	
	
	
	



![[2017-exam-paper-ocr.pdf#page=7&rect=63,270,551,573|2017-exam-paper-ocr, p.7]]
[[Pasted image 20250930044722.png]]

[[RISC 和CISC的区别]]  
[[指令格式]] 
#机器指令  
1. 分析给出的机器码  #分析机器码  
	1.    `00401020 55`: `push ebp` 指令，机器码是 `55`，长度为 **1字节**。
	    *   `0040105E 39 4D F4`: `cmp dword ptr [ebp-0Ch], ecx` 指令，机器码是 `39 4D F4`，长度为 **3字节**。
	    *   `00401066 D1 E2`: `shl edx, 1` 指令，机器码是 `D1 E2`，长度为 **2字节**。
	    *   `0040107F C3`: `ret` 指令，机器码是 `C3`，长度为 **1字节**
	2. 清楚地看到，指令的长度有1字节、2字节、3字节等多种，这是CISC架构最显著的特征之一
-  (2) f1的机器码共占多少字节？
	1. 定位首尾地址  
		 *   函数 `f1` 的第一条指令 `push ebp` 的地址是 `00401020H`。
	    *   函数 `f1` 的最后一条指令 `ret` 的地址是 `0040107FH`。
	2. 计算长度 
		1. 程序的长度等于其占用的地址空间大小。对于一个连续的块，其大小为 `(结束地址 - 开始地址 + 1)`。加1是因为开始地址本身也占用一个字节
		    *   计算（使用十六进制）:
		        $0x0040107F - 0x00401020 + 1$
		        $= 0x5F + 1$
		        $= 0x60$
		    *   将十六进制结果转换为十进制:
		        $0x60 = 6 \times 16^1 + 0 \times 16^0 = 96$
		2. 所以，函数 `f1` 的机器码总共占用了96个字节
-  (3) 第20行cmp指令执行后，进位标志CF的内容是什么？ 
	- 题目中隐含的上下文是第43题讨论过的 `f1(0)` 无限循环场景
	1. 当调用 `f1(0)` 时，`n=0`。由于 `n` 是 `unsigned int`，`n-1` 会下溢为 `0xFFFFFFFF`。
		循环从 `i=0` 开始。
			`cmp` 指令执行的是 `目的操作数 - 源操作数`，并根据结果设置标志位。根据汇编代码 `cmp dword ptr[ebp-0Ch], ecx`，我们通常可以推断编译器将循环变量 `i` 和 `n-1` 分别存放在这两个位置。为了使答案 `CF=1` 成立，`cmp` 执行的必须是 `i - (n-1)`
- 推导过程
	1. **确定操作数**: 假设 `dword ptr [ebp-0Ch]` 存放 `i`，`ecx` 存放 `n-1`。
	    *   `i = 0`
	    *   `n-1 = (unsigned)0 - 1 = 0xFFFFFFFF`
	2.   **执行减法**: `cmp` 指令执行 `0 - 0xFFFFFFFF`
	3. **理解进位标志CF (Carry Flag)**:
	    *   在**加法**中，CF=1表示最高位产生了进位。
	    *   在**减法**中，CF=1表示向最高位产生了**借位**。也就是说，当**被减数 < 减数** (在无符号意义下) 时，CF=1
	4. **分析运算**:
	    在无符号数中，`0` 显然小于 `0xFFFFFFFF`。因此，执行 `0 - 0xFFFFFFFF` 操作需要向更高位借位。所以 **CF=1**。
	5. 用二进制补码验证
		1. 计算机执行 `A - B` 实际上是计算 `A + (-B)`，而 `-B` 是 `B` 的补码（`~B + 1`）。
		    *   `A = 0x00000000`
		    *   `B = 0xFFFFFFFF`
		    *   `-B = ~0xFFFFFFFF + 1 = 0x00000000 + 1 = 0x00000001`
		    *   计算 `A + (-B) = 0x00000000 + 0x00000001 = 0x00000001`。
		    在x86架构中，对于减法 `A - B`，如果 `A < B` (无符号)，则 `CF=1`。我们的情况符合这个定义。
- (4) f2中能否也用shl指令实现power * 2？为什么？ 
	- **不能**。因为 `f2` 中的变量 `power` 如果是 `float` 类型，其在内存中的表示遵循 **IEEE 754 标准**，而不是一个简单的二进制整数。`shl` (Shift Left) 是一个**整数位移指令**，它会将操作数的所有二进制位向左移动，这对于浮点数的结构是破坏性的。
		1. 回顾`shl`指令  
			1. `shl edx, 1` 将寄存器 `edx` 中的内容看作一个32位二进制数，整体向左移动1位，最低位补0。对于整数（无论是无符号还是有符号补码），这等效于乘以2。
			    例如，整数5 (二进制 `0...0101`) 左移一位变成 `0...1010`，即十进制的10
		2. 理解`float`的存储格式 (IEEE 754)
			1. 一个32位的单精度浮点数由三部分组成： [[IEEE754单精度浮点数格式]] 
			    *   **符号位 (Sign)**: 1位 (第31位)
			    *   **阶码 (Exponent)**: 8位 (第30-23位)，使用移码（biased）表示
			    *   **尾数 (Mantissa/Fraction)**: 23位 (第22-0位)
			    其值为: $V = (-1)^{Sign} \times (1.Mantissa) \times 2^{Exponent - Bias}$ (对于规格化数)
		3. 分析`shl`对`float`的影响  #shl的破坏性 
			1. 如果对一个 `float` 型变量使用 `shl` 指令，会发生什么？
			    *   尾数的最高位会移入阶码的最低位。
			    *   阶码的最高位会移入符号位。
			    *   原来的符号位会被移出并丢失。
			    这个操作完全破坏了浮点数的“符号-阶码-尾数”结构，得到的结果毫无意义，绝不等于原来的浮点数乘以2
		4. 浮点数如何乘以2   [[浮点数运算规则]] 
			1. 正确的浮点数乘2操作，是保持符号位和尾数不变，将**阶码加1**。这需要专门的 #浮点运算指令 （例如x87 FPU的 `FMUL` 或 SSE/AVX 的 `MULSS` 指令）来完成，这些指令能够正确地解析和操作浮点数的各个组成部分
- 衍生 
	*   IEEE 754标准的详细内容（单精度/双精度格式、规格化/非规格化数、特殊值NaN/Infinity）。
	*   整数与浮点数在计算机中的表示方式的根本区别。
	*   浮点数运算的实现（FPU，SSE/AVX指令集）。
	*   数据类型转换（如 `int` 到 `float`）时可能发生的精度损失和溢出问题（呼应第43题）。
	*   CPU状态寄存器/标志寄存器（EFLAGS）中各个标志位的作用，特别是 CF, ZF, SF, OF。
	*   有符号比较 (`jg`, `jl`) 和无符号比较 (`ja`, `jb`) 指令依赖的标志位组合。
	*   补码运算规则，特别是减法如何通过加法实现。
	*   无符号数和有符号数的下溢（wraparound）和上溢。
	*   十六进制数的运算。
	*   内存地址和程序大小的计算。
	*   函数调用栈、栈帧（Stack Frame）的结构，理解 `ebp` (基址指针) 的作用。
	*   CISC与RISC的详细对比（指令集、寻址方式、寄存器数量、流水线实现、编译器角色等）。
	*   Load-Store 架构的含义和优势。
	*   x86、ARM、MIPS、RISC-V 分别属于哪种架构。
	*   指令格式和寻址方式的计算（例如，如何根据操作码和地址码计算指令长度）。
		
		
	







![[2017-exam-paper-ocr.pdf#page=7&rect=65,136,536,273|2017-exam-paper-ocr, p.7]]
[[Pasted image 20250930044741.png]]
1. 确定代码的起始和结束地址
    *   从第44题可知，`f1` 的第一条指令 `push ebp` 的虚拟地址是 `0x00401020`。
    *   `f1` 的最后一条指令 `ret` 的虚拟地址是 `0x0040107F`。
2. 计算代码所占的字节数 
	指令代码占据的地址空间是从起始地址到结束地址（包含结束地址本身）。
    *   `ret` 指令（机器码为 `C3`）本身占1个字节，所以它占据了 `0x0040107F` 这一个地址单元。
    *   因此，总字节数 = (结束地址 - 起始地址) + 1。
    *   计算：
        $Size = 0x0040107F - 0x00401020 + 1$
        先进行十六进制减法：
        $0x0040107F - 0x00401020 = 0x5F$
        然后加1：
        $0x5F + 1 = 0x60$
    *   将结果转换为十进制：
        $60_{16} = 6 \times 16^1 + 0 \times 16^0 = 96_{10}$
	**结论**: 函数 `f1` 的机器指令代码占 **96** 字节。
3. 

- 取第1条指令 `push ebp` 时，在进行地址变换的过程中需要访问内存中的页目录和页表，则会分别访问它们各自的第几个表项 (编号从0开始)？
	1. 获取目标虚拟地址 
		1.  第1条指令 `push ebp` 的虚拟地址是 `0x00401020`。 
	2. 将虚拟地址转换为二进制  
		1.  `0x00401020` = `0000 0000 0100 0000 0001 0000 0010 0000` (二进制)
	3. 按10-10-12格式拆分二进制地址   
		1. #页目录索引PDI 最高10位
	        `0000000001` (二进制) = $1_{10}$ 
	    2. #页表索引PTI 中间10位
	        `0000000001` (二进制) -- *这里需要仔细看，让我们从十六进制直接计算*
	        *   整个虚拟地址 `0x00401020` 右移12位得到页号（包含PDI和PTI）： `0x00401`。
	        *   这个页号 `0x00401` 是一个20位的数。它的二进制表示为 `0000 0000 0100 0000 0001`。
	        *   将这个20位数拆成两个10位数：
	            *   高10位 (PDI): `0000000001` (二进制) = $1_{10}$
	            *   低10位 (PTI): `0000000001` (二进制) = $1_{10}$
		3. #页内偏移 最低12位
	        `000000100000` (二进制) = $0x020$ = $32_{10}$ 
	4. 确定访问的表项编号
	    *   由于编号从0开始，索引值就是表项的编号。
	    *   **页目录**: CPU会访问页目录的第 **1** 号表项（索引为1）。
	    *   **页表**: 接着，CPU会访问由上述页目录项指向的那个页表的第 **1** 号表项（索引为1）。
	* **结论**: 分别访问页目录的第1个表项和页表的第1个表项（这里的“第1个”指的是编号为1，即第二个位置）
-   (3) 
	- M 的 I/O 采用中断控制方式。若进程 P 在调用 `f1` 之前通过 `scanf()` 获取 n 的值，则在执行 `scanf()` 的过程中，进程 P 的状态会如何变化？CPU 是否会进入内核态？  [[进程状态模型]]
	1.  **`scanf()` 的本质**:
	    *   `scanf()` 是一个C库函数，用于从标准输入（通常是键盘）读取数据。
	    *   读取键盘输入是一个I/O操作，用户程序无法直接控制硬件，必须请求操作系统来完成。
	    *   因此，`scanf()` 内部会触发一个 #系统调用 （例如 `read`）。  [[系统调用的过程]]
	
	2.  **第一次状态变化与模式切换 (发起I/O)**:
	    *   **模式切换**: 当进程P执行到系统调用指令时，会产生一个 #trap指令（陷阱指令）  ，这是一种内部中断。CPU的硬件状态会从**用户态切换到内核态**。
	    *   **状态变化**: CPU进入内核态后，开始执行操作系统的代码来处理这个I/O请求。由于等待用户输入是一个非常耗时的过程，操作系统不会让CPU空等。它会启动I/O设备（键盘），然后将进程P的状态从**运行态 (Running) 变为阻塞态 (Blocked/Waiting)**，并调用调度程序，选择另一个处于就绪态的进程来运行。
	
	3.  **第二次状态变化 (I/O完成)**:
	    *   当用户从键盘输入数据并按下回车后，键盘控制器会向CPU发送一个**中断信号**。
	    *   CPU响应中断，暂停当前正在执行的进程，并再次**进入内核态**，执行相应的中断服务程序 (ISR)。
	    *   中断服务程序将输入的数据从设备缓冲区复制到进程P的内存空间，并意识到P等待的事件已经完成。于是，它会将进程P的状态从**阻塞态 (Blocked) 改为就绪态 (Ready)**，并将其放入就绪队列。
	
	4.  **第三次状态变化 (重获CPU)**:
	    *   进程P现在处于就绪态，等待CPU资源。
	    *   当操作系统调度程序在未来的某个时间点选择P运行时，P的状态会从**就绪态 (Ready) 变为运行态 (Running)**。此时，它会从 `scanf()` 系统调用返回，继续执行后续代码。
	
	**结论**:
	*   **状态变化路径**: 运行态 -> 阻塞态 -> 就绪态 -> 运行态。
	*   **CPU模式**: 是的，CPU**会进入内核态**。这个切换发生在发起系统调用时和响应I/O中断时。

- 衍生 
	- #地址翻译过程   #地址翻译与TLB  #TLB快表  
		- 如果在系统中加入了快表 (TLB)，地址翻译过程是怎样的？（先查TLB，TLB命中则直接得到物理地址；TLB未命中则需要访问页目录和页表，并将结果存入TLB）。
	    *   计算包含TLB访问的平均访存时间。
	- [[段页式存储管理]]
		-  如果采用的是多级页表（如三级、四级），如何 #拆分虚拟地址 ？
	    *   计算页目录/页表自身占用的内存大小。
		    * 例如，一个页表有1024个表项，每个表项4字节，则一个页表占 $1024 \times 4 = 4096$ 字节，刚好一个页。
	    *   #反向页表 (Inverted Page Table) 的概念和工作原理。
	    *   #段页式存储管理 ，地址结构和翻译过程。


![[2017-exam-paper-ocr.pdf#page=8&rect=70,565,532,824|2017-exam-paper-ocr, p.8]]
[[Pasted image 20250930044751.png]]
- 这道题的核心是考察在多线程环境下，如何通过同步机制（这里是[[信号量]]）来保护共享资源，防止数据竞争（Race Condition），同时要尽可能地保留程序的并行性。 
	- 解决这类问题的标准步骤如下：
		1.  **识别共享资源**：找出被多个线程共同访问的变量。
		2.  **分析访问模式**：确定每个线程对共享资源是进行“读”操作还是“写”操作。
		3.  **确定互斥关系**：根据访问模式，找出哪些线程的哪些操作之间存在冲突，需要互斥执行。
		4.  **设计同步方案**：为每一对需要互斥的操作设置一个信号量（作为互斥锁），并用 P/V 操作（或 wait/signal）将临界区代码包围起来。
[[临界区问题]]  
1.  第一步：识别共享资源和访问模式 
	1.   **共享资源**：全局变量 `cnum x, y, z;`。
		*   **局部变量**：每个线程内部的 `cnum w;` 是局部变量，线程私有，不存在冲突。
		*   **函数 `add`**：这个函数是纯函数，它不修改全局变量，只是根据传入的参数计算并返回一个结果。因此，`add` 函数本身不是临界区。
	2. 列出每个线程对共享资源的访问模式：

| 线程 | 访问的共享变量 | 操作类型 | 涉及的代码行 |
| :--- | :--- | :--- | :--- |
| **thread1** | `x`, `y` | 读 `x`, 读 `y` | `w = add(x, y);` |
| **thread2** | `y`, `z` | 读 `y`, 读 `z` | `w = add(y, z);` |
| **thread3** | `z`, `y` | 读和写 `z` | `z = add(z, w);` |
| | | 读和写 `y` | `y = add(y, w);` |
2. 第二步：确定互斥关系 
	*   **读-读**：不需要互斥。（例如，thread1 和 thread2 同时读 `y` 是安全的）。
	*   **读-写**：需要互斥。
	*   **写-写**：需要互斥。
	逐个分析共享变量：
	1.  **变量 `x`**：
	    *   只有 `thread1` 访问（读）。没有其他线程访问它，所以**不需要**任何同步措施。
	2.  **变量 `z`**：
	    *   `thread2`：读 `z`。
	    *   `thread3`：读和写 `z`。
	    *   存在**读-写冲突**。因此，`thread2` 对 `z` 的访问和 `thread3` 对 `z` 的访问必须互斥。
	3.  **变量 `y`**：
	    *   `thread1`：读 `y`。
	    *   `thread2`：读 `y`。
	    *   `thread3`：读和写 `y`。
	    *   存在**读-写冲突**。具体来说：
	        *   `thread1` (读) 与 `thread3` (写) 之间有冲突。
	        *   `thread2` (读) 与 `thread3` (写) 之间有冲突。
	    *   `thread1` (读) 与 `thread2` (读) 之间**没有冲突**，它们可以并发执行。这是实现“最大限度并发执行”的关键。
3. 第三步：设计同步方案 
	- 根据互斥关系，我们需要设置信号量来 #保护临界区 。为了最大限度地并发，我们应该使用最细粒度的锁
	1. **保护变量 `z`**：
	    *   `thread2` 和 `thread3` 之间对 `z` 的访问需要互斥。
	    *   我们可以定义一个信号量 `mutex_z`，初始值为1。
	    *   `semaphore mutex_z = 1;`
	2. **保护变量 `y`**： 
	3. 题目中的解法非常精妙，它为每一对冲突关系设置了单独的锁：
        *   为 `thread1` 和 `thread3` 对 `y` 的冲突，定义 `semaphore mutex_y1 = 1;`。
        *   为 `thread2` 和 `thread3` 对 `y` 的冲突，定义 `semaphore mutex_y2 = 1;`。
    *   这样，`thread1` 只需要申请 `mutex_y1`，`thread2` 只需要申请 `mutex_y2`。因为这两个锁是独立的，所以 `thread1` 和 `thread2` 可以同时持有各自的锁，从而并发地读取 `y`。
    *   而 `thread3` 要写 `y`，它必须同时与 `thread1` 和 `thread2` 互斥，所以它必须申请**所有**与 `y` 相关的锁，即 `mutex_y1` 和 `mutex_y2`。
4. 第四步：添加 P/V (wait/signal) 操作
	1. 我们将 P/V 操作添加到代码中，包围临界区。P 操作（`wait()`）在进入临界区前执行，V 操作（`signal()`）在退出后执行
   **thread1**:
    *   临界区是 `w = add(x, y);`，因为它读取了共享变量 `y`。
    *   需要与 `thread3` 互斥，所以使用 `mutex_y1`。
    ```c
    wait(mutex_y1);
    w = add(x, y);
    signal(mutex_y1);
    ```

*   **thread2**:
    *   临界区是 `w = add(y, z);`，因为它读取了共享变量 `y` 和 `z`。
    *   对 `y` 的访问需要与 `thread3` 互斥，使用 `mutex_y2`。
    *   对 `z` 的访问需要与 `thread3` 互斥，使用 `mutex_z`。
    *   因此，必须同时获取这两个锁。
    ```c
    wait(mutex_y2);
    wait(mutex_z);    // P操作的顺序可以交换，但最好保持一致以避免死锁
    w = add(y, z);
    signal(mutex_z);    // V操作的顺序无所谓
    signal(mutex_y2);
    ```

*   **thread3**:
    *   第一个临界区是 `z = add(z, w);`，因为它读写了 `z`。
    *   需要与 `thread2` 互斥，使用 `mutex_z`。
    ```c
    wait(mutex_z);
    z = add(z, w);
    signal(mutex_z);
    ```
    *   第二个临界区是 `y = add(y, w);`，因为它读写了 `y`。
    *   需要与 `thread1` 和 `thread2` 都互斥，所以需要获取 `mutex_y1` 和 `mutex_y2`。
    ```c
    wait(mutex_y1);
    wait(mutex_y2);
    y = add(y, w);
    signal(mutex_y2);
    signal(mutex_y1);
    ```

将这些组合起来，就得到了题目给出的标准答案。

- 衍生 
	- #读者-写者问题  
		- 本题本质上是一个简化的读者-写者问题。`thread1` 和 `thread2` 是读者，`thread3` 是写者。
	    *   可能会要求你用经典的读者-写者算法来实现（通常使用一个计数器 `read_count` 和两个信号量 `mutex` 和 `rw_mutex`）。
	    *   可能会考察**读者优先**或**写者优先**的实现及其可能导致的饥饿问题。
	- #死锁
		- 如果题目中的加锁顺序设计不当，就可能导致死锁。例如，如果 `thread2` 的加锁顺序是 `wait(mutex_y2); wait(mutex_z);`，而另一个线程 `thread4` (假设存在) 的加锁顺序是 `wait(mutex_z); wait(mutex_y2);`，就可能发生死锁。
	    *   考点：识别代码中是否存在死锁风险；如何通过**统一加锁顺序**来避免死锁。
	- #生产者-消费者问题  
		- 题目可能被改编成一个线程生产数据放入缓冲区，另一个线程从缓冲区消费数据。
	    *   这需要使用两类信号量：一个互斥信号量 `mutex` 保护缓冲区本身，以及两个同步信号量 `empty` 和 `full` 来表示缓冲区的状态，并协调生产者和消费者的行为。
	* 使用其他同步原语 
		* 可能会要求使用**管程 (Monitor)** 或**条件变量 (Condition Variable)** 来解决同样的问题。这两种是更高级的同步工具，能更结构化地解决同步问题，减少出错的可能。
	* #同步与互斥的区别 
		* **互斥**是一种制约关系，指多个线程不能同时访问同一临界资源。是一种“竞争”关系。
	    *   **同步**是一种协作关系，指多个线程为了完成一个共同任务，在执行次序上需要遵循一定的先后顺序。例如，消费者必须等生产者生产后才能消费。
	    *   本题主要考察互斥，但更复杂的题目会同时考察两者。


![[2017-exam-paper-ocr.pdf#page=8&rect=75,127,536,568|2017-exam-paper-ocr, p.8]]
[[Pasted image 20250930044759.png]]
[[Pasted image 20250930044804.png]]
[[七状态模型]] 
[[后退N帧协议GBN]]    [[数据帧]]  #数据帧   
- (1) 对于图(a)，$t_1$ 时刻到期期间，甲方可以断定乙方已正确接收的数据帧数是多少？正确接收的是哪几个帧？  
1. #累积确认机制  
	在 $t_1$ 时刻，我们观察图(a)，甲方（发送方）收到的最后一个确认帧是 $R_{3,3}$。根据GBN的累积确认规则，$R_{x,y}$ 意味着接收方已经成功接收了所有序列号小于 $x$ 的数据帧，并且现在期望接收序列号为 $x$ 的数据帧。
	
	因此，$R_{3,3}$ 明确地告诉甲方：
	“我（乙方）已经成功接收了序列号为 0, 1, 2 的所有数据帧。我现在等待你发送序列号为 3 的数据帧。”
	
	所以，甲方可以确认乙方已正确接收了3个数据帧，它们的序列号分别是 0, 1, 2。对应图中的帧就是 $S_{0,0}$, $S_{1,0}$ 和 $S_{2,0}$。
- (2) 对于图(a)，从 $t_1$ 时刻起，甲方在不出现超时且未收到乙方新的数据帧之前，最多还可以发送多少个数据帧？重发的第一个帧和最后一个帧分别是哪个？  
1. 确定 #发送窗口 大小  
	1. 为了达到最大信道利用率，我们假设发送窗口大小 $W_T$ 取其理论最大值，即 $W_T = 2^3 - 1 = 7$。
2. 确定当前窗口状态 
	1. 在 $t_1$ 时刻，甲方收到了 $R_{3,3}$，这意味着序列号为 0, 1, 2 的帧已被确认。发送窗口的“基帧”（最老的未确认帧）现在是序列号为 3 的帧。因此，发送窗口覆盖的序列号范围是 {3, 4, 5, 6, 7, 0, 1}（注意序列号循环）
3. 分析已发送但未确认的帧 
	1. 从图(a)中可以看到，在收到 $R_{3,3}$ 之前，甲方已经发送了 $S_{3,0}$ 和 $S_{4,1}$。这两个帧位于新的发送窗口内，但尚未被确认 
4. 计算可发送的帧数 
	1. 发送窗口总容量为7。其中已经有2个帧（$S_{3,0}$ 和 $S_{4,1}$）被占用（已发送但未确认）。因此，甲方还可以发送的帧数是 $7 - 2 = 5$ 个
5. 确定新发送帧的序列号 
	1. 这5个新帧的序列号将紧跟在 $S_{4,1}$ 之后。序列号依次为 5, 6, 7, 0, 1。
	    *   所以，要发送的**第一个帧**的序列号是 **5** (例如 $S_{5,2}$)。
	    *   要发送的**最后一个帧**的序列号是 **1** (例如 $S_{1,2}$)。
-  (3) 对于图(b)，从 $t_1$ 时刻起，甲方在不出现新的超时且未收到乙方新的数据帧之前，需要重发多少个数据帧？重发的第一个帧是哪个？ 
1. #超时重传  #GBN超时重传 
	在图(b)的 $t_1$ 时刻，发生了“$S_{2,0}$ 超时”事件。$S_{2,0}$ 是序列号为2的数据帧。
	
	根据GBN的超时重传规则，  当发生超时或收到重复ACK时，发送会重传从超时帧开始的所有已发送但未被确认的帧。
	
	1.  **超时的帧**: $S_{2,0}$ (序列号为2)。
	2.  **在其之后已发送的帧**: 观察图(b)，在 $S_{2,0}$ 之后，甲方还发送了 $S_{3,2}$ (序列号为3) 和 $S_{4,2}$ (序列号为4)。
	
	因此，甲方需要重发这3个数据帧。重发的顺序与原始发送顺序相同。
	
	*   **需要重发的帧数**: 3个。
	*   **重发的第一个帧**: 是那个导致超时的帧，即序列号为2的帧。在图中记为 $S_{2,0}$。答案中的 $S_{2,3}$ 可能是指这是对序列号为2的帧的第3次尝试发送，或者仅仅是一个标记，核心是**重发的第一个帧的序列号是2**。
-  (4) 甲方可以达到的 #最大信道利用率 是多少？  [[最大信道利用率]] 
	1. 对于GBN，一个“周期”可以看作是从发送窗口的第一个帧开始，到收到该帧的确认为止。在这段时间内，发送方最多可以发送 $W_T$ 个数据帧。

	我们先计算几个基本时间参数：
	*   #数据帧传输时延 ($T_d$): 发送一个帧所需的时间。
	    $T_d = \frac{\text{帧长度 (bits)}}{\text{信道带宽 (bps)}} = \frac{1000 \times 8 \text{ bits}}{100 \times 10^6 \text{ bps}} = \frac{8000}{10^8} = 8 \times 10^{-5} \text{ s} = 0.08 \text{ ms}$
	 - 往返时延 ( #RTT ): 题目已给，RTT = 0.96 ms。
		信道利用率的公式为：
		$U = \frac{\text{发送方在一个周期内发送数据的时间}}{\text{整个周期的总时间}}$
	- 在一个理想的、流水线充满的情况下，发送方发送完 $W_T$ 个帧，总共用时 $W_T \times T_d$。而接收到第一个帧的确认，需要的时间是该帧的传输时延 $T_d$ 加上一个完整的往返时延 RTT。所以，总周期时间是 $T_d + RTT$ 
	- 为了达到100%的利用率，发送方必须能在 $T_d + RTT$ 这段时间内持续不断地发送数据。也就是说，发送 $W_T$ 个帧的时间必须大于等于一个传播周期。即 $W_T \times T_d \ge T_d + RTT$
	- 本题中，$W_T = 7$。
		*   发送7个帧所需时间 = $7 \times T_d = 7 \times 0.08 \text{ ms} = 0.56 \text{ ms}$。
		*   一个传播周期 = $T_d + RTT = 0.08 \text{ ms} + 0.96 \text{ ms} = 1.04 \text{ ms}$。

$U = \frac{W_T \times T_d}{2 \times T_d + RTT}$，并得到了50%的结果。这个公式通常是在考虑**确认帧（ACK）本身也有传输时延** ($T_a$) 的情况下使用的，并且假设确认帧的大小和数据帧相同（例如在捎带确认的场景下），即 $T_a = T_d$。此时，一个完整的周期是：发送方发送第一个数据帧($T_d$) -> 信号传播到接收方($RTT/2$) -> 接收方发送确认帧($T_a$) -> 确认信号传播回发送方($RTT/2$)。总时间为 $T_d + T_a + RTT$。如果 $T_a=T_d$，则总时间为 $2T_d + RTT$。

让我们用这个公式来计算：
$U = \frac{W_T \times T_d}{2T_d + RTT} = \frac{7 \times 0.08 \text{ ms}}{2 \times 0.08 \text{ ms} + 0.96 \text{ ms}} = \frac{0.56}{0.16 + 0.96} = \frac{0.56}{1.12} = 0.5 = 50\%$

