![[2013-exam-paper-ocr.pdf#page=1&rect=72,656,530,705|2013-exam-paper-ocr, p.1]]
1. 利用 #归并排序 中的“归并”思想来解决   
	1. [[链表]] [[排序算法]]  [[头插法]]
		1. **降序**。我们可以对标准归并算法做一个巧妙的修改：  
			1.   我们仍然比较两个升序链表的当前节点，取出**值较小**的那个节点。 
			2.  但是，我们将取出的这个节点插入到 L3 新链表的**头部**，而不是尾部。这个方法叫做 #头插法  
			3. 最后，将另一个未处理完的链表中的所有剩余元素，依次用头插法插入 L3 新链表 
				1. 通过这个过程，我们每次都将当前所有未处理元素中最小的那个放到了新链表的头部，最终形成的链表自然就是降序的 
		2. 时间复杂度分析：
			1. 在整个合并过程中，我们需要遍历两个链表的所有节点 
			2. 对于 L1 中的每个元素，我们都要进行一次比较（除非另一个链表已经为空）和一次插入操作 
			3. 对于 L2 中的每个元素，我们也要进行一次比较和一次插入操作。 
			4. 链表的头插法操作的时间复杂度是 $O(1)$ 
			5. 因此，总的操作次数与两个链表的总长度成正比。我们需要处理 $m$ 个元素和 $n$ 个元素，总共 $m+n$ 个元素 
			6.  所以，总的时间复杂度为 $O(m+n)$ 
		3. 与选项的等价关系： 
			1. 在分析时间复杂度时，我们通常用输入规模的最大项来表示 
			2. $O(m+n)$ 和 $O(\max(m, n))$ 是等价的  [[时间复杂度等价]]
				1.  **关于“最坏情况”**：对于这个 #归并算法 ，无论输入数据如何分布（例如，一个链表的所有元素都小于另一个，或者两个链表的元素交错分布），我们都需要完整地遍历两个链表中的每一个元素。因此，其最好、最坏和平均情况下的时间复杂度都是 $O(m+n)$。题目中提到“最坏情况”是为了严谨，但在这里并不影响最终结果。
- [[时间复杂度分析]]
-  衍生考点 
	- #原地合并算法 不使用额外的空间（即不创建新链表），直接在原有两条链表的节点上进行修改，将它们合并。这会增加算法的复杂度，但空间复杂度可以降到 $O(1)$。 
	- #合并K个有序链表  将问题扩展到合并 $k$ 个有序链表。
	    *   **暴力法：** 逐一合并，先合并第1和第2个，结果再和第3个合并，以此类推。效率较低。
	    *   **分治法：** 类似归并排序，两两合并，然后将合并结果再两两合并，直到剩下一个。
	    *   **优先队列（最小堆）：** 将 $k$ 个链表的头节点放入一个最小堆中，每次取出堆顶（最小）元素，然后将该元素所在链表的下一个节点放入堆中。这是最优解法，时间复杂度为 $O(N \log k)$，其中 $N$ 是所有链表的总元素个数。 
	* #求两个有序序列合并后的中位数 ： 这是一个更高级的问题，可以在不完全合并序列的情况下，用 $O(\log(\min(m, n)))$ 的时间复杂度找到中位数。 
[[Pasted image 20250909014602.png]]
D 
![[2013-exam-paper-ocr.pdf#page=1&rect=75,608,534,656|2013-exam-paper-ocr, p.1]]
[[栈]] #栈  #解答错了 p1 可以为4 
1. 分析 $p_2 = 3$ 的前提条件 
	1.    根据入栈顺序 $1, 2, 3, \dots, n$，元素 1 和 2 必须在 3 之前入栈。 
	2. 要让 3 成为**第二个**出栈的元素，意味着在 3 出栈之前，必须有且仅有一个元素（即 $p_1$）已经出栈 
	3.  在 3 出栈的那一刻，它必须位于栈顶 
2. 确定 $p_1$ 的可能值 
	1. 在 3 入栈后，栈内的情况是 1 和 2 已经在栈中，3 刚刚入栈。此时栈顶是 3 
	2. 操作序列：`入栈(1)` -> `入栈(2)` -> `入栈(3)` 
	3. 此时栈的状态（从底到顶）：`[1, 2, 3]` 
	4.  如果此时立即出栈，第一个出栈的将是 3，即 $p_1 = 3$，这与题目条件 $p_2 = 3$ 矛盾 
	5. 因此，第一次出栈操作（得到 $p_1$）必须发生在 3 入栈之前。
	    让我们重新梳理操作序列： 
		*   `入栈(1)`
	    *   `入栈(2)`
		*    此时，栈中有 `[1, 2]`。在 `入栈(3)` 之前，我们可以选择出栈。
        *   **可能性一：$p_1 = 2$**
            *   操作：`入栈(1)` -> `入栈(2)` -> `出栈(2)`。此时 $p_1=2$，栈中剩下 `[1]`。
            *   为了让 $p_2=3$，接下来必须 `入栈(3)`。栈变为 `[1, 3]`。
            *   然后 `出栈(3)`。此时 $p_2=3$。这个序列是合法的。
		* 可能性二：$p_1 = 1$  
			*   这要求 1 在 2 入栈后出栈，这是不可能的，因为 2 在 1 上面。所以，1 必须在 2 入栈前出栈。 
			*  操作：`入栈(1)` -> `出栈(1)`。此时 $p_1=1$，栈为空 `[]` 
			 *   然后 `入栈(2)`，栈为 `[2]`。
            *   然后 `入栈(3)`，栈为 `[2, 3]`。
            *   然后 `出栈(3)`。此时 $p_2=3$。这个序列也是合法的。
结论：要满足 $p_2=3$，第一个出栈的元素 $p_1$ 只能是 1 或 2
3. 分情况讨论 $p_3$ 的可能值 
	  *   **情况一：当 $p_1 = 2, p_2 = 3$ 时**
	        *   我们回顾一下操作序列和栈的状态：
	            `入栈(1)` -> `入栈(2)` -> `出栈(2)` (得到 $p_1$) -> `入栈(3)` -> `出栈(3)` (得到 $p_2$)
	        *   在 $p_2=3$ 出栈后，栈中还剩下元素 **1**。
	        *   此时，尚未入栈的元素是 $4, 5, \dots, n$。
	        *   对于 $p_3$，我们有两种选择：
	            1.  **直接出栈**：将栈中仅剩的 1 出栈。所以 $p_3$ 可以是 **1**。
	            2.  **先入栈再出栈**：我们可以继续将 $4, 5, \dots, k$（其中 $k \le n$）入栈，然后将栈顶的 $k$ 出栈。例如：
	                *   `入栈(4)` -> `出栈(4)`。$p_3$ 可以是 **4**。
	                *   `入栈(4)` -> `入栈(5)` -> `出栈(5)`。$p_3$ 可以是 **5**。
	                *   ...
	                *   `入栈(4)` -> ... -> `入栈(n)` -> `出栈(n)`。$p_3$ 可以是 **n**。
	        *   因此，在这种情况下，$p_3$ 的可能取值集合是 $\{1, 4, 5, \dots, n\}$。
	    
    *   **情况二：当 $p_1 = 1, p_2 = 3$ 时**
        *   我们回顾一下操作序列和栈的状态：
            `入栈(1)` -> `出栈(1)` (得到 $p_1$) -> `入栈(2)` -> `入栈(3)` -> `出栈(3)` (得到 $p_2$)
        *   在 $p_2=3$ 出栈后，栈中还剩下元素 **2**。
        *   此时，尚未入栈的元素是 $4, 5, \dots, n$。
        *   对于 $p_3$，我们同样有两种选择：
            1.  **直接出栈**：将栈中仅剩的 2 出栈。所以 $p_3$ 可以是 **2**。
            2.  **先入栈再出栈**：同理，我们可以将 $4, 5, \dots, n$ 中的任意一个作为第一个入栈并立即出栈的元素。所以 $p_3$ 也可以是 **$4, 5, \dots, n$** 中的任意一个。
        *   因此，在这种情况下，$p_3$ 的可能取值集合是 $\{2, 4, 5, \dots, n\}$。
将两种情况下的可能值集合取并集，得到 $p_3$ 所有可能的取值：
    $\{1, 4, 5, \dots, n\} \cup \{2, 4, 5, \dots, n\} = \{1, 2, 4, 5, \dots, n\}$
    这个集合包含了从 1 到 n 的所有整数，除了 3。因为 3 已经是 $p_2$，不能再次出栈。
    所以，$p_3$ 的可能取值个数为 $n-1$ 个。 

-  衍生考点 

[[Pasted image 20250909014617.png]]
C
![[2013-exam-paper-ocr.pdf#page=1&rect=74,558,531,607|2013-exam-paper-ocr, p.1]]
#平衡二叉树  #平衡因子  [[平衡因子]] [[平衡二叉树]]  [[平衡二叉树的旋转]]
1. 插入 1, 2
	1. 2 > 1，插入到 1 的右子树 
	2. 此时结点 1 的平衡因子为 -1，结点 2 的为 0。树是平衡的 
2. 插入 3  
	1. 插入 3：3 > 1，3 > 2，插入到 2 的右子树。树变为 `1 -> (右) 2 -> (右) 3`   
	2. 失衡： 结点 1 失衡（平衡因子绝对值 > 1）。由于新结点 3 插入在结点 1 的**右子树(R)的右子树(R)**上，这属于 **RR 型失衡**  
	3. **调整：** 对失衡结点 1 进行**左旋 (Left Rotation)**。
        *   将 2 提升为新的根结点。
        *   将 1 变为 2 的左孩子。
        *   3 保持为 2 的右孩子。 
    *   调整后的树如下图所示：
        ```
          2
         / \
        1   3
        ```
3. 插入 4, 5  
	```
	  2
	 / \
	1   3
		 \
		  4
		   \
			5
	```
	*   **调整：** 对失衡结点 2 进行**左旋**。
	*   将 4 提升为新的根结点。
	*   将 2 变为 4 的左孩子。
	*   将 3（原来 4 的父结点）变为 2 的右孩子。
	*   5 保持为 4 的右孩子。 
    *   调整后的树如下图所示：
        ```
            4
           / \
          2   5
         / \
        1   3
        ```
4. 插入 6, 7  
	```
		4
	   / \
	  2   5
	 / \   \
	1   3   6
			 \
			  7
	```
    *   **调整：** 对失衡结点 5 进行**左旋**。
        *   将 6 提升为 5 的位置。
        *   将 5 变为 6 的左孩子。
        *   7 保持为 6 的右孩子。
    *   最终的平衡二叉树如下图所示：
        ```
              4
             / \
            /   \
           2     6
          / \   / \
         1   3 5   7
        ```
5.  **计算最终树中分支结点的平衡因子：**
    *   **分支结点**是指有子结点的结点，在这里是 4, 2, 6。
    *   **结点 2:** 左子树（以1为根）高度为 1，右子树（以3为根）高度为 1。平衡因子 = $1 - 1 = 0$。
    *   **结点 6:** 左子树（以5为根）高度为 1，右子树（以7为根）高度为 1。平衡因子 = $1 - 1 = 0$。
    *   **结点 4:** 左子树（以2为根）高度为 2，右子树（以6为根）高度为 2。平衡因子 = $2 - 2 = 0$。

**结论：**
分支结点 2, 4, 6 的平衡因子都为 0。因此，平衡因子为 0 的分支结点个数是 **3**。
所以选择 **D**。
-  衍生考点 #AVL树的删除操作 [[AVL树的高度与结点数关系]]

[[Pasted image 20250909014632.png]] 
D

![[2013-exam-paper-ocr.pdf#page=1&rect=76,523,523,558|2013-exam-paper-ocr, p.1]]
[[哈夫曼树]]  #带权路径长度  [[带权路径长度]]
1. 判断是否需要添加 #虚节点 
	*   叶子节点数 $n_0 = 6$。
	*   树的叉数 $m = 3$。
	*   计算 $(n_0 - 1) \pmod{m-1}$：
	    $(6-1) \pmod{3-1} = 5 \pmod 2 = 1$
	*   结果为1，不等于0，所以需要添加虚节点。
	*   需要添加的虚节点数量为 $k = (m-1) - u = (3-1) - 1 = 1$ 个。
	*   我们添加一个权值为0的虚节点。现在，我们的叶子节点权值集合变为：**{0, 2, 3, 4, 5, 6, 7}**。总叶子数 $n'_0 = 7$。
		*  验证一下：$(7-1) \pmod{3-1} = 6 \pmod 2 = 0$。条件满足。 
2. 构造三叉 #哈夫曼树 
	1. 使用集合 {0, 2, 3, 4, 5, 6, 7}构造树 
		1. 第一次合并 
		    选取权值最小的三个节点：0, 2, 3。
		    将它们合并，生成一个新的父节点，权值为 $0+2+3=5$。
		    现在的节点集合变为：**{4, 5, 5, 6, 7}**。
		2. 第二次合并 
		    选取权值最小的三个节点：4, 5, 5。
		    将它们合并，生成一个新的父节点，权值为 $4+5+5=14$。
			现在的节点集合变为：**{6, 7, 14}**。
		3. 第三次合并 
			只剩下最后三个节点：6, 7, 14。
		    将它们合并，生成根节点，权值为 $6+7+14=27$。
		    构造完成。
3. 计算最小带权路径长度 (WPL)
	1. 我们可以通过两种方法计算WPL 
		1. 方法一：使用定义公式 $WPL = \sum w_i l_i$ 
			1.     根据构造过程画出树的结构：
			    *   根节点 (27)
			    *   第一层：叶子节点 6, 7 (路径长度 $l=1$) 和内部节点 14。
			    *   第二层 (14的孩子)：叶子节点 4, 5 (路径长度 $l=2$) 和内部节点 5。
			    *   第三层 (5的孩子)：叶子节点 0, 2, 3 (路径长度 $l=3$)。
				    计算WPL（忽略权值为0的虚节点）：
				    $WPL = (6 \times 1) + (7 \times 1) + (4 \times 2) + (5 \times 2) + (2 \times 3) + (3 \times 3)$
				    $WPL = 6 + 7 + 8 + 10 + 6 + 9$
				    $WPL = 46$
		2. 方法二：WPL等于所有非叶子（内部）节点的权值之和  
			1.     这是一个 #哈夫曼树的重要性质 ，对于m叉哈夫曼树同样适用。
			    在我们的构造过程中，产生的内部节点（非叶子节点）的权值分别是：5, 14, 27。
			    $WPL = 5 + 14 + 27 = 46

[[Pasted image 20250909014645.png]]
[[Pasted image 20250909014726.png]]
B 

![[2013-exam-paper-ocr.pdf#page=1&rect=79,477,522,524|2013-exam-paper-ocr, p.1]]
#二叉树的后序遍历 [[线索二叉树]] [[前驱后继，前中后序]] 
3. 后序线索二叉树（本题考点）
*   **线索规则：**
    *   **左线索 (`LTag=1`)**: 指向该节点的**后序前驱**。
    *   **右线索 (`RTag=1`)**: 指向该节点的**后序后继**。
*   **特点：**
    *   与前序类似，在后序线索树上遍历和查找**后序后继**也非常困难，因为节点的后继可能是其父节点，无法仅通过线索直接找到。
    *   **这正是本题的核心**：你需要先写出后序遍历序列，然后严格按照“空左指针指向后序前驱，空右指针指向后序后继”的规则来检查线索的正确性

3. 分析已知条件 
	1. X 是一个叶结点 
		1. 这意味着 X 没有左孩子也没有右孩子。在普通的二叉树中，`X->lchild` 和 `X->rchild` 都为 `NULL`。因此，在线索二叉树中，这两个指针都将作为**线索**使用  
	2. X 存在左兄弟结点 Y
		1. 这意味着 X 和 Y 有同一个父结点。既然 Y 是 X 的**左**兄弟，那么 Y 一定是父结点的**左孩子**，而 X 一定是父结点的**右孩子** 
		2. 
		   ```
			  P
			 / \
			Y   X
		    ```
	3. 确定后序遍历序列 
		1. “左 → 右 → 根”的规则 
			1. 遍历顺序是：
				1.  遍历 P 的左子树（即以 Y 为根的子树）。
				2.  遍历 P 的右子树（即以 X 为根的子树）。
				3.  访问根结点 P。
			2. 由于 X 是一个叶结点，遍历它的子树就等于访问 X 本身。因此，这个局部结构的遍历序列必然是 `... (Y子树中的结点) ..., Y, X, P, ...`。
	4. 寻找 X 的后序后继
		1. 从上面的遍历序列 `... Y, X, P, ...` 可以清晰地看到，在访问完结点 X 之后，紧接着访问的下一个结点就是它们的父结点 P。
			因此，**X 的后序后继是其父结点 P** 
	5.  应用后序线索化规则
		1.   根据 #后序线索二叉树的定义 ，当一个结点的右孩子为空时，其右指针作为线索，指向它在后序遍历中的**后继**  
		2. 我们已经知道 X 是叶结点（右孩子为空），并且它的后序后继是其父结点 P。  
4.  X 的右线索指向它的父结点。这与选项 A 完全吻合
- 衍生考点 
	1. 寻找后序前驱
		1.    **问题**：在同样的条件下，X 的**左线索**指向谁？ 
		2.  **分析**：X 的左线索指向它的**后序前驱**。在遍历序列 `... (Y子树中的结点) ..., Y, X, P, ...` 中，X 的前一个结点是 Y 子树中**最后被访问**的那个结点。
		    *   如果 Y 也是叶结点，那么 X 的前驱就是 Y。
		    *   如果 Y 不是叶结点，那么 X 的前驱是 Y 的右子树的根（如果存在的话），或者是 Y 的左子树的根（如果 Y 只有左子树）。总的来说，是 Y 子树中按后序遍历的最后一个结点。这个结论对应了选项 D 的描述，但问的是前驱。
	2. 改变 X 的位置
		1. 若 X 是一个**左孩子**叶结点，且有**右兄弟** Y，那么 X 的右线索指向谁？ 
		2.  **问题**：若 X 是一个**左孩子**叶结点，且有**右兄弟** Y，那么 X 的右线索指向谁？
		*   **结构**：
		    ```
		          P
		         / \
		        X   Y
		    ```
		*   **分析**：此时的后序遍历序列是 `X, ... (Y子树中的结点) ..., Y, P, ...`。X 的后序后继是 Y 子树中**第一个被访问**的结点。根据“左→右→根”的顺序，这个结点通常是 Y 子树的**最左下结点**。这对应了选项 B 的描述。
	3. 与中序、前序线索二叉树的对比  
		*   **中序线索二叉树**：遍历顺序是“左→根→右”。如果 X 是一个没有右子树的右孩子，它的中序后继是其某个祖先结点。
		*   **前序线索二叉树**：遍历顺序是“根→左→右”。如果 X 是叶结点，它的前序后继通常是它的右兄弟（如果存在的话），或者是其叔父结点等。
	4. #线索二叉树的遍历算法
[[Pasted image 20250909014736.png]]
A

![[2013-exam-paper-ocr.pdf#page=1&rect=75,397,529,476|2013-exam-paper-ocr, p.1]]
- 情况一：若$v$是$T_1$的叶结点
	1. 步骤1：删除叶结点$v$ 
	2. 步骤2：将$v$重新插入到$T_2$中
	3.  **结论**
	    *   当$v$是叶结点时，$T_1$与$T_3$的结构是**相同**的。
	    *   这使得论述 **II** 正确，论述 **I** 错误。
-  情况二：若$v$不是$T_1$的叶结点 
	1. 子情况 2a: 节点$v$只有一个孩子 
		1. 步骤1：删除$v$ 
			1.  删除操作会将$v$的父结点直接连接到$v$的那个唯一的孩子。这相当于在树中“绕过”了$v$。树的结构发生了改变，$v$的子树被“提升”了一层 
		2. 步骤2：将$v$重新插入到$T_2$中 
			1.  如前所述，插入操作总是将新结点作为一个**叶结点**。当我们把$v$重新插入$T_2$时，它会被放置在树的某个叶子位置。
			2. 在$T_1$中，$v$是一个内部节点。在$T_3$中，$v$变成了一个叶结点。因此，$T_1$和$T_3$的结构必然**不同** 
	2. 子情况 2b: 节点$v$有两个孩子
		1. 步骤1：删除$v$ 
			1. 这是最复杂的情况。标准删除算法是：
	            1.  在$v$的左子树中找到值最大的结点（即$v$的中序前驱），或者在$v$的右子树中找到值最小的结点（即$v$的中序后继）。我们假设用中序后继$s$。
	            2.  将结点$s$的值复制到结点$v$的位置。
	            3.  递归地删除原来的结点$s$。（注意：结点$s$最多只有一个孩子，所以删除它会归结为叶结点或单孩子结点的删除情况）
			2. 这个操作的关键在于：**原先存放$v$的那个物理结点并没有被删除**，只是它的值被$s$的值覆盖了。而树的结构因为结点$s$的删除而发生了改变。
		2. 步骤2：将$v$的值重新插入到$T_2$中 
			1. 同样地，当我们将$v$的值作为一个新结点插入时，它会被添加到树的某个**叶子**位置。 
			2.  在$T_1$中，$v$是拥有两个孩子的内部节点。在$T_3$中，$v$的值存在于一个新插入的叶结点上。显然，树的整体结构已经发生了根本性的变化。$T_1$和$T_3$的结构必然**不同** 
	3. 结论
		*   当$v$不是叶结点时（无论有一个还是两个孩子），$T_1$与$T_3$的结构总是**不同**的。
		*   这使得论述 **III** 正确，论述 **IV** 错误。
* [[树的高度和树的深度的区别]]  

[[Pasted image 20250909014807.png]]
C
![[2013-exam-paper-ocr.pdf#page=1&rect=77,311,476,398|2013-exam-paper-ocr, p.1]]
[[邻接矩阵，邻接表 ，稀疏图，稠密图]]
1. #顶点的度 [[顶点的度]]
	1. 判断图的类型 
		1. 我们发现$A_{12} = 1$但是$A_{21} = 0$。由于$A_{ij} \neq A_{ji}$，该矩阵不是 #对称矩阵  。因此，该图是一个**有向图**。  
	2. 计算各顶点的度
		1. 根据 #有向图总度的定义$d(v_i) = d^+(v_i) + d^-(v_i)$，我们需要分别计算每个顶点的出度（行和）和入度（列和） 
	3. 
    *   **顶点$v_1$的度:**
        *   出度$d^+(v_1)$ = 第1行元素之和 = $0+1+0+1 = 2$
        *   入度$d^-(v_1)$ = 第1列元素之和 = $0+0+0+1 = 1$
        *   总度$d(v_1) = d^+(v_1) + d^-(v_1) = 2+1 = 3$

    *   **顶点$v_2$的度:**
        *   出度$d^+(v_2)$ = 第2行元素之和 = $0+0+1+1 = 2$
        *   入度$d^-(v_2)$ = 第2列元素之和 = $1+0+1+0 = 2$
        *   总度$d(v_2) = d^+(v_2) + d^-(v_2) = 2+2 = 4$

    *   **顶点$v_3$的度:**
        *   出度$d^+(v_3)$ = 第3行元素之和 = $0+1+0+0 = 1$
        *   入度$d^-(v_3)$ = 第3列元素之和 = $0+1+0+0 = 1$
        *   总度$d(v_3) = d^+(v_3) + d^-(v_3) = 1+1 = 2$

    *   **顶点$v_4$的度:**
        *   出度$d^+(v_4)$ = 第4行元素之和 = $1+0+0+0 = 1$
        *   入度$d^-(v_4)$ = 第4列元素之和 = $1+1+0+0 = 2$
        *   总度$d(v_4) = d^+(v_4) + d^-(v_4) = 1+2 = 3$
2.  **得出结论**
    各顶点的度依次是 3, 4, 2, 3。
    对比选项，正确答案是 **C. 3, 4, 2, 3**。

[[握手定理（有无向图）]]
[[路径数量]]   [[连通图与强连通图]]  [[图的连通性]]

[[Pasted image 20250909014814.png]]
C



![[2013-exam-paper-ocr.pdf#page=1&rect=77,193,514,310|2013-exam-paper-ocr, p.1]]
[[广度优先搜索（BFS）和深度优先搜索（DFS）]]
用广度优先搜索（BFS）的规则来验证每个选项。请注意，由于邻接点的访问顺序不唯一，一个图可以有多个合法的BFS序列。我们要做的是判断一个序列**是否可能**是BFS序列。

**A. h, c, a, b, d, e, g, f**

1.  **起始点**: `h`。队列：`[h]`。
2.  `h`出队，访问`h`。序列：`h`。将`h`的邻居`c`, `a`入队。队列：`[c, a]`。
3.  `c`出队，访问`c`。序列：`h, c`。将`c`未访问的邻居`b`, `d`入队。队列：`[a, b, d]`。
4.  `a`出队，访问`a`。序列：`h, c, a`。将`a`未访问的邻居`e`入队。队列：`[b, d, e]`。
5.  `b`出队，访问`b`。序列：`h, c, a, b`。`b`的邻居`a, c, d`均已访问或在队列中。
6.  `d`出队，访问`d`。序列：`h, c, a, b, d`。`d`的邻居`b, c`均已访问。
7.  `e`出队，访问`e`。序列：`h, c, a, b, d, e`。将`e`未访问的邻居`g`, `f`入队。队列：`[g, f]`。
8.  `g`出队，访问`g`。序列：`h, c, a, b, d, e, g`。
9.  `f`出队，访问`f`。序列：`h, c, a, b, d, e, g, f`。
**结论**: 序列A是**一个有效**的BFS序列。

**B. e, a, f, g, b, h, c, d**

1.  **起始点**: `e`。队列：`[e]`。
2.  `e`出队，访问`e`。序列：`e`。将`e`的邻居`a`, `f`, `g`入队。队列：`[a, f, g]`。
3.  `a`出队，访问`a`。序列：`e, a`。将`a`未访问的邻居`b`, `h`入队。队列：`[f, g, b, h]`。
4.  `f`出队，访问`f`。序列：`e, a, f`。
5.  `g`出队，访问`g`。序列：`e, a, f, g`。
6.  `b`出队，访问`b`。序列：`e, a, f, g, b`。将`b`未访问的邻居`c`, `d`入队。队列：`[h, c, d]`。
7.  `h`出队，访问`h`。序列：`e, a, f, g, b, h`。
8.  `c`出队，访问`c`。
9.  `d`出队，访问`d`。
**结论**: 序列B是**一个有效**的BFS序列。

**C. d, b, c, a, h, e, f, g**

1.  **起始点**: `d`。队列：`[d]`。
2.  `d`出队，访问`d`。序列：`d`。将`d`的邻居`b`, `c`入队。队列：`[b, c]`。
3.  `b`出队，访问`b`。序列：`d, b`。将`b`未访问的邻居`a`入队。队列：`[c, a]`。
4.  `c`出队，访问`c`。序列：`d, b, c`。将`c`未访问的邻居`h`入队。队列：`[a, h]`。
5.  `a`出队，访问`a`。序列：`d, b, c, a`。将`a`未访问的邻居`e`入队。队列：`[h, e]`。
6.  后续`h`, `e`, `f`, `g`的访问顺序也符合BFS规则。
**结论**: 序列C是**一个有效**的BFS序列。

**D. a, b, c, d, h, e, f, g**

1.  **起始点**: `a`。队列：`[a]`。
2.  `a`出队，访问`a`。序列：`a`。`a`的邻居是`b`, `e`, `h`。它们应该被**全部**放入队列。队列：`[b, e, h]` (假设按此顺序入队)。
3.  `b`出队，访问`b`。序列：`a, b`。`b`的未访问邻居是`c`, `d`。它们应该被放入队列。队列：`[e, h, c, d]`。
4.  **关键点**: 根据 #BFS的规则 ，下一个被访问的顶点必须是队列的队头，也就是`e`。但是，选项D给出的下一个顶点是`c`。
5.  `c`不是`a`的直接邻居，而是`b`的邻居。在访问完`a`的所有直接邻居（`b`, `e`, `h`）之前，BFS算法是不会去访问`b`的邻居`c`的。序列`a, b, c, d...`体现了“一条路走到底”的深度优先（DFS）特性，而不是“层层推进”的广度优先（BFS）特性。

**最终结论**: 序列D**不是**一个有效的BFS序列。它是一个有效的DFS序列。


#算法复杂度 

[[Pasted image 20250909014851.png]]
D
![[2013-exam-paper-ocr.pdf#page=1&rect=76,76,520,196|2013-exam-paper-ocr, p.1]]
[[AOE网]] [[关键路径]] 
1. 找出所有从起点到终点的路径并计算其长度
	 1. 路径1 ① → ② → ④ → ⑥  
	    *   活动序列: a, c, g
	    *   路径长度: $3 + 9 + 6 = 18$
	2. 路径2 ① → ② → ⑤ → ⑥ 
	    *   活动序列: a, e, h
	    *   路径长度: $3 + 6 + 9 = 18$
	3. 路径3 ① → ③ → ② → ④ → ⑥
	    *   活动序列: b, d, c, g
	    *   路径长度: $8 + 4 + 9 + 6 = 27$
	4. 路径4 ① → ③ → ② → ⑤ → ⑥ 
	    *   活动序列: b, d, e, h
	    *   路径长度: $8 + 4 + 6 + 9 = 27$
	5. 路径5  ① → ③ → ⑤ → ⑥
	    *   活动序列: b, f, h
	    *   路径长度: $8 + 10 + 9 = 27$
2. 确定 #关键路径 
	比较所有路径的长度：18, 18, 27, 27, 27。
	最长的路径长度为27，所以项目总工期为27。
	所有长度为27的路径都是**关键路径**。因此，这个项目有**三条**关键路径：
	*   **关键路径1 (CP1)**: b → d → c → g
	*   **关键路径2 (CP2)**: b → d → e → h
	*   **关键路径3 (CP3)**: b → f → h
3. 分析选项，找到能缩短所有关键路径的活动组合 
	要缩短总工期，我们必须缩短**所有**关键路径的长度。如果只缩短了其中一两条，那么未被缩短的那条关键路径仍然是27，总工期就不会变。 
4. 分析每个选项
	1. A. c 和 e
	    *   活动 `c` 位于 **CP1**。
	    *   活动 `e` 位于 **CP2**。
	    *   **CP3** (b, f, h) 没有受到影响，其长度仍然是27。
	    *   结论：总工期不变，仍然是27。
	2. B. d 和 c 
	    *   活动 `d` 位于 **CP1** 和 **CP2**。
	    *   活动 `c` 位于 **CP1**。
	    *   **CP3** (b, f, h) 没有受到影响，其长度仍然是27。
	    *   结论：总工期不变，仍然是27。
	3. C. f 和 d 
	    *   活动 `f` 位于 **CP3**。
	    *   活动 `d` 位于 **CP1** 和 **CP2**。
	    *   这个组合同时缩短了**所有三条**关键路径。
	    *   结论：总工期可以被缩短。
	4. D. f 和 h
	    *   活动 `f` 位于 **CP3**。
	    *   活动 `h` 位于 **CP2** 和 **CP3**。
	    *   **CP1** (b, d, c, g) 没有受到影响，其长度仍然是27。
	    *   结论：总工期不变，仍然是27。
* 最终答案 只有选项 **C** 中的活动组合（f 和 d）能够确保所有关键路径都被缩短，从而缩短整个项目的工期
[[事件最早和最晚发生时间]]  [[活动最早和最晚开始时间]]
[[活动的时差]]
[[Pasted image 20250909014901.png]]
C
![[2013-exam-paper-ocr.pdf#page=1&rect=72,40,466,75|2013-exam-paper-ocr, p.1]]
1.  **初始状态**：树为空，高度为 0。插入第一个关键字后，树由一个根节点构成，高度为 1。
2.  **插入关键字**：我们持续向这个唯一的节点（根节点）中插入关键字。对于一个 5 阶 B 树，一个节点最多可以容纳 $m-1 = 5-1 = 4$ 个关键字。
3.  **节点未满**：当我们插入第 1、2、3、4 个关键字时，它们都被放在根节点中。此时树的高度仍然是 1。例如，插入 10, 20, 30, 40 后，根节点为 `[10, 20, 30, 40]`。
4.  **触发分裂**：当我们尝试插入第 5 个关键字时（例如，插入 50），该节点中的关键字数量达到了 5，即阶数 $m$。这超过了单个节点的最大容量（4个），因此必须进行分裂。
5.  **分裂过程**：
    *   假设插入 50 后，节点中的关键字（排序后）为 `[10, 20, 30, 40, 50]`。
    *   中间的关键字（第 $\lceil m/2 \rceil = \lceil 5/2 \rceil = 3$ 个），也就是 `30`，被提升（promote）成为新的根节点。
    *   原节点分裂成两个新的子节点。左子节点包含 `30` 左边的关键字，即 `[10, 20]`。
    *   右子节点包含 `30` 右边的关键字，即 `[40, 50]`。
6.  **形成高度为 2 的树**：分裂完成后，树的结构变为：
    *   **根节点 (第1层)**: `[30]`
    *   **子节点 (第2层)**: `[10, 20]` 和 `[40, 50]`
    此时，树的高度变成了 2。

7.  **计算最少关键字数量**：
    *   新的根节点有 1 个关键字。
    *   左子节点有 2 个关键字。
    *   右子节点有 2 个关键字。
    *   总关键字数 = $1 + 2 + 2 = 5$。

[[B树（B-树）]]  [[树的种类]]   [[B树和B+树的区别]]


[[Pasted image 20250909014921.png]]
A
![[2013-exam-paper-ocr.pdf#page=2&rect=75,756,521,818|2013-exam-paper-ocr, p.2]]
#基数排序 是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。通常，我们使用 #最低位优先法 
1. 第 1 趟排序：按个位数
	1.  **分配 (Distribution):**
	    *   `110` 的个位数是 `0` -> 放入 `0` 号桶
	    *   `119` 的个位数是 `9` -> 放入 `9` 号桶
	    *   `007` 的个位数是 `7` -> 放入 `7` 号桶
	    *   `911` 的个位数是 `1` -> 放入 `1` 号桶
	    *   `114` 的个位数是 `4` -> 放入 `4` 号桶
	    *   `120` 的个位数是 `0` -> 放入 `0` 号桶 (排在 `110` 之后)
	    *   `122` 的个位数是 `2` -> 放入 `2` 号桶
	
	    分配后的桶状态如下：
	    *   桶 0: `110, 120`
	    *   桶 1: `911`
	    *   桶 2: `122`
	    *   桶 3: (空)
	    *   桶 4: `114`
	    *   桶 5: (空)
	    *   桶 6: (空)
	    *   桶 7: `007`
	    *   桶 8: (空)
	    *   桶 9: `119`
	
	2.  **收集 (Collection):**
	    按桶的顺序（从0到9）依次取出所有元素，形成新的序列。
	    **第1趟排序后的序列:** `110, 120, 911, 122, 114, 007, 119`
2. 第 2 趟排序：按十位数
	**输入序列:** `110, 120, 911, 122, 114, 007, 119`
	1.  **分配 (Distribution):**
		*   `110` 的十位数是 `1` -> 放入 `1` 号桶
		*   `120` 的十位数是 `2` -> 放入 `2` 号桶
		*   `911` 的十位数是 `1` -> 放入 `1` 号桶 (排在 `110` 之后)
		*   `122` 的十位数是 `2` -> 放入 `2` 号桶 (排在 `120` 之后)
		*   `114` 的十位数是 `1` -> 放入 `1` 号桶 (排在 `911` 之后)
		*   `007` 的十位数是 `0` -> 放入 `0` 号桶
		*   `119` 的十位数是 `1` -> 放入 `1` 号桶 (排在 `114` 之后)
	
		分配后的桶状态如下：
		*   桶 0: `007`
		*   桶 1: `110, 911, 114, 119`
		*   桶 2: `120, 122`
		*   桶 3-9: (空)
	
	2.  **收集 (Collection):**
		再次按桶的顺序（从0到9）依次取出所有元素。
		**第2趟排序后的序列:** `007, 110, 911, 114, 119, 120, 122`
[[基数排序]]  #MSD基数排序  MSD基数排序从最高位开始，将数据分到不同的桶后，对每个桶内的数据递归地进行次高位排序。它比LSD实现起来更复杂。
[[Pasted image 20250909014930.png]]
C
![[2013-exam-paper-ocr.pdf#page=2&rect=77,633,503,758|2013-exam-paper-ocr, p.2]]
#MIPS  [[计算机性能评测的四个指标]] 
 1.    $1 \text{ GHz} = 1000 \text{ MHz} = 1,000,000,000 \text{ Hz}$  
	 1.  CPI值越小，说明执行每条指令所需的时钟周期越少，性能越好 
	 2. MIPS值越高，通常意味着性能越强
2. 计算程序的平均CPI 
	1. $CPI_{平均} = \sum_{i=1}^{n} (CPI_i \times P_i)$ 
		*   A类指令：$CPI_A = 2$, $P_A = 50\% = 0.5$
		*   B类指令：$CPI_B = 3$, $P_B = 20\% = 0.2$
		*   C类指令：$CPI_C = 4$, $P_C = 10\% = 0.1$
		*   D类指令：$CPI_D = 5$, $P_D = 20\% = 0.2$
	2. $CPI_{平均} = (2 \times 0.5) + (3 \times 0.2) + (4 \times 0.1) + (5 \times 0.2)$
		1. $CPI_{平均} = 1.0 + 0.6 + 0.4 + 1.0 = 3$  
3. $MIPS = \frac{\text{主频}}{\text{平均CPI} \times 10^6}$ 
	1. $1 \text{ MHz} = 10^6 \text{ Hz}$ 
	2. $MIPS = \frac{\text{主频 (in MHz)}}{CPI_{平均}}$ 
	3. 题目给出的主频是1.2GHz。我们将其转换为MHz：
	$1.2 \text{ GHz} = 1200 \text{ MHz}$
	$MIPS = \frac{1200}{3} = 400$
4. #程序执行时间 $T_{exec} = \frac{IC \times CPI_{avg}}{\text{Clock Frequency (Hz)}}$ 
	1. 其中 $IC$ (Instruction Count) 是程序执行的总指令数 
#总指令数  若该基准程序包含6亿条指令，求其执行时间。
*   执行时间 $T = \frac{IC \times CPI_{平均}}{\text{主频 (Hz)}} = \frac{6 \times 10^8 \times 3}{1.2 \times 10^9 \text{ Hz}} = \frac{1.8 \times 10^9}{1.2 \times 10^9} = 1.5$ 秒。
[[Pasted image 20250909014940.png]]
C

![[2013-exam-paper-ocr.pdf#page=2&rect=74,598,485,636|2013-exam-paper-ocr, p.2]]
#IEEE754单精度浮点数格式  [[IEEE754单精度浮点数格式]] 
1. 第一步：十六进制转二进制
	1.  32 位的二进制表示：
		`1100 0110 0100 0000 0000 0000 0000 0000`
2. 第二步：字段解析

| 字段  | 符号位 (S) | 阶码 (E)    | 尾数 (M)   |
| :-- | :------ | :-------- | :------- |
| 位数  | 1 位     | 8 位       | 23 位     |
| 位置  | 第 31 位  | 第 30-23 位 | 第 22-0 位 |

3.  第三步：数值计算 
	1. 符号  
		1.   $S=1$ 表示这是一个负数。($S=0$ 表示正数) 
	2. 指数 
		1. 阶码 E 是一个用**移码 (Biased Representation)** 表示的无符号整数。其值为：
			$E = (10001100)_2 = 1 \times 2^7 + 0 \times 2^6 + 0 \times 2^5 + 0 \times 2^4 + 1 \times 2^3 + 1 \times 2^2 + 0 \times 2^1 + 0 \times 2^0 = 128 + 8 + 4 = 140$
		    *   在单精度格式中，偏移量 (bias) 固定为 $127$。
		    *   实际的指数值 $e$ 需要用阶码 $E$ 减去偏移量：
		        $e = E - \text{bias} = 140 - 127 = 13$
	3. 尾数 和有效数  
		1. 尾数部分 $M$ 是 `100 0000 ... 0`
		2. 有效数是 $1.M = (1.1000...)_2$ 
		3.   将这个二进制小数转换为十进制：
		$(1.1)_2 = 1 \times 2^0 + 1 \times 2^{-1} = 1 + 0.5 = 1.5$
		浮点数的最终值由以下公式计算得出：
        $V = (-1)^S \times (1.M) \times 2^e$
    *   代入我们计算出的值：
        $V = (-1)^1 \times 1.5 \times 2^{13} = -1.5 \times 2^{13}$

[[IEEE 754 标准双精度浮点数]]  
#特殊值判断 给你一个十六进制表示（如 `7F80 0000H`），问它代表什么。
    *   `7F80 0000H` -> `0 11111111 0000...0`
    *   S=0 (正), E=255 (全1), M=0。这符合无穷大的定义，所以是 $+\infty$
#浮点数精度和范围     
- 单精度浮点数能表示的大致范围和有效数字位数（约 7 位十进制有效数字）。
*   双精度浮点数能表示的大致范围和有效数字位数（约 15-16 位十进制有效数字）。
#反向转换 给你一个十进制数（如 $-12.5$），要求你将其转换为 IEEE 754 单精度十六进制格式。
    *   **示例：转换 -12.5**
        1.  **符号：** 负数，所以 $S=1$。
        2.  **转二进制：** $12.5 = (1100.1)_2$。
        3.  **科学计数法：** $(1100.1)_2 = 1.1001 \times 2^3$。
        4.  **获取 M 和 e：**
            *   尾数 $M$ 是小数点后的部分：`1001`。补全 23 位为 `10010000000000000000000`。
            *   指数 $e=3$。
        5.  **计算阶码 E：** $E = e + 127 = 3 + 127 = 130$。
        6.  **E 转二进制：** $130 = (10000010)_2$。
        7.  **组合：**
            *   S: `1`
            *   E: `10000010`
            *   M: `10010000000000000000000`
            *   完整二进制：`1100 0001 0100 1000 0000 0000 0000 0000`
        8.  **转十六进制：** `C148 0000H`。

[[Pasted image 20250909014951.png]]
A

![[2013-exam-paper-ocr.pdf#page=2&rect=77,549,491,598|2013-exam-paper-ocr, p.2]]
1. 第一步：计算 $[2x]_补$ 
	1. 有符号的定点数，乘以2等价于**算术左移一位**
	2. #算术左移规则 将所有位向左移动一位，符号位也参与移动，最低位（LSB）补0。
		*   原始 $[x]_补 = 11110100$
		*   算术左移一位后：$11110100 \ll 1 = 11101000$
		*   所以，$[2x]_补 = 11101000$
	3. 溢出判断 算术左移的 #溢出判断规则 是：如果**原符号位**与**原最高数值位**（即符号位旁边的一位）不同，则会发生溢出。
		*   在 $[x]_补 = 1\ 1110100$ 中，符号位是1，最高数值位也是1。两者相同，因此**没有发生溢出**。
2. 第二步：计算 $[y/2]_补$ 
	1. #算术右移规则 将所有位向右移动一位，最高位（符号位）用**原符号位**填充，最低位（LSB）被丢弃。
		*   原始 $[y]_补 = 10110000$
		*   算术右移一位后：$10110000 \gg 1 = 11011000$ （原符号位1被复制到新的最高位）
		*   所以，$[y/2]_补 = 11011000$
	2. #精度损失判断 算术右移可能会导致精度损失。当被丢弃的最低位为1时，就会发生精度损失。
		*   在 $[y]_补 = 10110000$ 中，被丢弃的最低位是0，因此**没有精度损失**。 
3. 第三步：计算 $[z]_补 = [2x]_补 + [y/2]_补$  
	现在我们将前两步的结果相加。补码加法规则是直接将两个补码数（包括符号位）按二进制加法规则相加。

```
   11101000   ( [2x]_补 )
+  11011000   ( [y/2]_补 )
-----------------
 1 11000000
```

4. **加法过程详解**（从右到左）：
	*   第0位: $0+0=0$
	*   第1位: $0+0=0$
	*   第2位: $0+0=0$
	*   第3位: $1+1=10$ (结果为0，进位为1)
	*   第4位: $0+1+1(进位)=10$ (结果为0，进位为1)
	*   第5位: $1+0+1(进位)=10$ (结果为0，进位为1)
	*   第6位: $1+1+1(进位)=11$ (结果为1，进位为1)
	*   第7位(符号位): $1+1+1(进位)=11$ (结果为1，进位为1)
	结果是 `11000000`，从符号位产生的进位 `1` 被丢弃（因为计算机字长是8位）。
	所以，$[z]_补 = 11000000$

5. 加法溢出判断 
	1. 我们可以使用两种方法来判断补码加法是否溢出。
		1.  **双符号位法（变形补码）**：将符号位扩展为两位。
		    *   $[2x]_{补} = 11\ 1101000$
		    *   $[y/2]_{补} = 11\ 1011000$
		    *   相加得 $11\ 1000000$。双符号位为`11`，表示结果为负且未溢出。
		2.  **单符号位法**：
		    *   **方法A（看符号）**：当两个**同号数**相加，得到的结果与加数**符号相反**时，发生溢出。本题中，两个负数（符号位为1）相加，结果仍然是负数（符号位为1），因此**没有溢出**。
		    *   **方法B（看进位）**：如果**符号位的进位** ($C_{sign}$) 和**最高数值位的进位** ($C_{high}$) **不同**，则发生溢出。
		        *   最高数值位（第6位）向符号位（第7位）的进位 $C_{high}=1$。
		        *   符号位（第7位）产生的进位 $C_{sign}=1$。
		        *   因为 $C_{sign} = C_{high}$，所以**没有溢出**。
6. 计算结果为 $[z]_补 = 11000000$，且整个过程没有发生溢出。这对应于选项A

[[补码]]   [[算术移位]]   [[补码加法溢出判断]]  #不同码制间的转换 
- 逻辑移位 vs 算术移位 
	*   **逻辑移位**：用于**无符号数**。左移和右移都用0填充空位。
    *   **循环移位**：移出的位会从另一端补入。
* [[补码减法]] 


[[Pasted image 20250909014958.png]]
A
![[2013-exam-paper-ocr.pdf#page=2&rect=80,515,503,551|2013-exam-paper-ocr, p.2]]

#海明码 [[海明码]] 核心的计算公式 
1. 为了能够纠正一位错误，校验位的位数 $k$ 和数据位的位数 $n$ 必须满足以下不等式：
    $2^k \ge n + k + 1$ 
	1.   $n=8$ 代入公式中：
	    $2^k \ge 8 + k + 1$
	    $2^k \ge k + 9$
 当 $k=4$ 时, $2^4 = 16$, $k+9 = 13$。$16 \ge 13$ **成立**。  
 满足不等式的最小整数 $k$ 是4  
- 衍生考点
	1. #反向转换   如果使用4位校验位，海明码最多可以为多少位的数据进行1位纠错？
	    *   **解法:** 已知 $k=4$，求解最大的 $n$。
	        $2^4 \ge n + 4 + 1$
	        $16 \ge n + 5$
	        $n \le 11$  
	2. #求解码字总长度 对一个16位的数据进行1位纠错，编码后的海明码总长度是多少 
		*   第一步，求 $k$。已知 $n=16$。
		  $2^k \ge 16 + k + 1 \implies 2^k \ge k + 17$
		  试错：当 $k=4$ 时, $16 \ge 21$ (×)；当 $k=5$ 时, $32 \ge 22$ (√)。所以 $k=5$。
		*   第二步，求总长度 $n+k$。
		  总长度 = $16 + 5 = 21$ 位。
	3. #区分纠错和检错能力  
	    *   **纠正1位错误 (SEC - Single Error Correction):**
        这是本题的情况，公式为 $2^k \ge n + k + 1$。
	    *   **检测1位错误 (SED - Single Error Detection):**
	        只需要1个校验位（奇偶校验位）即可。公式为 $2^k \ge n + 1$，其中 $k=1$。
	    *   **纠正1位错误，并检测2位错误 (SEC-DED):**
	        这是一种更强的编码。它需要在满足1位纠错的校验位数基础上，再增加1位校验位。
	        *   **问题示例:** 对8位数据进行1位纠错和2位检错，需要多少校验位？
	        *   **解法:**
	            1.  先按1位纠错计算：$n=8$, 求出 $k=4$。
	            2.  再增加1位用于双位检错：总校验位 = $4 + 1 = 5$ 位。
[[Pasted image 20250909015005.png]]
C
![[2013-exam-paper-ocr.pdf#page=2&rect=81,382,514,515|2013-exam-paper-ocr, p.2]]
考察的是计算机体系结构中“ #虚拟地址到物理地址的转换 ”过程， [[虚拟地址到物理地址的转换]] 特别是涉及到快表（TLB）的查询
#快表（TLB）的查询 #TLB快表  [[快表（TLB）的查询]]
1. 第一步：分析地址结构
	1. 即虚拟地址是如何被划分为“ #虚拟页号”和“ #页内偏移 ” 
	2. #页内偏移的位数 
	    题目指出页面大小为4KB。页内偏移地址的位数由页面大小决定。
	    计算公式为：$位数 = \log_2(\text{页面大小})$
	    $4KB = 4 \times 1024 \text{ Bytes} = 2^2 \times 2^{10} \text{ Bytes} = 2^{12} \text{ Bytes}$
	    所以，页内偏移需要12位。
	3. #虚拟地址的位数   
	    题目指出虚拟地址空间大小为4GB。
	    $4GB = 4 \times 1024^3 \text{ Bytes} = 2^2 \times (2^{10})^3 \text{ Bytes} = 2^{32} \text{ Bytes}$
	    所以，虚拟地址总共有32位。
	4. #虚拟页号的位数 （Virtual Page Number, VPN） 
	    虚拟页号的位数等于总地址位数减去页内偏移位数。
	    $VPN位数 = \text{总位数} - \text{页内偏移位数} = 32 - 12 = 20 \text{位}$
	5. 一个32位的虚拟地址被划分为：
		*   高20位：虚拟页号 (VPN)
		*   低12位：页内偏移 (Offset)
 2. 第二步：拆分给定的虚拟地址 
	要转换的虚拟地址是 `03FFF180H`（H代表十六进制）。
	*   **提取页内偏移**：取低12位。因为12位正好对应3个十六进制数（$12 / 4 = 3$），所以页内偏移是`180H`。
	*   **提取虚拟页号**：取高20位。因为20位正好对应5个十六进制数（$20 / 4 = 5$），所以虚拟页号是 `03FFFH`。
3. 第三步：查询快表（TLB）
	1. 地址转换时，CPU会首先在TLB中查找虚拟页号（VPN）。TLB是一个高速缓存，用于存储最近使用过的页表项，以加速地址转换 
	2. 将提取出的虚拟页号 `03FFFH` 与TLB中每一项的“标记”（Tag）进行比较 
	3. TLB采用 #全相联映射 ，意味着输入的VPN可以与TLB中任何一个entry的Tag进行比较。
		1.  Tag: `FF180H` ≠ `03FFFH`
		2.  Tag: `3FFF1H` ≠ `03FFFH`
		3.  Tag: `02FF3H` ≠ `03FFFH`
		4.  Tag: `03FFFH` == `03FFFH`  **命中（Hit）！**
4. 第四步：检查有效位并获取页框号 
	1. 找到匹配项后，检查其“ #有效位”（Valid Bit）。该行的有效位是 `1`，表示这个页表项是有效的，对应的物理页面在主存中。因此，不会发生 #缺页 （Page Fault） 
	2. 从该行读取“页框号”（Frame Number），即 `0153H`。页框号就是物理页号 
5. 第五步：拼接成物理地址 
	1. 物理地址由“页框号”和“页内偏移”拼接而成。
	*   物理地址 = 页框号 + 页内偏移
	*   物理地址 = `0153H` + `180H` = `0153180H`
因此，虚拟地址 `03FFF180H` 转换后的物理地址是 `0153180H`  A
[[Pasted image 20250909015021.png]]
A
- [[页式存储管理]]  [[快表TLB]] [[多级页表]]
#TLB缺失与缺页的区别 [[TLB缺失与缺页的区别]]  [[计算物理地址位数]]
 [[页面置换算法]]

![[2013-exam-paper-ocr.pdf#page=2&rect=79,318,515,385|2013-exam-paper-ocr, p.2]]
[[变址寻址]]
1. 理解题目给出的信息：
	*   **变址寄存器 R 的内容 (R):** $1000H$
	*   **指令中的形式地址 A (Displacement/Offset):** $2000H$
	*   **内存中的内容:**
	    *   地址 $1000H$ 处存放的数据是 $2000H$
	    *   地址 $2000H$ 处存放的数据是 $3000H$
	    *   地址 $3000H$ 处存放的数据是 $4000H$
2. 推导过程：
	1. #变址寻址的核心 是计算 #有效地址  然后用这个 #有效地址 去内存中取出最终的操作数  
3. 第一步：计算有效地址 (EA)  #变址寻址的有效地址计算公式
	1. 有效地址 (EA) = 变址寄存器的内容 + 指令中的形式地址 
		1. $EA = (R) + A$ 
		2. $EA = 1000H + 2000H = 3000H$
4. 第二步：获取操作数 
	1. 根据计算出的有效地址 $EA = 3000H$，我们去访问内存中对应地址的内容。
		题目中给出，地址 $3000H$ 中的内容为 $4000H$。
		因此，最终访问到的操作数是 **4000H**  选D 
[[寻址方式的定义]]  [[常见的寻址方式]] 
[[Pasted image 20250909015035.png]]
D

![[2013-exam-paper-ocr.pdf#page=2&rect=78,257,519,319|2013-exam-paper-ocr, p.2]]
1.  第一步：计算执行100条指令所需的总时钟周期数 
	1. #流水线执行指令 
		1. 充满阶段 ：第一条指令从进入流水线到执行完成，需要经过所有流水段 
		2. 流出阶段 ：从第一条指令执行完成开始，后续的指令每隔一个时钟周期就完成一条。 
		*   **流水线级数 (k):** 题目中给出为4级，所以 $k=4$。
		*   **指令条数 (n):** 题目中给出为100条，所以 $n=100$。
		*   **每个流水段的时间:** 题目中说明需要1个时钟周期。
	2. 第一条指令（$I_1$）完成需要 $k$ 个时钟周期，也就是4个时钟周期。
		当第一条指令完成后，流水线已经“充满”。从此刻起，每过一个时钟周期，就有一条新的指令完成。
		剩下的指令还有 $n-1$ 条，即 $100-1=99$ 条。这99条指令需要99个时钟周期来完成。
		因此，执行全部100条指令所需的总时钟周期数为：
		总周期数 = (第一条指令完成所需周期) + (剩余指令完成所需周期)
		总周期数 = $k + (n-1)$
		代入数值：
		总周期数 = $4 + (100 - 1) = 4 + 99 = 103$ 个时钟周期。
		
2.  第二步：计算执行这些指令的总时间（以秒为单位） 
	*   **CPU主频 (f):** 题目给出为1.03GHz。
	    $1 \text{ GHz} = 10^9 \text{ Hz}$，所以 $f = 1.03 \times 10^9$ Hz。
	    Hz的含义是“周期/秒”，所以CPU主频意味着每秒钟有 $1.03 \times 10^9$ 个时钟周期。
	*   **单个时钟周期的时间 ($\Delta t$):** 它是主频的倒数。
	    $\Delta t = 1/f = 1 / (1.03 \times 10^9)$ 秒。
	执行103个时钟周期的总时间 $T$ 为：
	$T = \text{总周期数} \times \Delta t = 103 \times \frac{1}{1.03 \times 10^9} = \frac{103}{1.03 \times 10^9}$ 秒。
3.  第三步：计算流水线的吞吐率 
	吞吐率的定义是单位时间内完成的指令数量。
	吞吐率 (TP) = 总指令数 / 总执行时间
	
	$TP = \frac{n}{T} = \frac{100}{\frac{103}{1.03 \times 10^9}}$
	$TP = \frac{100 \times 1.03 \times 10^9}{103}$
	
	注意到 $103 = 100 \times 1.03$，所以：
	$TP = \frac{100 \times 1.03 \times 10^9}{100 \times 1.03} = 1 \times 10^9$ 条指令/秒。
[[指令流水线与冲突]]  [[流水线性能分析]]  [[计算流水线加速比]]  
[[Pasted image 20250909015046.png]]
C

![[2013-exam-paper-ocr.pdf#page=2&rect=79,222,488,261|2013-exam-paper-ocr, p.2]]

1. 计算机总线（Bus）标准的分类和理解 [[总线的分类]]
	1. 用于**设备**和**设备控制器 (I/O 接口)** 之间互连的接口标准 
		1. 设备 : 通常指计算机外部的输入/输出设备，例如鼠标、键盘、打印机、U盘、移动硬盘等 
		2. 设备控制器 : 这是计算机主板上或内部的硬件电路，用于管理和控制外部设备，是CPU与外部设备之间的桥梁。 
	2. A. PCI(Peripheral Component Interconnect) 
		1. 这是一种**内部**总线标准，以插槽的形式存在于计算机主板上，用于连接声卡、网卡、RAID卡等**内部**扩展卡。它不是用来连接外部设备的。 
	3. B. USB   (Universal Serial Bus) 
		1.  通用串行总线。从它的名字“通用”就可以看出，它被设计用来连接各种各样的**外部**设备，如鼠标、键盘、打印机、摄像头、U盘等。这完全符合题目中“设备和设备控制器之间”的描述 
	4. C. AGP(Accelerated Graphics Port) 
		1.  加速图形端口。这是一种专用的**内部**接口，也是主板上的一个插槽，专门用于连接**显卡**。它已经被PCI-Express取代
	5.  D. PCI-Express (PCIe) 
		1.   这是PCI和AGP的后继者，是一种高速的**内部**总线标准，同样以插槽形式存在于主板上。它用于连接高性能的**内部**组件，如现代显卡、高速固态硬盘(NVMe SSD)、万兆网卡等 
[[Pasted image 20250909015054.png]]
B  [[串行和并行总线的区别]]
2.  **分类题**:
    *   “下列哪个接口标准属于串行总线？” (答案可能包含USB, PCIe, SATA)
    *   “下列哪个接口主要用于连接计算机内部的显卡？” (答案可能是AGP或PCI-Express)
    *   “PCI-Express x16中的‘x16’代表什么？” (答案：代表它有16个数据传输通道/Lanes)
3.  **比较题**:
    *   “与PCI总线相比，PCI-Express总线有何优势？” (答案：串行传输、点对点连接、带宽高、可扩展性好等)
    *   “USB接口与PCI接口的主要区别是什么？” (答案：内外总线之分、串并口之分、是否支持热插拔等)
4.  **特性题**:
    *   “下列哪种接口标准支持热插拔？” (答案：USB, Thunderbolt, eSATA)
    *   “目前主流计算机中，用于连接高性能固态硬盘（NVMe SSD）的接口标准是？” (答案：PCI-Express)
5.  **性能计算题 (较少见，但可能出现)**:
    *   可能会给出某个总线版本的理论带宽计算。例如，PCIe 3.0每条通道（per lane）的速率是8 GT/s，采用128b/130b编码。
    *   计算PCIe 3.0 x16的理论带宽：
        *   单通道有效速率: $8 \text{ GT/s} \times \frac{128}{130} \approx 7.877 \text{ Gbps}$
        *   转换为GB/s: $\frac{7.877 \text{ Gbps}}{8} \approx 0.985 \text{ GB/s}$
        *   16通道总带宽: $0.985 \text{ GB/s} \times 16 \approx 15.76 \text{ GB/s}$
    *   这类题目会考察你对总线版本、编码效率和通道数的理解。

掌握了内部/外部总线、串行/并行总线的区别，以及各种主流接口（USB, PCIe, SATA等）的用途，就能轻松应对这类问题。


![[2013-exam-paper-ocr.pdf#page=2&rect=81,174,511,225|2013-exam-paper-ocr, p.2]]
核心是区分 RAID 技术中哪些是为了**提高可靠性**（即数据冗余和容错能力），哪些是为了**提高性能**（即读写速度）
1. 用于提高 RAID **可靠性**的措施 现这种能力的核心手段是**数据冗余（Redundancy）** 
2. I. 磁盘镜像  
	1. 这是 RAID 1 的核心技术。它将一份数据完全相同地写入两块或多块硬盘。如果其中一块硬盘损坏，另一块硬盘上仍有完整的数据备份。这显然是一种数据冗余技术，**极大地提高了可靠性**。因此，I 是正确的。
3.  II. 条带化 
	1. 这是 RAID 0 的核心技术。它将数据分割成小块（条带），然后将这些小块分别写入阵列中的不同硬盘。这样做可以同时从多块硬盘上读写数据，**显著提高了性能（读写速度）**。但是，它没有任何数据冗余。如果阵列中任何一块硬盘损坏，整个阵列的数据都会丢失，因为每个文件的数据块都散布在所有硬盘上。因此，条带化本身**降低了可靠性**。所以，II 是错误的。
4. III. 奇偶校验 
	1. 这是 RAID 3, 4, 5, 6 等技术的核心。它通过对数据块进行计算（通常是异或运算）得出一个校验块。当阵列中有一块硬盘损坏时，可以利用剩下硬盘的数据块和校验块，通过逆向计算恢复出损坏硬盘上的数据。这是一种高效的数据冗余方式，**能够提高可靠性**。因此，III 是正确的。 
5. IV. 增加 Cache 机制
	1. Cache（高速缓存）是用于临时存放数据的快速存储器（如内存）。它的主要作用是加快数据访问速度，通过将热点数据或待写入数据放在缓存中，减少对慢速硬盘的直接访问次数。这是一种**提高性能**的措施。虽然带有备用电源的写缓存（Write-back Cache）可以在断电时保护尚未写入硬盘的数据，但其根本目的不是为了防止硬盘故障，因此在 RAID 的核心可靠性讨论中，它不被视为提高可靠性的主要措施。所以，IV 是错误的。 
[[Pasted image 20250909015126.png]]
B
[[几种技术和常见的 RAID 级别]]
[[不同RAID级别的比较]]   [[奇偶校验的计算原理]]   [[写惩罚RAID]]  [[热备份]]
   

![[2013-exam-paper-ocr.pdf#page=2&rect=76,124,516,179|2013-exam-paper-ocr, p.2]]
[[磁盘存储时间的计算（磁盘访问时间的计算）]]  
 总存取时间 $T_a$ = 寻道时间 $T_s$ + 旋转延迟时间 $T_r$ + 数据传输时间 $T_t$+ 控制器延迟 
 1.  平均寻道时间 $T_{seek} = 6 \text{ ms}$
 2. 平均旋转延迟 
	 1. 磁盘转速为 10000 rpm
		 1.  $T_{r\_avg} = \frac{1}{2} \times \frac{60}{n}$
		 2. 旋转一圈所需的时间为：$T_{revolution} = \frac{1}{\frac{1000}{6} \text{ rps}} = \frac{6}{1000} \text{ s} = 0.006 \text{ s}$
		 3. 平均旋转延迟 $T_{rotation} = \frac{1}{2} \times T_{revolution} = \frac{1}{2} \times 6 \text{ ms} = 3 \text{ ms}$ 
3. 传输时间 
	$T_t = \frac{\text{要传输的字节数}}{\text{磁盘传输速率}}$
	1. 在计算时，需要统一单位。通常在磁盘传输速率中，M 表示 $10^6$，K 表示 $10^3$。
	    *   $4 \text{ KB} = 4 \times 10^3 \text{ Bytes}$
	    *   $20 \text{ MB/s} = 20 \times 10^6 \text{ Bytes/s}$
	2.  $T_{transfer} = \frac{\text{Data Size}}{\text{Transfer Rate}} = \frac{4 \times 10^3 \text{ B}}{20 \times 10^6 \text{ B/s}} = \frac{4}{20000} \text{ s} = 0.0002 \text{ s}$ 
	3. 换算成毫秒：$0.0002 \text{ s} \times 1000 \text{ ms/s} = 0.2 \text{ ms}$  
4. 控制器延迟  $T_{controller} = 0.2 \text{ ms}$ 
5. $T_{total} = T_{seek} + T_{rotation} + T_{transfer} + T_{controller}$
	1. $T_{total} = 6 \text{ ms} + 3 \text{ ms} + 0.2 \text{ ms} + 0.2 \text{ ms} = 9.4 \text{ ms}$ 
[[Pasted image 20250909015134.png]]
B
- #间接给出传输速率  
    *   题目可能不直接给出“传输速率”，而是给出“磁盘转速”和“每条磁道的容量（或扇区数及每扇区大小）”。
    *   **示例**：转速为6000rpm，每条磁道有300个扇区，每扇区512B。
    *   **计算**：
        *   每秒转数 = $6000 / 60 = 100 \text{ rps}$
        *   每条磁道容量 = $300 \times 512 \text{ B}$
        *   传输速率 = $(300 \times 512 \text{ B}) \times 100 \text{ rps} = 15360000 \text{ B/s} \approx 15.36 \text{ MB/s}$
        *   然后用这个速率去计算传输时间。
- 读取连续的多个扇区/磁道 
	-   **读取同一磁道上的N个连续扇区**：寻道和旋转延迟只需要一次，传输时间是N个扇区的总传输时间。
        $T = T_{seek} + T_{rotation} + N \times T_{transfer\_one\_sector}$
    *   **读取一整个磁道**：寻道和旋转延迟也只需要一次，传输时间就是磁盘转一圈的时间。
        $T = T_{seek} + T_{rotation} + T_{revolution}$ 
- 读取非连续的多个扇区（随机读取） 
	-   如果读取N个随机分布在磁盘不同位置的扇区，那么每次读取都需要完整的“寻道+旋转+传输”过程。
    *   总时间 $\approx N \times (T_{seek\_avg} + T_{rotation\_avg} + T_{transfer\_one\_sector})$


![[2013-exam-paper-ocr.pdf#page=2&rect=74,44,452,125|2013-exam-paper-ocr, p.2]]
1. A. 中断 I/O 方式请求的是 CPU 处理时间，DMA 方式请求的是总线使用权。
	1. #中断I/O 当I/O设备准备好数据后，它会向CPU发送一个中断信号。CPU必须暂停当前正在执行的程序，转而去执行一个称为“中断服务程序（ISR）”的软件例程。在这个例程中，CPU亲自执行指令来完成数据的读取或写入。因此，中断I/O实质上是请求并占用了CPU的处理时间来完成数据传送。
	2. #DMA (Direct Memory Access) DMA方式下，数据传送不经过CPU。CPU预先设置好DMA控制器（DMAC），告知它要传送的数据源地址、目标地址、传送长度等信息。然后，DMAC会向总线仲裁器请求总线的使用权。一旦获得总线控制权，DMAC就会直接在I/O设备和主存之间传送数据。整个过程中，CPU可以继续执行其他任务。
2. B. 中断响应发生在一条指令执行结束后，DMA 响应发生在一个总线事务完成后
	1. #中断响应 为了保证指令的原子性（不可分割性），CPU通常在执行完当前的一条指令后，才会去检查是否有中断请求。如果有，并且中断是开启的，CPU才会响应中断。这个时间点被称为“中断响应周期”，确实是在指令执行周期之后 
	2. #DMA响应  DMA控制器需要使用总线来传输数据。它向CPU（或总线仲裁器）发出总线请求。CPU在执行指令的过程中，总线并不是一直被占用的。CPU会在一个总线周期（或称机器周期，通常是读/写一个存储单元或I/O端口）结束后，检查是否有总线请求。如果DMA请求的优先级更高，CPU会放弃对总线的控制权，让给DMA控制器。所以说DMA响应发生在一个总线事务（或总线周期）完成后是准确的 
3. C. 中断 I/O 方式下数据传送通过软件完成，DMA 方式下数据传送由硬件完成 
	1. #中断I/O 如A选项所述，数据传送是在中断服务程序中，由CPU执行`IN`或`OUT`之类的I/O指令来完成的。中断服务程序是一段代码，属于软件范畴。
	2. #DMA 数据传送是由专门的硬件——DMA控制器（DMAC）来控制和执行的。CPU不参与具体的数据搬运，DMAC这个硬件电路负责产生读/写信号和地址信号，完成整个数据块的传送。
4. D. 中断 I/O 方式适用于所有外部设备，DMA 方式仅适用于快速外部设备 
	1. 中断I/O方式适用于所有外部设备 
		1. 这句话过于绝对。对于像硬盘、高速网卡这类高速设备，如果采用中断方式，每传送一个字或一个字节就要中断一次CPU。这会导致CPU频繁地在用户程序和中断服务程序之间切换，耗费大量时间在保存和恢复现场上，极大地降低了系统效率，甚至可能因为来不及处理中断而导致数据丢失。因此，中断I/O方式**不适用**于传输速率非常高的设备 
	2. DMA方式仅适用于快速外部设备
		1. DMA的设计初衷确实是为了解决高速设备与CPU之间速度不匹配的问题，它在处理高速设备的大块数据传输时效率极高。但对于低速设备（如键盘），每次只传输一个字节，如果使用DMA，设置DMA控制器（地址、计数器等）的开销，远大于CPU直接通过中断处理这个字节的开销。所以DMA**不适合**用于低速、少量数据的设备。因此，说它“仅适用于快速外部设备”在实践上是合理的，但整个命题的错误点在于前半句。
[[IO控制方式]]  [[DMA的传送方式]] [[中断处理机制]]  [[总线仲裁]]
#中断服务程序ISR 

[[Pasted image 20250909015142.png]]
D
![[2013-exam-paper-ocr.pdf#page=3&rect=79,766,476,818|2013-exam-paper-ocr, p.3]]
1. 分析操作对象
	1. 用户的指令是“删除一个文件”，而不是“删除一个目录”。这是解题的关键前提 
2.  A (删除此文件所在的目录) 
    *   目录（或文件夹）是一个容器，它本身也是一个特殊的文件，其内容是它所包含的文件和子目录的列表。
    *   一个目录中通常会包含多个文件。如果删除一个文件的同时，操作系统把整个目录都删除了，那么该目录下的其他所有文件也会被一并删除。这显然违背了用户“只删除这一个文件”的意图。
    *   即使该文件是目录中的最后一个文件，标准的删除文件操作也不会自动删除这个现在变为空的目录。删除空目录是一个独立的操作（例如在Linux中的`rmdir`命令）。
    *   因此，操作系统在删除文件时，**不可能**去删除该文件所在的整个目录。
3. B (删除与此文件关联的目录项) 
    *   目录中存储的是一系列的**目录项 (Directory Entry)**。每个目录项通常包含两部分信息：文件名和指向该文件元数据（即文件控制块）的指针。
    *   当用户通过文件名来访问文件时，操作系统首先在目录中查找对应的目录项。
    *   因此，要删除一个文件，首先必须将其对应的目录项从它所在的目录中移除。这样，用户就无法再通过文件名找到这个文件了。这是删除文件的**必要步骤**。
4.  C (删除与此文件对应的文件控制块) 
    *   #文件控制块 (File Control Block, FCB)，在Unix/Linux系统中也称为**inode**，是操作系统为了管理文件而设置的核心数据结构。它存储了文件的所有元信息，如文件权限、所有者、大小、创建时间，以及最重要的——**文件数据在磁盘上存放位置的指针**。
    *   当删除了目录项后，文件本身的数据块和FCB还存在。为了彻底删除文件并回收磁盘空间，操作系统必须根据FCB中的信息，找到所有属于该文件的数据块，并将它们标记为空闲。
    *   最后，这个FCB本身所占用的空间也需要被回收。这是删除文件的**核心步骤**。
5. D (释放与此文件关联的内存缓冲区) 
    *   为了提高I/O效率，操作系统通常会使用 #内存缓冲区（Cache） #高速缓存Cache  来缓存最近读写过的文件数据。
    *   当一个文件被删除后，其在内存缓冲区中的数据就变成了无效的“脏数据”。继续保留它们会浪费宝贵的内存资源。
    *   因此，操作系统在删除文件时，会检查并释放所有与该文件相关的内存缓冲区，将这部分内存归还给系统。这是一个**常规的清理步骤**。
- [[文件删除的完整过程]]   [[软连接和硬连接]]  [[408/补充资料/操作系统/文件系统/文件实现/文件分配方式]]   [[磁盘空闲空间管理]]
[[Pasted image 20250909015150.png]]
A

![[2013-exam-paper-ocr.pdf#page=3&rect=72,731,524,769|2013-exam-paper-ocr, p.3]]
1. [[CD-ROM 的物理特性]]  
	1. 只读媒体 
		1. 数据一旦写入就不能修改。这意味着文件大小是固定的，不会增长，因此不需要考虑文件动态扩展的问题。 
	2. 机械寻道慢 
		1. CD-ROM 是一种机械式存储设备，其读写头需要在盘片上移动来定位数据。这个“寻道（seek）”过程是整个数据读取过程中最耗时的部分。相比之下，一旦磁头定位好了，连续读取数据的速度（传输速率）是很快的 
2. 快速随机播放的需求 
	1. “随机播放”或“随机访问”指的是可以直接跳转到文件的任意位置进行播放，例如拖动进度条。 
	2.  “快速”意味着从发出跳转指令到开始播放的延迟要尽可能短。根据 CD-ROM 的特性，要实现快速，就必须**最大限度地减少磁头的寻道次数和寻道距离**。 
3.  [[408/补充资料/操作系统/文件系统/文件实现/文件分配方式]]
比较四种方式的随机访问寻道次数：
*   连续结构：1 次
*   链式结构：N 次 (访问第 N 块时)
*   直接索引结构：2 次
*   多级索引结构：M+1 次 (M 为索引级数)
[[截屏2025-09-09 上午2.17.20.png]]
A

- #性能计算题  给定磁盘的寻道时间 $T_{seek}$、旋转延迟 $T_{rotation}$、数据传输率 $R_{transfer}$ 和块大小。计算在不同分配方式下，读取文件的特定数据块（例如第 1000 个块）所需的时间。
    *   **计算公式**：读取一个块的总时间 $T_{access} = T_{seek} + T_{rotation} + \frac{\text{BlockSize}}{R_{transfer}}$。
    *   **示例**：对于索引分配，读取第 `i` 个数据块需要两次访问，总时间约为 $2 \times (T_{seek} + T_{rotation}) + 2 \times \frac{\text{BlockSize}}{R_{transfer}}$（简化模型）。
*  #最大文件大小计算   
	*   **题目类型**：给定一个索引节点的结构（如有多少个直接/间接指针）、块大小和地址大小（如 4 字节），计算该系统能支持的最大文件大小。
    *   **示例**：一个索引块大小为 4KB，每个地址占 4B，则一个索引块可以存放 $4096 / 4 = 1024$ 个地址。如果采用一级间接索引，它可以指向 1024 个数据块。如果块大小也是 4KB，则仅这一个间接指针就能支持 $1024 \times 4\text{KB} = 4\text{MB}$ 的文件。





![[2013-exam-paper-ocr.pdf#page=3&rect=77,685,523,731|2013-exam-paper-ocr, p.3]]

1. I/O请求处理流程：
	`用户程序 → 系统调用处理程序 → 设备驱动程序 → 中断处理程序`
2. 问题的核心  ： 哪一个环节负责将逻辑地址转换为物理地址 即“计算数据所在磁盘的柱面号、磁头号、扇区号”？ 
	1. A. 用户程序 
		*   这是最高层的应用程序。它不关心数据在磁盘上的物理存储位置。
	    *   它通过文件名、记录号或文件内的偏移量（字节位置）来请求数据。例如，"读取文件 `data.txt` 的第100个字节开始的50个字节"。
	    *   它完全与硬件细节隔离。因此，它不计算柱面号、磁头号、扇区号。
	2. B. 系统调用处理程序 
	    *   这是操作系统内核的一部分，负责处理来自用户程序的请求（如 `read`, `write`）。
	    *   它会将用户程序提供的文件名和偏移量，通过文件系统，转换为一个与设备无关的 #逻辑块号 (Logical Block Number, LBN) 。例如，"读取逻辑块号为 12345 的数据"。
	    *   这一层仍然是设备无关的，它不知道磁盘的具体物理构造（有多少个柱面、磁头）。它的任务是屏蔽不同文件系统的差异，提供一个统一的逻辑块视图。因此，它也不计算物理地址。
	3. C. 设备驱动程序  
	    *   这是连接操作系统内核与具体硬件设备的桥梁。**它的核心职责就是将上层传来的、设备无关的逻辑请求（如逻辑块号LBN）翻译成具体硬件能够理解的物理指令。**
	    *   对于磁盘来说，这个翻译过程就包括了将逻辑块号（LBN）转换为物理地址，即**柱面号（Cylinder）、磁头号（Head）、扇区号（Sector）**，也就是 #物理CHS地址   。
	    *   因为不同的磁盘型号、不同的磁盘控制器，其物理参数（总柱面数、磁头数、每磁道扇区数）都可能不同，所以这个转换算法是高度**设备相关**的。这正是设备驱动程序存在的意义——封装硬件差异性。
	    *   因此，计算CHS地址的工作正是由设备驱动程序完成的。
	4. D. 中断处理程序  
	    *   当中断处理程序被调用时，意味着磁盘I/O操作已经**完成**（或出错）。
	    *   磁盘控制器在完成读/写任务后，会向CPU发送一个中断信号。中断处理程序被激活，它的任务是检查操作状态，将数据从硬件缓冲区拷贝到内存，并唤醒等待该I/O的进程。
	    *   它的工作是在I/O操作**之后**进行善后处理，而不是在操作**之前**计算地址。
* [[IO层次结构与地址转换]] 
	[[SPOOLing技术]] [[高速缓存Cache]] [[磁盘调度算法]]

[[截屏2025-09-09 上午2.17.27.png]]
C

![[2013-exam-paper-ocr.pdf#page=3&rect=78,621,520,685|2013-exam-paper-ocr, p.3]]
[[文件块]]  [[索引节点 (inode)]]    [[地址项]]
1. 分析四个选项与**单个文件最大长度**的关系 
	1. B. 间接地址索引的级数 
		1.     间接地址的级数直接决定了一个文件可以有多大。
		    *   只有直接地址：文件大小有限。
		    *   增加一级间接地址：可以多管理成百上千个数据块。
		    *   增加二级间接地址：可以管理的数量呈指数级增长。
		    所以，级数越多，单个文件的最大长度就越大。**因此 B 是相关的。**
	2. C. 地址项的个数 
		1. `inode`中包含的地址项总数是固定的。比如一个典型的`inode`可能有12个直接地址项、1个一级间接地址项、1个二级间接地址项。这些地址项的数量越多，能指向的数据块就越多，单个文件的最大长度也就越大。因此 C 是相关的 
	3. D. 文件块大小 
		1. 文件块的大小是计算文件总长度的基础单位。假设一个`inode`总共能指向 $N$ 个文件块，每个文件块的大小是 $B_{size}$，那么文件的最大长度就是 $N \times B_{size}$。显然，文件块大小 $B_{size}$ 越大，单个文件的最大长度也越大。**因此 D 是相关的。**
	4. A. 索引结点的总数
		前面我们提到，一个文件对应一个`inode`。因此，文件系统中`inode`的总数决定了该文件系统**最多能创建多少个文件**，而不是单个文件能有多大。一个文件系统可以有很多`inode`（能存很多小文件），也可以`inode`数量较少（只能存少量但可能很大的文件）。单个文件的长度是由其对应的那个`inode`内部的结构（如选项B、C）和文件系统的块大小（如选项D）决定的。
	    **因此 A 与单个文件的长度无关。**
2. 数学公式表达 
	1. 可以用一个公式来精确表示单个文件的最大长度 $L_{max}$，这能更清晰地展示各因素的关系 
			假设：
		*   每个文件块的大小为 $B$ 字节。
		*   每个磁盘地址（指针）占用 $P$ 字节。
		*   一个文件块能存放的地址个数为 $K = \lfloor B/P \rfloor$。
		*   `inode`中有 $N_d$ 个直接地址项。
		*   `inode`中有 $N_{s1}$ 个一级间接地址项。
		*   `inode`中有 $N_{s2}$ 个二级间接地址项。
		*   `inode`中有 $N_{s3}$ 个三级间接地址项。
		
		则单个文件的最大长度 $L_{max}$ 计算公式为：
		$L_{max} = (N_d + N_{s1} \cdot K + N_{s2} \cdot K^2 + N_{s3} \cdot K^3) \times B$
		
		从这个公式中我们可以清楚地看到：
		*   $L_{max}$ 与**间接地址索引的级数**（体现在 $K, K^2, K^3$ 的项数上）有关 (选项B)。
		*   $L_{max}$ 与**地址项的个数**（$N_d, N_{s1}, N_{s2}, \dots$）有关 (选项C)。
		*   $L_{max}$ 与**文件块大小** $B$ 直接相关，并且 $B$ 还影响了 $K$ 的值 (选项D)。
		*   整个公式中没有出现**索引结点的总数**这一变量。
[[截屏2025-09-09 上午2.17.34.png]]
A
- [[最大文件长度]]   [[文件块访问次数（磁盘IO次数）]]  [[文件系统设计与比较]]

![[2013-exam-paper-ocr.pdf#page=3&rect=78,467,517,620|2013-exam-paper-ocr, p.3]]

1. 系统配置
	1. 系统缓冲和用户工作区都采用 #单缓冲 。这意味着在任何时候，系统缓冲区只能存放一个数据块 
2. 操作流程
	1. 一个数据块的处理需要经过三个步骤：
	    *   **从外设读入系统缓冲区 (I/O操作)**：耗时 $T_{in} = 100$。
	    *   **从系统缓冲区复制到用户工作区 (内存操作)**：耗时 $T_{move} = 5$。
	    *   **CPU在用户工作区对数据块进行分析 (CPU计算)**：耗时 $T_{cpu} = 90$。
3. 目标 计算从外设读入并分析**2个数据块**所需的最短时间 
	1. “最短时间”的关键在于**并行处理**，也就是我们常说的“流水线”（Pipelining）思想。在操作系统中，CPU的计算和I/O设备的数据传输是可以同时进行的。
 4. 推导过程 (时间轴分析)  
	 1. 处理数据块 1
		*   **时间 0 → 100:**
		    *   将数据块1从外设读入系统缓冲区。
		    *   耗时 $T_{in} = 100$。
		    *   此时，CPU处于等待状态
		*   **时间 100 → 105:**
		    *   将数据块1从系统缓冲区复制到用户工作区。
		    *   耗时 $T_{move} = 5$。
		    *   在时间点 `105`，数据块1准备就绪，可以被CPU分析。同时，**系统缓冲区变为空闲状态**，可以开始读取下一个数据块
	2. 处理数据块 1 和 数据块 2 的并行阶段 
		*   **时间 105:**
		    *   **任务A (CPU):** CPU开始在用户工作区分析数据块1。此任务将持续90个时间单位，预计在 $105 + 90 = 195$ 时刻完成。
		    *   **任务B (I/O):** I/O设备开始将数据块2从外设读入系统缓冲区。此任务将持续100个时间单位，预计在 $105 + 100 = 205$ 时刻完成
		    这两个任务是并行执行的。	
		*   **时间 195:**
		    *   CPU完成了对数据块1的分析，变为空闲。
		    *   但是，数据块2此时还未完全读入系统缓冲区（I/O任务要到205才结束）。因此，CPU必须等待。
		*   **时间 205:**
		    *   I/O设备完成数据块2的读取，数据块2已完整  存放在系统缓冲区中。
		    *   CPU已经等待了 $205 - 195 = 10$ 个时间单位。
	3. 处理数据块 2
		*   **时间 205 → 210:**
		    *   将数据块2从系统缓冲区复制到用户工作区。
		    *   耗时 $T_{move} = 5$。
		*   **时间 210 → 300:**
		    *   CPU开始在用户工作区分析数据块2。
		    *   耗时 $T_{cpu} = 90$。
		    *   任务完成于 $210 + 90 = 300$。
#甘特图 

| 时间段 | 0-100 | 100-105 | 105-195 | 195-205 | 205-210 | 210-300 |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **I/O设备** | 读数据块1 | 空闲 | 读数据块2 | (已完成) | 空闲 | 空闲 |
| **系统缓冲区** | 填充数据块1 | 移出数据块1 | 填充数据块2 | (已填满) | 移出数据块2 | 空闲 |
| **CPU** | 等待 | 移入数据块1 | **分析数据块1** | 等待I/O | 移入数据块2 | **分析数据块2** |
- 处理N个数据块的总时间 $T_{total}$
	1.  **启动时间**：将第一个数据块读入并移动到用户工作区的时间。
	    $T_{startup} = T_{in} + T_{move}$
	2.  **流水线处理时间**：处理中间的 $N-1$ 个数据块。在单缓冲下，处理每个后续数据块的时间取决于CPU处理前一个块和I/O读取当前块哪个更耗时。这个阶段的时间是 $\max(T_{cpu}, T_{in})$。然后还需要加上数据移动的时间 $T_{move}$。
	3.  **收尾时间**：处理最后一个数据块的CPU时间。 
	一个更通用的公式（适用于单缓冲）是：
	$T_{total}(N) = (T_{in} + T_{move}) + \sum_{i=2}^{N} (\max(T_{cpu}, T_{in}) + T_{move}) + T_{cpu}$ 
    *   $(T_{in} + T_{move})$: 第一个数据块准备好的时间。
    *   $(N-1) \times \max(T_{cpu}, T_{in})$: 之后 $N-1$ 个块的并行处理时间，由CPU和I/O读入的瓶颈决定。
    *   $(N-1) \times T_{move}$: 之后 $N-1$ 个块的移动时间。
    *   $T_{cpu}$: 最后一个块的CPU处理时间。

[[截屏2025-09-09 上午2.17.40.png]]
C
[[单缓冲区]] [[双缓冲区]]  [[SPOOLing技术]] 
![[2013-exam-paper-ocr.pdf#page=3&rect=75,414,485,467|2013-exam-paper-ocr, p.3]]
1. 核心是理解什么操作需要操作系统的介入 
	1. I. 整数除以零 
		1. #异常  ，也称为内部中断。当CPU在执行一条指令时，如果发现一个错误（比如除数为零、内存访问越界等），它无法继续正常执行。此时，CPU会暂停当前的用户程序，自动地将控制权交给操作系统内核预设好的异常处理程序。这个交接过程就完成了从用户态到内核态的切换。内核会根据异常的类型进行处理，对于除零错误，通常是终止该进程。因此，整数除以零会导致模式切换。 
	2. II. sin()函数调用 
		1. `sin()`函数是一个标准的数学库函数，用于计算一个角度的正弦值，例如计算$sin(x)$。这个计算过程是纯粹的数学运算，不涉及任何需要操作系统特权才能访问的资源（如硬件设备、文件系统等）。它在程序的用户空间内，由CPU直接执行一系列浮点运算指令即可完成。因此，调用`sin()`函数是一个普通的过程调用，**不会**导致从用户态切换到内核态 
	3. III. #系统调用
		1. 系统调用是用户程序请求操作系统服务的**唯一**和**正式**的接口。例如，当程序需要读取文件、创建新进程、分配内存或进行网络通信时，它不能直接操作硬盘或网卡，因为这些是受保护的系统资源。程序必须通过系统调用向内核发出请求。系统调用本身就是一种特殊的中断（软件中断或陷阱），其目的就是主动地、有控制地从用户态切换到内核态，让内核来执行相应的服务。例如`read()`、`write()`、`fork()`等都是常见的系统调用。因此，系统调用必然会导致模式切换。 

[[截屏2025-09-09 上午2.17.47.png]]
B

- [[用户态与内核态]]  [[用户态与核心态的状态切换]] [[中断、异常和系统调用的区别与联系]]
- [[模式切换vs上下文切换]] [[缺页中断]]
![[2013-exam-paper-ocr.pdf#page=3&rect=74,378,465,420|2013-exam-paper-ocr, p.3]]
计算机开机后，BIOS首先启动，它从硬盘中找到操作系统，然后将操作系统的核心部分加载到RAM中，最后将控制权交给操作系统。因此，操作系统最终是在RAM中运行的。 
[[计算机启动流程]] 
[[存储器的层次结构]]  [[RAM和ROM的区别]]
[[BIOS vs. UEFI]]   [[虚拟内存]] 

[[Pasted image 20250909021805.png]]
D
![[2013-exam-paper-ocr.pdf#page=3&rect=78,333,487,380|2013-exam-paper-ocr, p.3]]
1. 中断触发 [[缺页中断（缺页异常）的处理流程]] 
	1. CPU在尝试通过页表转换虚拟地址到物理地址时，发现页表项的“存在位”（Present Bit）为0，表示该页不在物理内存中。此时，CPU会产生一个缺页中断，将控制权交给操作系统 
2. #合法性检查（缺页中断） :  操作系统接管后，开始处理这个中断 
	  *   如果地址**不合法**（即越界访问），操作系统会判定这是一个真正的错误，此时会执行“处理越界错”的操作，通常是向该进程发送一个段错误信号（Segmentation Fault），并终止该进程。
	*   然而，题目的前提是“产生缺页”，这已经隐含了这次访问是**合法的**，只是目标数据不在内存中。因此，选项 **I. 处理越界错** 是在缺页中断处理流程中、确认访问合法后**不会**执行的操作。缺页和越界是两种性质完全不同的事件。 
3. 加载页面 ：在确认访问合法后，操作系统需要将所需的页面从外存（如硬盘）调入物理内存。 
	1. 情况一：有空闲页框 
		1.  直接分配一个空闲页框 这对应了选项 **III. 分配内存** 
	2. 情况二：没有空闲页框 
		1. [[页面置换算法]] 这对应了选项 II. 置换页 
根据上述流程，当发生缺页时，操作系统为了将页面调入内存，**可能**需要分配一个新的空闲页框（III. 分配内存），也**可能**在没有空闲页框时需要先进行页面置换（II. 置换页）。但它不会处理越界错（I），因为缺页的前提是访问合法。

[[Pasted image 20250909021839.png]]
B
- [[虚拟内存]]   [[有效内存访问时间EAT]]  [[颠簸抖动]]

[[缺页中断与缺页异常]]

![[2013-exam-paper-ocr.pdf#page=3&rect=76,227,530,334|2013-exam-paper-ocr, p.3]]

1. 分析进程特性  [[CPU密集型 vs. IO密集型进程]]
    *   **P₁ (进程1)**: 90% 计算时间，10% I/O 时间。这是一个典型的 **计算密集型（CPU-bound）** 进程。它大部分时间都在使用CPU进行计算，很少需要等待I/O操作。
    *   **P₂ (进程2)**: 50% 计算时间，50% I/O 时间。这是一个 **平衡型** 进程，CPU和I/O的需求相当。
    *   **P₃ (进程3)**: 15% 计算时间，85% I/O 时间。这是一个典型的 **I/O密集型（I/O-bound）** 进程。它只需要短暂的CPU计算来发起I/O请求，然后大部分时间都在等待I/O操作完成。
[[饥饿]]  [[常见进程调度算法与优先级关系]]


[[Pasted image 20250909021851.png]]
B
![[2013-exam-paper-ocr.pdf#page=3&rect=72,134,371,227|2013-exam-paper-ocr, p.3]]
[[死锁预防 vs 死锁避免vs 死锁检测与解除]] 
1. A. 银行家算法可以预防死锁 
	1.  **错误** 根据上面的定义，银行家算法属于**死锁避免**，而不是**死锁预防**。它并没有破坏死锁的四个必要条件，而是通过动态检查来避免进入可能导致死锁的“不安全状态” 
2. B. 当系统处于安全状态时，系统中一定无死锁进程 
	1.  **正确**。[[安全状态]]的定义是：系统能够找到一个**安全序列 (Safe Sequence)** `<P₁, P₂, ..., Pn>`，按照这个序列为每个进程分配其所需资源，使得所有进程都能顺利执行完毕。如果系统中存在死锁，那么处于死锁状态的进程将永远无法完成，也就不可能存在一个能让所有进程都完成的安全序列。因此，**安全状态是无死锁的充分条件**。一个系统处于安全状态，就意味着它当前没有死锁，并且未来也可以通过合理的调度顺序避免死锁。
3. C. 当系统处于不安全状态时，系统中一定会出死锁进程 
	1.  **错误**。**不安全状态 (Unsafe State)** 只是意味着系统**无法保证**能找到一个安全序列来避免死锁，即系统**存在发生死锁的可能性**。但这并不等于必然会发生死锁。例如，一个处于不安全状态的系统，如果某个进程在请求更多资源之前就提前完成了任务并释放了它持有的资源，那么系统就可能从不安全状态转回到安全状态，从而避免了死锁。可以理解为：**不安全状态是死锁的必要不充分条件**。进入不安全状态是发生死锁的“前兆”，但不一定会“病发” 
4. D. 银行家算法破坏了死锁必要条件中的“请求和保持”条件 
	1. **错误**。银行家算法**允许**“请求和保持”条件的存在。进程可以持有资源，同时去申请新的资源。银行家算法的核心正是在这种情况下，判断是否应该批准这个新的申请。破坏“请求和保持”条件是**死锁预防**的一种手段（例如，要求进程一次性申请所有所需资源），而银行家算法是**死锁避免**。
 [[安全性算法]]

[[Pasted image 20250909021859.png]]
B
![[2013-exam-paper-ocr.pdf#page=3&rect=82,96,498,135|2013-exam-paper-ocr, p.3]]
#TCP/IP模型与OSI模型的对比  [[TCPIP模型的网络层的核心协议（IP协议）]] [[OSI七层模型]] 
1. 分析选项 
    *   **A. 对话管理 (Dialogue Management)**：这是**会话层**（第5层）的主要功能，负责建立、管理和终止两个通信主机之间的会话或连接。
    *   **B. 数据格式转换 (Data Format Conversion)**：这是**表示层**（第6层）的核心功能。它确保一个系统的应用层所发送的信息可以被另一个系统的应用层理解。这包括数据编码转换（如 ASCII 和 EBCDIC 之间的转换）、数据加密与解密、数据压缩与解压缩等。
    *   **C. 路由选择 (Routing Selection)**：这是**网络层**（第3层）的主要功能，负责在复杂的网络环境中为数据包选择最佳的传输路径。
    *   **D. 可靠数据传输 (Reliable Data Transmission)**：这是**传输层**（第4层）的主要功能之一，通过序列号、确认和重传机制（如 TCP 协议）来确保数据能够完整、无误、按序地到达目的地。
- 衍生考点 
	*   问：TCP/IP 模型中的应用层对应 OSI 模型中的哪几层？（答：应用层、表示层、会话层）。
	1. 功能与层次的直接匹配 
	    *   问：流量控制功能在 OSI 模型的哪几层实现？（答：传输层和数据链路层都有，但侧重点不同。传输层是端到端的，数据链路层是点到点的）。
	    *   问：IP 地址属于哪一层？（答：网络层）。MAC 地址属于哪一层？（答：数据链路层）
	2. 设备与层次的匹配 
	    *   问：路由器工作在 OSI 模型的哪一层？（答：网络层）。
	    *   问：交换机工作在 OSI 模型的哪一层？（答：数据链路层）。
	    *   问：集线器（Hub）工作在哪一层？（答：物理层）。
	3. #协议数据单元（PDU） 的名称
	    *   问：在传输层，数据被称为什么？（答：段，Segment）。
	    *   问：在网络层，数据被称为什么？（答：包，Packet）。
	    *   问：在数据链路层，数据被称为什么？（答：帧，Frame）。
[[Pasted image 20250909022037.png]]
B
![[2013-exam-paper-ocr.pdf#page=3&rect=74,24,496,102|2013-exam-paper-ocr, p.3]]
[[曼彻斯特编码]]
1. 题目中提到了 **10BaseT** 网卡，并给出了信号波形，要求解码出对应的比特串。10BaseT 是以太网标准之一，其物理层编码方式是**曼彻斯特编码 (Manchester Encoding)**。这是解决本题的关键 
2. 曼彻斯特编码是一种同步的、自同步时钟的线路编码技术。它的核心思想是**将时钟信号和数据信号合并在一起** 
3. 按图解码 
	1. 题目中的波形图，它由8个码元周期组成。我们逐个分析每个周期中间的电平跳变 
		*   **第1个码元**: 电平从 **高** 跳变为 **低**。
		*   **第2个码元**: 电平从 **高** 跳变为 **低**。
		*   **第3个码元**: 电平从 **低** 跳变为 **高**。
		*   **第4个码元**: 电平从 **低** 跳变为 **高**。
		*   **第5个码元**: 电平从 **高** 跳变为 **低**。
		*   **第6个码元**: 电平从 **低** 跳变为 **高**。
		*   **第7个码元**: 电平从 **低** 跳变为 **高**。
		*   **第8个码元**: 电平从 **高** 跳变为 **低**。
4. 应用编码约定进行推导
	1. 现在我们用两种约定来尝试解码：
	
	*   **尝试约定一 (IEEE 802.3)**:
	    *   高 -> 低 = **0**
	    *   低 -> 高 = **1**
	    *   解码结果: **0011 0110**
	
	*   **尝试约定二 (G.E. Thomas)**:
	    *   高 -> 低 = **1**
	    *   低 -> 高 = **0**
	    *   解码结果: **1100 1001**
	    * 解码结果 `0011 0110` 与选项 **A** 完全匹配。而解码结果 `1100 1001` 在选项中不存在。因此，本题采用的是第一种约定（IEEE 802.3 标准）。 
[[Pasted image 20250909022045.png]]
[[Pasted image 20250909022051.png]]
A
![[2013-exam-paper-ocr.pdf#page=4&rect=73,741,528,821|2013-exam-paper-ocr, p.4]]
考察的是计算机网络中两种基本的数据交换方式：**报文交换 (Message Switching)** 和 **分组交换 (Packet Switching)** 在“存储转发 (Store-and-Forward)”网络中的传输时延计算 
1. #报文交换 #分组交换 #存储转发网络  #发送时延 已知条件 
	1. 网络拓扑： 主机甲 -> 路由器 -> 主机乙。这是一个两段链路（2跳）的路径 
	2. 交换方式 : 路由器采用“存储转发”方式。这意味着路由器必须完整接收一个数据单元（无论是整个报文还是一个分组），才能开始向下一跳发送。 
	3. 链路速率 (带宽) : 两段链路的数据传输速率均为 $10\text{Mbps}$ (兆比特每秒) 
	4. 报文大小 : 原始报文总大小为 $8\text{Mb}$ (兆比特)
	5. 分组大小 : 在分组交换中，每个分组（包）的大小为 $10\text{kb}$ (千比特) 
	6. 单位换算 : 题目给出 $1\text{M} = 10^3\text{k}$ 
	7. 忽略项 : 传播延迟、分组头开销、拆装时间。这简化了计算，我们只需要关注**发送时延 (Transmission Delay)** 
2. #发送时延 是指将数据帧或分组等数据单元的所有比特推向链路所需的时间
	1. $发送时延 = \frac{数据单元大小}{链路带宽}$
3. 报文交换  
	1. 在报文交换中，整个 $8\text{Mb}$ 的报文被视为一个独立的数据单元 
	2. 第一步：主机甲 -> 路由器 
	    *   主机甲将整个 $8\text{Mb}$ 的报文发送到路由器。
	    *   发送时延 $T_1 = \frac{报文大小}{带宽} = \frac{8\text{Mb}}{10\text{Mbps}}$
	    *   为了方便计算，我们将单位统一。$8\text{Mb} = 8 \times 10^3 \text{kb}$，$10\text{Mbps} = 10 \times 10^3 \text{kbps}$。
	    *   $T_1 = \frac{8\text{Mb}}{10\text{Mbps}} = 0.8\text{s} = 800\text{ms}$。
	3. 第二步：路由器 -> 主机乙 
	    *   由于是“存储转发”，路由器必须**完整接收**这 $8\text{Mb}$ 的报文后（即等待了 $800\text{ms}$），才能开始向主机乙转发。
	    *   路由器将整个 $8\text{Mb}$ 的报文发送到主机乙。
	    *   发送时延 $T_2 = \frac{报文大小}{带宽} = \frac{8\text{Mb}}{10\text{Mbps}} = 800\text{ms}$。
	4. 总时间 
	    *   总时间是这两步操作的串行总和。主机乙接收到报文的最后一个比特，是在路由器完成第二次发送之后。
	    *   $T_{报文总} = T_1 + T_2 = 800\text{ms} + 800\text{ms} = 1600\text{ms}$。
4. 分组交换
	1. 在分组交换中，原始的 $8\text{Mb}$ 报文被分割成多个小的数据包（分组） 
	2. 第一步：计算分组数量和单个分组的发送时延 
		  *   报文总大小 = $8\text{Mb} = 8 \times 10^3 \text{kb} = 8000\text{kb}$。
	    *   单个分组大小 = $10\text{kb}$。
	    *   分组数量 $N = \frac{报文总大小}{单个分组大小} = \frac{8000\text{kb}}{10\text{kb}} = 800$ 个分组。
	    *   发送一个分组的时延 $T_{分组} = \frac{单个分组大小}{带宽} = \frac{10\text{kb}}{10\text{Mbps}} = \frac{10\text{kb}}{10 \times 10^3\text{kbps}} = 0.001\text{s} = 1\text{ms}$。
	3. 第二步：计算总时间 
	    *   分组交换的关键优势在于**流水线 (Pipelining)** 传输。路由器不需要等待所有800个分组都到达，而是在完整接收到第1个分组后，就可以立即开始向主机乙转发它。与此同时，主机甲正在向路由器发送第2个分组。
    *   **时间线分析：**
        1.  主机甲发送所有800个分组需要的时间：$T_{甲发送全部} = N \times T_{分组} = 800 \times 1\text{ms} = 800\text{ms}$。
        2.  当主机甲发送完最后一个（第800个）分组的最后一个比特时，时间过去了 $800\text{ms}$。
        3.  此时，前面的799个分组已经在网络中传输。我们关心的是最后一个分组何时能到达主机乙。
        4.  最后一个分组在 $800\text{ms}$ 时刻离开主机甲，到达路由器。路由器接收它需要 $1\text{ms}$，然后立即开始转发。
        5.  因此，最后一个分组从路由器发送到主机乙还需要一个 $T_{分组}$ 的时间。
    *   **总时间计算：**
        *   总时间 = (主机甲发送完所有分组的时间) + (最后一个分组在第二段链路上的发送时延)
        *   $T_{分组总} = T_{甲发送全部} + T_{分组} = 800\text{ms} + 1\text{ms} = 801\text{ms}$。

[[Pasted image 20250909022144.png]]
D
- [[关键时延类型和计算]]  [[三大交换技术对比]]  [[分组头开销]]

![[2013-exam-paper-ocr.pdf#page=4&rect=79,710,471,740|2013-exam-paper-ocr, p.4]]

[[信道划分协议]]
选项 A、C、D 都属于这一类，所以它们不会发生冲突
    *   **FDMA (频分多路复用)**：按频率划分信道。
    *   **TDMA (时分多路复用)**：按时间划分信道。
    *   **CDMA (码分多路复用)**：按特殊的编码序列划分信道。
2. [[随机访问协议]]
这类协议不进行预先分配，所有站点共享同一个信道，并遵循一套规则来竞争信道的使用权。由于是竞争使用，**这类协议存在发生冲突的可能性** 
#CSMA载波监听多路访问 

**结论**：在四个选项中，只有CSMA是随机访问协议，其工作机制决定了它无法完全避免冲突。因此，正确答案是B。

-  [[频分多路复用FDMA]]  [[时分多路复用TDMA]]   [[码分多路复用CDMA]]  [[载波侦听多路访问CSMA]]  [[CSMA-CD协议的工作原理]] [[CSMA-CA带冲突避免的载波监听多路访问]]




[[Pasted image 20250909022134.png]]
B
![[2013-exam-paper-ocr.pdf#page=4&rect=72,658,473,708|2013-exam-paper-ocr, p.4]]
[[HDLC协议]] 
1. 对题目给出的原始比特串 `01111100 01111110` 进行 #比特填充 操作 
	1. 步骤 1从左向右扫描比特串。
	    `011111...`
	    我们找到了第一组连续的 5 个 “1”
		*   **步骤 2**: 根据规则，在这 5 个 “1” 之后插入一个 “0”。
		    原始部分: `011111`
		    填充后变为: `0111110`
		*   **步骤 3**: 将填充后的部分与原始数据中未扫描的部分拼接起来，继续扫描。
		    已处理部分: `0111110`
		    剩余未处理部分: `0001111110`
		    当前结果: `01111100001111110`
		*   **步骤 4**: 从上次停止的地方继续扫描。
		    `...00011111...`
		    我们找到了第二组连续的 5 个 “1”。
		*   **步骤 5**: 同样，在这 5 个 “1” 之后插入一个 “0”。
		    原始部分: `11111`
		    填充后变为: `111110`
		*   **步骤 6**: 将所有部分拼接起来得到最终结果。
		    第一段填充结果: `0111110`
		    中间未变部分: `000`
		    第二段填充结果: `111110`
		    最后剩余部分: `10`
		    **最终比特串**: `011111000011111010`
		*   **步骤 7**: 将结果与选项进行比对。
		    A. `01111100 00111110 10` -> `011111000011111010` (匹配)
		    B. `01111100 01111101 01111110`
		    C. `01111100 01111101 0`
		    D. `01111100 01111110 01111101`
[[Pasted image 20250909022253.png]]
A
- 衍生考点 #比特删除    **考题形式**: 给出一段经过比特填充后的数据，要求还原出原始数据。
	*   **示例**: 接收方收到的数据为 `011011111011111010`，请问原始数据是什么？
	*   **解法**: 扫描数据，每当遇到 5 个连续的 “1” 后面跟着一个 “0” 时，就将这个 “0” 删除。
	    *   `0110111110...` -> 找到 `111110`，删除 `0` -> `011011111`
	    *   `...111110...` -> 找到 `111110`，删除 `0` -> `...11111`
	    *   原始数据为: `0110111111111110`
	* #与字符填充法对比 
		*   **考题形式**: 比较比特填充法和字符填充法的异同点。
		*   **字符填充法 (Character Stuffing)**:
		    *   **应用场景**: 用于面向字符的协议（如 PPP）。
		    *   **核心思想**: 使用一个特殊的控制字符，称为 **转义字符 (Escape character, ESC)**，通常是 `DLE` (Data Link Escape)。
		    *   **规则**:
		        *   帧的开始和结束用特殊的标志字符 `FLAG` 表示。
		        *   如果数据中出现了 `FLAG` 字符，就在其前面插入一个 `ESC` 字符。
		        *   如果数据中出现了 `ESC` 字符，就在其前面也插入一个 `ESC` 字符。
		    *   **对比**: 比特填充是 bit 级别的操作，不依赖于8位字符边界，效率更高；字符填充是 byte 级别的操作，处理简单，但可能增加较多开销。
	* #HDLC帧结构 [[HDLC帧结构]]  [[差错控制与流量控制]]  #差错控制与流量控制  
![[2013-exam-paper-ocr.pdf#page=4&rect=78,609,527,658|2013-exam-paper-ocr, p.4]]
 #直通交换  [[交换机的工作方式]]
1.    **速率 (Rate):** $100 \text{ Mbps}$ (每秒100兆比特)
2.   **交换方式:** 直通交换
3. **问题:** 引入的**至少**的 #转发延迟 
4. 关键信息 
    *   “输出端口无排队”：这意味着一旦交换机决定转发，数据可以立刻被发送出去，我们不需要考虑因端口繁忙而产生的排队延迟。
    *   “不包括前导码”：计算时从以太网帧的第一个字段开始，即目的MAC地址。
5. 根据 #直通交换 的定义，交换机需要接收到足以确定目标端口的信息就开始转发。在 #以太网帧结构 中，这部 分信息就是 #目的MAC地址
	1. 一个标准的 #以太网MAC地址长度 为 **6字节 (Bytes)** 
		1. 因此，最小转发延迟就是交换机接收这6个字节所需的时间。一旦这6个字节到达输入端口，交换机就能查表并建立内部通路，开始向输出端口转发数据流 
	2. 第一步：计算需要接收的数据量（比特位） 
		1. 交换机需要接收目的MAC地址，其大小为6字节。我们需要将其转换为比特（bit），因为网络速率的单位是比特/秒。
		$数据量 = 6 \text{ Bytes} \times 8 \text{ bits/Byte} = 48 \text{ bits}$
	3. 第二步：计算传输这些数据所需的时间
		1. 延迟的计算公式为：
		$延迟 = \frac{数据量}{传输速率}$
	4. $延迟 = \frac{48 \text{ bits}}{100 \text{ Mbps}} = \frac{48 \text{ bits}}{100 \times 10^6 \text{ bits/s}}$ 
		1. $延迟 = 0.48 \times 10^{-6} \text{ s}$ 
	5. 将秒（s）转换为微秒（μs），因为$1 \mu s = 10^{-6} s$。
		$延迟 = 0.48 \mu s$
所以，引入的转发延迟至少是 **0.48μs**。 答案选择 **B** 
[[Pasted image 20250909022650.png]]
B
- 衍生考点 #存储转发网络  #存储转发 #存储转发下的延迟计算  “对于一个100 Mbps的交换机，采用 #存储转发 方式转发一个长度为1518字节的以太网帧，其转发延迟是多少？”
	- **计算方法:**
    1.  数据量 = 1518 Bytes = $1518 \times 8 \text{ bits} = 12144 \text{ bits}$
    2.  延迟 = $\frac{12144 \text{ bits}}{100 \times 10^6 \text{ bits/s}} = 121.44 \times 10^{-6} \text{ s} = 121.44 \mu s$
    *   （这恰好是本题的选项D，通常出题人会把其他模式的计算结果作为干扰项。）
* #碎片隔离 (Fragment-Free) 模式
	* 直通交换的一种改良模式 。它会等待接收完以太网帧的**前64个字节**后再开始转发 
	*   **为什么是64字节？** 因为以太网协议规定，最小有效帧长是64字节。在早期共享式以太网中，如果发生冲突，产生的冲突碎片（collision fragment）通常小于64字节。通过检查前64字节，交换机可以过滤掉大部分由冲突产生的无效帧，从而在延迟和可靠性之间取得一个平衡。
	*   **考题形式:** “若该交换机采用碎片隔离方式，转发延迟至少是多少？”
	*   **计算方法:**
	    1.  数据量 = 64 Bytes = $64 \times 8 \text{ bits} = 512 \text{ bits}$
	    2.  延迟 = $\frac{512 \text{ bits}}{100 \times 10^6 \text{ bits/s}} = 5.12 \times 10^{-6} \text{ s} = 5.12 \mu s$
    *   （这恰好是本题的选项C。）
[[网络延迟组成]]
![[2013-exam-paper-ocr.pdf#page=4&rect=74,548,532,609|2013-exam-paper-ocr, p.4]]
1. 计算甲发送的确认序号 (ack)  [[TCPIP模型的网络层的核心协议（IP协议）]] [[TCP的序号和确认序号]] 
	1. 确认序号的作用是**告知对方我期望收到的下一个字节的序号是多少**。
		*   甲收到了来自乙的报文段，这个报文段的序号是 $1913$，并且携带了 $100$ 字节的数据。
		*   这意味着甲收到的数据字节范围是从序号 $1913$ 到 $1913 + 100 - 1 = 2012$。
		*   既然甲已经成功收到了到 $2012$ 为止的所有字节，那么它期望从乙那里收到的下一个字节的序号就是 $2013$。
		*   因此，甲发送给乙的报文段中，确认序号 `ack` 的值就是为了确认它收到的这批数据。
		计算公式为：
		$ack_{甲 \to 乙} = seq_{乙 \to 甲} + \text{Payload}_{乙 \to 甲}$
		$ack_{甲 \to 乙} = 1913 + 100 = 2013$
	所以，甲回送的 **确认序号是 2013**
2.  计算甲发送的序号 (seq) 
	1. 序号的作用是**标记本报文段所发送的数据的第一个字节的编号**。 
		*   在甲收到乙的报文段中，有一个确认序号 `ack = 2046`。
		*   这个 `ack` 值是乙发给甲的，它代表**乙期望从甲那里收到的下一个字节的序号是 2046**。
		*   这也就告诉了甲，它之前发送的、序号在 $2046$ 之前的所有数据，乙都已经成功接收了。
		*   因此，当甲现在要发送新的数据时，它必须从乙期望的序号开始，也就是 $2046$。
	2. 所以，甲回送的 **序号是 2046** 
[[Pasted image 20250909022707.png]]
B
- [[TCP三次握手]] [[TCP四次挥手]] [[TCP数据传输中的丢包与重传]]

![[2013-exam-paper-ocr.pdf#page=4&rect=79,486,513,545|2013-exam-paper-ocr, p.4]]
1. I. 只支持传输 7 比特 ASCII 码内容 
	1. SMTP 协议只支持传输 7 比特的 ASCII 码内容 
2. II. 支持在邮件服务器之间发送邮件 
	  *   观察图中的流程，有一个箭头从“发送方邮件服务器”指向“接收方邮件服务器”，并且这条连接上标注了“发送邮件SMTP TCP连接”。这清晰地表明SMTP协议用于在两个邮件服务器之间传递（或中继）邮件。
    *   “解析”部分的文字也证实了这一点：“...或在邮件服务器之间发送邮件。”
    *   因此，叙述 **II 是正确的**
3. III. 支持从用户代理向邮件服务器发送邮件 
    *   观察图的左侧，“发件人用户代理”（即邮件客户端，如Outlook, Foxmail）通过“发送邮件SMTP TCP连接”将邮件发送给“发送方邮件服务器”。
    *   “解析”部分的文字也明确说明：“SMTP 协议用于用户代理向邮件服务器发送邮件...”
    *   因此，叙述 **III 是正确的**。
4. IV. 支持从邮件服务器向用户代理发送邮件 
	  *   观察图的右侧，当“收件人用户代理”需要接收邮件时，它与“接收方邮件服务器”建立的连接是“读取邮件POP3 TCP连接”。这里使用的协议是POP3，而不是SMTP。SMTP负责“推”（push）送邮件，而POP3或IMAP负责“拉”（pull）取邮件。
	    *   因此，叙述 **IV 是错误的**。
* 正确的叙述是 I、II 和 III。所以，正确答案是 **A**。  
![[Pasted image 20250909022715.png]]
A
- [[简单邮件传输协议SMTP]]  [[互联网消息访问协议IMAP]]  [[邮局协议第3版POP3]]  
[[MIME协议的作用]]   [[协议与端口号的对应]]  [[DNS在邮件系统中的作用]]
  [[邮件传输的完整过程]]


![[2013-exam-paper-ocr.pdf#page=4&rect=75,366,524,488|2013-exam-paper-ocr, p.4]]
1. #寻找主元素 #主元素的定义 是：在一个数组中出现次数超过数组长度一半（$n/2$）的元素。
	1. [[摩尔投票算法]]
2. 算法推导与核心思想
	*   **暴力法**：对每个元素，都遍历一次数组来统计它的出现次数。时间复杂度为 $O(n^2)$，效率太低。
	*   **哈希表法**：用一个哈希表（或字典）来存储每个元素及其出现的次数。遍历一遍数组填充哈希表，然后再遍历一遍哈希表找出次数超过 $n/2$ 的元素。时间复杂度为 $O(n)$，空间复杂度为 $O(n)$（最坏情况下所有元素都不同）。虽然时间效率高，但空间开销大。
	*   **排序法**：将数组排序。如果主元素存在，那么排序后，数组中间位置的那个元素（下标为 $\lfloor n/2 \rfloor$）必然是主元素。因为主元素的数量超过了一半，无论如何排列，它都会占据中间的位置。时间复杂度为 $O(n \log n)$，空间复杂度取决于排序算法（例如，原地快排是 $O(\log n)$，归并排序是 $O(n)$）。
3. 方法一：哈希表法 
	 (1) 算法的基本设计思想
	哈希表法利用了其键值对（key-value）存储的特性，可以高效地统计数组中每个元素出现的次数 
	1.  **遍历与计数**：创建一个哈希表（在C++中可用 `std::unordered_map`），其中键（key）存储数组中的元素，值（value）存储该元素的出现次数。遍历整个输入数组，对于每个元素，更新它在哈希表中的计数值。
	2.  **查找主元素**：完成计数后，再次遍历哈希表。检查每一个键值对，如果某个元素（值）的出现次数大于数组长度的一半（`n/2`），那么这个元素就是主元素，返回它。
	3.  **处理不存在情况**：如果遍历完整个哈希表都没有找到符合条件的元素，说明该数组中不存在主元素，按要求返回 -1。
	(2) C++ 语言算法描述    [[哈希表]]
	```cpp
#include <iostream>
#include <vector>
#include <unordered_map>

/**
 * @brief 使用哈希表法寻找数组中的主元素
 * @param nums 整数数组
 * @return 如果存在主元素，则返回该元素；否则返回 -1
 */
int findMajorityElement_HashTable(const std::vector<int>& nums) {
    // 处理空数组的边界情况
    if (nums.empty()) {
        return -1;
    }

    // 关键点1: 使用哈希表来存储每个数字及其出现的次数
    // key 是数组中的元素，value 是该元素的出现次数
    std::unordered_map<int, int> counts;

    // 第一次遍历：填充哈希表，统计每个元素的频率
    for (int num : nums) {  
        counts[num]++;   
    }

    // 计算主元素的阈值
    size_t threshold = nums.size() / 2;

    // 关键点2: 第二次遍历（遍历哈希表），检查是否存在主元素
    // auto& 表示以引用的方式访问键值对，避免复制，提高效率
    for (const auto& pair : counts) {
        // 如果某个元素的出现次数大于数组长度的一半，则它就是主元素
        if (pair.second > threshold) {
            return pair.first;
        }
    }

    // 如果遍历完哈希表都没有找到，则说明不存在主元素
    return -1;
}

// --- 测试代码 ---
void test(const std::vector<int>& arr) {
    std::cout << "数组: [ ";
    for(int x : arr) std::cout << x << " ";
    std::cout << "], 主元素是: " << findMajorityElement_HashTable(arr) << std::endl;
}

int main() {
    // 题目示例1：存在主元素 5
    test({0, 5, 5, 3, 5, 7, 5, 5}); 
    // 题目示例2：不存在主元素
    test({0, 5, 3, 5, 1, 5, 7});
    // 其他测试用例
    test({1, 1, 2, 1, 3});
    test({1, 2, 3, 4});
    test({}); // 空数组
    return 0;
}
```
 (3) 时间复杂度和空间复杂度

*   **时间复杂度: O(n)**
    *   第一次遍历数组以填充哈希表需要 O(n) 的时间。
    *   第二次遍历哈希表，在最坏情况下（所有元素都不同），哈希表中有 n 个条目，需要 O(n) 的时间。
    *   因此，总的时间复杂度为 O(n) + O(n) = O(n)。

*   **空间复杂度: O(k)** 或 **O(n)**
    *   空间复杂度取决于哈希表中存储的唯一元素的数量，我们称之为 k。
    *   在最好的情况下（所有元素都相同），k=1，空间复杂度为 O(1)。
    *   在最坏的情况下（所有元素都不同），k=n，哈希表需要存储 n 个键值对，空间复杂度为 O(n)。
[[Pasted image 20250909022725.png]]
[[Pasted image 20250909022747.png]]
[[Pasted image 20250909022809.png]]
- [[数据流中的主元素]]

![[2013-exam-paper-ocr.pdf#page=4&rect=77,263,530,370|2013-exam-paper-ocr, p.4]]
#平均查找长度（ASL）  [[平均查找长度 (ASL)]]
1. 数据集 S = {"do", "for", "repeat", "while"} 
2. 各元素的查找概率：
    *   $p_{do} = 0.35$
    *   $p_{for} = 0.15$
    *   $p_{repeat} = 0.15$
    *   $p_{while} = 0.35$ 
3. 基准线：采用折半查找（Binary Search）的 ASL 为 2.2 
4. 目标：找到一种排列和查找方法，使得 ASL < 2.2 
-  (1) 详解：顺序存储结构 
	-  若采用顺序存储结构（如数组）保存 S，且要求平均查找长度更短，则元素应如何排列？应使用何种查找方法？查找成功的平均查找长度是多少？ 
1. 可选的查找方法 
	 在顺序存储结构（数组）中，我们主要有两种查找方法：
    *   **顺序查找 (Sequential Search):** 从头到尾逐个比较。
    *   **折半查找 (Binary Search):** 要求元素必须有序。通过不断缩小查找范围来查找。
2. 评估 #折半查找  
	题目已经给出折半查找的 ASL 是 2.2。折半查找的效率不依赖于元素的查找概率，只依赖于元素的位置。例如，它总是先比较中间位置的元素，而这个元素的查找概率可能很低，这就导致了性能上的浪费。因此，当各元素查找概率不均时，折半查找不一定是最优的。 
3. 评估顺序查找
	1. 顺序查找的比较次数 $C_i$ 就是元素在列表中的位置（第 $i$ 个元素需要比较 $i$ 次）。为了让高概率元素的 $C_i$ 最小，我们应该把**查找概率最高的元素放在最前面**
4. 确定排列顺序 
	1. 根据各元素的查找概率进行降序排列。 
		*   $p_{do} = 0.35$
	    *   $p_{while} = 0.35$
	    *   $p_{for} = 0.15$
	    *   $p_{repeat} = 0.15$
	    *   因此，最优排列为：`{"do", "while", "for", "repeat"}` 或 `{"while", "do", "for", "repeat"}`。我们以第一种为例。
	2. 确定查找方法：  采用**顺序查找**  
5.  **计算 ASL：**
    *   查找 "do"：概率 $p_1=0.35$，比较次数 $C_1=1$。
    *   查找 "while"：概率 $p_2=0.35$，比较次数 $C_2=2$。
    *   查找 "for"：概率 $p_3=0.15$，比较次数 $C_3=3$。
    *   查找 "repeat"：概率 $p_4=0.15$，比较次数 $C_4=4$
    根据公式计算 ASL：
    $ASL = p_1 C_1 + p_2 C_2 + p_3 C_3 + p_4 C_4$
    $ASL = 0.35 \times 1 + 0.35 \times 2 + 0.15 \times 3 + 0.15 \times 4$
    $ASL = 0.35 + 0.70 + 0.45 + 0.60 = 2.1$
6.  **得出结论：**
    *   ASL = 2.1，小于题目给出的折半查找的 2.2。
    *   **排列方式：** 按查找概率降序排列。
    *   **查找方法：** 顺序查找。
    *   **平均查找长度：** 2.1。
- 问题 (2) 详解： #链式存储结构 
1. 可选的查找方法 
	1. 在链式存储结构中，元素在内存中不连续，我们无法通过下标直接访问任意元素（即不支持随机访问）。因此，**折半查找不可行**。我们只能从头结点开始，沿着指针逐个遍历，这正是**顺序查找**  
2. 优化策略 
	 *   **答案一（基于简单链表）：** 既然只能用顺序查找，那么优化思路和问题 (1) 完全相同：将查找概率高的元素放在链表的头部。
	        *   **排列方式：** 按查找概率降序排列。
	        *   **查找方法：** 顺序查找。
	        *   **平均查找长度：** 计算过程和结果与问题 (1) 完全相同，ASL = 2.1。
    *   **答案二（基于更优的链式结构——二叉排序树）：** 链式存储不仅仅指线性链表，树（如二叉树）也是一种典型的链式存储结构。为了获得更优的查找性能，我们可以构建一棵**最优二叉查找树 (Optimal Binary Search Tree, OBST)**。其核心思想依然是：让查找概率高的节点尽可能靠近根节点，以减少平均比较次数（即深度）。
3. 解题步骤（基于答案二）
	1. 确定查找方法 
		1.  采用**二叉排序树**进行查找 
	2. 确定排列方式（构建树） 
		1. 我们需要构建一棵树，使得 ASL 最小。这需要让概率高的节点深度小。观察题目给出的图示“二叉排序树1” 
		-   根节点："for" (p=0.15, 深度为1, 比较1次)
	    *   "for"的左孩子："do" (p=0.35, 深度为2, 比较2次)
	    *   "for"的右孩子："while" (p=0.35, 深度为2, 比较2次)
	    *   "while"的左孩子："repeat" (p=0.15, 深度为3, 比较3次)
	    *   注意：这棵树的构造是为了优化查找效率，但它不满足严格的二叉排序树定义（即 `left < parent < right`），例如 "repeat" 应该在 "while" 的左边。所以更准确地称之为“判定树”或“次优查找树”。但解题时我们遵循其思路。
	3.  **计算 ASL：**
	    *   查找 "for"：概率 $p_{for}=0.15$，比较次数 $C_{for}=1$。
	    *   查找 "do"：概率 $p_{do}=0.35$，比较次数 $C_{do}=2$。
	    *   查找 "while"：概率 $p_{while}=0.35$，比较次数 $C_{while}=2$。
	    *   查找 "repeat"：概率 $p_{repeat}=0.15$，比较次数 $C_{repeat}=3$。
		
	    $ASL = 0.15 \times 1 + 0.35 \times 2 + 0.35 \times 2 + 0.15 \times 3$
	    $ASL = 0.15 + 0.70 + 0.70 + 0.45 = 2.0$

4.  **得出结论：**
    *   ASL = 2.0，比 2.2 和 2.1 都更短。
    *   **排列方式：** 构建一棵最优（或次优）的二叉查找树，将高概率节点置于浅层。
    *   **查找方法：** 基于该树的查找。
    *   **平均查找长度：** 2.0。 
[[Pasted image 20250909022849.png]]
- [[最优二叉查找树]] 
- [[哈夫曼树]]  
	-     **关联性：** OBST 的思想与哈夫曼树非常相似。哈夫曼树用于数据压缩，其目标是最小化带权路径长度（WPL），即让出现频率高的字符拥有更短的编码。两者都遵循“高频短路，低频长路”的核心思想。
    *   **区别：** 哈夫曼树中，所有待编码的字符都在叶子节点上，非叶子节点没有实际意义。而在 OBST 中，所有关键字都存储在树的内部节点上。
 [[自组织线性表]]

![[2013-exam-paper-ocr.pdf#page=4&rect=74,115,535,267|2013-exam-paper-ocr, p.4]]
- (1) CPU和总线的时钟周期各为多少？总线的带宽为多少？ 
1. #时钟周期 
	*   CPU主频为 $f_{CPU} = 800 \text{MHz}$。
    *   CPU时钟周期 $T_{CPU} = \frac{1}{f_{CPU}} = \frac{1}{800 \times 10^6 \text{ Hz}} = 1.25 \times 10^{-9} \text{ s} = 1.25\text{ns}$。
    *   总线时钟频率为 $f_{Bus} = 200 \text{MHz}$。
    *   总线时钟周期 $T_{Bus} = \frac{1}{f_{Bus}} = \frac{1}{200 \times 10^6 \text{ Hz}} = 5 \times 10^{-9} \text{ s} = 5\text{ns}$。
2. #总线带宽  
	*   公式为：带宽 = 总线宽度 × 总线频率。
    *   总线宽度为32位，即4字节 (4B)。
    *   总线带宽 = $4\text{B} \times 200 \text{MHz} = 4\text{B} \times 200 \times 10^6 \text{/s} = 800 \times 10^6 \text{B/s} = 800\text{MB/s}$。 
- (2) Cache缺失时，需要用几个读突发传送总线事务来完成一个主存块的读取？ 
1. 
	*   **Cache与主存的数据交换单位是“块”（Block/Line）**。当Cache缺失时，需要从主存中读取一整个数据块到Cache中。
	*   题目给出Cache块大小为32字节。
	*   题目也明确指出“每次读突发传送32字节”。
	*   因此，读取一个32字节的主存块正好需要一次32字节的读突发传送。
	1. 需要 **1** 个读突发传送总线事务 
-  (3) 存储器总线完成一次读突发传送总线事务所需要的时间是多少？ 
1. 精确理解总线事务的流程和时间的计算。一次突发传送（Burst Transfer）包含三个主要阶段 
	1. 地址和命令传送 
		1. CPU通过总线将要读取的主存地址和读命令发送给存储器。
		    *   题目说明：“传送首地址和命令...需要一个总线时钟周期”。
		    *   时间 = $1 \times T_{Bus} = 1 \times 5\text{ns} = 5\text{ns}$。
	2. 主存准备数据 
		1. 主存接收到地址后，需要一段时间来寻址并取出第一个数据。这个时间通常由主存的存储周期决定。
		    *   题目说明：主存的存储周期为40ns。这就是从接收地址到第一个数据准备好的时间。
		    *   时间 = $40\text{ns}$
	3. 数据传送 
		1. 数据准备好后，通过总线传回给CPU。由于是突发传送，后续的数据会以最快的速度（每个总线周期一个）连续传送 
		    *   总共需要传送32字节的数据。
		    *   总线宽度为32位 = 4字节。
		    *   需要传送的次数 = $\frac{\text{总数据量}}{\text{总线宽度}} = \frac{32\text{B}}{4\text{B}} = 8$ 次。
		    *   每次传送需要一个总线时钟周期。
		    *   数据传送总时间 = $8 \times T_{Bus} = 8 \times 5\text{ns} = 40\text{ns}$。
2. 总时间计算
	1. 在典型的总线模型中，这三个阶段是部分 #串行 的。首先发送地址，然后是存储器访问延迟，最后是数据传输。总时间是从总线事务开始（地址被放上总线）到最后一个数据传输完成为止
	2.   $T_{总} = T_{地址传送} + T_{主存延迟} + T_{数据传送}$
	3.   $T_{总} = 5\text{ns} + 40\text{ns} + 40\text{ns} = 85\text{ns}$ 
3. 关于 #交叉存储 的说明  
	题目提到“8体交叉存储方式”，存储周期为40ns，总线周期为5ns。这意味着存储器可以被流水线式访问。当第一个存储体（Bank）在进行40ns的读操作时，后续的7个存储体可以依次启动（每隔一个总线周期5ns启动一个）。
	*   $T_{存储周期} = 40\text{ns}$
	*   $m \times T_{Bus} = 8 \times 5\text{ns} = 40\text{ns}$
	*   因为 $T_{存储周期} \le m \times T_{Bus}$，所以主存可以完美地支持总线以每个周期传送一个数据的速度进行突发传送，不会让总线产生等待。这证明了上面计算中使用 $8 \times 5\text{ns}$ 作为数据传送时间是合理的
-  (4) 若程序BP执行过程中，共执行了100条指令，平均每条指令需进行1.2次访存，Cache缺失率为5%，不考虑替换等开销，则BP的CPU执行时间是多少？ 
	1. CPU的执行时间由两部分构成：所有指令在Cache命中情况下的执行时间，以及因Cache缺失而导致的额外等待时间（开销） 
	2. Cache全部命中时的执行时间 ($T_{hit}$): 
	    *   指令总数 = 100条。
	    *   Cache命中时的CPI (Cycles Per Instruction) = 4。
	    *   CPU时钟周期 = $1.25\text{ns}$。
	    *   $T_{hit} = \text{指令数} \times \text{CPI}_{hit} \times T_{CPU}$
	    *   $T_{hit} = 100 \times 4 \times 1.25\text{ns} = 500\text{ns}$。
		1. 注意：这里的CPI=4已经包含了指令执行和数据访问在Cache中命中的所有周期，所以不需要再乘以1.2次访存 
	3. Cache缺失导致的额外开销 ($T_{miss\_overhead}$) 
	    *   首先计算总的访存次数：
        *   总访存次数 = 指令数 × 平均每条指令访存次数 = $100 \times 1.2 = 120$ 次。
    *   然后计算Cache缺失的总次数：
        *   缺失次数 = 总访存次数 × 缺失率 = $120 \times 5\% = 120 \times 0.05 = 6$ 次。
    *   计算总的缺失开销：
        *   每次缺失的开销 (Miss Penalty) 就是第(3)问算出的 $85\text{ns}$。
        *   $T_{miss\_overhead} = \text{缺失次数} \times \text{Miss Penalty}$
        *   $T_{miss\_overhead} = 6 \times 85\text{ns} = 510\text{ns}$。
    1.  总的CPU执行时间 ($T_{total}$) 
	      *   $T_{total} = T_{hit} + T_{miss\_overhead}$
	    *   $T_{total} = 500\text{ns} + 510\text{ns} = 1010\text{ns}$。
[[Pasted image 20250909022909.png]]
[[Pasted image 20250909022942.png]]
-  [[计算机性能评测的四个指标]]   
- [[TLB，Cache，Page的协同工作关系和逻辑依赖]]  [[高速缓存Cache]]
- [[总线与主存技术]] 


![[2013-exam-paper-ocr.pdf#page=5&rect=76,429,548,818|2013-exam-paper-ocr, p.5]]
1. #指令格式  #程序计数器PC  [[程序计数器PC]]  [[标志寄存器]]  [[PC相对寻址]]  [[补码]]  [[数据通路]] 
- (1) 该计算机存储器按字节编址还是按字编址？该条件转移指令向后（反向）最多可跳转多少条指令？ 
1. 编址方式的判断 [[按字节编址]]  [[编址方式]]
	1.   题目指出指令长度为16位，即2字节 
	2.  在计算**不转移**时的下一条指令地址时，公式为 $PC_{new} = (PC) + 2$ 
		1. 这意味着当前指令地址（在PC中）和下一条指令地址相差2 
			1. 如果按字（16位）编址，地址应该加1。既然地址加2，说明内存的最小可寻址单位是字节（8位），每条16位指令占用两个连续的字节地址 
		2.    因此，该计算机是**按字节编址** 
2. 跳转范围的计算 
	1.    `OFFSET` 字段是8位，且为补码表示。其取值范围是 $[-2^{8-1}, 2^{8-1}-1]$，即 $[-128, 127]$ 
	2. 转移目标地址的计算公式为 $PC_{new} = (PC) + 2 + 2 \times OFFSET$ 
	3. 跳转的位移是相对于**下一条指令的地址** `(PC)+2` 进行的，位移量为 $2 \times OFFSET$ 字节
	4. 向后（正向）跳转 `OFFSET`取最大正值127。
        *   跳转位移 = $2 \times 127 = 254$ 字节。
        *   因为每条指令占2字节，所以最多可向后跳转 $254 / 2 = 127$ 条指令。 
    5. 向前（反向）跳转  `OFFSET`取最小负值-128。
        *   跳转位移 = $2 \times (-128) = -256$ 字节。
        *   因此，最多可向前（反向）跳转 $256 / 2 = 128$ 条指令。
	* **结论**：按字节编址。反向最多可跳转128条指令，向后最多可跳转127条指令  
-  (2) 某条件转移指令的地址为200CH...请求出PC的值
1. 指令分析 
	1. 指令地址 `PC = 200CH` 
	2. 指令内容中，控制位 `C=0, Z=1, N=1`。这意味着该指令**只检查ZF和NF标志**，不检查CF标志  
	3.  转移条件是：被检查的标志中（这里是ZF和NF），**有且仅有1个**为1时，才发生转移  
	4.  `OFFSET` 字段为 `11100011B`
2. 情况a: CF=0, ZF=0, NF=1 
	1. 条件判断
		1. 指令检查ZF和NF。当前 `ZF=0`, `NF=1`。被检查的两个标志中，恰好有一个为1 
	2. 结论 ：满足转移条件，**发生转移** 
	3. 目标地址计算
		*   `OFFSET` = `11100011B` = `E3H`。这是一个8位的补码。
        *   **符号扩展**：由于最高位是1，将其扩展为16位，高位补1，得到 `1111111111100011B` = `FFE3H`。
        *   **计算 $2 \times OFFSET$**：这等价于将16位的补码左移一位。`FFE3H << 1` = `FFC6H`。（二进制 `...11100011` 左移一位是 `...11000110`）。
        *   **计算新PC值**：
            $PC_{new} = (PC) + 2 + 2 \times OFFSET$
            $PC_{new} = 200CH + 2H + FFC6H$
            $PC_{new} = 200EH + FFC6H$
            （进行16位加法，最高位的进位舍去）
            $PC_{new} = 1FD4H$
		1. PC值：`1FD4H` 
	4. 情况b: CF=1, ZF=0, NF=0 
		*   **条件判断**：指令检查ZF和NF。当前 `ZF=0`, `NF=0`。被检查的两个标志中，没有一个为1。
	    *   **结论**：不满足“有且仅有一个为1”的条件，**不发生转移**。
	    *   **目标地址计算**：
	        *   执行顺序的下一条指令。
	        *   $PC_{new} = (PC) + 2$
	        *   $PC_{new} = 200CH + 2H = 200EH$
	    *   **PC值**：`200EH`。
-  (3) 实现“无符号数比较小于等于时转移”功能的指令中，C、Z和N应各是什么？  
1. 理解无符号数比较 
	1.  在计算机中，比较操作通常通过减法实现。判断 `A <= B` (无符号) 等价于计算 `A - B` 并观察标志位 
	2. 对于无符号数减法 `A - B` 
		1.  如果 `A < B`，会产生**借位**。在大多数体系结构中，这会导致进位标志CF被置为特定值（通常是`CF=1`表示有借位，或`CF=0`表示有借位，这取决于具体设计，但`JBE/JNA`等指令依赖于它）。我们假设`CF=1`表示有借位（即`A<B`） 
		2. 此，“无符号数小于等于”（`A <= B`）的条件是 `(A < B) OR (A = B)`，这在标志位上体现为 **`CF=1` OR `ZF=1`** 
2. 映射到本题指令
    *   该指令的功能是检查指定的标志位。要实现上述逻辑，我们需要检查`CF`和`ZF`。
    *   因此，对应的控制位 `C` 和 `Z` 应该置为1，即 `C=1, Z=1`。
    *   无符号数比较不关心结果的符号（正负），所以不需要检查`NF`标志。因此 `N=0`。\
3. **结论**：`C=1, Z=1, N=0` 
-  (4) 以下是该指令对应的数据通路示意图，要求给出图中部件①~③的名称或功能说明 
1. 通过分析数据在指令执行过程中的流动路径来识别各个部件
	1. 部件① 
		1. **位置**：该部件的输出连接到指令的各个字段（OP, C, Z, N, OFFSET）的译码逻辑
		2.  **功能**：在指令执行周期中，从内存取出的指令首先要被存放在一个寄存器中，以便CPU在整个执行周期内能够稳定地访问它。这个寄存器就是**指令寄存器（Instruction Register, IR）**
		3. #指令寄存器IR  [[CPU寄存器]] 
	2. 部件②
	    *   **位置**：它有两个输入端和一个输出端。一个输入来自`(PC)+2`（由PC和加法器计算得出），另一个输入来自部件②的输出（即 $2 \times OFFSET$）。其输出是转移目标地址。
	    *   **功能**：执行加法操作，计算转移目标地址。
	    *   **名称**：**加法器 (Adder)**。
	* 通路总结 
		* 指令从内存取出后放入**①指令寄存器(IR)**。IR中的`OFFSET`字段送入**②符号扩展和移位部件**，计算出 $2 \times OFFSET$。同时，PC的值送入一个加法器计算出`(PC)+2`。然后，`(PC)+2`和 $2 \times OFFSET$ 送入**③加法器**，计算出最终的转移目标地址。最后，**多路选择器**根据标志寄存器和控制位`C,Z,N`的判断结果，选择将`(PC)+2`（不转移）还是将加法器③的计算结果（转移）送回PC
[[Pasted image 20250909023013.png]]
[[指令系统设计]]  [[数据通路]]  [[控制器设计]]  [[标志寄存器]]  [[流水线技术]]

![[2013-exam-paper-ocr.pdf#page=5&rect=66,198,542,430|2013-exam-paper-ocr, p.5]]
[[信号量]]
1. 容量限制 (同步关系) 
	博物馆最多只能容纳 500 人。这意味着当馆内人数达到 500 时，新的参观者必须在门外等待，直到有人离开才能进入。这是一个“资源数量”的问题，馆内的 500 个“空位”就是资源 
2. 出入口限制 (互斥关系) 
	出入口一次只允许一个人通过。无论是“进门”这个动作，还是“出门”这个动作，都必须是**原子**的、**排他**的。当一个人正在通过门口时，其他人（无论是想进还是想出）都不能通过。这是一个典型的“互斥访问”问题，出入口是那个被互斥访问的“临界资源”
- 使用信号量和 P、V 操作来实现这两个约束 
1. 解决容量限制问题 
	*   **约束**：最多 500 人。
	*   **资源**：博物馆内的 500 个“空位”。
	*   **工具**：这是一个典型的多资源管理问题，应使用**计数信号量**。
	*   **定义信号量**：我们定义一个计数信号量 `empty`，表示博物馆内还剩多少个空位。
	    *   **初始值**：博物馆刚开门时，是空的，有 500 个空位。所以，`Semaphore empty = 500;`。
	*   **操作逻辑**：
	    *   **进入前**：一个参观者要进入博物馆，就需要消耗一个“空位”资源。因此，在执行“进门”动作之前，他必须先申请一个空位。这个操作是 `P(empty)`。如果 `empty` 的值大于 0，他申请成功，`empty` 减 1，他可以继续去进门；如果 `empty` 的值为 0，他申请失败，就会被阻塞在 `P(empty)` 这里，直到有人离开。
	    *   **离开后**：一个参观者离开博物馆，就释放了一个“空位”资源。因此，在执行完“出门”动作之后，他必须归还这个空位。这个操作是 `V(empty)`。这会使 `empty` 的值加 1，如果此时有其他参观者因为没有空位而在等待，`V(empty)` 操作会唤醒其中一个
2. 解决出入口互斥问题 
	*   **约束**：出入口一次只允许一人通过。
	*   **资源**：“出入口”这个物理设施。它是一个单一的、不可被多人同时使用的资源。
	*   **工具**：这是一个典型的互斥问题，应使用**二值信号量**（也叫互斥锁 Mutex）。
	*   **定义信号量**：我们定义一个二值信号量 `mutex`，用于保护“进门”和“出门”这两个动作。
	    *   **初始值**：出入口一开始是空闲的，可供使用。所以，`Semaphore mutex = 1;`。
	*   **操作逻辑**：
	    *   **进门时**：“进门”这个动作是临界区。为了保证原子性，在执行 `进门` 之前，必须先获得出入口的使用权，即执行 `P(mutex)`。执行完 `进门` 之后，必须立刻释放使用权，即执行 `V(mutex)`，以便下一个人（无论是想进还是想出）可以使用。
	    *   **出门时**：“出门”这个动作同样是临界区，也使用同一个物理出入口。因此，在执行 `出门` 之前，也必须执行 `P(mutex)` 来获得使用权。执行完 `出门` 之后，再执行 `V(mutex)` 释放它。
3.  组合逻辑
	1.  **想进入**：首先要确保馆内有位置。执行 `P(empty)`。如果没位置，就阻塞等待。
	2.  **有位置了，准备进门**：现在要通过门口。门口是互斥的，执行 `P(mutex)`。如果门口有人，就阻塞等待。
	3.  **通过门口**：执行 `进门` 动作。
	4.  **进门完成**：立刻释放门口，让别人可以用。执行 `V(mutex)`。
	5.  **在馆内参观**：执行 `参观` 动作。这个过程不涉及与其他参观者的资源竞争（题目未提及），所以不需要信号量操作。
	6.  **准备出门**：要通过门口离开。门口是互斥的，执行 `P(mutex)`。
	7.  **通过门口**：执行 `出门` 动作。
	8.  **出门完成**：立刻释放门口。执行 `V(mutex)`。
	9.  **彻底离开**：把占用的馆内名额还回来。执行 `V(empty)`
4. 这个顺序非常重要。必须先申请“空位”(`P(empty)`)，再申请“门口”(`P(mutex)`)。如果反过来，一个参观者先锁住了门口(`P(mutex)`)，然后发现馆内没位置了(`P(empty)`)而阻塞，那么他就占着门口不放，导致馆内的人也出不来，无法释放空位，最终形成**死锁 (Deadlock)**。
5. 
```c
// 信号量定义与初始化
Semaphore empty = 500;  // 计数信号量，代表馆内剩余空位数，用于同步
Semaphore mutex = 1;    // 二值信号量，代表出入口是否可用，用于互斥

cobegin
    参观者进程 i:
    {
        ...
        P(empty);   // 申请一个馆内空位。若无空位则等待。
        P(mutex);   // 申请使用出入口。若出入口被占用则等待。
        进门;       // (临界区)
        V(mutex);   // 释放出入口。
        
        参观;       // 在馆内自由活动
        
        P(mutex);   // 再次申请使用出入口，准备出门。
        出门;       // (临界区)
        V(mutex);   // 释放出入口。
        V(empty);   // 释放一个馆内空位，通知等待者可以进入了。
        ...
    }
coend
```
[[Pasted image 20250909023028.png]]
[[Pasted image 20250909023038.png]]
- [[读者-写者问题]] 
- [[死锁预防 vs 死锁避免vs 死锁检测与解除]]
	- **变种**：如上文分析，如果将 `P(empty)` 和 `P(mutex)` 的顺序写反，会导致什么后果？请分析并说明如何避免。
    *   **考点**：考察对死锁产生条件（互斥、请求与保持、不剥夺、循环等待）的理解，以及如何通过正确的资源申请顺序来破坏“循环等待”条件，从而避免死锁。 
- 增加复杂约束 
	-   **变种1**：博物馆有1个大门（用于进）和1个小门（用于出）。如何修改信号量？（答案：可能需要两个不同的互斥信号量 `mutex_in` 和 `mutex_out`）。
    *   **变种2**：馆内有一个特殊的展厅，该展厅最多容纳 10 人。如何修改？（答案：需要再增加一个计数信号量 `special_room_empty = 10;`）。
    *   **变种3**：参观者分为 VIP 和普通两种，VIP 有优先进入权。如何实现？（答案：这超出了普通信号量的能力，可能需要更复杂的同步机制，如条件变量或优先级队列）。
* 用其他同步机制实现 
    *   **变种**：请不要使用信号量，改用 #管程 (Monitor) 或 #条件变量 (Condition Variable) 来实现同样的功能。
    *   **考点**：考察对不同同步原语的理解和应用。管程将共享数据和操作封装起来，由编译器自动处理互斥，程序员只需关心同步条件（使用 `wait` 和 `signal` 操作条件变量）。
![[2013-exam-paper-ocr.pdf#page=6&rect=72,541,532,818|2013-exam-paper-ocr, p.6]]
[[页式存储管理]]  #单级页表   [[逻辑地址结构]]  
*   计算机按字节编址（Byte-addressable）。
*   逻辑地址和物理地址都是32位。
*   页表项（Page Table Entry, PTE）大小为4字节。
1. (1) 单级页表 
	1. [[逻辑地址结构]]被划分为两部分：
		1. **页号 (Page Number)**: 20位 
		2. **页内偏移量 (Page Offset)**: 12位 
	2. 计算页面的大小  [[计算页面的大小]] 
		1. 页面的大小由页内偏移量的位数决定。因为偏移量需要能够唯一地寻址页面内的每一个字节
			1. 页内偏移量有12位，所以一个页面内可以有 $2^{12}$ 个不同的地址。由于是按字节编址，所以页面的大小就是 $2^{12}$ 字节。 
			2. $PageSize = 2^{12} \text{ B} = 4096 \text{ B} = 4 \text{ KB}$ 
	3. 计算页表最大占用的字节数  [[计算页表所占内存]]
		1. 页表的作用是记录每个逻辑页到物理页框的映射。页表中的条目数（页表项）等于逻辑地址空间中总的页面数。
		*   **推导过程**：
		    页号部分有20位，这意味着逻辑地址空间最多可以被划分为 $2^{20}$ 个页面。每个页面的映射信息都需要一个页表项来存储。
		    因此，页表项的总数就是 $2^{20}$ 个。
		    每个页表项的大小为4字节。
		    所以，页表的最大尺寸 = (总页数) × (每个页表项的大小)。
		*   **计算**：
		    $MaxPageTableSize = 2^{20} \times 4 \text{ B} = 1,048,576 \times 4 \text{ B} = 4,194,304 \text{ B} = 4 \text{ MB}$
2. (2) 二级页表 
	1.  逻辑地址结构被划分为三部分
		*   **页目录号 (Page Directory Index)**: 10位
		*   **页表索引 (Page Table Index)**: 10位
		*   **页内偏移量 (Page Offset)**: 12位
	* 给出逻辑地址LA，求其对应的页目录号和页表索引的表达式：
		1. 推导过程 
			* 我们需要从32位的逻辑地址 `LA` 中提取出特定的位段。这通常通过位运算（右移和按位与）来实现 
			* 页目录号 
				* 它位于32位地址的最高10位 (bit 31 到 bit 22)。为了得到它，我们需要将 `LA` 右移 $10+12 = 22$ 位
			* 页表索引 
				* 它位于中间的10位 (bit 21 到 bit 12)。为了得到它，我们先将 `LA` 右移12位，把页内偏移量去掉。此时，我们想要的10位就在最低有效位的部分了。为了确保只取这10位，我们使用一个掩码 (mask) 与其进行按位与操作。10个1的二进制数是 `1111111111`，其十六进制表示为 `0x3FF` 
		2. 表达式 
			1. 页目录号`(LA >> 22) & 0x3FF` 
				1.  (注：简单地写成 `LA >> 22` 也可以，但使用掩码 `& 0x3FF` 是更严谨的写法，可以确保结果不会超过10位所能表示的范围。) 
			2. 页表索引 `(LA >> 12) & 0x3FF`  
 3. (3) 具体情景计算  
	 1. 存储模型 ：采用第(1)问的单级页表  
	 2. 逻辑段信息 
		*   起始逻辑地址: `0000 8000H`
		*   长度: `8KB`
	3. 物理内存信息 
		 *   代码段被装载到以 `0090 0000H` 为起始的**连续**主存空间。
	    *   该段的**页表**被存放在以 `0020 0000H` 为起始的物理地址。
	4. 需要计算并填写图中的空白： 
		*   两个页表项的物理地址（物理地址1, 物理地址2）
		*   两个代码页面的起始物理地址
* 详细推导步骤 
	1. 确定代码段占用的逻辑页面 
		*   页面大小为 `4KB` = `4096` B = `1000H`。
		*   代码段的起始逻辑地址为 `0000 8000H`。
		*   计算起始页号： [[逻辑地址到物理地址的转换]] 
		    $P_{start} = \lfloor \frac{\text{逻辑地址}}{\text{页面大小}} \rfloor = \lfloor \frac{0x8000}{0x1000} \rfloor = 8$
		    所以，该代码段从逻辑页 **8** 开始。
		*   代码段长度为 `8KB`，页面大小为 `4KB`。
		*   占用的页面数：
		    $\text{页面数} = \frac{\text{代码长度}}{\text{页面大小}} = \frac{8\text{KB}}{4\text{KB}} = 2$
		    所以，该代码段占用了 **逻辑页8** 和 **逻辑页9** 这两个页面。
	2. 计算页表项的物理地址  
		*   页表的基地址（起始地址）为 `0020 0000H`。
		*   每个页表项大小为 `4` 字节。
		*   页表项的地址计算公式为：$\text{PTE地址} = \text{页表基地址} + \text{页号} \times \text{页表项大小}$
		*   **逻辑页8对应的页表项（物理地址1）**：
		    $\text{地址}_1 = 0x00200000 + 8 \times 4 = 0x00200000 + 32 = 0x00200020\text{H}$
		*   **逻辑页9对应的页表项（物理地址2）**：
		    $\text{地址}_2 = 0x00200000 + 9 \times 4 = 0x00200000 + 36 = 0x00200024\text{H}$
	3.  确定代码页面的物理地址  
		 *   题目告知，代码段被装载到从 `0090 0000H` 开始的**连续**物理内存中。
		*   **代码页面1 (对应逻辑页8)** 的起始物理地址就是这段连续内存的起始地址：
		    $\text{代码页面1起始地址} = 0x00900000\text{H}$
		*   **代码页面2 (对应逻辑页9)** 的起始物理地址紧跟在页面1之后：
		    $\text{代码页面2起始地址} = \text{代码页面1起始地址} + \text{页面大小} = 0x00900000\text{H} + 0x1000\text{H} = 0x00901000\text{H}$
	4. 填写图示 
		   - **物理地址1**: `0020 0020H`
		*   **物理地址2**: `0020 0024H`
		*   从 `页框号1` 指向的 **代码页面1** 的起始地址是: `0090 0000H`
		*   从 `页框号2` 指向的 **代码页面2** 的起始地址是: `0090 1000H`
*注：* 页表项中实际存储的是**物理页框号(Physical Frame Number, PFN)**，而不是完整的物理地址。物理页框号可以通过物理地址右移页内偏移位数得到。例如，代码页面1的物理页框号为 $0x00900000 >> 12 = 0x00900$。但题目图示的箭头指向的是整个代码页面的内存块，所以填写其起始物理地址是符合题意的 

[[Pasted image 20250909023054.png]]
- [[有效内存访问时间EAT]]   结合[[TLB(快表)的结合]]
	-  题目会给出TLB的命中率、TLB访问时间、内存访问时间，要求计算EAT。
	    *   公式为：$EAT = \text{命中率} \times (\text{TLB访问时间} + \text{内存访问时间}) + (1 - \text{命中率}) \times (\text{TLB访问时间} + k \times \text{内存访问时间})$
	    *   这里的 $k$ 是访问内存的次数，对于单级页表是2次（一次查页表，一次访问数据），对于二级页表是3次
-  [[多级页表]]    #反向页表  [[页面置换算法]]  [[段页式存储管理]]


![[2013-exam-paper-ocr.pdf#page=6&rect=69,224,544,544|2013-exam-paper-ocr, p.6|700]]
1. [[路由聚合（路由汇总-超网）]] #动态路由 
2.  访问 AS1 中的网络 (经由 R1) [[路由协议中的汇总]] [[最长前缀匹配]] 
	1. AS1 中有两个子网需要通过 R1 到达：`153.14.5.0/25` 和 `153.14.5.128/25` 
	2. 第一步：转换为二进制 
		1. 为了找到它们共同的前缀，我们需要看它们的二进制表示。我们重点关注发生变化的第三和第四个字节。
		    *   `153.14.5.0`: `... .00000101.00000000`
		    *   `153.14.5.128`: `... .00000101.10000000` 
	3.   第二步：寻找共同前缀 
		1. 比较这两个二进制地址，我们可以发现它们的前 24 位是完全相同的：`... .00000101`。第 25 位开始不同（一个是 0，一个是 1）  
		2. 因此，我们可以将这两个 `/25` 的子网聚合成一个 `/24` 的网络 
	4. 第三步：计算聚合后的网络地址 
		取共同的前 24 位，后面全部补 0，得到聚合后的网络地址。
	    `153.14.5.0`
	    聚合后的子网掩码是 24 位，即 `255.255.255.0`。
	    所以聚合路由为：`153.14.5.0/24`。
	5. 第四步：确定下一跳和接口  
		1. **路由条目 1：** 目的网络 `153.14.5.0/24`，下一跳 `153.14.3.2`，接口 `S0`  
3. 访问 AS2 中其他网络 (经由 R3)  
	1. AS2 中有两个子网需要通过 R3 到达：`194.17.20.0/25` 和 `194.17.21.0/24` 
	2. 第一步：转换为二进制  [[进制转化]]
		1. 我们重点关注第三个字节。
	    *   `194.17.20.0`: `... .00010100.00000000`
	    *   `194.17.21.0`: `... .00010101.00000000` 
	3. 第二步：寻找 #共同前缀   
		1. 比较第三个字节的二进制：
		    *   `20` = `00010100`
		    *   `21` = `00010101`
		    它们的前 7 位 `0001010` 是相同的。加上前面两个字节的 16 位，总共有 $16 + 7 = 23$ 位
	4. 第三步：计算聚合后的网络地址  
		1. 取共同的前 23 位，后面全部补 0。
		    前 23 位为 `11000010.00010001.0001010...`。将第 24 位置 0，得到 `... .00010100.00000000`，即 `194.17.20.0`。
	    所以聚合路由为：`194.17.20.0/23`
		2. 这个 `/23` 的网络范围是 `194.17.20.0` 到 `194.17.21.255`，正好包含了原先的两个子网 
	5. 第四步：确定下一跳和接口
		从 R2 出发，要去往这个聚合网络，必须经过 R3。数据包需要从 R2 的 `S1` 接口发出，下一跳地址是 R3 的接口 IP。
	    **路由条目 2：** 目的网络 `194.17.20.0/23`，下一跳 `194.17.24.2`，接口 `S1`。
4. 访问直连网络 
	1. 有一个子网 `194.17.20.128/25` 是直接连接在 R2 的 `E0` 接口上的。对于直连网络，不需要下一跳地址。
	*   **路由条目 3：** 目的网络 `194.17.20.128/25`，下一跳 `-`，接口 `E0`。 
	最终 R2 的路由表： 

| 目的网络               | 下一跳           | 接口   |
| :----------------- | :------------ | :--- |
| `153.14.5.0/24`    | `153.14.3.2`  | `S0` |
| `194.17.20.0/23`   | `194.17.24.2` | `S1` |
| `194.17.20.128/25` | `-`           | `E0` |
 - 2）[[最长前缀匹配]]  
	 - 若 R2 收到一个目的 IP 地址为 `194.17.20.200` 的 IP 分组，R2 会通过哪个接口转发该分组？  
	1. 第一步：将目的 IP 地址转换为二进制  
		1. `194.17.20.200` = `11000010.00010001.00010100.11001000`  
	2. 第二步：与 R2 路由表中的每个条目进行匹配  
	    1.  **匹配 `153.14.5.0/24`？**
	        目的地址 `194.17...` 与网络地址 `153.14...` 的前缀不匹配。 **不匹配**。
	    2.  **匹配 `194.17.20.0/23`？**
	        *   网络前缀（23位）: `11000010.00010001.0001010`
	        *   目的地址前 23 位: `11000010.00010001.0001010`
	        *   前 23 位完全相同。 **匹配，匹配长度为 23**。
	    3.  **匹配 `194.17.20.128/25`？**
	        *   网络地址: `194.17.20.128` = `... .00010100.10000000`
	        *   网络前缀（25位）: `11000010.00010001.00010100.1`
	        *   目的地址: `194.17.20.200` = `... .00010100.11001000`
	        *   目的地址前 25 位: `11000010.00010001.00010100.1`
	        *   前 25 位完全相同。 **匹配，匹配长度为 25**。
	3. 第三步：选择最长匹配 
		 我们找到了两个匹配项：一个长度为 23，另一个长度为 25。根据最长前缀匹配原则，路由器会选择长度为 25 的路由。
	    因为 $25 > 23$，所以选择路由条目 `194.17.20.128/25`。
	4. 第四步：确定转发接口 
		1. 该路由条目对应的接口是 `E0`  
		2. **结论：** R2 会通过 `E0` 接口转发该 IP 分组
- 3） [[自治系统间的路由协议IGPvsEGP]]  
	- R1 与 R2 之间利用哪个路由协议交换路由信息？该路由协议的报文被封装到哪个协议的分组中进行传输？   
	1. 第一步：识别 R1 和 R2 的关系 
	    根据题目描述，“自治系统 AS1 由路由器 R1 连接两个子网构成；自治系统 AS2 由路由器 R2、R3 互联并连接 3 个子网构成”。
	    这明确指出 R1 属于 AS1，R2 属于 AS2。它们位于两个不同的自治系统（AS）中。
	2. 第二步：区分 #内部网关协议IGP 和 #外部网关协议EGP    
		*   #内部网关协议IGP (Interior Gateway Protocol, IGP)：在一个自治系统 **内部** 使用的路由协议。例如：RIP, OSPF, EIGRP。
	    *   #外部网关协议EGP (Exterior Gateway Protocol, EGP)：在不同的自治系统 **之间** 使用的路由协议。 
	    * 由于 R1 和 R2 分属不同的 AS，它们之间交换路由信息必须使用 EGP
	3. 第三步：确定具体的 EGP 协议 
		1. 当今互联网上使用的标准 EGP 协议是 #边界网关协议BGP  (Border Gateway Protocol, BGP)**，通常指的是 BGP-4 
	4. 第四步：确定 BGP 的传输层协议  [[边界网关协议BGP]] 
		1. BGP 是一个非常复杂的协议，它需要一个可靠的、面向连接的传输服务来确保路由信息的准确交换。在 TCP/IP 协议栈中，提供这种服务的是 **传输控制协议 (TCP)**。BGP 协议工作在 TCP 协议之上，使用 TCP 端口号 179。
		2. 因此，BGP 的路由更新报文是作为应用层数据，被封装在 TCP 报文段（Segment）中，然后 TCP 报文段再被封装到 IP 数据报（Packet）中进行传输
	**结论：**
1.  R1 和 R2 之间使用 **BGP**（或 BGP4）协议交换路由信息。
2.  该协议的报文被封装到 **TCP** 协议的分组（报文段）中进行传输。 

[[Pasted image 20250909023110.png]]
[[Pasted image 20250909023118.png]]
- [[反向聚合（路由泄露）]]  
- [[CIDR无类域间路由]]  [[VLSM可变长子网掩码]]   [[静态路由vs动态路由]] 