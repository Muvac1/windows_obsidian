 ![[2011-exam-paper-ocr.pdf#page=1&rect=73,623,536,701|2011-exam-paper-ocr, p.1]]
[[时间复杂度分析]]
1. 第$k$次循环后：我们可以推断出$x = 2^{k+1}$
   $2^{k+1} \ge n/2$ 
2. 我们需要解出$k$关于$n$的表达式 
	1. $\log_2(2^{k+1}) \ge \log_2(n/2)$ 
		1. $k+1 \ge \log_2 n - \log_2 2$ 
		2. $k+1 \ge \log_2 n - 1$ 
		3.  $k \ge \log_2 n - 2$  
	2. 循环执行的次数$k$（也就是我们所说的$T(n)$）约等于$\log_2 n - 2$ 
		1. 不同底数的对数之间只差一个常数因子（ #换底公式 ：$\log_a n = \frac{\log_b n}{\log_b a}$ 
	3. $O(\log n)$
[[截屏2025-08-19 下午5.55.15.png]] 
A
![[2011-exam-paper-ocr.pdf#page=1&rect=74,575,535,623|2011-exam-paper-ocr, p.1]]
 #进退栈   #栈   

[[Pasted image 20250819175542.png]]
B

![[2011-exam-paper-ocr.pdf#page=1&rect=73,513,542,578|2011-exam-paper-ocr, p.1]]
#循环队列 [[循环队列]]
[[判别队列空满的状态]] 
B #概念不懂  
[[Pasted image 20250819175633.png]]


![[2011-exam-paper-ocr.pdf#page=1&rect=70,477,494,516|2011-exam-paper-ocr, p.1]]
[[结点总数与度]]  #满二叉树  #完全二叉树 
解法一：利用完全二叉树的编号性质 [[二叉树的性质]]
解法二：利用二叉树 #结点度的性质   [[结点总数与度]] [[二叉树结点度的性质]]
解法三：按层计算法 (另解2) [[按层计算法]]

[[Pasted image 20250819175648.png]]
C

![[2011-exam-paper-ocr.pdf#page=1&rect=67,426,554,477|2011-exam-paper-ocr, p.1]]
C
[[遍历序列的基本性质]] [[退化二叉树（斜树）]] 

[[Pasted image 20250819175705.png]]

![[2011-exam-paper-ocr.pdf#page=1&rect=71,383,524,431|2011-exam-paper-ocr, p.1]]

#叶节点 [[树到二叉树的转换规则]]
分析题目中的问题：“在对应的二叉树中，哪些结点**没有右孩子**
#树到二叉树的转换规则 根据转换规则的第二条，
	一个结点在二叉树中**有**右孩子，当且仅当它在原树中有**下一个兄弟结点**
	一个结点在二叉树中**没有**右孩子，当且仅当它在原树中**没有下一个兄弟结点** 
2. 在原树中，哪些结点没有“下一个兄弟 
	1.  **树的根结点**：根结点没有父结点，自然也没有任何兄弟结点。所以它肯定没有“下一个兄弟”。
	2.  **所有分支中“最右边”的孩子**：对于任何一个父结点，它的孩子结点们排成一排，最后一个孩子（即最右边的孩子）没有“下一个兄弟”。
3. **二叉树中无右孩子的结点个数 = 原树中的根结点个数 + 原树中作为“最右孩子”的结点个数**
	1. **根结点个数**：题目中说的是“一棵树”，所以根结点只有 **1** 个 
	2. #最右孩子 的结点个数 ：在原树中，每一个有孩子的结点（即**分支结点**或**非叶子结点**）都必然有且仅有一个“最右边的孩子”。因此，“最右孩子”的结点个数就等于**分支结点的个数** 
4. 树的总结点数 = 分支结点数 + 叶子结点数
	1. 分支结点数 = 总结点数 - 叶子结点数
		1. 分支结点数 $N_b = N - N_0 = 2011 - 116 = 1895$ 
	2. [[无右孩子的结点数 = 根结点数 + 分支结点数]] 
		1. 无右孩子的结点数 = $1 + 1895 = 1896$ 
D 
[[Pasted image 20250819175732.png]]


![[2011-exam-paper-ocr.pdf#page=1&rect=79,333,484,385|2011-exam-paper-ocr, p.1]]
#二叉树的性质 #验证查找路径的合法性  #画图 [[二叉树的性质]] #二叉树的性质  #二叉排序树

[[Pasted image 20250819175749.png]]
A

![[2011-exam-paper-ocr.pdf#page=1&rect=73,270,531,331|2011-exam-paper-ocr, p.1]]

[[拓扑排序]]  #拓扑排序的核心性质  
- #联通图 #强连通图 [[连通图与强连通图]] [[连通分量与强连通分量的求解算法]]  [[图的储存结构选择 ]] [[拓扑排序]] 
1. [[简单路径]] [[路径与回路（图论）]] 
	1. 简单路径的定义是所有顶点都不能重复 命题 I 是错误的 
2. [[邻接矩阵，邻接表 ，稀疏图，稠密图]] 
	1. 对于稀疏图，因为 $e$ 的数量级远小于 $n^2$，所以邻接表的空间复杂度 $O(n+e)$ 明显优于邻接矩阵的 $O(n^2)$。例如，一个有1000个顶点但只有2000条边的图，邻接矩阵需要 $1000^2=1,000,000$ 个存储单元，而邻接表大约只需要 $1000+2000=3000$ 个存储单元。因此，存储稀疏图时，邻接表比邻接矩阵更节省空间
3. 正确 

[[Pasted image 20250819175759.png]]
C

![[2011-exam-paper-ocr.pdf#page=1&rect=72,208,492,270|2011-exam-paper-ocr, p.1]]
[[装填因子]]     [[散列函数Hash哈希函数]]  [[聚集现象]]  [[常用哈希函数的设计方法]]   [[哈希表的删除操作]]

[[Pasted image 20250819175812.png]]
D
![[2011-exam-paper-ocr.pdf#page=1&rect=74,173,353,210|2011-exam-paper-ocr, p.1]]
[[动态分区存储管理（动态分区分配算法）]] [[快速排序的核心：分区操作]]  [[存储结构]]


[[Pasted image 20250819175823.png]]
A

![[2011-exam-paper-ocr.pdf#page=1&rect=68,125,530,172|2011-exam-paper-ocr, p.1]]
[[大根堆]]  [[完全二叉树]]
[[截屏2025-08-19 下午5.58.46.png]]
B


![[2011-exam-paper-ocr.pdf#page=1&rect=72,89,463,130|2011-exam-paper-ocr, p.1]]
[[计算机性能评测的四个指标]]


[[Pasted image 20250819175902.png]]
D

![[2011-exam-paper-ocr.pdf#page=1&rect=76,37,534,89|2011-exam-paper-ocr, p.1]]
[[IEEE754单精度浮点数格式]]
1. 确定符号位 (S) 
	1. 数字是 `-8.25`，为负数，所以符号位 $S=1$ 
2. 将绝对值转换为二进制 
	1.  $8.25$ 转换为二进制 
		1.   **整数部分**：$8_{10} = 1000_2$ 
		2. **小数部分**：
		    *   $0.25 \times 2 = 0.5$  (取整数部分 0)
		    *   $0.5 \times 2 = 1.0$   (取整数部分 1)
		    *   所以，$0.25_{10} = 0.01_2$
			1. $8.25_{10} = 1000.01_2$
3. 规格化二进制数 
	1. 规格化的形式是 $1.xxxxx \times 2^e$。我们将小数点左移，直到左边只剩一个 "1" 
	2. $1000.01_2 = 1.00001_2 \times 2^3$
	3. 从这个形式中，我们可以得到两个关键信息：
		*   **实际指数 (e)**：$e=3$
		*   **尾数 (M)**：小数点后的部分是 `00001`
4. 计算阶码 (E)
	1. 阶码使用偏移量127来计算 
	2. $E = e + 127 = 3 + 127 = 130$ 
	3. 将阶码 $130$ 转换为8位二进制数 
		1. $130_{10} = 128 + 2 = 2^7 + 2^1 = 10000010_2$  [[进制转化]]
	4. 8位的阶码部分是 `10000010` 
5. 组合成32位二进制数
	1. 将符号位 (S)，阶码 (E) 和尾数 (M) 组合起来。
	*   S: `1`
	*   E: `10000010`
	*   M: `00001`。尾数部分需要补齐到23位，所以在后面填充18个0。
	    M = `00001000000000000000000`
	1. `1` `10000010` `00001000000000000000000`
6. 转换为十六进制 
	1. 将这32位二进制数每4位一组进行分组：
		`1100` `0001` `0000` `0100` `0000` `0000` `0000` `0000`
		*   `1100` -> C
		*   `0001` -> 1
		*   `0000` -> 0
		*   `0100` -> 4
		*   `0000` -> 0
		*   `0000` -> 0
		*   `0000` -> 0
		*   `0000` -> 0
	 最终得到的十六进制表示为 `C1040000H`  
A
[[Pasted image 20250819175943.png]] 
衍生考点 ： [[IEEE 754 标准双精度浮点数]] 
[[IEEE 754 标准 特殊值的表示]] 
A
![[2011-exam-paper-ocr.pdf#page=2&rect=76,778,454,820|2011-exam-paper-ocr, p.2]]
[[存储器的四种主要存取方式]]   [[存储器的层次结构]]  [[SRAM与DRAM对比]]  [[易失性与非易失性储存器]]
[[磁盘存储时间的计算]] 
[[Pasted image 20250819175954.png]]
B

![[2011-exam-paper-ocr.pdf#page=2&rect=76,731,524,779|2011-exam-paper-ocr, p.2]]
#按字节编址 #主存地址空间 #主存存储器容量  #MAR存储器地址寄存器 
[[按字节编址]]  [[主存地址空间]] [[主存储器容量]] [[MAR存储器地址寄存器]] 
1. 关键
	1. 主存地址空间大小为 64MB 这是决定 MAR 位数的**唯一**决定性因素 
2. 忽略干扰信息
	1. 题目中提到的 “现用 4MB×8 位的 RAM 芯片组成 32MB 的主存储器” 描述的是当前物理内存的**实现方式**和**实际容量**。虽然系统目前只有32MB内存，但它的设计（CPU的寻址能力）是面向整个64MB空间的。MAR 必须能够访问到这个地址空间内的任何一个位置，为未来的内存扩展做准备。因此，32MB 是一个 #干扰项
3. 我们需要计算要能寻址 64MB 空间需要多少位地址 
	1. 4MB 换算成字节 (Bytes) 
		1.  $1\text{M} = 1\text{K} \times 1\text{K} = 2^{10} \times 2^{10} = 2^{20}$ 
		2. $64\text{MB} = 64 \times 2^{20} \text{ Bytes}$ 
		3.  将 64 表示为 2 的幂 
		4. $64\text{MB} = 2^6 \times 2^{20} \text{ Bytes} = 2^{26} \text{ Bytes}$
	2. **主存地址空间大小 = $2^{\text{MAR位数}} \times$ 编址单位大小 
		1. 本题是按字节编址，所以编址单位大小为1字节。公式简化为：
				**主存地址空间大小 (以字节为单位) = $2^{\text{MAR位数}}$ 
	3. 地址空间有 $2^{26}$ 个字节，每个字节都需要一个唯一的地址。为了能够表示 $2^{26}$ 个不同的地址，地址寄存器 MAR 至少需要 **26** 位 

衍生知识 
#计算所需RAM芯片数量 [[存储器地址分配与片选]]


[[Pasted image 20250819180007.png]]
D 

![[2011-exam-paper-ocr.pdf#page=2&rect=73,682,521,730|2011-exam-paper-ocr, p.2]]
[[指令寻址方式]]
B. 基址寻址 $EA = A + (BR)$ 
	将一个**基址寄存器 (Base Register, BR)** 的内容与指令中的地址  (偏移量) 相加 
C. 相对寻址$EA = A + (PC)$ 
	它将**程序计数器 (Program Counter, PC)** 的内容与指令中的地址 $A$ (偏移量) 相加 
D. 变址寻址$EA = A + (IX)$ 
	将一个**变址寄存器 (Index Register, IX)** 的内容与指令中的地址 $A$ (通常是数组的基地址) 相加
A. 间接寻址 $EA = (A)$ 
	指令中给出的形式地址 $A$ 
		存放操作数有效地址的内存单元的地址
		需要先根据地址 $A$ 访问一次内存，取出里面的内容，这个内容才是最终的有效地址 

[[Pasted image 20250819180018.png]]
A
[[计算有效地址]] [[寻址方法的比较]]
![[2011-exam-paper-ocr.pdf#page=2&rect=76,629,527,681|2011-exam-paper-ocr, p.2]]
[[标志寄存器]] [[条件转移指令]]  [[无符号数与有符号数的比较指令]]
1. **指令:**  bgt
	1. 操作数 
		1.  无符号整数 
	2. 条件 
		1. 当第一个操作数 **大于** 第二个操作数时发生转移（跳转） 
	3. 实现方式
		1. 计算机中的比较操作通常是通过减法来实现的。比较 `A` 和 `B` 就是计算 $A-B$，然后根据结果设置标志寄存器中的各个标志位 
2. 分析标志位
	1. 对于 **无符号数** 的比较，我们主要关心以下两个标志位： 
	*   CF (Carry/Borrow Flag, 进位/借位标志):
	    *   在加法中，如果最高位产生了进位，则 $CF=1$。
	    *   在减法 ($A-B$) 中，如果需要向更高位 **借位**，则 $CF=1$。这等价于当无符号数 $A<B$ 时，计算 $A-B$ 会发生借位。
	*   ZF (Zero Flag, 零标志): 
	    *   如果运算结果为 0，则 $ZF=1$。
		*   在减法 ($A-B$) 中，如果 $A=B$，则结果为 0，$ZF=1$。
	1. #符号标志 (SF) 和 #溢出标志 (OF) 主要用于 #有符号数  的运算和比较，因此对于本题（无符号数比较）来说，它们是无关的。
3. 推导跳转条件 
	1. `bgt` 指令的跳转条件是 "大于"，即 $A>B$。我们来分析当 $A>B$ 时，执行 $A-B$ 后 CF 和 ZF 的状态：
	2. A > B (例如 5 > 3) 
		*   $A-B$ 的结果是一个正数，不为 0。因此，**$ZF=0$**。
	    *   因为 $A$ 比 $B$ 大，所以计算 $A-B$ 不需要向高位借位。因此，**$CF=0$**。
	3. 所以，当 $A>B$ 时，必须同时满足 $CF=0$ **并且** $ZF=0$ 
4. 审视选项 
	1. 题目要求的是 **转移条件**，也就是一个逻辑表达式，当这个表达式为真 (等于1) 时，就发生跳转。 
	2. 需要的条件是 "$CF=0$ 且 $ZF=0$"。用逻辑运算表示就是：
		$(\neg CF) \land (\neg ZF) = 1$  #否定标志Overline   [[不同领域的非]]
 $\overline{(CF+ZF)}$    
 
[[Pasted image 20250819180031.png]]
C

![[2011-exam-paper-ocr.pdf#page=2&rect=72,573,498,630|2011-exam-paper-ocr, p.2]]
[[指令流水线与冲突]] #指令系统的设计特点 
I. 指令格式规整且长度一致
-  #指令流水线 的第一步通常是**取指 (Instruction Fetch, IF)**，第二步是**译码 (Instruction Decode, ID)** 
	 简化取指:  如果所有指令长度都一样（例如，都是32位或4字节），那么取下一条指令时，程序计数器（PC）只需简单地增加一个固定的值即可（`PC = PC + 4`）。这使得取指部件的设计非常简单和快速。相反，如果指令是变长的（如x86架构），处理器需要先译码当前指令的一部分才能知道它的总长度，然后才能计算下一条指令的地址，这会使取指阶段变得复杂和缓慢 
-  简化译码  规整的格式意味着操作码（opcode）和操作数（如寄存器号）总是在指令的固定位置。这使得译码硬件可以并行地、快速地解析出指令的各个部分，而不需要复杂的逻辑来判断字段的位置。 
	**结论:** 这极大地简化了IF和ID阶段，使每个阶段的执行时间更加均衡和确定，从而避免了流水线中的“瓶颈”，非常有利于流水线的顺利执行。
2. II. 指令和数据按边界对齐存放 
	1. 原因
		1. 现代计算机通常通过一个固定宽度的总线（如64位）从内存中读取数据
		2. 避免多次访存 
			1. 如果一个4字节（32位）的数据或指令存放在按4字节对齐的地址上（即地址是4的倍数），那么处理器就可以通过一次内存访问（Memory Access）将其完整地取回
		3. 处理非对齐 
			1. 如果它没有对齐（例如，一个4字节的数据跨越了两个4字节的边界），处理器可能需要进行两次内存访问，然后通过移位和拼接操作才能得到完整的数据。这会引入额外的时钟周期延迟 
		4. 按边界对齐可以确保在 #取指IF 和 #访存MEM 阶段，总能在一个时钟周期内完成一次读取或写入操作，避免了因非对齐访问造成的流水线停顿（stall），保证了流水线的高效运行
3. III. 只有 Load/Store 指令才能对操作数进行存储访问 
	1. 原因 
		1. 这种架构也称为“寄存器-寄存器”架构。它将访存操作和算术逻辑操作完全分离开
		2. 简化指令功能 
			1. #算术逻辑指令 （如ADD, SUB）只对寄存器中的数据进行操作，不直接访问内存。这使得执行(Execute, EX)阶段的功能非常纯粹和快速 
		3. 规整流水线阶段 
			1. 它将所有内存访问都集中在Load（从内存读到寄存器）和Store（从寄存器写到内存）两条指令中，并且这些操作通常在流水线的访存(MEM)阶段完成。这避免了像“ADD R1, [memory_address]”这样一条指令既要计算地址、又要访问内存、还要执行加法运算的复杂情况。这种复杂的指令会使得流水线阶段的划分非常困难，且执行时间不一，严重破坏流水线的节奏 
	2. Load/Store架构使得指令功能单一，各流水线阶段（特别是EX和MEM）职责分明，执行时间更加均匀，极大地简化了流水线控制逻辑，减少了冲突  
- 衍生考点 [[RISC 和CISC的区别]]  [[流水线性能分析]]
[[Pasted image 20250819180057.png]]
D

![[2011-exam-paper-ocr.pdf#page=2&rect=70,479,527,573|2011-exam-paper-ocr, p.2]]
- 前提条件 
	1. 不采用 Cache 
		1. 这意味着 CPU 每次需要指令或数据时，都必须直接从主内存（Main Memory）中读取，而不能从速度更快的缓存中获取 
	2. 不采用 #指令预取技术 
		1. 这意味着 CPU 必须在当前指令完全执行完毕后，才能开始下一条指令的“取指令”阶段。它不能提前将后续指令从内存中取出放入指令缓冲区 
	3. 机器处于“开中断”状态 
		1. 这意味着 CPU 的中断标志位是开启的，允许响应来自外部设备的中断请求 
1. A. 每个指令周期中 CPU 都至少访问内存一次 
	1. 一个完整的[[指令周期]]  至少包含“取指令”（Fetch）阶段。由于题目明确指出**不采用 Cache 和指令预取**，那么获取指令的唯一途径就是访问主内存。因此，为了取出指令本身，CPU 必须访问一次内存。对于某些指令（如 `LOAD`、`STORE` 或带有内存操作数的算术指令），在执行阶段可能还需要再次访问内存来读取或写入数据。所以，每个指令周期**至少**访问内存一次 
		1. 该叙述是 **正确** 的 
2. B. 每个指令周期一定大于等于一个 CPU 时钟周期 
	1. 在计算机体系结构中，时间单位有如下层级关系  [[时间单位的层级关系]]
	    *   **时钟周期 (Clock Cycle)**：是 CPU 的最基本、最小的时间单位，由 CPU 的主频决定，例如 $T_{clk} = 1/f_{cpu}$。CPU 内的每一个微操作（micro-operation）至少需要一个时钟周期。
	    *   **机器周期 (Machine Cycle)**：也称 CPU 周期，通常定义为完成一个基本操作（如一次内存读取或写入）所需的时间。一个机器周期通常包含多个时钟周期。
	    *   **指令周期 (Instruction Cycle)**：是指 CPU 从内存中取出一条指令并执行该指令所花费的全部时间。一个指令周期通常包含多个机器周期（例如，取指周期、执行周期等）。
    *   因此，它们的关系是：**指令周期 ≥ 机器周期 ≥ 时钟周期**。一个指令周期包含取指、译码、执行等多个步骤，这些步骤不可能在少于一个时钟周期的时间内完成。
3. C. 空操作指令的指令周期中任何寄存器的内容都不会被改变 
	1. 空操作指令（NOP, No-Operation）在执行阶段确实什么也不做。但是，CPU 执行任何指令都必须先经过“取指令”阶段。在这个阶段，[[程序计数器PC]]（Program Counter, PC）** 的内容会被使用（送入地址总线以定位指令），然后**自动加 1**（或加上指令长度），以指向下一条将要执行的指令。PC 是 CPU 内部一个非常重要的寄存器。因此，即使是 NOP 指令，PC 寄存器的内容也发生了改变
		1. 该叙述声称“任何寄存器”内容都不变，这是 **错误** 的 
4. D. 当前程序在每条指令执行结束时都可能被外部中断打断 
	1. CPU 响应中断的标准时机是在一条指令的**执行周期结束之后，下一条指令的取指周期开始之前**。题目明确指出机器处于“开中断”状态，这意味着中断是允许的。因此，在每条指令执行完毕后，CPU 都会检查是否有中断请求。如果有，并且中断是开启的，程序就会被中断。  [[中断处理机制]]
[[计算机性能评测的四个指标]] #CPU性能计算 #CPU执行时间 #指令流水线  #Cache高速缓存  [[高速缓存Cache]] 
[[Pasted image 20250819180110.png]]
C

![[2011-exam-paper-ocr.pdf#page=2&rect=74,429,398,481|2011-exam-paper-ocr, p.2]]
[[系统总线结构（数据，地址，控制总线）]]  
1. A. 指令
	1. 指令也是一种数据。在CPU执行程序的“取指周期”中，CPU会根据 #程序计数器PC  中的地址，从内存中读取指令。这条指令就是通过 #数据总线 从内存传送到CPU的指令寄存器中的。 
2. B. 操作数 
	1. 操作数是指令要处理的数据。例如，`ADD AX, BX` 这条指令的操作数就是寄存器 `AX` 和 `BX` 中的值。如果指令需要从内存中读取数据（例如 `ADD AX, [1000H]`），那么地址为 `1000H` 的内存单元中的数据就会通过 #数据总线 传送到CPU。 
3. D. 中断类型号 
	1. 当一个外部设备（如键盘）需要CPU的服务时，它会发出一个中断请求信号。CPU响应中断后，需要知道是哪个设备请求中断，以便调用相应的处理程序。这时， #中断控制器 或设备会将一个唯一的识别码，即“中断类型号”（也叫中断向量），放到 #数据总线 上，由CPU读取。CPU根据这个号码去中断向量表中查找对应处理程序的入口地址。
4. C. 握手 (应答) 信号 
	1. 握手信号是用于协调两个不同速度设备之间数据传输的**定时和联络信号**。例如，在一个异步总线通信中，主设备（如CPU）发出“数据准备好”的信号，从设备（如打印机）接收数据后返回一个“数据已收到”的应答信号。这些“准备好”、“已收到”的信号是为了控制数据传输的流程，它们本身不属于被传输的数据。它们是典型的**控制信号**，因此应该在 #控制总线 上传输
衍生考点 [[总线带宽计算]] [[地址总线与存储容量的关系]] [[总线仲裁]]  [[区分不同总线上传输的信息]]
 [[Pasted image 20250819180121.png]]
C 

![[2011-exam-paper-ocr.pdf#page=2&rect=76,371,524,432|2011-exam-paper-ocr, p.2]]
#中断源 #中断屏蔽字 #屏蔽规则 #中断优先级 
1. 推理过程
	1. #中断系统设计的基本原则 是处理 #中断嵌套  [[中断屏蔽的规则（处理中断嵌套）]] 
		1. 规则1 (屏蔽低级/同级) 
			1. 需要屏蔽 $L_1$ 本身以及所有比 $L_1$ 优先级低的中断
				*   根据优先级顺序 ($L_4 > L_0 > L_2 > L_1 > L_3$)，比 $L_1$ 优先级低的中断只有 $L_3$。
			    *   因此，需要屏蔽 $L_1$ 和 $L_3$。
			    *   根据屏蔽规则 ($M_i=1$ 为屏蔽)，我们必须设置 $M_1=1$ 和 $M_3=1$。
		2. 应用规则2 (允许高级)
			1. 需要允许所有比 $L_1$ 优先级高的中断 
			    *   根据优先级顺序，比 $L_1$ 优先级高的中断有 $L_4$、$L_0$ 和 $L_2$。
				*   因此，需要允许 $L_4$, $L_0$, $L_2$ 这三个中断。
			    *   根据屏蔽规则 ($M_i=0$ 为允许)，我们必须设置 $M_4=0$, $M_0=0$, $M_2=0$。
		3. 构建屏蔽字
			1. 上述结果组合成最终的中断屏蔽字 $M_4M_3M_2M_1M_0$ 
				*   $M_4 = 0$
				*   $M_3 = 1$
				*   $M_2 = 0$
				*   $M_1 = 1$
				*   $M_0 = 0$ 
				所以，屏蔽字为 **01010**  D  

[[Pasted image 20250819180134.png]]
D
 
![[2011-exam-paper-ocr.pdf#page=2&rect=76,308,523,372|2011-exam-paper-ocr, p.2]]
1. 计算CPU每秒的总时钟周期数  #CPU主频 
	1.   CPU主频：$F_{CPU} = 50 \text{ MHz}$ 
	2.  1 MHz (兆赫兹) = $10^6$ Hz (赫兹) 
	3. CPU每秒的总时钟周期数为：
	    $C_{total} = 50 \times 10^6 \text{ 个周期/秒}$
2. 计算CPU每秒用于设备A的I/O操作所消耗的时钟周期数 
	1. 用“定时查询方式”（Polling）来控制设备 
		1. **查询频率**：为保证数据不丢失，每秒需要查询**至少**200次。
		    $N_{poll} = 200 \text{ 次/秒}$ 
		2. **单次查询耗时**：查询程序运行一次所用的时钟周期数**至少**为500个。
		    $C_{per\_poll} = 500 \text{ 个周期/次}$ 
3. CPU每秒用于查询设备A所消耗的总时钟周期数为 查询频率与 单次查询耗时的乘积： 
	1. $C_{IO} = N_{poll} \times C_{per\_poll} = 200 \frac{\text{次}}{\text{秒}} \times 500 \frac{\text{周期}}{\text{次}} = 100,000 \frac{\text{周期}}{\text{秒}}$ 
4. 计算I/O时间占CPU总时间的百分比 
	1. 这个百分比就是用于I/O的时钟周期数占CPU总时钟周期数的比例 
		1. 百分比 ($P$) = (每秒用于I/O的周期数) / (CPU每秒的总周期数)
		    $P = \frac{C_{IO}}{C_{total}}$ 
		2. $P = \frac{100,000}{50 \times 10^6} = \frac{1 \times 10^5}{5 \times 10^7} = \frac{1}{5 \times 10^2} = \frac{1}{500} = 0.002$   
			1. $P\% = 0.002 \times 100\% = 0.20\%$  
			2. C 
	
 [[CPU主频]]  [[IO控制方式]]   


[[Pasted image 20250819180145.png]]
C 
![[2011-exam-paper-ocr.pdf#page=2&rect=73,274,514,311|2011-exam-paper-ocr, p.2]]
[[饥饿]]   [[常见调度算法与优先级关系]]  
#先来先服务（FCFS）  #非强占式短任务优先（SJF）  [[高响应比优先]] #时间片轮转（RR）  


[[Pasted image 20250819180155.png]]
B
![[2011-exam-paper-ocr.pdf#page=2&rect=73,237,508,275|2011-exam-paper-ocr, p.2]]
-  #用户态与核心态 [[用户态与内核态]] [[进程的状态与切换]] [[用户态与核心态的状态切换]]
1. A. #命令解释程序  
	1. 命令解释程序是用户与操作系统交互的接口，例如Windows的`cmd.exe`或Linux的`bash`。它本身是一个应用程序 
	2. 它在用户态下运行，等待用户输入命令（如`ls`, `dir`, `copy`）。当它解析完命令后，如果这个命令需要操作系统的服务（例如，`ls`命令需要读取目录文件信息），它就会通过**系统调用**请求内核来完成。但命令解释程序本身，包括接收输入、解析字符串等大部分工作，都是在**用户态**完成的。因此，它是在用户态执行的 
2. B. #缺页处理程序  
	1. 当一个程序试图访问一个在虚拟地址空间中存在、但当前尚未加载到物理内存的页面时，MMU（内存管理单元）硬件会产生一个**缺页异常** 
	2. 这个异常会立即中断当前程序，使CPU从用户态切换到**核心态**，然后执行操作系统内核中的“缺页处理程序”。这个处理程序需要修改页表、可能需要将页面从磁盘加载到内存，这些都是高度特权的操作系统行为。因此，它必须在**核心态**执行
3. C. #进程调度程序  
	1. 它是操作系统内核的一部分，负责决定在多道程序环境下，下一个应该占用CPU运行的进程是哪一个 
	2. 进程调度涉及保存当前进程的上下文（寄存器、程序计数器等）、选择下一个进程、恢复下一个进程的上下文等操作。这些操作直接管理和修改最核心的系统资源——进程控制块（PCB）和CPU状态。这必须在**核心态**下才能完成，以防止用户程序干扰调度策略。进程调度通常由时钟中断或进程阻塞等事件触发
4. 时钟中断处理程序
	1. 计算机中有一个硬件时钟，它会以固定的频率（例如每秒100次）产生**时钟中断** 
	2. 每次时钟中断发生，CPU都会无条件地切换到**核心态**，执行内核中的“时钟中断处理程序”。这个程序通常用来更新系统时间、管理进程的时间片（time slice）、检查是否有延时任务到期，并可能触发进程调度。这些都是操作系统内核的底层任务，必须在**核心态**执行  
衍生考点： [[区分中断、异常和系统调用]]   [[系统调用的过程]]  [[特权指令与非特权指令的划分  ]]   [[上下文切换]]   [[用户栈与内核栈]]
[[Pasted image 20250819180206.png]]
A 

![[2011-exam-paper-ocr.pdf#page=2&rect=74,190,446,239|2011-exam-paper-ocr, p.2]]
[[进程与线程的区别]] 
1. A. 进程 P 的代码段 
	1.  #代码段 包含了 #程序执行的指令 。一个进程中的所有线程执行的是同一份代码（尽管可能在代码的不同位置）。因此，代码段是整个进程共享的。此选项不正确 
2. B. 进程 P 中打开的文件 
	1. #文件句柄 是由操作系统为进程管理的资源。当一个进程打开一个文件时，这个文件句柄归进程所有，该进程内的所有线程都可以使用这个句柄来读写文件。因此，打开的文件是共享的。此选项不正确
3. C. 进程 P 的 #全局变量 
	1. #全局变量 和 #静态变量 存储在进程的 #数据段 数据段是进程 #虚拟地址空间 的一部分，被该进程的所有线程共享。这也是为什么在多线程编程中， #访问全局变量 需要使用 #互斥锁 （Mutex）等同步机制来防止数据竞争。因此，全局变量是共享的。此选项不正确
4. D. 进程 P 中某线程的 #栈指针 
	1. 每个线程都需要一个独立的执行环境来运行。这个环境中最核心的部分就是**栈 (Stack)** 
		1. 线程的栈用于存储局部变量、函数参数、返回地址等。为了保证每个线程的函数调用和局部变量互不干扰，每个线程都必须有自己私有的栈。 
		2. #栈指针SP (Stack Pointer, $SP$) 
			1. 是一个特殊的寄存器，它总是指向当前线程栈的栈顶。既然每个线程的栈是私有的，那么指向这个私有栈的栈指针自然也是每个线程独有的，不能被其他线程共享。如果一个线程能修改另一个线程的栈指针，将会导致另一个线程的执行流被彻底破坏 

- [[进程与线程的区别]]  [[独享资源与共享资源]]
- [[线程同步]]  [[进程间通信与线程间通信]]   [[多线程的优缺点]]  [[用户级线程和内核级线程]]
[[截屏2025-08-19 下午6.02.39.png]]

D
![[2011-exam-paper-ocr.pdf#page=2&rect=70,111,402,194|2011-exam-paper-ocr, p.2]]
- 一个运行在**用户态**的程序，需要请求操作系统内核来操作一个物理设备（磁盘）
1. #用户程序 发出请求 
	1. 比如，你在程序中调用了一个 `read()` 函数来读取文件。这个 `read()` 函数本身是C库提供的，但它内部会封装一个**系统调用 (System Call)**。 
	2. 用户程序无法直接操作硬件，这是操作系统的保护机制决定的。如果允许，任何程序都可以随意读写磁盘，系统会立刻崩溃或数据混乱 
	3. 第一步必然是 **用户程序**
2. #系统调用处理程序 介入  
	1. 当用户程序执行到系统调用指令时（例如 `int 0x80` 或 `syscall`），CPU会产生一个**陷阱 (Trap)**，这是一种内部中断 
	2. CPU的执行模式从**用户态 (User Mode)** 切换到 **内核态 (Kernel Mode)**，并将控制权交给操作系统内核中预先设定的地址，这个地址就是**系统调用处理程序**的入口 
	3. 这个处理程序会分析系统调用的参数（比如，要读取哪个文件，读多少字节，存到哪里），并进行权限检查、参数合法性验证等。这个层面是**与具体设备无关**的，它只处理逻辑请求
3. #设备驱动程序 执行
	1. 系统调用处理程序在验证请求后，需要找到具体操作硬件的方法。它会根据请求的设备（比如 `/dev/sda1`），调用对应的**设备驱动程序** 
	2. 设备驱动程序是操作系统内核的一部分，它专门负责与某一类硬件（如特定型号的磁盘控制器）通信。它知道如何向该设备的寄存器写入命令、设置内存地址等 
	3.   驱动程序会将上层传来的逻辑请求（“读取文件A的第5个数据块”）翻译成具体的硬件指令（“命令磁盘控制器，将磁头移动到X磁道Y扇区，读取512字节数据到内存地址Z”）
	4.   然后，驱动程序启动设备，开始物理I/O操作 
4. 硬件操作与 #中断处理程序 
	1. 磁盘I/O是一个非常慢的物理过程（相对于CPU的计算速度）。在驱动程序发出指令后，CPU不会傻等，操作系统会把当前进程**阻塞 (Block)**，然后调度其他就绪的进程来使用CPU，以提高系统效率
	2. 当磁盘完成了数据读取，并将数据放入了指定内存区域（通常是通过DMA，直接内存访问）后，磁盘控制器会向CPU发送一个 #硬件中断信号 
	3. CPU接收到中断信号后，会立即暂停当前正在执行的任何任务，保存现场，然后跳转到操作系统内核中预设的**中断处理程序**
	4.  中断处理程序会分析中断来源，确认是磁盘I/O完成了。然后，它会进行一系列收尾工作，比如检查操作是否成功，最重要的是，**唤醒**之前因为等待I/O而被阻塞的那个进程，将其状态从“阻塞态”改为“就绪态” 


[[Pasted image 20250819180255.png]]
B 

![[2011-exam-paper-ocr.pdf#page=3&rect=70,680,552,815|2011-exam-paper-ocr, p.3]]
- [[（不）安全状态队列]]    #最大需求矩阵 #分配矩阵 #需求矩阵 #银行家算法（安全性算法） [[安全性算法]]
- 执行算法所需的向量和矩阵 
	1.  **可利用资源向量 `Available`**: 这是一个长度为 $m$ 的向量（$m$ 是资源种类的数量），表示当前系统中每种资源可用的实例数量。
	2.  **最大需求矩阵 `Max`**: 这是一个 $n \times m$ 的矩阵（$n$ 是进程数量），定义了每个进程对每种资源的最大需求量。
	3.  **分配矩阵 `Allocation`**: 这是一个 $n \times m$ 的矩阵，表示当前已分配给每个进程的每种资源的数量。
	4.  **需求矩阵 `Need`**: 这是一个 $n \times m$ 的矩阵，表示每个进程**还需**要的每种资源的数量。它由以下公式计算得出：
	    $Need[i, j] = Max[i, j] - Allocation[i, j]$
1. 初始状态数据
	*   **可用资源 `Available`**: (0, 2, 1)
	*   **已分配资源 `Allocation`**:
	    *   P₁: (2, 0, 0)
	    *   P₂: (1, 2, 0)
	    *   P₃: (0, 1, 1)
	    *   P₄: (0, 0, 1)
	*   **尚需资源 `Need`**:
	    *   P₁: (0, 0, 1)
	    *   P₂: (1, 3, 2)
	    *   P₃: (1, 3, 1)
	    *   P₄: (2, 0, 0)
2. 执行 #银行家算法（安全性算法）  
	1. 第 1 轮： 
		*   初始化 $Work = Available = (0, 2, 1)$。
		*   初始化 $Finish = [false, false, false, false]$。
		*   寻找满足 $Need_i \le Work$ 的进程：
		    *   **P₁**: $Need_1=(0, 0, 1) \le Work=(0, 2, 1)$？ **是** (因为 $0\le0$, $0\le2$, $1\le1$)。
		    *   **P₂**: $Need_2=(1, 3, 2) \le Work=(0, 2, 1)$？ **否** (因为 $1>0$)。
		    *   **P₃**: $Need_3=(1, 3, 1) \le Work=(0, 2, 1)$？ **否** (因为 $1>0$)。
		    *   **P₄**: $Need_4=(2, 0, 0) \le Work=(0, 2, 1)$？ **否** (因为 $2>0$)。
				只有进程 P₁ 可以被满足。所以如果存在安全序列，它必须以 P₁ 开头。
			*   **更新**:
			    *   将 P₁ 加入安全序列: `<P₁>`
			    *   模拟 P₁ 执行完毕并释放资源:
			        $Work = Work + Allocation_1 = (0, 2, 1) + (2, 0, 0) = (2, 2, 1)$
			    *   更新 $Finish$: $Finish = [true, false, false, false]$
	2. 第 2 轮： 
		*   当前 $Work = (2, 2, 1)$。
		*   从剩余的进程 {P₂, P₃, P₄} 中寻找满足 $Need_i \le Work$ 的进程：
		    *   **P₂**: $Need_2=(1, 3, 2) \le Work=(2, 2, 1)$？ **否** (因为 $3>2$)。
		    *   **P₃**: $Need_3=(1, 3, 1) \le Work=(2, 2, 1)$？ **否** (因为 $3>2$)。
		    *   **P₄**: $Need_4=(2, 0, 0) \le Work=(2, 2, 1)$？ **是** (因为 $2\le2$, $0\le2$, $0\le1$)。
		
		*   **结论**: 只有进程 P₄ 可以被满足。
		*   **更新**:
		    *   将 P₄ 加入安全序列: `<P₁, P₄>`
		    *   模拟 P₄ 执行完毕并释放资源:
		        $Work = Work + Allocation_4 = (2, 2, 1) + (0, 0, 1) = (2, 2, 2)$
		    *   更新 $Finish$: $Finish = [true, false, false, true]$
	3. 第 3 轮： 
		*   当前 $Work = (2, 2, 2)$。
		*   从剩余的进程 {P₂, P₃} 中寻找满足 $Need_i \le Work$ 的进程：
		    *   **P₂**: $Need_2=(1, 3, 2) \le Work=(2, 2, 2)$？ **否** (因为 $3>2$)。
		    *   **P₃**: $Need_3=(1, 3, 1) \le Work=(2, 2, 2)$？ **否** (因为 $3>2$)。
		
		*   **结论**: 此时，剩余的进程 P₂ 和 P₃ 的需求都无法被满足。我们无法继续找到下一个可以完成的进程。
*   算法结束时，$Finish = [true, false, false, true]$。
*   由于 $Finish[1]$ 和 $Finish[2]$ （对应P₂和P₃）仍然为 `false`，说明系统无法让所有进程都执行完毕。
*   因此，系统处于**不安全状态**，**不存在**安全序列 
[[Pasted image 20250819180311.png]]
- [[资源请求算法]] 

D
![[2011-exam-paper-ocr.pdf#page=3&rect=75,632,480,683|2011-exam-paper-ocr, p.3]]
#缺页中断的处理流程  [[缺页中断的处理流程]]
 [[缺页中断]]
1. III. 分配页框 
	1. 页的根本原因就是需要的页面不在物理内存中。为了将这个页面从外存（如硬盘）调入内存，操作系统首先必须在物理内存中为它找到一个存放位置。这个存放位置就是一个 #页框 因此，操作系统必须找到一个空闲的页框并将其分配给这个即将调入的页面。如果当前没有空闲页框，操作系统还需要执行 #页面置换算法  选择一个已在内存中的页面（称为“牺牲页”）换出，以腾出页框。所以，“分配页框”是处理缺页的第一步
2. II. 磁盘 I/O  
	1. 当操作系统找到了一个可用的页框后，它需要将程序所需的页面从外存（通常是硬盘上的交换空间或可执行文件本身）读取到这个刚刚分配的页框中。这个从硬盘读取数据的过程就是一个典型的 #磁盘I/O操作 这是整个缺页处理过程中最耗时的步骤 
3. I. 修改页表 
	1. 当 #磁盘I/O操作 完成，所需要的页面被成功加载到物理内存的 #页框 后，程序并不能立即使用它。因为记录虚拟地址到物理地址映射关系的 #页表 还没有更新。之前，该页在页表中的对应 #条目 的 #有效位 被标记为0或无效，表示该页不在内存中。现在，操作系统必须修改这个页表项： 
		*   将有效位置为1（表示该页现在在内存中）。
		*   填入该页所载入的物理页框的编号。
	    *   可能还会更新其他标志位（如访问位、修改位等）。
	* 只有在页表被正确修改后，MMU才能完成地址翻译，程序才能正常访问该页面

- [[页面置换算法]]  [[有效内存访问时间EAT]]  [[颠簸抖动]] [[写时复制]]
[[Pasted image 20250819180322.png]]
D
![[2011-exam-paper-ocr.pdf#page=3&rect=79,583,526,633|2011-exam-paper-ocr, p.3]]
#颠簸抖动  
1. I. 撤销部分进程 
	1. 最直接有效 抖动的根本原因是 内存不足 
	2. 被撤销进程所占用的内存页框会被释放出来，这些空闲的页框可以分配给仍在运行的其他进 
2. II. 增加磁盘交换区的容量
	1. 磁盘交换区（Swap Space）是用来存放从内存中换出的页面的地方
	2. 动的问题在于**换入换出的动作过于频繁**，而不是交换区**空间不够大**。增加交换区的容量，只是让你可以存放更多的“冷”数据，但并不能减少页面在内存和磁盘之间来回颠簸的频率。
	3. 所以，这个措施对于解决抖动是无效的，它治标不治本 
3. III. 提高用户进程的优先级: 
	  *   进程优先级决定了CPU调度器选择哪个进程来运行。提高一个进程的优先级，意味着它有更多的机会获得CPU时间。
	*   然而，抖动的问题是**内存不足**，而不是CPU时间不足。给一个频繁缺页的进程更多的CPU时间，只会让它更快地触发下一次缺页中断，然后再次进入等待磁盘I/O的状态。这不仅不能解决问题，反而可能因为该进程频繁地换入换出页面，而抢占了其他进程本已稀缺的内存资源，加剧整个系统的抖动。
	*   因此，这个措施也是无效的。

- [[抖动的预防与检测]]  [[缺页率控制法]]  [[页面置换算法与抖动的关系]]
[[Pasted image 20250819180337.png]]
A
 
![[2011-exam-paper-ocr.pdf#page=3&rect=76,535,530,585|2011-exam-paper-ocr, p.3]]
#逻辑地址  #线性地址/虚拟地址 #物理地址  [[地址的分类与定义]] 
1. 结合程序生命周期进行推导
	1. 把这些概念放入一个程序的完整生命周期中： 
		1. 编程 
			1. 程序员编写源代码（如`.c`文件）。此时只有符号名（如变量名`my_var`、函数名`my_func`），还没有形成数字地址
		2. 编译  
			1. 编译器将单个源文件（如`main.c`）转换成一个目标模块（`main.o`）。在这个过程中，编译器会：
			    *   生成机器指令。
			    *   为文件内的函数和全局/静态变量分配地址。这些地址是相对于该模块起始位置（地址0）的**偏移量**。
			    地址变换机构（如MMU）将逻辑地址（也称为虚拟地址）变换为物理地址。逻辑地址的形成涉及程序的编译和链接阶段，但最终完整的逻辑地址空间是在链接阶段形成的。
		3. 链接 
			1. 链接器将多个目标模块（`main.o`, `file1.o`...）和库文件组合成一个单一的可执行文件。它会解决模块间的符号引用，并进行“重定位”（Relocation），将每个模块的相对地址（逻辑地址）合并，形成一个统一的**线性地址空间** 
			2. 链接器将多个目标文件合并成一个可执行文件，并解析所有地址引用，分配统一的虚拟地址空间，从而形成完整的 #逻辑地址 。因此，逻辑地址最终在链接阶段形成
		4. 装载/运行 
			1. 操作系统将可执行文件加载到内存中。在程序运行时，当CPU访问一个地址（线性地址）时，MMU（内存管理单元）会介入，通过页表等机制，将其翻译成最终的**物理地址**。 

 - [[地址绑定]]  [[虚拟地址到物理地址的转换]]   [[编译、链接、加载的详细过程]]  [[分段与分页]]
 [[Pasted image 20250819180356.png]]
C
![[2011-exam-paper-ocr.pdf#page=3&rect=72,462,525,540|2011-exam-paper-ocr, p.3]]
[[IO缓冲]] [[单缓冲区]] [[双缓冲区]]
- 题目条件
	-    文件大小：10个磁盘块 ($N=10$)
	*   从磁盘读一个块到缓冲区的时间：$T_{io} = 100\mu s$
	*   从缓冲区将数据传送到用户区的时间：$T_m = 50\mu s$
	*   CPU分析一个数据块的时间：$T_c = 50\mu s$
1. #单缓冲区 情况计算 
	1. 根据题意，“当上一个磁盘块从缓冲区读入用户区完成时，下一磁盘块才能开始读入”。这意味着处理一个数据块的周期包括了I/O时间和内存移动时间
		1. 处理第1个块   
			*   磁盘 -> 缓冲区：耗时 $T_{io} = 100\mu s$
		    *   缓冲区 -> 用户区：耗时 $T_m = 50\mu s$
			*   CPU分析：耗时 $T_c = 50\mu s$
	2. 分析时间线
		1. 块1
	        *   $0\mu s \sim 100\mu s$: 读入块1。
	        *   $100\mu s \sim 150\mu s$: 传送块1到用户区。
	        *   此时，块2可以开始读入了。
	        *   $150\mu s \sim 200\mu s$: CPU分析块1。
	    2. 块2 
		    *   $150\mu s \sim 250\mu s$: 读入块2。
	        *   $250\mu s \sim 300\mu s$: 传送块2到用户区。
	        *   $300\mu s \sim 350\mu s$: CPU分析块2。
	    *   ...
	3. 可以看到，每处理一个数据块（直到下一个数据块可以开始读入），所花费的时间是一个“读入+传送”的周期。
	*   每个周期的耗时为：$T_{cycle} = T_{io} + T_m = 100\mu s + 50\mu s = 150\mu s$
		* 对于前9个块，CPU的分析时间 $T_c=50\mu s$ 完全可以和下一个块的读入时间 $T_{io}=100\mu s$ 重叠。瓶颈在于“读入+传送”这个串行过程
	1. 总时间计算
	    *   系统需要完成10个这样的“读入+传送”周期，总耗时为 $10 \times (T_{io} + T_m) = 10 \times 150\mu s = 1500\mu s$。
	    *   在$1500\mu s$这个时间点，第10个数据块刚刚被传送到用户区。
	    *   此时，前9个块的分析工作早已完成，但第10个块的分析工作还未开始。
	    *   因此，还需要加上分析最后一个数据块的时间 $T_c = 50\mu s$。
	    *   总时间 = $T_{单} = 10 \times (T_{io} + T_m) + T_c = 1500\mu s + 50\mu s = 1550\mu s$。
	    * $T_{单} = N \times (T_{io} + T_m) + T_c$
2. #双缓冲区 情况计算
	1. 分析时间线
	    *   **$0\mu s \sim 100\mu s$**：
	        *   磁盘向缓冲区1读入**块1**。($T_{io} = 100\mu s$)
	        *   CPU空闲。
	    *   **$100\mu s \sim 200\mu s$**：
	        *   磁盘向缓冲区2读入**块2**。($T_{io} = 100\mu s$)
	        *   CPU将**块1**从缓冲区1传送到用户区并进行分析。CPU耗时为 $T_m + T_c = 50\mu s + 50\mu s = 100\mu s$。
	    *   **$200\mu s \sim 300\mu s$**：
	        *   磁盘向缓冲区1读入**块3**。($T_{io} = 100\mu s$)
	        *   CPU处理**块2**。($T_m + T_c = 100\mu s$)
	    *   ...
	2. 寻找瓶颈  
		-  在这个流水线中，每个阶段的耗时取决于较慢的那个操作。
	    *   I/O操作耗时: $T_{io} = 100\mu s$
	    *   CPU操作（传送+分析）耗时: $T_m + T_c = 100\mu s$
	    *   两者时间相等，$\max(T_{io}, T_m + T_c) = 100\mu s$。这意味着流水线可以完美运行，每$100\mu s$就能处理完一个数据块。
	3. 总时间计算 
		-   首先，需要花费$100\mu s$将第一个数据块读入，以“填满”流水线。
	    *   之后，磁盘可以连续不断地将全部10个数据块读入内存。这个过程耗时为 $10 \times T_{io} = 10 \times 100\mu s = 1000\mu s$。
	    *   在$1000\mu s$这个时间点，第10个数据块刚刚被读入某个缓冲区，而第9个数据块的分析工作也刚刚完成。
	    *   接下来，系统需要处理最后一个（第10个）数据块，这部分工作无法与后续的I/O操作重叠了。
	    *   处理第10个块耗时为：$T_m + T_c = 50\mu s + 50\mu s = 100\mu s$。
	    *   总时间 = (连续读入10个块的时间) + (处理最后一个块的时间) = $1000\mu s + 100\mu s = 1100\mu s$。
	    *   或者，换一种更通用的思考方式：总时间 = (所有I/O操作耗时) + (最后一个块的CPU处理时间)。因为在第10个块I/O完成前，前9个块的CPU处理已经可以穿插完成了。
	    *   总时间 = $T_{双} = N \times T_{io} + T_m + T_c = 10 \times 100\mu s + 50\mu s + 50\mu s = 1100\mu s$。
	4. $T_{双} = T_{io} + (N-1) \times \max(T_{io}, T_m+T_c) + (T_m+T_c)$ 
		1. $T_{io}=T_m+T_c$ 
		2. $T_{双} = N \times T_{io} + T_m + T_c$ 
 
- [[CPU与IO时间不匹配]]  #多缓冲区 #缓冲池 #SPOOLing技术  [[SPOOLing技术]]  [[缓冲池]]
[[Pasted image 20250819180410.png]]
B 

![[2011-exam-paper-ocr.pdf#page=3&rect=70,329,534,461|2011-exam-paper-ocr, p.3]]
#并发执行 #竞争条件 
1. **初始状态**: 有两个并发执行的进程$P_1$和$P_2$。它们共享一个变量`x`，其初始值为$x=1$ 
2. 进程操作 
    *   $P_1$对`x`执行“加1”操作。
    *   $P_2$对`x`执行“减1”操作。 
[[（非）原子操作]]
	$P_1$和$P_2$是并发执行的，它们的指令可以以任意顺序交错（interleave）执行，只要每个进程内部的指令顺序（加载 -> 修改 -> 存储）不变即可。最终`x`的值取决于这两组共6条指令的实际执行序列 
3. 进程$P_1$（加1操作） 
	1.   `load R1, x` // R1是$P_1$使用的寄存器
    2.  `inc R1`
    3.  `store x, R1`
4. 进程$P_2$（减1操作） 
    4.  `load R2, x` // R2是$P_2$使用的寄存器
    5.  `dec R2`
    6.  `store x, R2`
5. 分析几种典型的指令交错执行顺序，看看会导致`x`的最终值是什么
	1. 情况一：顺序执行（串行），结果为1 
		1. 最理想的情况，一个进程的“加1”或“减1”操作整体是 #原子性 的 ，没有被打断
			1. **$P_1$先执行完，然后$P_2$执行 (序列: 1→2→3→4→5→6)
			    1.  `load R1, x` (此时$x=1$, R1=1)
			    2.  `inc R1` (R1=2)
			    3.  `store x, R1` (x=2)
			    4.  `load R2, x` (此时$x=2$, R2=2)
			    5.  `dec R2` (R2=1)
			    6.  `store x, R2` (x=1)
			    *   **最终结果: $x=1$**
			2. **$P_2$先执行完，然后$P_1$执行 (序列: 4→5→6→1→2→3)**
			    1.  `load R2, x` (此时$x=1$, R2=1)
			    2.  `dec R2` (R2=0)
			    3.  `store x, R2` (x=0)
			    4.  `load R1, x` (此时$x=0$, R1=0)
			    5.  `inc R1` (R1=1)
			    6.  `store x, R1` (x=1)
			    *   **最终结果: $x=1$

	2. 情况二：交错执行，发生“丢失更新”，结果为0或2
		1. 这是出现 #竞争条件 的情况
			 1. **$P_1$的更新被$P_2$覆盖，结果为0 (例如序列: 1→4→2→5→3→6)**
			    *   两个进程都先从内存中读取了`x`的旧值。
			    1.  $P_1$: `load R1, x` (此时$x=1$, R1=1)
			    2.  $P_2$: `load R2, x` (此时$x=1$, R2=1)
			    3.  $P_1$: `inc R1` (R1=2)
			    4.  $P_2$: `dec R2` (R2=0)
			    5.  $P_1$: `store x, R1` (将2写入x, 此时$x=2$)
			    6.  $P_2$: `store x, R2` (将0写入x, 此时$x=0$)
			    *   **最终结果: $x=0$**。$P_1$的更新（将x变成2）丢失了。
			
			 2.  **$P_2$的更新被$P_1$覆盖，结果为2 (例如序列: 4→1→5→2→6→3)**
			    *   同样，两个进程都先读取了旧值。
			    1.  $P_2$: `load R2, x` (此时$x=1$, R2=1)
			    2.  $P_1$: `load R1, x` (此时$x=1$, R1=1)
			    3.  $P_2$: `dec R2` (R2=0)
			    4.  $P_1$: `inc R1` (R1=2)
			    5.  $P_2$: `store x, R2` (将0写入x, 此时$x=0$)
			    6.  $P_1$: `store x, R1` (将2写入x, 此时$x=2$)
			    *   **最终结果: $x=2$**。$P_2$的更新（将x变成0）丢失了。
			*   要得到-1，需要对0执行减1操作。这意味着$P_2$必须在`x`已经变成0之后再执行一次完整的减1操作，但这违反了“$P_2$只执行一次减1”的题目设定。
			*   要得到3，需要对2执行加1操作。同理，这违反了“$P_1$只执行一次加1”的设定。
综上所述，所有可能的最终结果是 **0、1、2**  C 

- [[并发]] [[独享资源与共享资源]] [[临界区问题]]  [[竞争条件]]  [[（非）原子操作]]   
[[Pasted image 20250819180419.png]]
C 
![[2011-exam-paper-ocr.pdf#page=3&rect=73,281,471,330|2011-exam-paper-ocr, p.3]]
[[有（无）连接服务]]  [[（不）可靠服务]] [[TCPIP模型的网络层的核心协议（IP协议）]] #数据报服务 #虚电路服务 
[[TCP IP参考模型]] #网络层 
 
- [[TCP UDP运输层]]  [[IP头部校验和]] 
衍生考点 
 #IP数据报分片 当一个IP数据包的大小超过了链路的最大传输单元(MTU)时，它需要被分片。考察IP头部中与分片相关的字段（标识、标志位、片偏移）
  #TCP的可靠性机制 深入考察TCP如何通过三次握手、四次挥手、滑动窗口、超时重传、快速重传等机制来保证可靠性 
   #TCP/IP模型与OSI模型的对比 
- #IP地址与子网划分 考察IP地址的分类（A、B、C类）、子网掩码、CIDR（无类域间路由）以及如何进行子网划分和路由汇聚。
- #ARP协议与RARP协议 考察网络层相关的辅助协议。ARP（地址解析协议）用于将IP地址解析为MAC地址；RARP（逆地址解析协议）则相反。
- #ICMP互联网控制报文协议   考察网际控制报文协议的作用，例如`ping`命令（使用ICMP回显请求和应答报文）和`traceroute`命令（使用ICMP TTL超时报文） 
- #虚电路服务与数据报服务的比较  详细对比两者的优缺点、适用场景以及代表性技术（如数据报网络的Internet，虚电路网络的ATM、帧中继） 
[[Pasted image 20250819180430.png]]
A 

![[2011-exam-paper-ocr.pdf#page=3&rect=70,245,515,283|2011-exam-paper-ocr, p.3]]

1. 已知条件
	1.  数据传输速率 (比特率) $C = 2400 \text{ bps}$ (bits per second)
	2. 调制方式：四相位调制 (QPSK) 
2. 理解调制方式的含义：
	1.   “四相位调制”意味着载波信号有4种不同的相位状态
	2.  每一个信号状态被称为一个 #码元 
	3. 因此，一个 #码元 可以表示 $N=4$ 种不同的状态 
3. 计算每个 #码元 携带的信息量 
	1. 一个 #码元 能携带的 #比特数 $k$ 由码元的 #状态数 $N$ 决定。它们的关系是 $k = \log_2 N$
	2.  $k = \log_2 4 = 2$ bit  
	3. 每发送一个码元，就相当于发送了2个比特的数据
4. 计算波特率 
	1. #波特率B 也叫码元速率，指的是通信链路每秒钟可以传输的码元个数。单位是波特 
	2. #比特率C   是每秒钟传输的比特个数 
		1. $C = B \times k$  或者  $C = B \times \log_2 N$ #比特率与波特率的关系  
		2. $B = \frac{C}{k} = \frac{2400 \text{ bps}}{2 \text{ bit/symbol}} = 1200 \text{ symbol/s}$ 
		3.  1 symbol/s 等于 1 Baud，所以该链路的波特率是 **1200 波特**   选 B

[[比特率 波特率 码元]]

#求解调制方式/码元状态数    [[结合信道带宽（奈奎斯特定理）]]
[[Pasted image 20250819180457.png]]
B 

![[2011-exam-paper-ocr.pdf#page=3&rect=74,199,538,248|2011-exam-paper-ocr, p.3]]
[[选择重传协议SR]]  #SR协议的核心机制 
1. 发送方行为 
	1. 发送方已发送了 0、1、2、3 号共 4 个数据帧。根据 SR 协议，发送方会为每一个已发送但未确认的帧启动一个独立的计时器。因此，有 4 个计时器正在运行，分别对应 0、1、2、3 号帧 
2. 接收方确认 
	1. 发送方收到了 1 号帧的确认（ACK1）。在 SR 协议中，ACK 是**非累积的**，即 ACK1 仅仅表示“我已成功收到 1 号帧”，它并不暗示 0 号帧也一定被收到了。收到 ACK1 后，发送方取消 1 号帧的计时器，并标记 1 号帧为已成功发送 
3. 超时事件 
	1.  0 号帧和 2 号帧的计时器相继超时。在 SR 协议中，哪个帧的计时器超时，就意味着哪个帧（或其对应的ACK）在传输过程中丢失了。因此，发送方会且仅会重传那些计时期超时的帧 
4. 未超时帧 
	1. 3 号帧的计时器并未超时。因此，发送方会继续等待 3 号帧的确认，在当前时刻**不会**重传它 
5.  综上所述，因计时器超时而需要重传的帧是 **0 号帧**和 **2 号帧**。因此，需要重传的帧数是 2  

#SR协议的窗口大小 #GBN协议的窗口大小 

[[Pasted image 20250819180508.png]]
B 

![[2011-exam-paper-ocr.pdf#page=3&rect=74,152,467,198|2011-exam-paper-ocr, p.3]]
#CSMA #CDMA [[CSMA载波监听多路访问]]   [[CDMA码分多址]]   [[CSMA-CD协议的工作原理]]  [[CSMA-CA带冲突避免的载波监听多路访问]]

 只有 CSMA/CA 协议在 MAC 层设计了对数据帧的确认机制  D  

[[CSMA-CD最小帧长问题]]  #CSMA/CD与CSMA/CA的核心区别  [[二进制指数退避算法]] 
[[Pasted image 20250819180521.png]] 
D 

![[2011-exam-paper-ocr.pdf#page=4&rect=75,577,536,823|2011-exam-paper-ocr, p.4]]
#路由聚合（路由汇总-超网）
场景分析 
1.  我们有两个路由器，R1 和 R2。
2.  R1 要访问 R2 后面的网络。
3.  R2 后面连接了两个子网：`192.168.2.0/25` 和 `192.168.2.128/25`。
4.  题目要求在 R1 上**添加一条路由**，使得 R1 能够将 IP 分组（数据包）正确地路由到这两个子网。
	1. 这意味着我们需要找到一个能够同时**包含** `192.168.2.0/25` 和 `192.168.2.128/25` 这两个网络的**最小**的单一网络地址，即它们的 #路由聚合（路由汇总-超网） 
- #静态路由的组成 
1.  **目的网络 (Destination Network)**
2.  **子网掩码 (Subnet Mask)**
3.  **下一跳地址 (Next Hop)**
- [[路由聚合（路由汇总-超网）]]  
	1. 确定目标网络并转换为二进制 
	2. 需要聚合的两个目标网络是：
		*   网络 A: $192.168.2.0/25$
		*   网络 B: $192.168.2.128/25$
		1. 找到它们的共同部分，我们需要将它们的网络地址转换为二进制格式 
			*   $192.168.2.0$ -> $11000000.10101000.00000010.00000000$
			*   $192.168.2.128$ -> $11000000.10101000.00000010.10000000$
	3. 寻找最长共同前缀
		1. 11000000.10101000.00000010.
		2. 它们的前 24 位是完全相同的。第 25 位开始出现不同（一个是 `0`，一个是 `1`）。
			因此，最长的共同前缀长度是 **24** 位 
	4. 确定聚合后的 #网络地址和子网掩码
		1. 新的子网掩码 共同前缀的长度是 24 位，所以新的前缀长度是 `/24`。对应的子网掩码就是 24 个 `1` 后面跟 8 个 `0`：
		    *   二进制: $11111111.11111111.11111111.00000000$
		    *   十进制: $255.255.255.0$
		2. 新的网络地址 取共同的前 24 位，然后将剩余的主机位（8位）全部置为 `0` 
		    *   二进制: $11000000.10101000.00000010.00000000$
		    *   十进制: $192.168.2.0$
		3. 得到的聚合路由是 $192.168.2.0/24$ 
		4. 这意味着 **目的网络** 是 $192.168.2.0$，**子网掩码** 是 $255.255.255.0$  
	5. 确定下一跳地址 
		1. 从 R1 的角度看，无论数据包是去 $192.168.2.0/25$ 还是 $192.168.2.128/25$，它都必须先把数据包发给 R2。根据网络拓扑图，R1 与 R2 直连的链路上，R2 的接口地址是 $192.168.1.2$ 
		2. 因此，对于 R1 来说，到达 $192.168.2.0/24$ 这个网络的**下一跳地址**就是 $192.168.1.2$ 
	6. 组合并选择答案 
	7. 将我们推导出的三部分组合起来：
		*   目的网络: $192.168.2.0$
		*   子网掩码: $255.255.255.0$
		*   下一跳: $192.168.1.2$ 
		* D 
*   #更复杂的聚合 给出 4 个或 8 个不完全连续的子网，要求找出最优的聚合路由。例如，聚合 $192.168.4.0/24$, $192.168.5.0/24$, $192.168.6.0/24$, $192.168.7.0/24$，它们可以聚合成 $192.168.4.0/22$
* #反向问题-子网划分 与聚合相反，题目会给出一个大网络，如 $192.168.1.0/24$，要求你将其划分为 N 个大小相等的子网，或者满足不同主机数量需求的多个子网（VLSM - 可变长子网掩码）。
 - [[路由最长匹配原则]]  [[CIDR无类域间路由]]  [[路由协议中的汇总]]
[[Pasted image 20250819180538.png]]
D 

![[2011-exam-paper-ocr.pdf#page=4&rect=78,541,513,578|2011-exam-paper-ocr, p.4]]
1. 识别子网信息 
	1. 题目给出的网络是 `192.168.4.0/30`。这里的 `/30` 是    #CIDR无类域间路由 表示法，它告诉我们子网掩码中有 30 个连续的 `1` 
		 *   一个 IPv4 地址总共有 32 位。
		*   网络位 (Network Bits) = 30 位
		*   主机位 (Host Bits) = 总位数 - 网络位 = $32 - 30 = 2$ 位
	2. 计算子网的地址范围 
		1. 主机位有 2 位，所以这个子网总共可以有 $2^2 = 4$ 个地址。我们来列出这 4 个地址。 
		2. 首先，将网络地址 `192.168.4.0` 的最后一部分（最后一个字节）转换成二进制。
			`0` 的二进制是 `00000000`。
			因为网络位是 30 位，所以前 3 个字节和第 4 个字节的前 6 位是网络部分。
			`192.168.4.0` -> `11000000.10101000.00000100.00000000`
			网络部分是 `11000000.10101000.00000100.000000`
			主机部分是最后的 2 位，我们用 `xx` 表示。
			*   当主机位为 `00` 时：`...000000`**`00`** -> 十进制为 `0`。完整地址是 `192.168.4.0`。
			*   当主机位为 `01` 时：`...000000`**`01`** -> 十进制为 `1`。完整地址是 `192.168.4.1`。
			*   当主机位为 `10` 时：`...000000`**`10`** -> 十进制为 `2`。完整地址是 `192.168.4.2`。
			*   当主机位为 `11` 时：`...000000`**`11`** -> 十进制为 `3`。完整地址是 `192.168.4.3`。
		3. 所以，这个子网的地址范围是 `192.168.4.0` 到 `192.168.4.3` 
	3. 识别特殊地址
		在任何一个子网中，有两个地址是保留的，不能分配给主机：
		*   **网络地址 (Network Address)**：主机位全为 `0` 的地址，用来标识整个子网。在本例中是 `192.168.4.0`。
		*   **广播地址 (Broadcast Address)**：主机位全为 `1` 的地址，向这个地址发送数据包，子网内的所有主机都能收到。在本例中是 `192.168.4.3`
	4. 解答问题
		1. 能接收目的地址为 `192.168.4.3` 的 IP 分组的最大主机数是多少？
			1. 第 3 步的分析，`192.168.4.3` 是这个子网的广播地址。广播数据包会被发送到该子网内的 **所有主机** 
			2. 可用主机数 = 总地址数 - 2 = $4 - 2 = 2$ 个 
				1. 这两个可用的主机地址是 `192.168.4.1` 和 `192.168.4.2` 
				2. 当一个数据包的目的地址是 `192.168.4.3` 时，这个子网内的 2 个主机会接收到这个数据包
	5. 最大主机数是 2 
		   C 
- [[IP地址与子网掩码]]  [[CIDR无类域间路由]]  [[特殊地址计算（网络地址，广播地址）]]  [[可用主机数计算公式]]
 衍生考点 [[反向计算：根据主机数量求子网掩码]]   [[判断两个 IP 是否在同一个子网]]  [[ 判断 IP 地址的合法性]]     [[IP子网划分]]
[[Pasted image 20250819180550.png]]
C 

![[2011-exam-paper-ocr.pdf#page=4&rect=67,479,531,543|2011-exam-paper-ocr, p.4]]
[[TCP三次握手]]  [[初始序列号的作用]]  [[TCP状态转换]]
1. 第一次握手（客户端 -> 服务器）
	*   主机甲（客户端）向主机乙（服务器）发起连接请求。
    *   甲发送的TCP报文段为 `(SYN=1, seq=11220)`。
    *   `SYN=1`：这表示是一个**连接请求报文**（Synchronization）。SYN标志位为1时，表明这是一个请求建立连接的报文段。
    *   `seq=11220`：这是主机甲为这次通信选择的[[初始序列号的作用]] ， TCP是面向字节流的，`seq` 字段表示本报文段所发送的数据的第一个字节的序号。在建立连接时，这个值是随机生成的。
2. 第二次握手（服务器 -> 客户端） 
	 *   主机乙（服务器）收到了甲的连接请求，并同意建立连接。
    *   乙需要向甲发送一个**确认并同样请求连接**的报文段。这个报文段同时包含了对甲的请求的确认（ACK）和乙自己的同步请求（SYN）。
    *   我们来分析这个报文段的各个字段：
        *   **SYN标志位**：因为主机乙也需要建立一个从乙到甲方向的连接（TCP是全双工的），所以它也需要发送一个同步请求。因此，`SYN` 标志位必须为 **1**。
        *   **ACK标志位**：这个报文段同时也是对甲的连接请求的确认，所以 `ACK` 标志位必须为 **1**。
        *   **确认号 (ack)**：确认号是用来告诉甲，乙期望收到的甲的下一个字节的序号。根据TCP协议，确认号的值是收到的序号加1。甲发送的序号是 `seq=11220`，并且SYN报文会消耗一个序号。所以，乙期望收到的下一个序号是 $11220 + 1$。因此，确认号 `$ack = 11221$`。
        *   **序号 (seq)**：主机乙也需要为自己的数据传输选择一个初始序号（ISN）。这个序号由主机乙的操作系统随机生成，它与主机甲的初始序号没有任何关系。在题目选项中，我们需要找到一个合理的、由乙发起的 `seq` 值。
3. 匹配选项 
	1.  根据我们的分析，主机乙返回的报文段必须满足：`SYN=1`, `ACK=1`, `ack=11221`  
	2. C 


[[Pasted image 20250819180559.png]]
C  


![[2011-exam-paper-ocr.pdf#page=4&rect=81,417,527,482|2011-exam-paper-ocr, p.4]]
- 已知信息
	1.  主机甲（Sender）向主机乙（Receiver）发送了3个连续的TCP段。
	2.  第1段载荷：300字节 (B)。
	3.  第2段载荷：400字节 (B)。
	4.  第3段载荷：500字节 (B)。
	5.  第3段的序号（Sequence Number）为 900。
	6.  主机乙的接收情况：仅正确接收了第1段和第3段，第2段丢失。
- 求主机乙发送给主机甲的 #确认序号
1. 计算每个TCP段的序号 
	1. #TCP的序号 指的是**本段数据中第一个字节在整个字节流中的编号** 由于这3个段是连续发送的，我们可以根据第3段的序号反推出前两个段的序号
		1. 我们知道第3段的序号是900，其载荷为500B 
		2. 第3段的序号 ($SEQ_3$) 是由第2段的序号 ($SEQ_2$) 加上第2段的载荷长度 ($LEN_2$) 得来的 
		    公式为：$SEQ_3 = SEQ_2 + LEN_2$
		    代入数值：$900 = SEQ_2 + 400$
		    解得第2段的序号：$SEQ_2 = 500$
		3. 同理，第2段的序号 ($SEQ_2$) 是由第1段的序号 ($SEQ_1$) 加上第1段的载荷长度 ($LEN_1$) 得来的 
		    公式为：$SEQ_2 = SEQ_1 + LEN_1$
		    代入数值：$500 = SEQ_1 + 300$
		    解得第1段的序号：$SEQ_1 = 200$
		4. 整理一下这3个数据段的信息 
			*   **第1段**: 序号 $SEQ_1=200$，长度 $LEN_1=300$B。包含字节编号从 200 到 499。
			*   **第2段**: 序号 $SEQ_2=500$，长度 $LEN_2=400$B。包含字节编号从 500 到 899。
			*   **第3段**: 序号 $SEQ_3=900$，长度 $LEN_3=500$B。包含字节编号从 900 到 1399。
	2. 分析主机乙的接收情况和确认机制 
		1. TCP 使用 #累积确认机制 。这意味着，确认号 $ACK$ 表示的是：“我已经成功接收了所有到 $ACK-1$ 为止的字节，现在我期望接收的下一个字节的序号是 $ACK$” 
			*   主机乙收到了**第1段** (字节 200-499)。这是按序到达的第一个数据段，所以主机乙会正确接收并缓存它。
			*   主机乙**没有收到第2段** (字节 500-899)。这是一个数据缺口。
			*   主机乙收到了**第3段** (字节 900-1399)。由于第2段丢失，第3段是一个**失序**（out-of-order）的数据段。现代TCP协议通常会将这个失序的段缓存起来，等待中间缺失的段到达。
	3. 确定最终的确认号  #累积确认原则 主机乙只能确认它已经收到的、**连续的**字节流的末尾 
		*   主机乙已经连续地收到了从序号200开始到499结束的所有字节。
		*   它期望收到的下一个字节的序号是500。
		*   虽然它也收到了第3段（900-1399），但由于中间的500-899字节缺失，它不能“跳过”这个缺口去确认序号900之后的数据。这样做会告诉主机甲500-899也收到了，这与事实不符。
2. 因此，主机乙会发送一个确认号，告诉主机甲它下一个期望收到的字节是第500号
	-
- [[TCP的序号和确认序号]]   #计算ACK  [[选择性确认SACK]]  [[快速重传]]  [[TCP流量控制与拥塞控制]]
[[Pasted image 20250819180608.png]]
B



![[2011-exam-paper-ocr.pdf#page=4&rect=75,311,535,420|2011-exam-paper-ocr, p.4]]
#AOE网络   [[AOE网]]  [[关键路径]]  [[求解关键路径所需的参数]] 
-  (1) 写出图G的邻接矩阵A  [[邻接矩阵，邻接表 ，稀疏图，稠密图]]
1. 题目给出的`[4, 6, ∞, ∞, ∞, 5, ∞, ∞, 4, 3, ∞, ∞, 3, 3, ∞]` 是一个6顶点图的邻接矩阵的上三角部分， #按行优先存储 。顶点编号为0-5 
2. 填充步骤：
	1.  **第0行 (填充5个元素 `A[0][1]` 到 `A[0][5]`)**: 取数组前5个元素 `[4, 6, ∞, ∞, ∞]`
	2.  **第1行 (填充4个元素 `A[1][2]` 到 `A[1][5]`)**: 取接下来4个元素 `[5, ∞, ∞, ∞]`
	3.  **第2行 (填充3个元素 `A[2][3]` 到 `A[2][5]`)**: 取接下来3个元素 `[4, 3, ∞]`
	4.  **第3行 (填充2个元素 `A[3][4]` 到 `A[3][5]`)**: 取接下来2个元素 `[∞, 3]`
	    *   *注意：原题数组 `[..., 4, 3, ∞, ∞, 3, 3]` 共有14个元素，而一个6x6上三角矩阵需要 (6*5)/2 = 15个元素。这很可能是题目中的一个印刷错误。根据上下文和标准解法，第3行对应的应该是 `[∞, 3]`，即 `A[3][4]=∞`, `A[3][5]=3`。*
	5.  **第4行 (填充1个元素 `A[4][5]`)**: 取最后1个元素 `[3]`
		1. 构建完整的6x6邻接矩阵A。对角线为0，下三角部分为∞ 
根据这些信息，我们可以构建完整的6x6邻接矩阵A。对角线为0，下三角部分为∞（因为是有向图）。

$$A = \begin{bmatrix}
0 & 4 & 6 & \infty & \infty & \infty \\
\infty & 0 & 5 & \infty & \infty & \infty \\
\infty & \infty & 0 & 4 & 3 & \infty \\
\infty & \infty & \infty & 0 & \infty & 3 \\
\infty & \infty & \infty & \infty & 0 & 3 \\
\infty & \infty & \infty & \infty & \infty & 0
\end{bmatrix}$$
- (2) 画出 #有向带权图 G 
	根据邻接矩阵 `A`，我们可以画出图 `G`。矩阵中 `A[i][j]` 的值如果不为0或∞，就表示有一条从顶点 `i` 指向顶点 `j` 的有向边，权重为 `A[i][j]`。≤
	
	*   `A[0][1] = 4`  =>  边 `0 -> 1`，权重 `4`
	*   `A[0][2] = 6`  =>  边 `0 -> 2`，权重 `6`
	*   `A[1][2] = 5`  =>  边 `1 -> 2`，权重 `5`
	*   `A[2][3] = 4`  =>  边 `2 -> 3`，权重 `4`
	*   `A[2][4] = 3`  =>  边 `2 -> 4`，权重 `3`
	*   `A[3][5] = 3`  =>  边 `3 -> 5`，权重 `3`
	*   `A[4][5] = 3`  =>  边 `4 -> 5`，权重 `3`

- (3) 求图G的关键路径，并计算该路径的长度 
	#关键路径 是图中从源点（入度为0的点，这里是**顶点0**）到汇点（出度为0的点，这里是**顶点5**）的**最长路径**
	需要计算两个核心参数：
	*   **ve(k)**: 顶点的**最早发生时间** (Earliest Vertex Time)。
	*   **vl(k)**: 顶点的**最晚发生时间** (Latest Vertex Time)。
1.  步骤一：计算所有顶点的最早发生时间 (ve)
	1. 从源点开始，按拓扑顺序计算。`ve(源点) = 0`。
		`ve(j) = Max { ve(i) + weight(i, j) }`，其中`(i, j)`是所有指向`j`的边
		*   `ve(0) = 0`
		*   `ve(1) = ve(0) + 4 = 4`
		*   `ve(2) = Max(ve(0)+6, ve(1)+5) = Max(6, 4+5) = Max(6, 9) = 9`
		*   `ve(3) = ve(2) + 4 = 9 + 4 = 13`
		*   `ve(4) = ve(2) + 3 = 9 + 3 = 12`
		*   `ve(5) = Max(ve(3)+3, ve(4)+3) = Max(13+3, 12+3) = Max(16, 15) = 16`
	2. #关键路径的长度 就是汇点的最早发生时间，即 **16** 
2. 步骤二：计算所有顶点的最晚发生时间 (vl)  
	1. 从汇点开始，按逆拓扑顺序计算。`vl(汇点) = ve(汇点)`。
		`vl(i) = Min { vl(j) - weight(i, j) }`，其中`(i, j)`是所有从`i`出发的边 
		*   `vl(5) = ve(5) = 16`
		*   `vl(4) = vl(5) - 3 = 16 - 3 = 13`
		*   `vl(3) = vl(5) - 3 = 16 - 3 = 13`
		*   `vl(2) = Min(vl(3)-4, vl(4)-3) = Min(13-4, 13-3) = Min(9, 10) = 9`
		*   `vl(1) = vl(2) - 5 = 9 - 5 = 4`
		*   `vl(0) = Min(vl(1)-4, vl(2)-6) = Min(4-4, 9-6) = Min(0, 3) = 0`
3. 步骤三：确定关键路径 
	1. 关键活动（边 `<i, j>`）必须满足条件：`ve(i) == vl(i)` 且 `ve(j) == vl(j)` 且 `ve(j) - ve(i) == weight(i, j)`  
		1. 由关键活动组成的路径就是关键路径
	2. 我们检查 `ve(k) == vl(k)` 的顶点，这些是**关键顶点**：
		*   顶点0: `ve(0)=0`, `vl(0)=0`  (是)
		*   顶点1: `ve(1)=4`, `vl(1)=4`  (是)
		*   顶点2: `ve(2)=9`, `vl(2)=9`  (是)
		*   顶点3: `ve(3)=13`, `vl(3)=13` (是)
		*   顶点4: `ve(4)=12`, `vl(4)=13` (不是)
		*   顶点5: `ve(5)=16`, `vl(5)=16` (是)
	3. 关键路径必定由这些关键顶点组成。我们从源点0出发，沿着连接关键顶点的边寻找路径 
		*   **0 -> 1**:  `ve(0)=0, vl(0)=0`, `ve(1)=4, vl(1)=4`. `ve(1)-ve(0) = 4`, 权重也是4。 **是关键活动**。
		*   **1 -> 2**:  `ve(1)=4, vl(1)=4`, `ve(2)=9, vl(2)=9`. `ve(2)-ve(1) = 5`, 权重也是5。 **是关键活动**。
		*   **2 -> 3**:  `ve(2)=9, vl(2)=9`, `ve(3)=13, vl(3)=13`. `ve(3)-ve(2) = 4`, 权重也是4。 **是关键活动**。
		*   **3 -> 5**:  `ve(3)=13, vl(3)=13`, `ve(5)=16, vl(5)=16`. `ve(5)-ve(3) = 3`, 权重也是3。 **是关键活动**。
将这些关键活动连接起来，得到 #关键路径
4.  **关键路径**: `0 -> 1 -> 2 -> 3 -> 5`
5.  **关键路径长度**: `4 + 5 + 4 + 3 = 16`

[[Pasted image 20250819180624.png]]
[[Pasted image 20250819180641.png]]
![[2011-exam-paper-ocr.pdf#page=4&rect=77,176,528,316|2011-exam-paper-ocr, p.4]]
1. 核心思想是分治法，具体实现上类似 #二分查找 。我们的目标是在 $O(\log L)$ 的时间内找到解，这就强烈暗示了我们不能遍历数组，而是应该在每一步都排除掉一半的元素 
	1. 思路如下：
		1.  我们比较两个数组 A 和 B 的中位数，分别设为 $m_A$ 和 $m_B$。
		2.  基于 $m_A$ 和 $m_B$ 的大小关系，我们可以排除掉一部分肯定不包含最终解的元素。
2. 情况一：$m_A = m_B$ 
	1. 如果两个数组的中位数相等，那么这个值就是我们要求的中位数。
		*   **原因**：假设 $m_A = m_B = v$。在数组 A 中，大约有一半的元素小于或等于 $v$。在数组 B 中，也大约有一半的元素小于或等于 $v$。将这两个“一半”加起来，就构成了整个合并数组的前半部分。因此，$v$ 正好位于中间位置，它就是合并后数组的中位数
	2. 情况二：$m_A < m_B$ 
		1. 如果 A 的中位数小于 B 的中位数，那么最终合并后的大数组的中位数 $M$ 必定满足 $m_A \le M \le m_B$ 
		2. 既然真正的中位数 $M$ 不可能存在于 A 的前半部分（即小于 $m_A$ 的那些元素），也不可能存在于 B 的后半部分（即大于 $m_B$ 的那些元素），我们就可以安全地将这两部分**同时舍弃** 
		    *   舍弃 A 的前半部分：`A[0 ... mid_A]`
		    *   舍弃 B 的后半部分：`B[mid_B ... L-1]`
	3. 情况三：$m_A > m_B$ 
		1. 逻辑与情况二完全对称。真正的中位数 $M$ 必定满足 $m_B \le M \le m_A$ 
		2. 我们可以安全地舍弃 A 的后半部分和 B 的前半部分。
		    *   舍弃 A 的后半部分：`A[mid_A ... L-1]`
		    *   舍弃 B 的前半部分：`B[0 ... mid_B]`
	4. 通过上述比较和舍弃的步骤，我们每次都将问题的规模缩小一半（两个长度为 $L$ 的数组问题，变成两个长度约为 $L/2$ 的子数组问题）。我们重复这个过程，直到每个子数组只剩下一个元素。此时，这两个元素中较小的那个就是我们要求的全局中位数
-  2. 代码实现解析
```c++
int M_Search(int A[], int B[], int n) { // n 是数组长度 L
    int s1=0, d1=n-1, s2=0, d2=n-1; // s1, d1 分别是 A 的子数组首尾指针
                                     // s2, d2 分别是 B 的子数组首尾指针
    int m1, m2;

    // 当子数组长度大于 1 时循环
    // s1!=d1 就意味着长度至少为 2
    // 题目中两个数组长度始终保持一致，所以 || s2!=d2 是冗余的
    while(s1 != d1) { 
        m1 = (s1 + d1) / 2; // A 子数组的中点
        m2 = (s2 + d2) / 2; // B 子数组的中点

        if (A[m1] == B[m2]) {
            return A[m1]; // 情况一：中位数相等，直接返回
        }

        if (A[m1] < B[m2]) { // 情况二：mA < mB
            // 舍弃 A 的前半部分和 B 的后半部分
            // 这里需要精确控制舍弃的元素数量，必须保证两边舍弃的数量相同
            
            // (s1+d1)%2 == 0 表示当前子数组元素个数 (d1-s1+1) 是奇数
            if ((s1 + d1) % 2 == 0) { // 子数组长度为奇数
                s1 = m1;     // A 的新起点是中点 m1。保留 A[m1...d1]
                d2 = m2;     // B 的新终点是中点 m2。保留 B[s2...m2]
            } else { // 子数组长度为偶数
                s1 = m1 + 1; // A 的新起点是 m1+1。保留 A[m1+1...d1]
                d2 = m2;     // B 的新终点是 m2。保留 B[s2...m2]
            }
        } else { // 情况三：mA > mB
            // 舍弃 A 的后半部分和 B 的前半部分

            if ((s1 + d1) % 2 == 0) { // 子数组长度为奇数
                d1 = m1;     // A 的新终点是 m1
                s2 = m2;     // B 的新起点是 m2
            } else { // 子数组长度为偶数
                d1 = m1;     // A 的新终点是 m1
                s2 = m2 + 1; // B 的新起点是 m2+1
            }
        }
    }

    // 循环结束时，s1==d1，s2==d2，每个子数组只剩一个元素
    // 最终的中位数就是这两个元素中较小的那一个
    return A[s1] < B[s2] ? A[s1] : B[s2];
}
```
1. 对奇偶长度处理的解释 
	1. 算法能够成立的根本在于每次从A和B中**舍弃相同数量的元素**
		*   **当子数组长度为奇数时**，例如 5 个元素（索引0-4），中点`m1`索引为2。
		    *   `A[m1] < B[m2]`时，舍弃A的前半部分`A[0,1]`（2个元素），保留`A[2,3,4]`。为了保持平衡，也要从B舍弃2个元素，所以舍弃B的后半部分`B[3,4]`，保留`B[0,1,2]`。对应代码就是 `s1 = m1` 和 `d2 = m2`。
		*   **当子数组长度为偶数时**，例如 6 个元素（索引0-5），中点`m1`（下中位数）索引为2。
		    *   `A[m1] < B[m2]`时，舍弃A的前半部分`A[0,1,2]`（3个元素），保留`A[3,4,5]`。为了平衡，也要从B舍弃3个元素，所以舍弃B的后半部分`B[3,4,5]`，保留`B[0,1,2]`。对应代码就是 `s1 = m1 + 1` 和 `d2 = m2`。
- 3. 算法复杂度
	*   **时间复杂度**: $O(\log L)$。
	    每次循环，数组的搜索范围都缩小一半。设数组长度为$L$，循环次数约为 $\log_2 L$ 次。所以时间复杂度为 $O(\log L)$。
	*   **空间复杂度**: $O(1)$。
	    该算法是原地进行的，只使用了几个整型变量来存储首尾指针和中点，没有使用额外的数组或递归栈。因此空间复杂度为 $O(1)$。

[[Pasted image 20250819180705.png]]
[[Pasted image 20250819180734.png]]
- 衍生考点 
	- 这个题目是“在有序序列中寻找第k小元素”问题的一个特例。以下是一些常见的衍生和拓展 
		- 两个不等长有序数组的中位数
			- 这是更一般化的情况。假设数组 A 长度为 $m$，B 长度为 $n$。中位数是合并后第 $(m+n+1)/2$ 个元素。虽然不能再简单地比较两个数组的中位数，但分治和二分查找的思想依然适用。解法通常是在较短的数组上进行二分查找，确定一个分割点 `i`，同时在另一个数组中计算出对应的分割点 `j`，使得 `i+j` 等于目标排位，然后检查分割点是否满足中位数的定义（`A[i-1] <= B[j]` 且 `B[j-1] <= A[i]`）。时间复杂度为 $O(\log(\min(m, n)))$
		- 在两个有序数组中寻找第 k 小的元素 
			- 最通用的问题形式。上面的中位数问题都是它的特例。解法和不等长数组中位数问题类似，都是通过二分查找来寻找合适的分割点
		- 多个（k个）有序数组的 #中位数
			- 难度更大。一种常见解法是使用 #最小堆 （Min-Heap）。将每个数组的第一个元素放入一个大小为 $k$ 的最小堆中。然后，重复执行 $M$ 次（$M$为中位数的目标排位）：从堆顶取出最小元素，并将该元素所在数组的下一个元素放入堆中。第 $M$ 次取出的元素就是答案。另一种解法是二分答案的值，然后统计在所有数组中有多少个元素小于等于这个二分的值

![[2011-exam-paper-ocr.pdf#page=5&rect=72,578,536,823|2011-exam-paper-ocr, p.5]]
- 核心是考察在8位计算机体系结构下，C语言中`signed`和`unsigned`整型变量的存储、运算和溢出判断。关键前提是：**8位字长**，以及 #带符号整数 （`int`）使用 #补码 表示 
1. `unsigned int x = 134;` 
	*   `134`是无符号数。转换成8位二进制：
    *   $134 = 128 + 6 = 2^7 + 2^2 + 2^1$
    *   所以，`x`的机器数是 `1000 0110B`。
    *   这个值存放在寄存器 **R1** 中。
2. `unsigned int y = 246;`      
	*   `246`是无符号数。转换成8位二进制：
    *   $246 = 128 + 64 + 32 + 16 + 4 + 2 = 255 - 9$
    *   所以，`y`的机器数是 `1111 0110B`。
    *   这个值存放在寄存器 **R2** 中。
3. `int m = x;` 
    *   这是一个类型转换。`x`的位模式（bit pattern）`1000 0110B`被直接赋给`m`。
    *   但`m`是带符号整数`int`，所以我们需要按**补码**来解释这个位模式。
    *   `m`的机器数是 `1000 0110B`。
    *   这个值存放在寄存器 **R3** 中。
4. `int n = y;`  
    *   同理，`y`的位模式`1111 0110B`被赋给`n`。
    *   `n`的机器数是 `1111 0110B`。
    *   这个值存放在寄存器 **R4** 中。
- （1）执行上述程序段后，寄存器 R1、R5 和 R6 的内容分别是什么（用十六进制表示）？ 
1. R1 (对应 x): 
    *   `x`的机器数是 `1000 0110B`。
    *   转换为十六进制：`1000` 对应 `8`，`0110` 对应 `6`。
    *   所以，R1 的内容是 **`86H`**。
2. R5 (对应 z1 = x - y)
    *   这是**无符号数**减法。在计算机中，$x - y$ 通过计算 $x + (-y)$ 实现，对于无符号数，这相当于模 $2^8$ 运算。
    *   `x` 的机器数: `1000 0110B`
    *   `y` 的机器数: `1111 0110B`
    *   计算 `y` 的补码 `[-y]_补` (虽然是无符号运算，但硬件执行减法时就是这么做的)：
        *   `y` 按位取反: `0000 1001B`
        *   末位加1: `0000 1010B`
    *   执行加法：
      ```
        1000 0110  (x)
      + 0000 1010  (-y)
      -----------
        1001 0000
      ```
    *   `z1` 的结果是 `1001 0000B`。
    *   转换为十六进制：`1001` 对应 `9`，`0000` 对应 `0`。
    *   所以，R5 的内容是 **`90H`**。
3. R6 (对应 z2 = x + y) 
	*   这是**无符号数**加法。
      ```
          1000 0110  (x)
        + 1111 0110  (y)
        -----------
       (1)0111 1100
      ```
    *   最高位产生了进位 `(1)`，但由于 `z2` 是8位无符号整型，这个进位会丢失（或者说存入CPU的状态寄存器的进位标志CF）。寄存器中只保留低8位。
    *   `z2` 的结果是 `0111 1100B`。
    *   转换为十六进制：`0111` 对应 `7`，`1100` 对应 `C`。
    *   所以，R6 的内容是 **`7CH`**。
- （2）执行上述程序段后，变量 m 和 k1 的值分别是多少（用十进制表示）？ 
1. 变量 m 的值 
	*   `m` 的机器数（补码）是 `1000 0110B`。
    *   因为最高位是`1`，所以它是一个负数。求其真值需要“求补”操作（再次取反加一）：
        *   `1000 0110B` 按位取反: `0111 1001B`
        *   末位加一: `0111 1010B`
        *   转换成十进制: $64 + 32 + 16 + 2 = 122$。
    *   所以，`m` 的值是 **-122**
2. 变量 k1 的值 (k1 = m - n) 
	*   这是 #带符号数减法 。首先要求出 `n` 的十进制值。 
	    *   `n` 的机器数（补码）是 `1111 0110B`。
	    *   最高位是`1`，为负数。求其真值：
	        *   `1111 0110B` 按位取反: `0000 1001B`
	        *   末位加一: `0000 1010B`
	        *   转换成十进制: $8 + 2 = 10$。
	    *   所以，`n` 的值是 **-10**。
	    *   因此，$k1 = m - n = (-122) - (-10) = -122 + 10 = -112$。
	    *   **验证（计算机运算过程）**: $k1 = m - n$ 运算为 $[m]_补 + [-n]_补$。
	        *   $[m]_补 = 1000\ 0110B$
	        *   $[n]_补 = 1111\ 0110B$
	        *   $[-n]_补$ (对 $[n]_补$ 求补码): `0000 1010B`
	        *   相加:
	          ```
	            1000 0110  ([m]_补)
	          + 0000 1010  ([-n]_补)
	          -----------
	            1001 0000
	          ```
	        *   结果 `1001 0000B` 是 `-112` 的补码吗？我们来验证一下。`-112` 的绝对值是 `112 = 64+32+16 = 0111 0000B`。对其求补：取反 `1000 1111`，加一 `1001 0000`。完全正确。
	    *   所以，`k1` 的值是 **-112**。
- （3）上述程序段涉及带符号整数加/减、无符号整数加/减运算，这四种运算能否利用同一个加法器辅助电路实现？简述理由
1. 能 #补码  [[补码]] 体系 [[补码减法]] 
	1. 加法统一
		1. 对于加法 $a+b$，无论是无符号数还是带符号数（补码表示），其二进制加法规则是完全一样的。硬件加法器不需要区分操作数的类型
	2. 减法变加法 
		1. 对于减法 $a-b$，计算机通过计算 $a + (-b)$ 来实现。一个数的相反数的补码可以通过**对其原补码按位取反再末位加一**得到。即 $[a-b]_补 = [a]_补 + [-b]_补 \pmod{2^n}$
	3. 因此，只需要一个加法器，再配上一个求补（取反加一）的辅助电路，就可以实现带符号和无符号数的加减法。处理器根据指令（如`ADD` vs `SUB`, `JO` vs `JC`）来决定如何解释运算结果的标志位（如溢出标志和进位标志）
- （4） 计算机内部如何判断带符号整数加/减运算的结果是否发生溢出？上述程序段中，哪些带符号整数语句的执行结果会发生溢出？
1.  有两种等价的方法来判断带符号数（补码）运算的溢出 [[补码加法溢出判断]]
	1. 双符号位法（变形补码） 
		1. 用两个符号位表示数字，如`00`表示正，`11`表示负。如果运算结果的两个符号位不同（`01`或`10`），则表示发生溢出。`01`为上溢（正溢），`10`为下溢（负溢）
	2. 单符号位法（常用）
		1. 方法一（操作数与结果符号比较） 
			1. 当且仅当两个**同符号**的数相加，得到的结果**符号相反**时，发生溢出。两个异号数相加永远不会溢出 
		2. 方法二（进位比较）
			1. 设符号位（最高位）的进位为 $C_{in}$，而来自符号位的更高位的进位（即加法器的总进位/借位）为 $C_{out}$。当且仅当 $C_{in} \neq C_{out}$ (即 $C_{in} \oplus C_{out} = 1$) 时，发生溢出。CPU中的溢出标志位(OF)就是根据这个逻辑设置的 
2. 程序段中的溢出分析
	1. `k1 = m - n`：等价于 `m + (-n)`，即 `(-122) + (10)`。一个负数和一个正数相加，结果一定在两者之间，**永远不会溢出**。8位有符号数的表示范围是 $[-128, 127]$，`-112` 在此范围内 
	2.   `k2 = m + n`：这是一个带符号加法。
        *   $m = -122$ (负数)
        *   $n = -10$ (负数)
        *   理论结果：$(-122) + (-10) = -132$。
        *   这个结果超出了8位有符号数的最小范围 `-128`，因此**必然发生溢出**（下溢）
    3. 用硬件规则验证 `k2 = m + n` 的溢出
    运算为：$[m]_补 + [n]_补$
          ```
            Carry:    0  0  0  0  1  1  1  0  <- 进位到当前位
            m:         1  0  0  0  0  1  1  0
            n:       + 1  1  1  1  0  1  1  0
            ----------------------------------
            Result:    0  1  1  1  1  1  0  0
          ```
	4. 分析符号位（最高位，即bit 7）的进位
		*   从第6位（次高位）进到符号位的进位 $C_{in}$ 是 `0`。
            *   由符号位产生的总进位 $C_{out}$ 是 `1` (因为 $1+1+0 = 10_B$)。
            *   由于 $C_{in} (0) \neq C_{out} (1)$，所以**发生溢出**。
        *   **用符号比较法验证**：两个负数（符号位为`1`）相加，结果 `0111 1100B` 的符号位为`0`（正数）。负数+负数=正数，不合逻辑，所以**发生溢出**
 **结论：** `int k2 = m + n;` 这一句的执行结果会发生溢出 
 [[Pasted image 20250819180837.png]]
- 衍生
	- [[无符号数与有符号数的比较指令]]
	- C语言中的类型转换和提升 
		- `int m = x;` 演示了从`unsigned`到`int`的转换，这只是位模式的重新解释，可能导致数值巨大变化（如134变为-122）。
	    *   如果一个表达式中同时有`signed`和`unsigned`，C语言通常会将`signed`类型**提升**为`unsigned`类型再进行运算，这可能导致非预期的结果，是一个常见的编程陷阱和考点。
	- 不同位宽 
		- 题目可能会将8位改为16位或32位，解题思路完全相同，只是数值范围和二进制位数变化了 
	- 其他编码 
		- [[原码，反码的运算和溢出判断]]  #原码 #反码
			- 需要掌握它们的规则。例如，原码的加减法非常繁琐，反码存在 `+0` 和 `-0` 两种表示


![[2011-exam-paper-ocr.pdf#page=5&rect=64,172,548,580|2011-exam-paper-ocr, p.5]]

1.   #虚拟内存  [[分段与分页]] #分页存储   [[虚拟内存]]  [[快表TLB]]  [[高速缓存Cache]]
	1.  [[虚拟地址到物理地址的转换]] 
		1. ![[Pasted image 20250919065012.png]]
- (1) 虚拟地址和物理地址的位数，虚页号和页框号的位数？
1. 地址空间的位数由其总大小决定。地址位数 $n$ 和地址空间大小 $S$ 的关系是 $S=2^n$。页号/页框号的位数由总地址位数减去页内偏移地址的位数得到 [[计算所有位数]]
	1. #虚拟地址的位数  [[特殊地址计算（网络地址，广播地址）]]
	    *   逻辑地址空间大小 = 16MB
	    *   $16\text{MB} = 16 \times 2^{20}\text{B} = 2^4 \times 2^{20}\text{B} = 2^{24}\text{B}$
	    *   所以，虚拟地址需要 $24$ 位。
	2. #计算物理地址位数  [[计算物理地址位数]]
	    *   物理地址空间大小 (主存大小) = 1MB
	    *   $1\text{MB} = 2^{20}\text{B}$
	    *   所以，物理地址需要 $20$ 位。
	3. #页内偏移的位数  
	    *   页面大小 = 4KB
	    *   $4\text{KB} = 4 \times 2^{10}\text{B} = 2^2 \times 2^{10}\text{B} = 2^{12}\text{B}$
	    *   所以，页内偏移地址需要 $12$ 位。这个位数对于虚拟地址和物理地址是相同的（页和页框大小一致）。
	4. #虚拟页号的位数VPN [[计算物理地址位数]] 
		*   位数 = 虚拟地址总位数 - 页内偏移位数
	    *   位数 = $24 - 12 = 12$ 位。
	    *   虚拟地址结构：`| 虚页号 (12位) | 页内偏移 (12位) |`
	5. #页框号位数 
	    *   位数 = 物理地址总位数 - 页内偏移位数
	    *   位数 = $20 - 12 = 8$ 位。
	    *   物理地址结构：`| 页框号 (8位) | 页内偏移 (12位) |`
- (2) 物理地址如何划分为 Cache 字段？[[计算物理地址位数]]  [[物理地址]] 
	- 物理地址用于访问 Cache。对于 **直接映射 (Direct Mapped)** Cache，物理地址被划分为三个部分：**标记 (Tag)**、**索引 (Index)** 和 **块内偏移 (Offset)**
	1.    #块内偏移 
		*   Cache 块大小 = 32B
	    *   $32\text{B} = 2^5\text{B}$
	    *   所以，块内偏移需要 $5$ 位。
	2.   #索引
		*   Cache 总行数 = 8 行
	    *   $8 = 2^3$
	    *   所以，索引需要 $3$ 位，可以表示从 0 (000) 到 7 (111) 的行号。
	3. #标记 
	    *   位数 = 物理地址总位数 - 索引位数 - 块内偏移位数
	    *   位数 = $20 - 3 - 5 = 12$ 位。
		一个 20 位的物理地址被划分为：
		`| 标记 (12位) | 索引 (3位) | 块内偏移 (5位) |`
- (3) 虚拟地址 001C60H 是否在主存中？是否在 Cache 中？ [[地址访问流程]] 
1. 步骤一：虚拟地址到物理地址的转换 
	1. 分解虚拟地址 
		*   虚拟地址 VA = 001C60H (十六进制)
	    *   根据 (1) 的结论，高 12 位是 #虚页号 (VPN)，低 12 位是 #页内偏移 。
	    *   $001\text{C}60\text{H} = \underbrace{001}_{\text{VPN}} \underbrace{\text{C}60}_{\text{Offset}}$ (十六进制)
	    *   所以，VPN = 001H，Offset = C60H。
	2. 查询页表 (图 44-a)
		*   页表是根据 #虚拟页号的位数VPN  来索引的。我们要查找虚页号为 1 的条目。
	    *   在图 44-a 中，行号为 1 的条目：有效位 = 1，页框号 = 04H。
	    *   **有效位 = 1** 表示该页在主存中。**所以，虚拟地址 001C60H 所在的页面在主存中。** 
	3. 构建物理地址 (PA) 
	    *   物理地址 = 页框号 (PFN) + 页内偏移 (Offset)
	    *   PFN = 04H (来自页表)
	    *   Offset = C60H (来自虚拟地址)
	    *   将它们拼接起来：PA = 04C60H。
2. 步骤二：使用物理地址查询 Cache 
	1. 分解物理地址
	    *   物理地址 PA = 04C60H (20位)
	    *   PA (二进制) = `0000 0100 1100 0110 0000`
	    *   根据 (2) 的结论，将其划分为标记、索引和偏移：
	    *   $\underbrace{0000 \, 0100 \, 1100}_{\text{Tag, 12位}} \underbrace{011}_{\text{Index, 3位}} \underbrace{00000}_{\text{Offset, 5位}}$ 
	    *   **Tag** = `0000 0100 1100`B = 04CH
	    *   **Index** = `011`B = 3
	    *   **Offset** = `00000`B = 0
	2. 查询 Cache (图 44-b) 
	    *   使用 Index = 3 去访问 Cache 的第 3 行。
	    *   在图 44-b 中，行号为 3 的条目：有效位 = 1，标记 = 105H。
	    *   **检查有效位**：有效位为 1，说明该 Cache 行中有有效数据。
	    *   **比较标记**：
	        *   从物理地址中计算出的 Tag = 04CH
	        *   Cache 行中存储的 Tag = 105H
	        *   $04\text{CH} \neq 105\text{H}$
	    *   标记不匹配，这意味着虽然 Cache 第 3 行有数据，但它不是我们想要的物理地址 `04C60H` 所在的数据块。
3. 结论
	1. Cache 不命中 . 虚拟地址 `001C60H` 所在的页面在主存中，但对应的数据块不在 Cache 中 
- (4) 虚拟地址 024BACH 是否在主存中？（使用 TLB 判断） 
1. 需要使用 TLB 来加速判断。TLB 是 #组相联   [[地址映射方式]]  [[快表TLB]]
	1. 所以需要将虚页号 (VPN) 分解为 **TLB 标记 (TLB Tag)** 和 **TLB 组号 (TLB Index/Set)
2. 步骤一：分析 TLB 结构 
	1. 计算组数
	    *   总条目数 = 8
	    *   相联度 (路数) = 4 路 (4-way)
	    *   组数 = 总条目数 / 相联度 = $8 / 4 = 2$ 组。
	2. 计算 TLB 组号位数
	    *   $2 \text{ 组} = 2^1 \text{ 组}$
	    *   所以，TLB 组号需要 $1$ 位。
	3. 计算 TLB 标记位数 
	    *   TLB 的查询使用虚页号 (VPN)，VPN 共有 12 位。
	    *   TLB 标记位数 = VPN 总位数 - TLB 组号位数
	    *   TLB 标记位数 = $12 - 1 = 11$ 位。
	4. #虚拟页号的位数VPN划分 [[VPN划分]] 
		1.   12 位的 VPN 被划分为：`| TLB 标记 (11位) | TLB 组号 (1位) |` 
3. 步骤二：使用虚拟地址查询 TLB
	1. 分解虚拟地址 
	    *   虚拟地址 VA = 024BACH
	    *   VPN = 024H，Offset = BACH。
	2. 分解 VPN 
	    *   VPN = 024H (12位)
	    *   VPN (二进制) = `0000 0010 0100`
	    *   根据上面的划分：
	    *   $\underbrace{0000 0010 010}_{\text{TLB Tag, 11位}} \underbrace{0}_{\text{TLB Set, 1位}}$
	    *   **TLB Tag** = `0000 0010 010`B = 012H
	    *   **TLB Set Index** = `0`B = 组 0
	3. 查询 TLB (图 44-c) 
	    *   我们要在 TLB 的 **组 0** 中查找标记为 **012H** 的条目。
	    *   图 44-c 显示了 TLB 的内容。组 0 包含前 4 个条目，组 1 包含后 4 个条目（尽管表中只显示了部分）。
	    *   我们检查组 0 的所有条目：
	        *   第一个条目（组0，路0）：有效位=1，标记=001H。不匹配。
	        *   第二个条目（组0，路1）：有效位=0。无效条目，跳过。
	        *   第三个条目（组0，路2）：**有效位=1，标记=012H**。**匹配！**
	    *   我们找到了一个有效且标记匹配的条目。
结论：TLB 命中 (TLB Hit) 
	TLB 命中意味着该虚拟页到物理页框的映射关系存在于 TLB 中，这直接证明了该页面一定在主存中

[[Pasted image 20250819180852.png]]
衍生
- [[访存时间计算]]  #访存时间计算 
- 不同的 Cache/TLB 组织方式 
	- 全相联 ：地址没有索引位，只有标记和偏移。查询时需要并行比较所有行的标记 
	- 组相联  ：本题的 TLB 就是例子。地址有标记、组索引和偏移。查询时先定位到组，再并行比较组内所有行的标记 
- [[页面置换算法]]  [[写策略]] 

![[2011-exam-paper-ocr.pdf#page=6&rect=74,507,531,821|2011-exam-paper-ocr, p.6]]
- 本质上是一个有界的“**生产者-消费者**”问题变种 
	1. 生产者 
		1. 顾客。他们来到银行，“生产”出一个服务请求（通过取号）
	2. 消费者
		1. 营业员。他们“消费”这个服务请求（通过叫号并提供服务）
	3. 缓冲区 
		1. 10个等待座位。这是存放“服务请求”的有限空间
- 需要解决两个核心问题 
1.  #互斥  
	1. 确保共享资源在同一时刻只能被一个进程访问。这里的共享资源是**取号机**。 
2. #同步 协调不同进程的执行顺序，以确保它们在正确的时机执行。这里涉及多个同步关系：
    *   银行座位满了（缓冲区满了），顾客就不能再进入（生产者需要等待）。
    *   没有顾客在等待（缓冲区为空），营业员就需要休息等待（消费者需要等待）。
    *   顾客取完号后，需要等待营业员叫号才能接受服务。
基于以上分析，我们可以推导出需要哪些信号量以及它们的初始值 
-  信号量的设计与推导
1. #互斥信号量 `mutex`  
	1. 作用分析
		1. 题目中提到“取号机”，这是一个物理设备。在任何时刻，只允许一位顾客使用它来获取号码。如果两个顾客同时操作，可能会导致号码重复或者系统错乱。因此，对取号机的访问必须是互斥的
	2. #信号量定义 我们定义一个 #二元信号量（互斥锁，Mutex） `mutex`（mutual exclusion的缩写）来实现互斥 
	3. 初始值设定 
		1. 初始状态下，取号机是空闲的，任何顾客都可以使用。因此，其初始值应为 $1$。
		2. `semaphore mutex = 1;` // 值为1代表资源可用，值为0代表资源被占用 
2. 资源信号量 `empty` 
	1. 作用分析
		1. 题目中明确有“10个供顾客等待的座位”。这代表了系统中的“空闲资源”数量。每当一个顾客进来并决定等待时，他就占用一个座位，空座位数量减一。当座位全部被占用时，后来的顾客就无法进入等待区 
	2. 信号量定义
		1. 我们定义一个计数信号量`empty`来表示空座位的数量 
	3. 初始值设定 
		1. 银行刚开门时，所有10个座位都是空的。因此，其初始值应为 $10$
		2.  `semaphore empty = 10;` // 其值代表当前空座位的数量。
3. 资源信号量 `full`
	1. 作用分析
		1. 与`empty`相对应，我们需要一个信号量来记录当前有多少个座位**已被占用**，也就是有多少顾客正在等待服务。这个信息对营业员至关重要，因为如果没有顾客在等待（即被占用的座位数为0），营业员就应该休息
	2. 信号量定义 
		1. 我们定义一个计数信号量`full`来表示已占用的座位数量，或者说等待服务的顾客数
	3. 初始值设定 
		1. 银行刚开门时，没有顾客在等待。因此，其初始值应为 $0$。
	    2. `semaphore full = 0;` // 其值代表正在等待的顾客数
> **注**：`empty` 和 `full` 是一对典型的用于描述缓冲区状态的信号量，在任何时刻，它们的值都满足关系 $empty + full = 10$(缓冲区总容量)。
4. 同步信号量 `service` 
	1. 作用分析 
		1. 这是一个纯粹用于同步的信号量。顾客取完号后，并不能立即获得服务，他必须**等待**营业员的**呼叫**。同样，营业员叫号后，必须确保有一个顾客来接受服务。这个“呼叫-响应”的过程需要一个信号量来协调
	2. 信号量定义
		1. 我们定义信号量`service`来表示“可以开始服务”的信号
	3. 初始值设定
		1. 初始状态下，营业员没有呼叫任何顾客，没有服务正在准备开始。因此，其初始值应为 $0$。
	    *   当营业员准备好服务一位新顾客时，他会执行`V(service)`，通知顾客可以过来了。
	    *   当顾客取完号后，会执行`P(service)`，在此等待营业员的通知。
	    *   `semaphore service = 0;`
- 流程逻辑与代码实现
1. 顾客进程 `process 顾客 i` 
	1. `P(empty);`
		1.  **含义**：顾客到达银行，首先要找一个空座位。这个操作会检查`empty`的值。如果`$empty > 0$`，则将其减1并继续，表示成功占据一个座位。如果`$empty = 0$`，表示座位已满，顾客进程将在此阻塞（等待），直到有座位空出来
	2. `P(mutex);` 
		1. **含义**：顾客找到了座位后，走向取号机。此操作申请使用取号机。如果`$mutex = 1$`，则将其置为0并继续，表示成功获得取号机的使用权。如果`$mutex = 0$`，表示其他顾客正在使用，则阻塞等待。
	3.  `从取号机上取号;`
	    *   **含义**：这是临界区（Critical Section），执行取号操作。
	4.  `V(mutex);`
	    *   **含义**：顾客取号完毕，释放取号机，让其他等待的顾客可以使用。此操作将`mutex`的值加1（恢复为1）。
	5.  `V(full);`
	    *   **含义**：顾客取完号，成为一名等待服务的顾客。此操作将`full`的值加1，通知营业员“多了一位等待的顾客”。
	6.  `P(service);`
	    *   **含义**：顾客在座位上等待营业员叫号。此操作检查`service`的值。因为初始值为0，顾客进程会在此阻塞，直到营业员执行`V(service)`来唤醒他。
	7.  `接受服务;`
	    *   **含义**：被唤醒后，顾客离开座位，到窗口接受服务。
2.  营业员进程 `process 营业员`
	1.  `while (True)`
	    *   **含义**：营业员的工作是循环不断的。
	2.  `P(full);`
	    *   **含义**：营业员准备叫号。此操作检查是否有顾客在等待。如果`$full > 0$`，则将其减1并继续，表示将要为一位顾客服务。如果`$full = 0$`，表示没有顾客等待，营业员进程在此阻塞（休息），直到有顾客取号后执行`V(full)`来唤醒他。
	3.  `V(empty);`
	    *   **含义**：营业员叫到了一位顾客（`P(full)`成功了），这位顾客会从等待区座位上站起来走向窗口，因此他的座位就空出来了。此操作将`empty`的值加1，表示释放了一个空座位，让外面可能在等待的顾客可以进来。
	4.  `V(service);`
	    *   **含义**：营业员正式叫号。此操作将`service`的值加1，唤醒一个因`P(service)`而阻塞的顾客进程，通知他前来接受服务。
	5.  `为顾客服务;`
	    *   **含义**：执行服务操作。
[[Pasted image 20250819180912.png]]
衍生
- #经典同步问题模型 #管理并发进程对共享资源访问的经典同步机制  
    *   **生产者-消费者问题**：这是最直接的考点。可能会改变缓冲区大小，生产者/消费者数量，考察对`empty`, `full`, `mutex`的理解。
    *   **读者-写者问题**：允许多个“读者”同时访问资源，但“写者”必须互斥访问。考察如何实现“读优先”或“写优先”的策略。
    *   **哲学家就餐问题**：考察如何设计一个无死锁、无饥饿的资源分配算法。这是死锁问题的经典模型。
- [[1.死锁 (Deadlock)]] 
	- [[饥饿]]
	- [[信号量]] [[信号量与管程的对比]] 
![[2011-exam-paper-ocr.pdf#page=6&rect=72,421,525,511|2011-exam-paper-ocr, p.6]]
[[存储结构]]  #目录结构 [[目录结构]] 
- 在连续、链式、索引三种文件的数据块组织方式中，哪种更合适？要求说明理由。为定位文件数据块，需要 FCB 中设计哪些相关描述字段？
1. 分析三种物理结构 
	1. 需要评估这三种结构在题目给定场景下的优缺点
	2. #连续分配 
	    *   **优点:**
	        *   **支持高效的随机访问和顺序访问。** 因为所有数据块在物理上是连续的，所以只要知道起始块号和要访问的块的偏移量，就可以通过一次磁盘寻道直接定位到目标数据块。访问速度非常快。
	        *   **结构简单。** 只需要记录起始块号和文件长度（块数）即可。
	    *   **缺点:**
	        *   **文件大小难以动态增长。** 如果文件需要扩展，而其后的空间已被占用，就需要移动整个文件，开销巨大。
	        *   **会产生外部碎片 (External Fragmentation)。** 磁盘上可能会出现很多不连续的小空闲区，虽然总的空闲空间足够，但无法分配给一个需要较大连续空间的新文件。
	3. #链式分配 
	      *     **优点:**
	        *   **没有外部碎片。** 只要有空闲的物理块，就可以分配给文件。
	        *   **文件可以方便地动态增长。** 只需在链表末尾追加新的物理块即可。
	    *   **缺点:**
	        *   **不支持随机访问。** 要访问文件中的第`i`个块，必须从头开始，沿着指针链顺序访问前`i-1`个块，效率极低。
	        *   **可靠性差。** 指针的丢失或损坏会导致后续所有数据块丢失。
	        *   **指针占用额外的存储空间。**
	4. #索引分配 
	    *   **优点:**
	        *   **支持随机访问。** 要访问第`i`个块，只需先读入索引块，然后直接从索引表中找到第`i`个块的地址即可。
	        *   **没有外部碎片。**
	        *   **文件可以方便地动态增长。** （通过多级索引等方式）
	    *   **缺点:**
	        *   **索引块本身需要占用存储空间。** 对于非常小的文件，这个开销可能不划算。
	        *   **访问文件至少需要两次I/O操作：** 一次读取索引块，一次读取数据块。
2. 结合题目条件进行选择
	1.   **"文件数据一次性写入"** 和 **"文件不可修改"** 这两个条件意味着：
	    1.  文件大小从创建开始就固定了，不存在动态增长的需求。
	    2.  我们可以在创建文件时就知道它需要多大的连续空间。
	*   **分析结论：**
	    *   连续分配的最大缺点——“文件难以动态增长”——在这个场景下完全不成问题。
	    *   链式分配的最大缺点——“不支持随机访问”——是一个严重的性能瓶颈，而它的优点“支持动态增长”却毫无用武之地。
	    *   索引分配虽然支持随机访问，但比连续分配更复杂，并且至少需要两次磁盘I/O。在连续分配可用的情况下，其访问速度不如连续分配。                            
因此，**连续分配**是最佳选择。它充分利用了“一次写入、不可修改”的特性，规避了自身的核心缺点，同时发挥了其访问速度最快的核心优势。
3. [[文件控制块FCB]] 字段设计 
	1. 对于连续分配的文件，为了定位它的所有数据块，我们只需要知道它的**起点**和**长度**。因此，在FCB中需要包含以下信息：
		*   **起始块号 (Starting block number):** 文件第一个数据块在磁盘上的物理地址。
		*   **文件长度 (Length):** 文件占用的总块数
	* 所以，描述字段可以是 $<$起始块号, 块数$>$。或者，也可以用起始块号和结束块号来表示：$<$起始块号, 结束块号$>$。这两种方式是等价的，因为 `结束块号 = 起始块号 + 块数 - 1`。
 - (2)为快速找到文件，对于 FCB，是集中存储好，还是与对应的文件数据块连续存储好？要求说明理由 
1. 分析两种 #FCB存储方式 
	1. 集中存储
		1. 描述 
			1.  所有的FCB（在一级目录结构下，它们共同构成了目录文件）都存放在磁盘的特定区域，例如，存放在几个连续的物理块中
		2. 工作流程
			1. 当需要按文件名查找文件时，系统首先定位到存放FCB的目录区，将这部分目录信息读入内存。然后，在内存中快速遍历，查找匹配的文件名。找到对应的FCB后，再根据FCB中的物理地址信息去访问文件数据
		3. 优点
			1. 查找文件（即遍历目录）时，磁盘I/O操作非常少。可能只需要一次或几次连续的I/O就可以把整个目录加载到内存中。这使得目录搜索操作非常快
		4. 缺点
			1. 找到FCB后，访问数据块通常需要一次额外的磁盘寻道操作，因为数据块和FCB（目录区）在物理上是分开的
	2. 与数据块连续存储
		1. 描述
			1. 每个文件的FCB紧邻着该文件的数据块存放
		2. 工作流程
			1. 由于FCB和数据块在物理上是分散的，目录本身没有一个集中的物理实体。为了按名查找文件，系统必须在磁盘上逐个扫描，找到一个FCB，检查其文件名是否匹配，如果不匹配，就跳到下一个可能存放FCB的地方。这是一个非常低效的过程
		3. 优点
			1. 一旦找到了正确的FCB，数据就在旁边，不需要额外的磁盘寻道
		4. 缺点
			1. 查找过程极度缓慢。因为FCB散布在整个磁盘上，为了找到一个特定的文件，最坏情况下可能需要扫描大量不相关的磁盘块，导致大量的随机I/O和磁头移动
	3. 题目的目标是 **“为快速找到文件”** 
		1. **集中存储FCB**是更好的选择。 
[[Pasted image 20250819181016.png]]
衍生
- [[文件物理结构]]  [[磁盘存储时间的计算]]
- 不同场景下的最优选择
	- 如果题目改为“文件需要频繁地动态增长和删减”，那么链式或索引分配会更合适。
    *   如果题目是一个典型的通用操作系统，那么索引分配（例如Linux的i-node）是最佳选择，因为它在各方面表现均衡
- [[磁盘空闲空间管理]] 如何管理磁盘的空闲块？（空闲块表、空闲链表、位示图/Bitmap）
*   连续分配适合使用哪种空闲空间管理方法？（位示图或空闲块表，因为需要快速找到足够大的连续空间）
- [[索引分配的变种]]  #目录的实现方式  [[文件系统的可靠性]]

![[2011-exam-paper-ocr.pdf#page=6&rect=66,30,542,425|2011-exam-paper-ocr, p.6]]
- 这道题 围绕一个主机发起 Web 请求所产生的一个以太网 #数据帧 ，考察了从 #数据链路层 到  #应用层 的多个核心网络概念 

- (1) Web 服务器的 IP 地址是什么？该主机的默认网关的 MAC 地址是什么？ 
1. 解析图 47-b 中的十六进制数据。一个以太网帧的结构通常是：
	1. 目的 MAC 地址 (6字节)  源 MAC 地址 (6字节) 类型 (2字节)数据 (IP数据报)。 
		1. [[以太网帧结构]]  [[HDLC帧结构与以太网帧结构]]
2. 解析以太网帧头
	1. #目的MAC地址   帧的前 6 个字节是 `00 21 27 51 ee 00`
	2. #源MAC地址  接下来 6 个字节是 `00 15 c5 c1 5e 28`。这与题目给出的主机 MAC 地址 `00-15-C5-C1-5E-28` 一致
	3. 类型字段 
		1. 再接下来 2 个字节是 `08 00`。类型 `$0x0800$` 表示这个以太网帧承载的数据是一个 IPv4 数据报
3. 解析 #IP数据报头部   [[IP头部详解]]
	1. IP 数据报 紧跟在  #以太网帧头 之后。一个 IP 头部通常为 20 字节（无选项字段时）。
	    *   IP 头部从字节 `45 00 ...` 开始。
	    *   IP 头部中，第 13 到 16 字节是 **源 IP 地址**。
	    *   IP 头部中，第 17 到 20 字节是 **目的 IP 地址**。
	2. 定位这些字节在整个 #数据帧 中的位置
	  以太网头部共 $6+6+2 = 14$ 字节。
    *   源 IP 地址在 IP 头部的第 13 字节开始，也就是整个数据帧的第 $14+12=26$ 字节开始（注意，字节编号从0开始，所以是第12个字节之后）。在图 47-b 中，这 4 个字节是 `0a 02 80 64`。
        *   十六进制转十进制：`0a` -> $10$ , `02` -> $2$ , `80` -> $128$ , `64` -> $100$。
        *   所以源 IP 地址是 `10.2.128.100`，与题目给出的主机 IP 一致。
    *   目的 IP 地址在 IP 头部的第 17 字节开始，也就是整个数据帧的第 $14+16=30$ 字节开始。在图 47-b 中，这 4 个字节是 `40 aa 62 20`。
        *   十六进制转十进制：`40` -> $64$ , `aa` -> $170$ , `62` -> $98$ , `20` -> $32$。
        *   **所以 Web 服务器的 IP 地址是 `64.170.98.32
4. 确定默认网关的 MAC 地址
	*   主机 `10.2.128.100` 要访问公网上的服务器 `64.170.98.32`。这两个 IP 地址不在同一个子网中。
    *   因此，主机必须将数据包发送给它的 #默认网关 （路由器 R 的接口 `10.2.128.1`），由网关来负责转发。
    *   在数据链路层，这一跳（从主机到网关）的目标就是网关。所以，以太网帧的 **目的 MAC 地址** 必须是 #默认网关的MAC地址  
    *   从步骤 1 我们已经知道，帧的 #目的MAC地址 是 `00-21-27-51-EE-00`。
    *   **所以默认网关的 MAC 地址是 `00-21-27-51-EE-00`。**
- (2)该主机在构造 47-b 的数据帧时，使用什么协议确定目的 MAC 地址？封装该协议请求报文的以太网帧的目的 MAC 地址是什么？
1. 这个问题考察的是 [[IP 地址到 MAC 地址的映射过程]]
 - (3) 假设 HTTP/1.1 以持续的非流水线方式工作，一次请求-响应时间为 RTT，页面 `rfc.html` 引用了 5 个 JPEG 小图像。从发出 Web 请求开始到浏览器收到全部内容为止，需要多少个 RTT？
	- 问题考察对 HTTP 协议工作模式的理解 [[HTTP 协议版本演进]]
		1. #HTTP持续连接  HTTP/1.1 持续连接   
			 指的是 TCP 连接在一次请求-响应后不会立即关闭，可以被后续的请求重用。这避免了为每个资源都重新建立 TCP 连接（三次握手）的开销
		2. #HTTP非流水线方式 这是关键。它意味着客户端必须在一个请求完全收到响应之后，才能在同一个连接上发送下一个请求。请求是串行执行的 
		3. RTT 
- 计算过程
1. 获取 HTML 页面
	1. 浏览器首先要请求基础的 `rfc.html` 页面。这需要 **1 个 RTT**
2. 获取引用的图像
	1. 浏览器收到 `rfc.html` 并解析后，发现里面有 5 个 JPEG 图像的引用。由于是非流水线方式，浏览器必须一个一个地请求这些图像。
    *   请求第 1 个图像，需要 **1 个 RTT**。
    *   请求第 2 个图像，需要 **1 个 RTT**。
    *   ...
    *   请求第 5 个图像，需要 **1 个 RTT**。
    获取 5 个图像总共需要 **5 个 RTT**。
3. 总时间
	1. 将获取 HTML 和获取所有图像的时间相加。
    总 RTT = (获取 HTML 的 RTT) + (获取 5 个图像的 RTT) = $1 + 5 = 6$ 个 RTT。
    所以，总共需要 6 个 RTT。

- (4)该帧所封装的 IP 分组经过路由器 R 转发时，需修改 IP 分组头中的哪些字段？ 
	- 这个问题考察路由器转发 IP 数据包时的基本操作，特别是涉及 #NAT 
1. #生存时间 
	*   IP 协议的设计是为了防止数据包在网络中无限循环。每个路由器在转发 IP 数据包时，都必须将其 TTL 字段的值减 1。
    *   如果 TTL 减为 0，路由器会丢弃该包，并可能向源主机发送一个 ICMP 超时消息。
    *   所以 **TTL 字段** 必须修改。
2. 源 IP 地址
    *   主机 `10.2.128.100` 使用的是私有 IP 地址，这种地址不能在公共互联网上路由。
    *   路由器 R 连接了私有网络和公共网络，它扮演了 NAT 网关的角色。
    *   当数据包从私有网络发往公共网络时，路由器 R 必须将数据包的 **源 IP 地址** 从私有地址 `10.2.128.100` (`0a 02 80 64`) 替换为它自己的公共 IP 地址 `101.12.123.15` (`65 0c 7b 0f`)。这个过程称为源地址转换 (SNAT)。
3. 首部校验和
    *   IP 头部包含一个校验和字段，用于检验头部在传输过程中是否出错。
    *   由于 TTL 和源 IP 地址字段都被修改了，这意味着 IP 头部的内容发生了变化。
	*   因此，路由器必须 **重新计算整个 IP 头部的校验和**，并用新的值更新首部校验和字段。
**总结：** 路由器 R 至少需要修改以下三个字段：
*   **源 IP 地址** (因为 NAT)
*   **生存时间 (TTL)** (标准转发流程)
*   **首部校验和** (因为头部内容已改变)
[[Pasted image 20250819181026.png]]
 - [[NAT (网络地址转换) 详解]]
 - [[TCP-IP 协议栈封装与解封装]] 
 - [[IP头部详解]]