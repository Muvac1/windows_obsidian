![[2015-exam-paper-ocr.pdf#page=1&rect=80,598,541,704|2015-exam-paper-ocr, p.1]]
[[截屏2025-09-30 上午3.38.47.png]]
	A [[栈]]  #函数调用栈 
	在递归调用最深的时候（第3步），调用栈从底到顶的顺序是 `main()`，然后是 `S(1)`，最后是 `S(0)`。
 - 衍生
	 -  #栈溢出   [[栈溢出]] 
		 - 问：如果调用 `S(1000000)` 会发生什么？ 答：很可能发生栈溢出。
		    *   问：如何修改一个无限递归的函数（ #缺少基准情况 ）来避免错误？ 答：添加一个能最终被满足的基准情况。
	* 递归的时间与空间复杂度分析 [[递归的时间与空间复杂度分析]] 
	* #尾递归优化 
		* 如果一个函数中的递归调用是整个函数最后执行的操作，那么这个递归就称为**尾递归**。
		*   **题目中的函数是尾递归吗？**
		    *   不是。在 `return S(n-1) + n;` 中，递归调用 `S(n-1)` 之后，还必须执行 `+ n` 这个操作。所以它不是尾递归。
		[[尾递归]] **题目中的函数是尾递归吗？**
	    *   不是。在 `return S(n-1) + n;` 中，递归调用 `S(n-1)` 之后，还必须执行 `+ n` 这个操作。所以它不是尾递归。 
![[2015-exam-paper-ocr.pdf#page=1&rect=78,561,453,599|2015-exam-paper-ocr, p.1]]
[[截屏2025-09-30 上午3.38.55.png]]
[[二叉树的性质]]
#先序序列 
1. [[遍历与栈操作的等价性]]
	1. 因此，原问题 “先序序列为 `a, b, c, d` 的不同二叉树有多少个？” 就等价于 “一个栈的入栈顺序为 `a, b, c, d`，那么所有可能的、合法的出栈序列有多少个？”
2. #卡特兰数  
	- #组合计数
		- 询问 $n$ 个 #不同结点可以构成多少种不同的二叉树形态 。答案是 #卡特兰数   
			- $C_n = \frac{1}{n+1}\binom{2n}{n} = \frac{(2n)!}{(n+1)!n!}$  [[组合]] 
			- 
	 **计算过程**：
	    在本题中，序列 `a, b, c, d` 含有 4 个元素，所以 $n=4$。我们将 $n=4$ 代入卡特兰数公式：
	    $C_4 = \frac{1}{4+1}C_{2 \times 4}^{4} = \frac{1}{5}C_{8}^{4}$
	    我们先计算组合数 $C_{8}^{4}$：
	    $C_{8}^{4} = \frac{8!}{4!(8-4)!} = \frac{8!}{4!4!} = \frac{8 \times 7 \times 6 \times 5}{4 \times 3 \times 2 \times 1} = \frac{1680}{24} = 70$
	    然后代入原式：
	    $C_4 = \frac{1}{5} \times 70 = 14$	
	    所以，共有 14 种不同的出栈序列，也就对应着 14 棵不同的二叉树
- [[卡特兰数常见的应用场景]]  
- #根据遍历序列重建二叉树 
	- 这是非常高频的面试题。通常会给出先序和中序序列，或者后序和中序序列，要求你构建出这棵二叉树。
	    *   **先序+中序**：先序序列的第一个元素是根，在中序序列中找到这个根，其左边是左子树，右边是右子树。然后递归构建。
	    *   **后序+中序**：后序序列的最后一个元素是根，同样在中序序列中找到根来划分左右子树，然后递归构建。
- 判断出栈序列的合法性 
	-     给定一个入栈序列和一个出栈序列，判断该出栈序列是否合法。这可以通过模拟栈的操作来解决。



![[2015-exam-paper-ocr.pdf#page=1&rect=76,501,496,562|2015-exam-paper-ocr, p.1]]
[[截屏2025-09-30 上午3.39.01.png]]

- [[哈夫曼树]]  [[m叉哈夫曼树的构造规则]]  
1.   哈夫曼树中，任何一个非叶子结点（即父结点）的权值都等于其左、右两个孩子结点的权值之和。
	用公式表示为：
	$W_{parent} = W_{left\_child} + W_{right\_child}$
- C. 24, 10, 10 和 24, 14, 11
	*   **路径分析**：我们首先看路径 `24 -> 10 -> 10`。这表示一个权值为 `10` 的父结点，其下有一个权值为 `10` 的叶子结点。根据 #哈夫曼树的性质 ，$W_{parent} = W_{child1} + W_{child2}$，即 $10 = 10 + W_{child2}$。这要求另一个孩子的权值 $W_{child2}$ 必须为 `0`。在标准的哈夫曼树构造中，所有原始权值都是正数，因此这种情况是不可能的。
	*   **性质检验（另一种角度）**：我们也可以像分析 B 一样，检查根结点。根结点 `24` 的两个孩子权值分别为 `10` 和 `14`。它们的和为 $10 + 14 = 24$。根结点这一层是满足条件的。但是，如上所述，`10 -> 10` 这个子路径不满足条件。
	*   **结论**：由于存在不满足性质的子路径，选项 C 错误。
 - D. 24, 10, 5 和 24, 14, 6
	**路径分析**：这两条路径 `24 -> 10 -> 5` 和 `24 -> 14 -> 6` 描述了如下的局部树结构：
	    1.  根结点 `24` 有两个孩子，权值分别为 `10` 和 `14`。
	    2.  权值为 `10` 的结点有一个孩子是权值为 `5` 的叶子结点。
	    3.  权值为 `14` 的结点有一个孩子是权值为 `6` 的叶子结点。
	*   **性质检验**：
	    1.  **检验根结点**：其两个孩子的权值和为 $10 + 14 = 24$。这与根结点的权值 `24` 相符。
	    2.  **检验结点 10**：它有一个孩子是 `5`。根据性质，它必须还有另一个孩子。设另一个孩子的权值为 $x$，则 $10 = 5 + x$，解得 $x=5$。这是完全可能的，即结点 `10` 的两个孩子权值都是 `5`。
	    3.  **检验结点 14**：它有一个孩子是 `6`。设另一个孩子的权值为 $y$，则 $14 = 6 + y$，解得 $y=8$。这也是完全可能的。
	*   **结论**：所有路径描述的局部结构都能满足哈夫曼树的性质，我们可以构建出一个合法的哈夫曼树局部结构。因此，选项 D 正确。
- 衍生
	- #构造哈夫曼树 
		-  **问题**：给定一组权值（例如，字符的出现频率），要求画出完整的哈夫曼树。
		    *   **解法**：遵循“贪心”策略：每次从森林中选取权值最小的两棵树，合并成一棵新树（新树的根结点权值为两棵子树根结点权值之和），然后将新树放回森林。重复此过程，直到只剩下一棵树为止。
	- #带权路径长度  
		-   **问题**：计算给定哈夫曼树的 WPL (Weighted Path Length)。WPL 是衡量编码效率的指标，其值越小越好
		-    **公式**：$WPL = \sum_{i=1}^{n} w_i l_i$，其中 $w_i$ 是第 $i$ 个叶子结点的权值， $l_i$ 是该叶子结点的深度（根结点深度为0）。
	    *   **一个有用的结论**：哈夫曼树的 WPL 等于所有非叶子结点的权值之和。这个结论可以用来快速验算。
	* [[哈夫曼编码]] 
		*   **问题**：为一组字符（及其频率）设计哈夫曼编码。 


![[2015-exam-paper-ocr.pdf#page=1&rect=82,435,519,501|2015-exam-paper-ocr, p.1]]
[[Pasted image 20250930033912.png]]
- [[AVL树的高度与结点数关系]]  [[平衡二叉树]] 
- [[前驱后继，前中后序]] #中序遍历 
-  “对其进行中序遍历可得到一个**降序序列**”。
    *   对于一棵**标准**的二叉搜索树，其中任意结点的值都大于其左子树中所有结点的值，且小于其右子树中所有结点的值。对它进行中序遍历 (LNR)，会得到一个**升序序列**。
    *   而本题得到的是一个**降序序列**。这意味着这棵树的结构是“反过来”的。对于树中的任意一个结点，其值必须**小于**其左子树中所有结点的值，且**大于**其右子树中所有结点的值。我们可以称之为“ #降序二叉搜索树”。
    *   **结论：对于树中任意结点 `N`，其关键字满足 `key(LeftSubtree) > key(N) > key(RightSubtree)`。**
1. A. 根结点的度一定为2
	1. #结点的度 是指该结点的子树个数。度为2意味着结点既有左子树又有右子树。这个说法是错误的。
	*   **反例**: 我们可以构造一个只有两个结点的AVL树，例如包含关键字 {10, 5}。根据我们推导的“降序”规则，如果根是10，那么5比10小，应该在10的右子树。
    ```
      10
       \
        5
    ```
    这棵树是平衡的（根结点的平衡因子为 $0 - 1 = -1$），满足所有条件。但根结点10的度为1，而不是2。因此，A错误。
- B. 树中 #最小元素 一定是 #叶结点
	1. 要找到最小的元素，我们必须从根结点开始，一直向右走到底。这个最右侧的结点就是值最小的元素
		1. 最右侧的结点一定是叶结点吗？不一定。
			1. 一个结点是叶结点意味着它没有子结点（度为0）。但这个最小元素结点虽然没有右子树（因为已经是最右了），但它**可能有一个左子树**。
	2. #反例 
		构造一棵包含 {10, 5, 7} 的AVL树。
		    1.  插入10。
		    2.  插入5 (比10小，放右边)。
		    3.  插入7 (比10小，往右走；比5大，放5的左边)。
		    树的结构如下：
		    ```
		      10
		       \
		        5
		       /
		      7
		    ```
		    这棵树是平衡的（结点5的BF=1，结点10的BF=-1）。其中最小的元素是5，但它不是叶结点，因为它有一个左孩子7。因此，B错误。
- C. 最后插入的元素一定是叶结点  
	- 关于AVL树插入操作的一个常见误解。虽然新元素总是作为叶结点被**初步插入**到树中，但为了维持AVL树的平衡特性，插入后可能会触发一次或多次 #旋转 操作
- D. 树中最大元素一定是无左子树
	-  在我们这棵“降序二叉搜索树”中，最大的元素在哪里？根据规则 `key(LeftSubtree) > key(N)`，要找到最大的元素，我们必须从根结点开始，一直向左走到底。这个最左侧的结点就是值最大的元素。
	- 根据“降序二叉搜索树”的定义，任何结点的左孩子的值都必须比该结点自身的值要大。假设最大元素（最左侧的结点）`M` 有一个左子树，那么其左子树的根结点`L`的值必须满足 `key(L) > key(M)`。但这与`M`是树中最大元素的前提相矛盾。
	*   所以，树中的最大元素（最左侧的结点）**一定不能有左子树**。它可能有右子树，也可能没有，但它一定没有左子树。因此，D正确。
- 衍生
	- [[平衡二叉树的旋转]] 
		- 给定一棵二叉树，判断它是否为AVL树，并计算特定结点的 #平衡因子
		- #四种旋转操作 深入考察LL、RR、LR、RL四种失衡情况以及对应的旋转调整方法 
		- #AVL树的性能 插入、删除、查找操作的时间复杂度为什么是$O(\log n)$ 
		- #AVL树的高度 AVL树的高度与结点数之间的关系，最坏情况下（最“瘦高”的AVL树）的高度约为$1.44 \log_2 n$ 
		- [[平衡二叉树对比]]  与红黑树（Red-Black Tree）的比较 


![[2015-exam-paper-ocr.pdf#page=1&rect=76,392,525,439|2015-exam-paper-ocr, p.1]]
[[截屏2025-09-30 上午3.39.20.png]]
![[截屏2025-09-30 下午1.09.43.png]]
- #有向图  #深度优先遍历（先序遍历） #深度优先搜索DFS   [[有向图]]   [[深度优先遍历实现步骤（有向图）]]  
- 序列: **`<v_0, v_1, v_3, v_2>`**。所有顶点均已访问，遍历结束。
	 序列: **`<v_0, v_2, v_1, v_3>`**
		序列: **`<v_0, v_2, v_3, v_1>`**
		序列: **`<v_0, v_3, v_1, v_2>`**
		序列: **`<v_0, v_3, v_2, v_1>`**
**5** 种可能的序列 
- #广度优先搜索BFS  
	-  **考点**: 可能会问同一个图从 $v_0$ 开始进行BFS，有多少种可能的序列。
		-   **解析**: BFS是 #按层级遍历 。从 $v_0$ 开始，第一层是 $v_0$。第二层是 $v_0$ 的所有邻接点 $v_1, v_2, v_3$。BFS会先访问完所有第二层的节点，再进入下一层。访问第二层节点的顺序是不确定的。因此，可能的序列是 $v_0$ 后面跟着 $v_1, v_2, v_3$ 的任意排列。排列数是 $3! = 3 \times 2 \times 1 = 6$ 种。所以此图的BFS序列有6种。
	- [[邻接矩阵，邻接表 ，稀疏图，稠密图]] 
		- #邻接表与邻接矩阵的区别与选择 
			- **邻接矩阵**: 用一个二维数组 `adj[i][j] = 1` 表示存在从 $i$ 到 $j$ 的边。空间复杂度为 $O(|V|^2)$。对于本题，遍历 $v_0$ 的邻接点时，相当于按 $j$ 从 0 到 3 的顺序扫描矩阵的第0行，这会产生一个固定的遍历顺序。
		    *   **邻接表**: 为每个顶点维护一个链表或动态数组，存储其所有邻接点。空间复杂度为 $O(|V|+|E|)$。邻接表中节点的存储顺序是不确定的，这直接导致了DFS/BFS遍历序列的多样性。本题默认是基于邻接表的逻辑。
		-  [[拓扑排序]]
			- 判断一个有向图是否存在环（Cycle），并给出其拓扑序列






![[2015-exam-paper-ocr.pdf#page=1&rect=74,263,538,395|2015-exam-paper-ocr, p.1]]
[[截屏2025-09-30 上午3.39.31.png]]
[[截屏2025-09-30 上午3.39.38.png]]
[[最小生成树MST]]
- #Kruskal算法  核心思想是**按边的权重从小到大**依次考察，如果当前考察的边不会与已选择的边构成回路（环），就将其加入到最小生成树中，直到加入了 $n-1$ 条边为止（其中 $n$ 是顶点数） 
1.  **将所有边按权重升序排列：**
    *   $(V_1, V_4)$: 权重 5
    *   $(V_1, V_3)$: 权重 8
    *   $(V_2, V_3)$: 权重 8
    *   $(V_3, V_4)$: 权重 8
    *   $(V_1, V_2)$: 权重 10
    *   $(V_2, V_4)$: 权重 11
	1. 第1次选择 选择权重最小的边 $(V_1, V_4)$，权重为5。这条边不会形成环
	2. Kruskal算法第2次可能选中的边是 $(V_1, V_3)$, $(V_2, V_3)$, 或 $(V_3, V_4)$。
 2. 第二步：执行 Prim 算法
	1.  选择权重最小的边 $(V_4, V_1)$。
	    *   更新集合 $U = \{V_1, V_4\}$。
	2. 第2次选择
	    寻找连接 $U=\{V_1, V_4\}$ 中顶点与 $V-U=\{V_2, V_3\}$ 中顶点的权重最小的边。
	    *   **从 $V_1$ 出发的边：** $(V_1, V_3)$ 权重8，$(V_1, V_2)$ 权重10。
	    *   **从 $V_4$ 出发的边：** $(V_4, V_3)$ 权重8，$(V_4, V_2)$ 权重11。
	    *   所有候选边为：$(V_1, V_3)$, $(V_1, V_2)$, $(V_4, V_3)$, $(V_4, V_2)$。
	    *   其中权重最小的是 $(V_1, V_3)$ 和 $(V_4, V_3)$，权重均为8。
		1.   因此，Prim算法第2次选择的边**必定是 $(V_1, V_3)$ 或 $(V_3, V_4)$ 
	答案：C. $(V_2, V_3)$**
- 衍生 
	- #最小生成树MST的唯一性    **考点：** 判断一个图的最小生成树是否唯一。
		- **结论：** 如果一个连通图的所有边的权重都**互不相同**，那么它的最小生成树是**唯一**的。如果存在相同权重的边（如此题），最小生成树可能**不唯一**。 
	- #Prim和Kruskal的算法复杂度（稀疏图vs稠密图）   [[最小生成树MST]]
		*   **Kruskal:** 时间复杂度主要取决于对边的排序，为 $O(E \log E)$，其中 $E$ 是边数。它更适合**稀疏图**（边数 $E$ 远小于 $V^2$）。Q
	    *   **Prim:**
	        *   使用邻接矩阵实现：$O(V^2)$。
	        *   使用优先队列（最小堆）优化：$O(E \log V)$。
	        *   Prim算法的 $O(V^2)$ 版本适合**稠密图**（边数 $E$ 接近 $V^2$）。
		- [[次小生成树]] **考点：** 求解一个图的权重第二小的生成树。这是一个更深入的考点。 


![[2015-exam-paper-ocr.pdf#page=1&rect=70,228,512,268|2015-exam-paper-ocr, p.1]]
[[截屏2025-09-30 上午3.39.50.png]]
[[二分查找]]  #二分查找  #画图 
  1. **选项 A: 500, 200, 450, 180**
    1.  `500` -> `200`：因为 $200 < 500$，我们进入了500的左子树。**规则：之后所有比较值都必须 < 500**。
    2.  `200` -> `450`：因为 $450 > 200$，我们进入了200的右子树。**规则：之后所有比较值都必须 > 200**。
    3.  `450` -> `180`：下一个比较值是 `180`。
    4.  **矛盾出现**：根据第2步，后续比较值必须大于 `200`。但 `180` 却小于 `200`。这违反了折半查找的原则。在确定了查找区间为 `(200, 500)` 之后，不可能再回头去比较一个小于 `200` 的值。因此，这个序列不合法。
    *   **图解分析**：
        *   `500` (根)
        *   `200` (500的左孩子)
        *   `450` (200的右孩子)
        *   `180` (试图成为450的孩子)。但是，`180` 比它的“爷”节点 `200` 还要小，它本应该在 `200` 的左子树，而不是右子树的后代。这破坏了BST的结构。

- 衍生 
	- 根据有序序列构建折半查找判定树
		-    **考点：** 给定一个有序数组，如 `[2, 8, 15, 22, 31, 40, 45]`，要求画出其 #折半查找判定树 。
		    *   **解法：** 递归地取中间元素作为根节点。
		        *   根：`22` (索引 `(0+6)/2=3`)
		        *   左子树（`[2, 8, 15]`）的根：`8`
		        *   右子树（`[31, 40, 45]`）的根：`40`
		        *   依此类推，直到所有元素都成为节点。
		- [[平均查找长度 (ASL)]]
		[[查找算法的比较]]  #哈希查找 [[顺序表查找方法]]



![[2015-exam-paper-ocr.pdf#page=1&rect=74,179,520,231|2015-exam-paper-ocr, p.1]]
[[截屏2025-09-30 上午3.40.04.png]]
#KMP算法  [[KMP算法]] 
KMP 算法的匹配过程遵循以下规则：
*   如果 `s[i] == t[j]`，则 `i` 和 `j` 都加 1，继续比较下一对字符。
*   如果 `s[i] != t[j]`（发生失配），则：
    *   主串的指针 `i` **保持不变**。
    *   模式串的指针 `j` 更新为 `j = next[j]`。
    * 因此，下一次开始匹配时，`i` 和 `j` 的值分别是 5 和 2。这对应于选项 **C**。
- 衍生 
	- #如何手动计算next数组
		*   `j=0`: 按定义，`next[0] = -1`。
		*   `j=1`: 子串为 "a"。没有真前缀和后缀，最长公共前后缀长度为 0。`next[1] = 0`。
		*   `j=2`: 子串为 "ab"。前缀为 {"a"}，后缀为 {"b"}。没有公共部分。`next[2] = 0`。
		*   `j=3`: 子串为 "aba"。前缀为 {"a", "ab"}，后缀为 {"a", "ba"}。最长公共部分是 "a"，长度为 1。`next[3] = 1`。
		*   `j=4`: 子串为 "abaa"。前缀为 {"a", "ab", "aba"}，后缀为 {"a", "aa", "baa"}。最长公共部分是 "a"，长度为 1。`next[4] = 1`。
		*   `j=5`: 子串为 "abaab"。前缀为 {"a", "ab", "aba", "abaa"}，后缀为 {"b", "ab", "aab", "baab"}。最长公共部分是 "ab"，长度为 2。`next[5] = 2`。


![[2015-exam-paper-ocr.pdf#page=1&rect=79,147,471,185|2015-exam-paper-ocr, p.1]]
[[截屏2025-09-30 上午3.40.16.png]]
[[排序算法]]
1.  A. 直接插入排序 
	1. 算法将数组分为“已排序”和“未排序”两部分。每次从未排序部分取出一个元素，通过比较，将其插入到已排序部分的正确位置
	2. 元素的移动次数与初始次序**高度相关**。
	    *   **最好情况：** 如果数组基本有序或完全有序，那么每次插入的元素只需要很少的比较和移动（甚至不移动）就能找到自己的位置。此时移动次数最少。
2. B. 起泡排序
	1.  重复地遍历要排序的数列，一次比较两个相邻的元素，如果它们的顺序错误就把它们交换过来
3. C. 基数排序 
	1. 基数排序是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。它需要借助一个“桶”的结构。
	2.  **与初始次序的关系：** 元素的移动次数与初始次序**无关**
4. D. 快速排序
	1. **工作原理：** 通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序。
	2. **与初始次序的关系：** 元素的移动（交换）次数与初始次序**相关**


- 衍生 
	- #时间复杂度  #空间复杂度  #稳定性 #比较次数 



![[2015-exam-paper-ocr.pdf#page=1&rect=81,98,521,146|2015-exam-paper-ocr, p.1]]
[[截屏2025-09-30 上午3.40.27.png]]

```
      8
     / \
    15  10
   / \  / \
  21 34 16 12
```

删除堆顶元素（即最小值8）的标准流程如下：
[[大根堆]] #最小堆  
步骤二：执行删除根节点（最小值）的操作
1.  **替换**：将堆中最后一个元素（这里是`12`）移动到根节点的位置，替换被删除的元素`8`。
2.  **调整**：此时堆的结构变为如下，但堆序性可能被破坏。我们需要从根节点开始进行“向下调整”（Sift-down 或 Heapify-down）操作，以恢复小根堆的性质。

3. 删除`8`并用`12`替换后，堆的结构如下（对应题目解析中第二幅图）：

```
      12  <-- 堆序性可能被破坏
     / \
    15  10
   / \  /
  21 34 16
```
**交换**：将 `12` 和 `10` 交换位置。
 步骤三： 向下调整（Sift-down）并计数比较次数

**第1轮调整（从根节点开始）：**

*   当前节点为 `12`，其子节点为 `15` 和 `10`。
*   **第1次比较**：为了找到子节点中的最小值，需要比较 `15` 和 `10`。显然，$10 < 15$。
*   **第2次比较**：将当前节点 `12` 与其较小的子节点 `10` 进行比较。因为 $12 > 10$，不满足小根堆性质。
*   **交换**：将 `12` 和 `10` 交换位置。
交换后，堆的结构变为（对应题目解析中第三幅图）：

```
      10
     / \
    15  12  <-- 12移动到了新位置
   / \  /
  21 34 16
```

**第2轮调整（从 `12` 的新位置开始）：**

*   `12` 移动到了新的位置，我们需要继续检查它是否满足堆序性。
*   当前节点为 `12`，它的子节点是 `16`（它只有一个左子节点，因为原先`10`的右子节点是`12`，现在`12`是父节点了）。
*   **第3次比较**：将当前节点 `12` 与其子节点 `16` 进行比较。因为 $12 < 16$，满足小根堆性质。
*   **停止**：调整过程结束。

#### 步骤四：统计总比较次数

在整个重建堆的过程中，我们总共进行了3次比较：
1.  `15` 与 `10` 比较
2.  `12` 与 `10` 比较
3.  `12` 与 `16` 比较

因此，总的比较次数是 **3** 次。答案选 **C**。

- 衍生 
	- #堆堆插入操作 
		-    **过程**：将新元素添加到堆的末尾（即完全二叉树的下一个可用位置），然后执行“向上调整”（Sift-up）操作。将新节点与其父节点比较，如果它比父节点小，则交换，并继续向上比较，直到根节点或满足堆序性为止。
	    *   **考点**：可能会问插入一个元素后的堆形态，或者插入过程中的比较/交换次数。
	- #堆堆构建（初始化）     
		*   **过程**：给定一个无序数组，如何构建一个堆？最高效的方法（时间复杂度为$O(n)$）是从最后一个非叶子节点开始，向前逐个节点执行“向下调整”（Sift-down）操作，直到根节点。
	    *   **考点**：给定一个数组，要求构建成大根堆或小根堆，并写出最终的数组序列。
	-  #堆排序     
		*   **过程**：这是一个经典排序算法。首先将无序序列构建成一个大根堆（Max-Heap）。然后，重复执行以下步骤：将堆顶元素（当前最大值）与堆末尾元素交换，然后将堆的大小减一，并对新的根节点执行“向下调整”操作。
	    *   **考点**：堆排序的时间复杂度（始终为$O(n\log n)$）、空间复杂度（$O(1)$）、以及其稳定性（不稳定排序）。
	- #大根堆     与小根堆性质相反，大根堆中任意节点的值都**大于或等于**其子节点的值。根节点是最大值。所有操作（插入、删除）的逻辑与小根堆类似，只是比较的逻辑相反。
	- #堆堆应用-TOP-K问题  
		- 从海量数据中找出最大（或最小）的 K 个元素
	    *   **解法**：
	        *   找最大的K个元素：维护一个大小为K的小根堆。遍历数据，如果当前元素比堆顶元素大，则删除堆顶，插入当前元素。
	        *   找最小的K个元素：维护一个大小为K的大根堆。
	
![[2015-exam-paper-ocr.pdf#page=1&rect=81,60,475,98|2015-exam-paper-ocr, p.1]]
[[截屏2025-09-30 上午3.40.36.png]]

[[希尔排序]] 
A. 直接插入排序
希尔排序通过分组和逐步缩小增量的方式，让元素可以一次性地跳跃很长的距离，从而快速地使整个数组趋于有序，最后再通过一次高效的直接插入排序完成最终排序

![[2015-exam-paper-ocr.pdf#page=2&rect=79,771,469,818|2015-exam-paper-ocr, p.2]]
[[截屏2025-09-30 上午3.40.44.png]]
 - I: 机器语言程序
	 -  计算机硬件能够直接执行 #机器语言程序 
	 - 执行过程 
		 - CPU的控制单元从内存中取出一条机器指令，解码它，然后命令算术逻辑单元（ALU）等部件执行相应的操作。这个过程是硬件层面的，没有任何软件翻译。

-  II: 汇编语言程序
	 需要“汇编”这个翻译步骤，所以汇编语言程序不能被硬件**直接**执行。因此，选项 II 是错误的。
-  III: 硬件描述语言程序
	- #硬件描述语言程序 根本不是由计算机硬件执行的程序，而是用来设计硬件的。因此，选项 III 是错误的。
- [[编译器和解释器的区别]] 
- [[程序到可执行文件（程序的生命周期）]]
- [[指令集体系结构]] 
	-  **考点**: 可能会问为什么机器语言不通用。答案是因为不同类型的CPU（如Intel x86, ARM, MIPS）有不同的ISA，它们的机器语言互不兼容。

![[2015-exam-paper-ocr.pdf#page=2&rect=78,731,473,772|2015-exam-paper-ocr, p.2]]
[[截屏2025-09-30 上午3.40.51.png]]
[[截屏2025-09-30 上午3.40.56.png]]
[[补码的表示范围]]   
#补码  [[补码]] 
1. 确定符号位
	1. 要想表示的整数最小，这个数必须是负数。根据补码规则，负数的符号位（最高位）必须是 **1**。
	    所以，这个 8 位数的格式必定是 `1xxxxxxx`
2. 最小化数值
	我们使用 #按权展开求和 的公式来分析如何让数值最小。
	    $V = -1 \times 2^7 + (b_6 \times 2^6 + b_5 \times 2^5 + ... + b_0 \times 2^0)$
	    $V = -128 + (\text{后面7位数值位的加权和})$
	    我们必须让括号里的“后面7位数值位的加权和”尽可能**小**
	1.  2 个“1”和 5 个“0”可以用来填充这 7 个位置。为了使加权和最小，我们应该把“1”放在权重最低的位置上
		*   $b_1 = 1$
		*   $b_0 = 1$
3. **构建最终的补码：**
    将符号位和数值位组合起来，我们得到的 8 位二进制补码是：
    `10000011`
4.  **计算真值：**
    我们用公式来计算这个补码的十进制值：
    $V = -1 \times 2^7 + 0 \times 2^6 + 0 \times 2^5 + 0 \times 2^4 + 0 \times 2^3 + 0 \times 2^2 + 1 \times 2^1 + 1 \times 2^0$
    $V = -128 + 0 + 0 + 0 + 0 + 0 + 2 + 1$
    $V = -128 + 3$
    $V = -125$
 - 衍生 
	 - 求最大整数
		*   **思路：** 最大数必然是正数，符号位为 **0**。
	    *   **构建：** `0xxxxxxx`。剩下 3 个“1”和 4 个“0”。为了使数值最大，应将 3 个“1”放在权重最高的数值位上。
	    *   **补码：** `01110000`
	    *   **真值：** $0 \times 2^6 + 1 \times 2^6 + 1 \times 2^5 + 1 \times 2^4 + 0... = 64 + 32 + 16 = 112$。
	- 求最接近零的负数
		*   **思路：** 仍然是负数，符号位为 **1**。
	    *   **构建：** `1xxxxxxx`。剩下 2 个“1”和 5 个“0”。为了让负数的值最大（绝对值最小），应将 2 个“1”放在权重最高的数值位上。
	    *   **补码：** `11100000`
	    *   **真值：** $-128 + 1 \times 2^6 + 1 \times 2^5 = -128 + 64 + 32 = -32$。（这对应了选项 C）
	- [[编码方式]]  #不同编码方式 
		- 题目可能会将“补码”换成“**原码 (Sign-Magnitude)**”或“**反码 (One's Complement)**”。
	    *   **原码：** `10000011` 表示 -3。在原码中，要使负数最小（绝对值最大），应将“1”放在数值位的最高位。`11100000` 表示 $-(64+32)=-96$。
	    *   **反码：** 规则又有所不同，负数的反码是其原码数值位按位取反。
	- #特殊值的补码     
		*   最小负数：-128 的补码是 `10000000`。
	    *   最大正数：127 的补码是 `01111111`。
	    *   -1 的补码：`11111111`。
	    这些特殊值经常作为考点出现。


![[2015-exam-paper-ocr.pdf#page=2&rect=77,674,490,735|2015-exam-paper-ocr, p.2]]
[[截屏2025-09-30 上午3.41.04.png]]

[[浮点数运算规则]] 
   - I. 对阶操作不会引起阶码上溢或下溢。
	  **知识点**：对阶操作的规则。
	*   **详细分析**：对阶的目的是让两个浮点数的阶码相同，以便它们的尾数可以直接相加减。规则是“小阶向大阶看齐”。也就是说，将阶码较小的数的阶码增加，同时将其尾数相应地右移（每右移一位，阶码加1），直到两个数的阶码相等。
	*   **推导**：在这个过程中，最终的阶码等于两个原始阶码中较大的那个。既然两个原始浮点数都是合法的、可表示的数，它们的阶码（无论是较大的还是较小的）本身就没有溢出。因此，对阶后得到的公共阶码也必然在可表示的范围内，既不会上溢（超过最大阶码），也不会下溢（低于最小阶码）。
	*   **结论**：叙述 I 是**正确**的
- II. 右规和尾数舍入都可能引起 #阶码上溢 
	-  **知识点**：规格化（右规）与舍入操作。
	*   **详细分析**：
	    *   **右规 (Right Normalization)**：当尾数加减运算的结果发生溢出时（例如，两个正的规格化尾数相加，结果的整数部分为1，如 $0.1... + 0.1... = 1.0...$），需要进行右规。右规操作将尾数右移一位，并使阶码加1。如果此时的阶码已经是其能表示的最大值，再加1就会导致**阶码上溢**。
	    *   **尾数舍入 (Mantissa Rounding)**：在对阶或右规过程中，尾数可能会因为右移而丢失低位。为了保证精度，需要进行舍入操作（如“0舍1入”法）。如果舍入时发生进位，这个进位可能会一直传递，导致整个尾数溢出（例如，`0.111...1` + 进位 = `1.000...0`）。这种情况与尾数运算溢出类似，同样需要通过右规来处理，即尾数右移一位，阶码加1。因此，舍入操作也可能间接导致阶码加1，从而引发**阶码上溢**。
	*   **结论**：叙述 II 是**正确**的。
- III. 左规时可能引起 #阶码下溢
	*   **知识点**：规格化（左规）。
	*   **详细分析**：
	    *   **左规 (Left Normalization)**：当两个相近的数相减，或者一正一负的数相加时，结果的尾数可能会变得非常小，即小数点后出现多个0（例如，$0.000...1...$）。为了满足规格化要求（通常要求尾数最高位为有效数字），需要进行左规。左规操作将尾数左移一位，并使阶码减1，重复此过程直到尾数规格化。如果此时的阶码已经是其能表示的最小值，再减1就会导致**阶码下溢**。
	*   **结论**：叙述 III 是**正确**的。
-  IV. 尾数溢出时，结果不一定溢出
	*   **知识点**：尾数溢出与最终结果溢出的关系。
	*   **详细分析**：在第二步“尾数加减”中，可能会出现尾数溢出（也称为“假溢出”）。如前所述，尾数溢出（例如，结果为 $1.xxxx...$）是运算过程中的一个中间状态。计算机会通过**右规**操作来修正它：将尾数右移一位（变为 $0.1xxxx...$），同时将阶码加1。
	*   **推导**：
	    *   如果阶码加1后，新的阶码仍在可表示范围内，那么整个浮点数的结果就是有效的，**没有溢出**。
	    *   只有当阶码加1后，新的阶码超出了最大表示范围（即发生阶码上溢），整个浮点数的结果才被判断为**溢出**。
	*   **结论**：因此，尾数溢出只是一个中间步骤，它本身不代表最终结果溢出。最终结果是否溢出取决于右规后阶码的情况。叙述 IV 是**正确**的。

- 衍生 
	- [[IEEE 754 标准]] 
	- #浮点数运算的实例计算 
		-   给出两个具体的二进制或十六进制浮点数，要求手动完成加减运算的全过程，包括对阶、尾数运算、规格化、舍入和溢出判断。
	    *   例如：计算 $1.011 \times 2^3 + 1.101 \times 2^2$。
	- #舍入误差 
		-     对阶过程中，小阶码数的尾数右移会丢失最低有效位，这是浮点运算产生误差的主要来源之一。
	    *   常见的舍入策略：向0舍入、向 $+\infty$ 舍入、向 $-\infty$ 舍入、向最近偶数舍入（IEEE 754默认）。
	- #浮点数运算的性质 
		*   浮点数加法不满足结合律：$(a+b)+c$ 不一定等于 $a+(b+c)$，因为每次运算都可能引入舍入误差。
	    *   这是并行计算和编译器优化中需要特别注意的问题。
	

![[2015-exam-paper-ocr.pdf#page=2&rect=77,607,521,673|2015-exam-paper-ocr, p.2]]
[[截屏2025-09-30 上午3.41.13.png]]

[[写策略]]  
 1. 分析地址结构 #直接映射   [[地址映射]] 

| 标记 (Tag) | Cache 行号 (Index) | 块内地址 (Offset) |
| :--- | :--- | :--- |

1. **计算块内地址 (Offset) 的位数：**
    *   题目说明主存是**按字节编址 (Byte-addressable)**。
    *   块大小为 4 个字 (word)，每个字为 32 位。
    *   因此，一个 Cache 块的大小 (Block Size) 为：
        $Block Size = 4 \text{ words} \times 32 \text{ bits/word} = 128 \text{ bits}$
    *   换算成字节：
        $Block Size = 128 \text{ bits} / 8 \text{ bits/byte} = 16 \text{ Bytes}$
    *   为了能寻址块内的每一个字节，需要的地址位数是：
        $Offset Bits = \log_2(16) = \log_2(2^4) = 4 \text{ 位}$

*   **计算 Cache 行号 (Index) 的位数：**
    *   Index 用于确定主存块应该映射到 Cache 的哪一行。因此，Index 的位数由 Cache 的总行数决定。
    *   题目给出 Cache 能存放 4K 字的数据。
        $Cache Data Capacity = 4\text{K words}$
    *   每个 Cache 行（块）存放 4 个字的数据。
    *   因此，Cache 的总行数 (Number of Lines) 为：
        $Number of Lines = \frac{\text{Total words in Cache}}{\text{Words per line}} = \frac{4\text{K words}}{4 \text{ words/line}} = 1\text{K lines}$
    *   $1\text{K} = 1024 = 2^{10}$。所以，为了索引这 1024 行，需要的地址位数是：
        $Index Bits = \log_2(1024) = \log_2(2^{10}) = 10 \text{ 位}$

*   **计算标记 (Tag) 的位数：**
    *   主存地址总共 32 位，减去 Index 和 Offset 的位数，剩下的就是 Tag 的位数。
    *   $Tag Bits = \text{Total Address Bits} - \text{Index Bits} - \text{Offset Bits}$
    *   $Tag Bits = 32 - 10 - 4 = 18 \text{ 位}$
- 32 位地址的划分：18 位标记 (Tag)，10 位行号 (Index)，4 位块内地址 (Offset)。 
1. 计算 #Cache总容量  
	
	*   **计算数据存储容量 (Data Storage Capacity)：**
	    *   题目直接给出 Cache 能存放 4K 字的数据，每字 32 位。
	    *   $Data Capacity = 4\text{K words} \times 32 \text{ bits/word}$
	    *   $Data Capacity = 4 \times 1024 \times 32 = 131072 \text{ bits}$
	    *   为了方便与选项比较，我们换算成 K 位（注意，这里的 K 是 1024）：
	        $Data Capacity = \frac{131072}{1024} = 128\text{K bits}$
	
	*   **计算标记阵列容量 (Tag Array Capacity)：**
	    *   标记阵列为 Cache 的**每一行**都存储一些管理信息。这些信息通常包括：
	        1.  **有效位 (Valid Bit):** 1 位。用于表示该 Cache 行中的数据是否有效。
	        2.  **标记位 (Tag Bit):** 我们已经计算出为 18 位。
	        3.  **脏位 (Dirty Bit):** 1 位。由于题目明确采用**回写 (Write Back)** 方式，所以需要一个脏位。当 Cache 中的数据被修改后，脏位被置为 1，表示该数据与主存不一致，在被替换出去时需要写回主存。
	        4.  **替换算法控制位 (Replacement Bits):** 对于直接映射，一个主存块只能映射到唯一一个 Cache 行，不存在替换选择问题，因此不需要替换算法控制位。
	    *   因此，每个 Cache 行需要存储的额外信息位数为：
	        $Overhead per Line = \text{Tag Bits} + \text{Valid Bit} + \text{Dirty Bit}$
	        $Overhead per Line = 18 + 1 + 1 = 20 \text{ bits}$
	    *   Cache 共有 1K ($2^{10}$) 行，所以标记阵列的总容量为：
	        $Tag Array Capacity = \text{Number of Lines} \times \text{Overhead per Line}$
	        $Tag Array Capacity = 1\text{K} \times 20 \text{ bits} = 1024 \times 20 = 20480 \text{ bits}$
	    *   同样，换算成 K 位：
	        $Tag Array Capacity = \frac{20480}{1024} = 20\text{K bits}$
	
	*   **计算总容量 (Total Capacity)：**
	    *   $Total Capacity = \text{Data Capacity} + \text{Tag Array Capacity}$
	    *   $Total Capacity = 128\text{K bits} + 20\text{K bits} = 148\text{K bits}$
	
	所以，最终答案是 **148K**，选择 **C**。
- 衍生      
	- 改变映射方式
		- #全相联映射
			- 地址划分只有 **Tag** 和 **Offset**。Offset 仍为 4 位，则 Tag 为 $32-4=28$ 位。此外，全相联映射必须有替换算法（如 LRU），因此每行还需要额外的替换算法控制位。例如，对于 LRU 算法，1K 行 Cache 大约需要 $\lceil\log_2(1024!)\rceil$ 位，或者简化为 $\log_2(1024)=10$ 位来近似。计算会变得复杂
		- #组相连映射  
			- 例如，如果是 **4路组相联 (4-way set-associative)**，地址划分为 **Tag | 组号 (Set Index) | Offset**。
		        *   Cache 总行数为 1K，4 行为一组，则总组数 = $1\text{K} / 4 = 256 = 2^8$ 组。
		        *   组号 (Set Index) 需要 8 位。
		        *   Offset 仍然是 4 位。
		        *   Tag 位数 = $32 - 8 - 4 = 20$ 位。
		        *   每组内需要替换算法，例如用 2 位 LRU 控制位来管理 4 行。
		        *   此时每行开销 = $20 (\text{Tag}) + 1 (\text{Valid}) + 1 (\text{Dirty}) + 2 (\text{LRU}) = 24$ 位。
		        *   标记阵列容量 = $1\text{K} \times 24 \text{ bits} = 24\text{K bits}$。
		        *   总容量 = $128\text{K} + 24\text{K} = 152\text{K bits}$。
		- 改变[[写策略]] 
			-   如果题目改为 #写直通 ，那么 Cache 和主存的数据总是保持一致，就不再需要 #脏位
			    *   此时每行开销 = $18 (\text{Tag}) + 1 (\text{Valid}) = 19$ 位。
			    *   标记阵列容量 = $1\text{K} \times 19 \text{ bits} = 19\text{K bits}$。
			    *   总容量 = $128\text{K} + 19\text{K} = 147\text{K bits}$ (即选项 B)
		- 改变编码方式[[编码方式]] 
			- 如果题目改为**按字编址 (Word-addressable)**，那么地址的最小单位是字。
			    *   块大小为 4 个字，寻址块内的字需要 $\log_2(4)=2$ 位。
			    *   Offset 位数变为 2 位。
			    *   Index 仍为 10 位 (因为 Cache 总容量和块大小的单位都是“字”，计算行数不受影响)。
			    *   Tag 位数 = $32 - 10 - 2 = 20$ 位。
			    *   每行开销 = $20 (\text{Tag}) + 1 (\text{Valid}) + 1 (\text{Dirty}) = 22$ 位。
			    *   标记阵列容量 = $1\text{K} \times 22 \text{ bits} = 22\text{K bits}$。
			    *   总容量 = $128\text{K} + 22\text{K} = 150\text{K bits}$。



![[2015-exam-paper-ocr.pdf#page=2&rect=80,547,525,610|2015-exam-paper-ocr, p.2]]
[[截屏2025-09-30 上午3.41.24.png]]
[[主存访问]] [[1.主存]] 
#主存访问次数 [[总线与主存技术]]  [[指令周期]]  [[指令流水线与冲突]]
1. 读取 `x` 的值 
	1.  地址翻译 
		1. CPU发出 `x` 的虚拟地址 `xaddr`。为了得到物理地址，系统首先查找TLB。
		    *   **最理想情况**: **TLB命中 (TLB Hit)**。这意味着 `xaddr` 所在的页的页表项（Page Table Entry）已经在TLB中，因此**无需访问主存中的页表**来获取物理地址。
	2. **数据获取**: 获得物理地址后，CPU会先在Cache中查找该地址的数据。
	    *   **最理想情况**: **Cache命中 (Cache Hit)**。这意味着 `x` 的值已经在Cache中，CPU可以直接从Cache中读取，**无需访问主存**。
	3. **结论**: 在读取阶段，最理想的情况下（TLB命中 + Cache命中），访问主存的次数是 **0**。
2.  写入 `x` 的新值 
	1. **地址翻译**: 与读取操作一样，我们假设是**TLB命中**，因此地址翻译过程不需要访问主存。
	
	2. **数据写入**: CPU将计算出的新值写入 `xaddr`。此时，写策略起作用。
	    *   题目明确指出采用 #直写 (Write-Through)  策略。  [[写策略]]
	    *   根据直写策略的定义，每次写操作，数据不仅会更新到Cache中（如果该地址在Cache中），还**必须**被写入到主存中，以保证主存和Cache的数据一致性。
	    *   因此，无论Cache是否命中，这个写操作**必定会引发一次对主存的访问**。
	 **结论**: 在写入阶段，由于采用了直写策略，访问主存的次数**至少**是 **1**
- 知识点
	- [[页式存储管理]] 
		- #地址翻译 : CPU发出的虚拟地址 `VA` 分为虚拟页号 `VPN` 和页内偏移 `offset`。通过 `VPN` 在页表中查找对应的物理页框号 `PFN`，然后组合成物理地址 `PA = PFN + offset`
	- [[快表TLB]]
	- [[高速缓存Cache]]
- 衍生 
	- #最大访问次数 
		-   **读取 `x`**: TLB未命中 (访问主存1次查页表) + Cache未命中 (访问主存1次取数据) = **2次**。
	        *   **写入 `x`**: 由于地址在读取时已经翻译过，TLB此时应该命中了。但写操作因为是直写，必须访问主存1次。所以写入阶段是 **1次**。
	        *   总计最多访问次数 = $2 + 1 = 3$ 次。所以选项D是一个强干扰项。
	* 改变Cache写策略
		*   如果题目将策略改为**写回 (Write-Back)**，问最少访问次数：
	        *   **读取 `x`**: 最理想情况（TLB命中+Cache命中），访问主存 **0次**。
	        *   **写入 `x`**: 在写回策略下，写操作只更新Cache，不立即写入主存。因此，最理想情况下，访问主存 **0次**。
	        *   总计最少访问次数 = $0 + 0 = 0$ 次。答案会变成A
	- 考虑 #缺页中断  [[缺页中断]]  
		- 这是最极端的情况。如果在访问 `xaddr` 时发生缺页（即该页不在主存中），系统会触发缺页中断。处理过程包括：
	        1.  访问磁盘，将需要的页调入主存。
	        2.  更新页表（这本身可能是一次主存写操作）。
	        3.  重新执行指令。
	    *   这个过程涉及多次主存访问和极慢的磁盘I/O，通常在计算访问次数时会特别说明是否考虑缺页。
	- #平均访存时间AMAT  [[访存时间计算]]  
		-  这是一个综合性考点，会给出TLB命中率、Cache命中率、各级存储的访问时间，要求计算AMAT。
		- $AMAT = T_{TLB} + (1 - H_{TLB}) \times T_{Mem} + T_{Cache} + (1 - H_{Cache}) \times T_{Mem}$
			$H_{TLB}$ 是TLB命中率，$H_{Cache}$ 是Cache命中率，$T_{TLB}$、$T_{Cache}$、$T_{Mem}$ 分别是访问TLB、Cache和主存的时间。这个公式可以根据具体情况简化或复杂化 
![[2015-exam-paper-ocr.pdf#page=2&rect=82,510,466,550|2015-exam-paper-ocr, p.2]]
[[截屏2025-09-30 上午3.41.31.png]]
[[RAM和ROM的区别]]
[[Flash Memory 闪存的分类]] 
[[存储器的分类及其工作原理]] 

- 衍生  
	- [[SRAM与DRAM对比]]  比较维度： 存储原理、是否需要刷新、速度、集成度、成本、功耗、主要用途
	- [[存储器的层次结构]]      
		*   考察不同存储器在计算机系统中的位置。 
			* 从上到下依次是：**CPU寄存器 -> Cache (SRAM) -> 主存 (DRAM) -> 外部存储 (SSD/FLASH, 硬盘)**
		- [[DRAM刷新方式]]   可能会问及具体的刷新方式


![[2015-exam-paper-ocr.pdf#page=2&rect=81,466,519,512|2015-exam-paper-ocr, p.2]]
[[截屏2025-09-30 上午3.41.38.png]]
4体交叉编址存储器 #四体低位交叉存储  #交叉存储 [[总线与主存技术]]
- [[访存冲突]]  [[指令流水线与冲突]]  **在本题中的判断**：题目给出了一个连续的访存地址序列。要判断是否发生冲突，我们只需要检查在这个序列中，**两个连续的访问请求**是否指向了同一个存储模块。
1. 第一步：确定参数 
	*   交叉模块数 $N=4$。
	*   访存地址序列 A = {8005, 8006, 8007, 8008, 8001, 8002, 8003, 8004, 8000}。
2. 第二步：计算每个地址对应的模块序号 
	1. 使用公式 $M = A \pmod 4$ 来计算序列中每个地址对应的模块号。
		*   $8005 \pmod 4 = 1$
		*   $8006 \pmod 4 = 2$
		*   $8007 \pmod 4 = 3$
		*   $8008 \pmod 4 = 0$
		*   $8001 \pmod 4 = 1$
		*   $8002 \pmod 4 = 2$
		*   $8003 \pmod 4 = 3$
		*   $8004 \pmod 4 = 0$
		*   $8000 \pmod 4 = 0$
		观察计算出的模块序号序列：{1, 2, 3, 0, 1, 2, 3, **0, 0**}
	- 在这个序列的末尾，我们发现有两个连续的`0`。这对应着对地址 `8004` 和 `8000` 的访问。因为这两个**连续的访问**都请求了**同一个模块（模块0）**，所以它们之间会发生访存冲突。 
- 衍生   
	- [[高位交叉编址vs低位交叉编址]] 
		- **考法**：题目可能会明确指出是高位还是低位交叉，或者让你根据地址分配模式判断是哪一种，并分析其优缺点。
- [[存储器带宽计算]] 
- #冲突对性能的影响 
	- **考法**：给出一个访存地址序列，要求计算完成所有访问所需的总时间。你需要先计算出每个地址的模块号，找出冲突点。每发生一次冲突，就需要增加一个等待时间（通常是一个存储周期 $T$ 减去总线周期 $\tau$）。
[[总线带宽计算]]


![[2015-exam-paper-ocr.pdf#page=2&rect=80,387,349,462|2015-exam-paper-ocr, p.2]]
[[截屏2025-09-30 上午3.41.46.png]]
- [[总线定时]] 
- 
- [[异步通信]]    
	-   **A. 异步通信方式中，全互锁协议最慢**：正确。全互锁协议的握手过程最复杂，包含四步，因此耗时最长。
	- **B. 异步通信方式中，非互锁协议的可靠性最差**：正确。非互锁协议没有应答机制，完全依赖于时间假设，容易出错。
- [[同步通信]]  **C. 同步通信方式中，同步时钟信号可由各设备提供**：**错误**。同步通信的基石就是一个统一的、全局的时钟信号，由中心时钟源提供
- [[半同步通信]]  **D. 半同步通信方式中，握手信号的采样由同步时钟控制**：正确。主设备在时钟信号的边沿对`WAIT`/`READY`等握手信号进行采样，以决定是否需要插入等待周期
- 衍生  
	- [[总线带宽计算]]  - $总线带宽 = 总线时钟频率 \times \frac{总线宽度(bit)}{8} \div 每个数据传输所需的时钟周期数$   
	- [[总线仲裁]]
	- [[同步通信与异步通信的优缺点对比]] 
	- #实际总线标准举例   可能会要求你判断某个具体的总线标准（如ISA, PCI, PCIe, USB, I²C）属于哪种通信方式。 
		- 例如：PCI总线是典型的同步总线；RS-232是典型的 #异步串行通信 ；I²C总线则是一种半同步通信方式。


![[2015-exam-paper-ocr.pdf#page=2&rect=78,337,526,388|2015-exam-paper-ocr, p.2]]
[[截屏2025-09-30 上午3.41.54.png]]
- [[磁盘存储时间的计算（磁盘访问时间的计算）]]  
	-    总存取时间 $T_a$ = 寻道时间 $T_s$ + 旋转延迟时间 $T_r$ + 数据传输时间 $T_t$ + 控制器延迟
1. 第一步：计算平均旋转延迟时间
	1. 将转速单位从 rpm (转/分钟) 转换成 rps (转/秒):
		1. $7200 \text{ rpm} = \frac{7200 \text{ 转}}{60 \text{ 秒}} = 120 \text{ rps}$
	2. 计算旋转一圈所需的时间（秒）
		1. 时间 = $\frac{1}{\text{转速(rps)}} = \frac{1}{120}$ 秒
	3. 将时间单位转换为毫秒 (ms):
		1. $\frac{1}{120} \text{ 秒} \times 1000 \frac{\text{ms}}{\text{秒}} \approx 8.33 \text{ ms}$
	4. 计算平均旋转延迟时间（半圈时间）
		$T_{latency} = \frac{1}{2} \times \text{旋转一圈的时间} = \frac{1}{2} \times 8.33 \text{ ms} \approx 4.167 \text{ ms}$
	    题目解析中保留了两位小数，记为 $4.17 \text{ ms}$。
	其计算公式为：
	$T_{latency} = \frac{1}{2} \times \frac{60 \times 1000}{RPM} = \frac{1}{2} \times \frac{60000}{7200} \approx 4.17\text{ms}$
2. $T_{access} = T_{seek} + T_{latency} + T_{transfer}$
	$T_{access} = 8\text{ms} + 4.17\text{ms} + 0.01\text{ms} = 12.18\text{ms}$
- 衍生 
	- #读取连续的多个扇区 
	- #读取随机的多个扇区 
		-  **问题场景**：如果要读取分布在不同磁道、不同位置的 **N** 个扇区，总时间是多少？
		    *   **分析**：由于每个扇区的位置都是随机的，因此读取每一个扇区都需要完整地经历一次“寻道 + 延迟 + 传输”的过程。
		    *   **公式**：$T_{total\_N\_random} = N \times (T_{seek} + T_{latency} + T_{transfer}) = N \times T_{access}$
		    *   **本题示例**：若要随机读取10个扇区，总时间约为 $10 \times 12.2 = 122\text{ms}$
	-  [[磁盘调度算法]] 
		-    **背景**：当有多个 I/O 请求等待访问磁盘时，操作系统需要决定处理这些请求的顺序，以最小化总的寻道时间。








![[2015-exam-paper-ocr.pdf#page=2&rect=78,289,532,339|2015-exam-paper-ocr, p.2]]
[[截屏2025-09-30 上午3.42.03.png]]
1. [[IO控制方式]]  
- 衍生 
	- [[单级中断处理流程]]
		-  中断响应的条件是什么？（例如，中断允许位置`EINT=1`）
	    *   中断处理的具体步骤：关中断 -> 保存现场（程序计数器PC、寄存器等） -> 识别中断源 -> 执行中断服务程序 -> 恢复现场 -> 开中断 -> 中断返回
	- [[DMA工作流程]] 
	- 场景应用题
		-    问题可能会描述一个具体的应用场景（如“从磁盘读取一个10MB的文件”），然后问哪种I/O方式最合适。答案显然是DMA，因为它是高速设备和块数据传输。
		- 对于“响应用户键盘输入”，中断方式最合适，因为它能及时响应，且数据量小，CPU开销可以接受


![[2015-exam-paper-ocr.pdf#page=2&rect=79,200,524,292|2015-exam-paper-ocr, p.2]]
[[截屏2025-09-30 上午3.42.10.png]]

[[中断、异常和系统调用的区别与联系]]
[[缺页中断（缺页异常）的处理流程]]
[[区分中断、异常和系统调用]]
1. B. #内部异常的检测 由 CPU 内部逻辑实现  
	1. 这种检测异常的工作肯定是由 CPU（包括控制器和运算器）实现的”。CPU内部有专门的硬件逻辑电路来检测指令执行过程中的各种状态，比如检查除法运算的除数是否为零、检查内存访问地址是否越界、检查指令操作码是否合法等 
2. C. 内部异常的响应发生在指令执行过程中
	1. 分析： 解析中指出，“内中断不能被屏蔽，一旦出现应立即处理”。这意味着当CPU的内部逻辑在执行一条指令的过程中检测到异常时，它会立即暂停当前的指令流，转而去执行异常处理程序。这个响应动作就发生在指令的执行周期内。
3. D. 内部异常处理后返回到发生异常的指令继续执行
	1. 分析：“考虑到特殊情况，如除数为零和自行中断（INT）都会自动跳过中断指令，所以不会返回到发生异常的指令继续执行”。
	    *   对于**故障 (Fault)** 类型的异常，比如“缺页中断”，操作系统处理完（把需要的页调入内存）之后，会返回到**引起缺页的指令**，让它**重新执行**一次，这一次就能成功访问内存了。
        *   但对于**陷阱 (Trap)**（如系统调用）和**终止 (Abort)**（如除零错误）类型的异常，处理完后通常不会重新执行原指令。陷阱执行完后会返回到**下一条指令**继续执行。而终止类型的错误往往是致命的，程序可能会被直接终止。
- [[异常的分类]]  
- 衍生 
	- [[缺页中断（缺页异常）的处理流程]]
	- [[中断向量与中断向量表]]   **作用：** 存储了不同中断号对应的中断服务程序的入口地址。当中断发生时，CPU根据中断号查询此表，以确定跳转到哪里去执行
	- [[用户态与内核态]]


![[2015-exam-paper-ocr.pdf#page=2&rect=78,149,427,203|2015-exam-paper-ocr, p.2]]
[[截屏2025-09-30 上午3.42.26.png]]
- 核心是区分在中断处理过程中，**硬件自动完成**的工作和**操作系统（软件）需要完成**的工作 
[[中断处理机制]]
*   **A. 程序计数器 (PC) 的内容**: 如上所述，PC（断点）是由硬件在中断响应阶段通过“中断隐指令”自动保存的。因此，这不是操作系统的工作。
*   **B. 通用寄存器的内容**: 操作系统编写的中断服务程序在开始执行时，必须先将当前所有可能被用到的通用寄存器的值压入栈中保存起来，在处理完中断准备返回前，再从栈中弹出这些值，恢复到寄存器中。这是操作系统的任务。因此，B是正确的。
*   **C. 块表 (TLB) 中的内容**: TLB (Translation Lookaside Buffer) 是用于加速虚拟地址到物理地址转换的硬件缓存。它的内容由MMU（ #内存管理单元 ）硬件管理。在发生进程切换时（中断可能导致进程切换），TLB可能会被刷新（清空），但操作系统不会“保存”和“恢复”它的内容。
*   **D. Cache 中的内容**: Cache是CPU的高速缓存，用于存储主存中常用数据的副本，由硬件自动管理。操作系统一般不直接干预Cache内容的保存与恢复。Cache中的数据通过地址与进程关联，只要地址空间不变，其内容就是有效的。

- 衍生 
	- #中断向量表 (IVT) 
		-   **作用**: 存储中断服务程序入口地址的表。每个中断类型都有一个唯一的编号（中断向量号），CPU通过这个编号在IVT中查找对应的ISR地址 
		- **考点**: IVT的地址存放在哪里？（通常在内存的固定低地址区域，由一个专门的寄存器指向）。如何计算ISR地址？通常是 $ISR_{地址} = IVT_{基地址} + 中断向量号 \times 表项大小$ 
	- #用户态与核心态的状态切换  
		*   **如何切换**: 这个切换过程也是由中断隐指令自动完成的，通常通过修改PSW中的特权级标志位来实现。中断返回时再切换回用户态。
	- [[中断嵌套]]  
		- **处理**: 如果系统允许中断嵌套，那么在ISR执行前，除了关中断，还需要设置一个更高的中断屏蔽级别。当更高优先级的中断到来时，CPU会再次暂停当前的ISR，去处理新的中断，形成嵌套。处理完后逐层返回。这就要求现场保护必须使用**栈**结构来保存上下文，以支持后进先出的返回顺序。

![[2015-exam-paper-ocr.pdf#page=2&rect=77,54,519,151|2015-exam-paper-ocr, p.2]]
[[Pasted image 20250930034311.png]]
 [[用户态与核心态的状态切换]] 
- **总结：** 任何导致 **中断** 或 **异常** 发生的指令，都会引发 CPU 从用户态切换到内核态。 
1. A. DIV R0, R1 
	1. **操作**：执行除法运算，将寄存器 R0 的内容除以寄存器 R1 的内容，结果存回 R0。数学表示为 $(R0) / (R1) \rightarrow R0$ 
	2.    **分析**：如果此时寄存器 R1 中的值为 0，执行该指令将引发一个“**除零异常 (Divide-by-zero Exception)**”。这是一个典型的异常事件，CPU 会立即停止当前程序的执行，切换到内核态，并调用相应的异常处理程序。
	    *   **结论**：**可能**导致状态切换。
2. B. INT n 
	1. **操作**：产生一个软件中断 (Software Interrupt)。 [[特权指令类型]]
	    *   **分析**：`INT` 指令是专门设计用来触发中断的，是实现**系统调用**的经典方式。执行这条指令会**主动地**、**确定地**使 CPU 从用户态切换到内核态，去执行中断向量表中第 `n` 号中断服务程序。
	    *   **结论**：**必然**导致状态切换。
- 衍生 
	- #特权指令与非特权指令 
		*   **特权指令**：只能在内核态下执行的指令，如启动 I/O、修改程序状态字 (PSW)、设置时钟、清空内存等。如果在用户态下尝试执行，会引发“非法指令”异常。
	    *   **非特权指令**：在用户态和内核态下都可以执行的指令，如算术运算、逻辑运算、大部分的访存指令等。`NOT R0` 就是一个典型的非特权指令。
	- [[单级中断处理流程]] **考点**：中断处理过程的排序、中断屏蔽、中断嵌套等 
	- [[异常的分类]]
		- 考点：区分不同类型的异常及其处理后的返回行为
	- 系统调用的实现机制 [[系统调用的过程]]  **考点**： #系统调用的参数传递方式 、 #用户态和内核态堆栈的切换 



![[2015-exam-paper-ocr.pdf#page=2&rect=74,20,535,63|2015-exam-paper-ocr, p.2]]
[[Pasted image 20250930034317.png]]
- [[进程状态模型]] 
	*   **就绪态 (Ready):** 万事俱备，只欠CPU。
    *   **阻塞态 (Blocked):** 缺少CPU以外的某种资源或等待某个事件，即使给了CPU也无法运行。
1.  选项A、B、C都是因为进程需要等待CPU以外的资源或事件而主动放弃CPU，进入阻塞态。只有选项D是进程在依然可以运行的情况下，被动地被操作系统剥夺了CPU使用权，回到了就绪态。因此，D是正确答案。
- 衍生
	- 其他 #状态转换原因  考试可能会问导致其他状态转换的事件。例如：
		*   什么事件导致进程从**阻塞态**变为**就绪态**？（答案：等待的I/O操作完成、申请的资源得到满足等）。
	    *   什么事件导致进程从**就绪态**变为**执行态**？（答案：被进程调度程序选中）。
	    *   在分时系统中，什么事件会导致进程从**执行态**变为**就绪态**？（答案：时间片用完）。
	- [[七状态模型]] 
		- 考点可能涉及：
		    *   从**就绪态**到**静止就绪态**的转换原因是什么？（答案：内存被换出到外存）。
		    *   一个被挂起的阻塞进程，在它等待的I/O事件完成后，会进入什么状态？（答案：静止就绪态）。
	- [[进程同步的经典问题]] 
		$P/V$操作是解决进程同步问题的工具。考试可能会出一些经典问题，要求用$P/V$操作来解决。
		*   生产者-消费者问题
		*   读者-写者问题
		*   哲学家就餐问题
	
		


![[2015-exam-paper-ocr.pdf#page=3&rect=78,741,499,817|2015-exam-paper-ocr, p.3]]
[[Pasted image 20250930034331.png]]

[[死锁预防 vs 死锁避免vs 死锁检测与解除]] 
1. I. S1 会限制用户申请资源的顺序，而 S2 不会
	1. “限制用户申请资源的顺序”（例如，要求所有进程必须按资源编号递增的顺序申请资源）是一种**死锁预防**的手段，其目的是破坏“循环等待”条件
	*   **S1 (死锁避免)**：它不限制申请顺序，而是通过银行家算法等手段动态检查每次分配的安全性。
	*   **S2 (死锁检测)**：它更不会限制申请顺序，它允许死锁发生。
2. II. S1 需要进程运行所需资源总量信息，而 S2 不需要
	*   **S1 (死锁避免)**：其核心算法（如银行家算法）的运行基础就是必须预先知道每个进程对各类资源的**最大需求量 (Max)**，以便计算出每个进程未来还**需要 (Need)** 的资源量，从而判断系统的安全性。
	*   **S2 (死锁检测)**：它只关心**当前**的资源分配状态和进程的等待请求，通过分析资源分配图或类似的等待关系来查找是否存在循环等待。它完全不需要知道进程未来的最大需求。
3. III. S1 不会给可能导致死锁的进程分配资源，而 S2 会 
	1.   **结论**：这个叙述也准确地描述了两种策略的行为模式。**叙述 III 正确**。
- 衍生  
	- [[银行家算法核心思想与数据结构]]








![[2015-exam-paper-ocr.pdf#page=3&rect=78,692,532,747|2015-exam-paper-ocr, p.3]]
[[Pasted image 20250930034341.png]]

[[页式存储管理]]  #LRU [[页面置换算法]]
	- [[高速缓存Cache]] 
- 便捷法（逆向查找法）
	- 跳过重复的4 ，扫描到 **2**，找到第4个不同的页号。当前找到集合：`{5, 4, 8, 2}`。
		- 确定淘汰页：我们已经找到了4个不同的页号，这4个页号 `{5, 4, 8, 2}` 就是在访问页面`7`之前，驻留在内存中的4个页面。我们找到它们的顺序 `5, 4, 8, 2`
		- 淘汰这个最近最久未使用的页面`2`
- 衍生 
	- [[页面置换算法]] 



![[2015-exam-paper-ocr.pdf#page=3&rect=76,642,409,694|2015-exam-paper-ocr, p.3]]
[[Pasted image 20250930034348.png]]

[[缓冲技术]]  
- 衍生  
	- [[写策略]]
		- 数据同时写入缓存和磁盘。
	    *   **优点**：数据一致性好，可靠性高。
	    *   **缺点**：写操作的速度受限于较慢的磁盘，性能提升有限。
	* [[磁盘存储时间的计算（磁盘访问时间的计算）]] 
		* $T_a = T_s + T_r + T_t$
			* **示例**：假设一个磁盘转速为6000 RPM，平均寻道时间为8ms，每磁道有600个扇区，每扇区512字节。读取一个包含1200个扇区的文件的总时间是多少（假设文件数据连续存放）？




![[2015-exam-paper-ocr.pdf#page=3&rect=75,583,527,644|2015-exam-paper-ocr, p.3]]
[[Pasted image 20250930034354.png]]
[[Pasted image 20250930034401.png]]

[[索引文件的储存结构]]  [[多级索引]]  [[文件分配方式（文件物理结构） 文件分配方式的对比]]   [[索引分配]]
- **重要前提**: 文件的索引结点**已在内存中**。这意味着我们获取任何一个直接或间接指针的地址时，不需要访问磁盘。第一次访问磁盘是为了读取索引指针所指向的**索引块**或**数据块** 
1. 计算各级索引能表示的文件大小范围
	1. 在计算访问次数之前，我们首先要确定每个 #偏移量 （byte offset）属于哪个索引范围 
		1. 直接索引
		    *   有10个直接指针，每个指针指向一个数据块。
		    *   可寻址的数据大小为：$10 \times 1\text{KB} = 10\text{KB}$。
		    *   对应的字节偏移范围是 $[0, 10\text{KB} - 1]$，即 $[0, 10239]$。
		2. #一级索引 一级索引可寻址的数据大小为：$256 \times 1\text{KB} = 256\text{KB}$
		3. #二级索引 它覆盖的范围是在一级索引之后，字节偏移范围是 $[10\text{KB} + 256\text{KB}, 10\text{KB} + 256\text{KB} + 64\text{MB} - 1]$，即 $[272384, \dots]$。
 2. 分析具体偏移量的访问次数
	1.  **情况一：偏移量为 1234**
	    1.  **定位范围**: 因为 $1234 < 10240$，所以这个偏移量位于**直接索引**的范围内。
	    2.  **访问过程**:
	        *   由于索引结点已在内存中，系统直接从内存里的索引结点中找到对应的直接指针。（**0次磁盘访问**）
	        *   通过这个指针，系统获得了目标数据块在磁盘上的地址。
	        *   访问磁盘，读取该数据块。 （**1次磁盘访问**）
	    3.  **结论**: 总共需要 **1** 次磁盘访问。
	2.   **情况二：偏移量为 307400**
	    1.  **定位范围**:
	        *   直接索引范围：$[0, 10239]$
	        *   一级索引范围：$[10240, 272383]$
	        *   因为 $307400 > 272383$，所以这个偏移量位于**二级索引**的范围内。
	    2.  **访问过程**:
	        *   索引结点已在内存中，系统从中获取二级索引指针的地址。（**0次磁盘访问**）
	        *   该指针指向一级索引块。访问磁盘，读取这个**一级索引块**。（**第1次磁盘访问**）
	        *   现在一级索引块在内存中了。系统根据偏移量计算出需要用到该块中的哪个指针，这个指针指向二级索引块。
	        *   访问磁盘，读取这个**二级索引块**。（**第2次磁盘访问**）
	        *   现在二级索引块也在内存中了。系统再次根据偏移量计算出需要用到该块中的哪个指针，这个指针最终指向目标数据块。
	        *   访问磁盘，读取这个**数据块**。（**第3次磁盘访问**）
	    3.  **结论**: 总共需要 **3** 次磁盘访问。
两个偏移量所需的磁盘访问次数分别是 **1** 和 **3**。因此，正确答案是 **B**
- 衍生 
	- #索引结点不在内存中  
		- 这是最常见的变种。如果题目没有“索引结点已在内存中”这个前提，那么在所有计算之前，都需要**额外增加1次磁盘访问**来读取索引结点本身。在这种情况下，本题的答案就会变成 **2** 和 **4**。
	- #计算最大文件大小  #最大文件大小计算 
		- 题目可能会问，在这样的索引结构下，一个文件最大可以有多大？
		    *   最大文件大小 = 直接索引大小 + 一级索引大小 + 二级索引大小
		    *   $Size_{max} = (10 \times 1\text{KB}) + (256 \times 1\text{KB}) + (256 \times 256 \times 1\text{KB})$
		    *   $Size_{max} = 10\text{KB} + 256\text{KB} + 64\text{MB}$
	- 包含三级索引
		-  题目可能会增加一个三级索引指针（Triple indirect pointer）。其计算方式与二级索引类似，只是多了一层间接访问。
		- 三级索引可寻址大小 = $256 \times 256 \times 256 \times 1\text{KB} = 16\text{GB}$。
    *   访问三级索引范围内的数据（且索引结点在内存）需要4次磁盘访问（3次读索引块 + 1次读数据块）
- 反向计算
	- 给出文件大小，让你分析最后一个数据块是通过哪种索引方式访问的。例如，一个大小为300KB的文件，其最后一个块肯定是通过二级索引访问的，因为 $10\text{KB} + 256\text{KB} = 266\text{KB} < 300\text{KB}$。



![[2015-exam-paper-ocr.pdf#page=3&rect=79,532,452,584|2015-exam-paper-ocr, p.3]]
[[Pasted image 20250930034409.png]]
[[页面分配策略]] 
 [[页面置换策略]]    
1.  逻辑关系分析 
	1.   **A. 可变分配，全局置换**：
	    *   这种组合是**可行且常见**的。全局置换本身就隐含了“可变分配”的思想。因为当进程A从进程B那里“抢”来一个页框时，进程A的页框数增加了，进程B的减少了。这自然导致了每个进程的页框数是动态变化的。
	2.  **B. 可变分配，局部置换**：
	    *   这种组合也是**可行**的。虽然页面置换的范围是局部的（只能在自己的页框里换），但操作系统仍然可以根据监控到的进程行为（如缺页率）来主动增加或减少分配给该进程的页框总数。例如，当一个进程的缺页率过高，系统可以从空闲页框池中分配一个新的页框给它，这并不违反局部置换的原则。
	3. **C. 固定分配，全局置换**：
	    *   这种组合存在**根本性的逻辑矛盾**。
	    *   **固定分配**的核心要求是：每个进程的页框数量**恒定不变**。
	    *   **全局置换**的核心机制是：一个进程可以从**其他进程**那里获取页框。
	    *   **矛盾点**：如果允许全局置换，那么当进程A从进程B那里置换一个页面时，进程A的页框数就会+1，而进程B的页框数就会-1（在某个时间点上）。这就直接破坏了“固定分配”中每个进程页框数不变的基本前提。
	    *   因此，**固定分配和全局置换是互斥的，不能组合使用**。
	4. **D. 固定分配，局部置换**：
	    *   这种组合是**可行且最简单**的。系统给每个进程固定数量的页框，当进程缺页时，它就在自己的这几个页框里进行置换。进程之间互不干扰，实现简单。
	**结论：** 根据以上分析，选项C是不能组合使用的策略。题目解析中“对各进程进行固定分配时页面数不变，不可能出现全局置换”正是点明了这个核心矛盾。
- 衍生 
	- [[颠簸抖动]] 
		- #抖动/颠簸与策略的关系 
	        *   **局部置换**可以将抖动限制在单个进程内部，不会影响其他进程。
	        *   **全局置换**可能导致“抖动传播”，一个频繁缺页的进程可能会不断抢占其他进程的页面，导致整个系统都陷入抖动状态。
	        *   **可变分配**（特别是基于工作集的分配策略）是解决抖动的主要方法。
	* [[工作集模型]]
		*  **考点**：这是一种典型的**可变分配**策略
	- [[缺页率控制法]] 




![[2015-exam-paper-ocr.pdf#page=3&rect=80,471,514,535|2015-exam-paper-ocr, p.3]]
[[Pasted image 20250930034417.png]]
#文件管理系统 
	[[位图法]]  
-  题目解析 
	1. 第 1 步：计算一个位图盘块能表示多少个磁盘块
		1.  1 字节 = 8 位 (bit)
		*   一个位图盘块的总位数 = $1024 \times 8 = 8192$ 位
	2.  第 2 步：确定 409612 号盘块在位图的哪个盘块中
		1. 计算它在位图中的**相对盘块索引**（从 0 开始）：
		    $i = \lfloor \frac{\text{待释放盘块号}}{\text{每位图块表示的块数}} \rfloor = \lfloor \frac{409612}{1024 \times 8} \rfloor = \lfloor \frac{409612}{8192} \rfloor = \lfloor 50.00146... \rfloor = 50$
		2. 这个结果 `50` 表示，我们要找的 bit 位于位图的第 50 个盘块中  
		3. 计算它在磁盘上的**绝对盘块号**
			1. $盘块号 = \text{位图起始块号} + i = 32 + 50 = 82$
			2. 控制 409612 号盘块状态的那个 bit，存储在磁盘的 **82 号盘块**中
	3. 第 3 步：确定该 bit 在 82 号盘块的哪个字节中 
		1. 已经定位到了 82 号盘块， 现在需要精确定位到是这个盘块里的哪个字节
		2. 计算第 409612 个 bit 在其所在的位图盘块（即 82 号块）内的**相对 bit 位置**（从 0 开始）。这可以通过取模运算得到
			1. $\text{块内bit序号} = \text{待释放盘块号} \pmod{\text{每位图块表示的块数}} = 409612 \pmod{8192} = 12$
		3. 我们要找的 bit 是 82 号盘块中的第 12 个 bit
		4. 将这个**块内 bit 序号**转换为**块内字节序号**。因为每个字节有 8 个 bit，并且字节也是从 0 开始编号的（bit 0-7 在字节 0，bit 8-15 在字节 1，以此类推），我们用 bit 序号除以 8 并取整。
		    $\text{块内字节序号} = \lfloor \frac{\text{块内bit序号}}{8} \rfloor = \lfloor \frac{12}{8} \rfloor = \lfloor 1.5 \rfloor = 1$
		    这个 bit 位于 82 号盘块的**第 1 个字节**中
[[指令周期]]

- 衍生 
	- #计算块内位号 
		-  题目可能会更进一步，问这个 bit 是它所在字节的第几位
		- 计算公式：$\text{字节内bit序号} = \text{块内bit序号} \pmod{8}$ 
	- 反向计算 
		- 题目给出修改了位图中某个盘块的某个字节的某个位，反过来问是哪个磁盘块的状态被改变了
		-  例如：修改了位图起始块后的第 20 个块（即 $32+20=52$ 号块）中的第 100 个字节的第 3 位，求对应的 #磁盘块号
			- 计算：$\text{盘块号} = (\text{相对块索引} \times \text{每块bit数}) + (\text{字节序号} \times 8) + \text{位序号}$ 
			-  $\text{盘块号} = (20 \times 8192) + (100 \times 8) + 3 = 163840 + 800 + 3 = 164643$ 
	- 位图大小计算 
		- 题目给出磁盘总容量和盘块大小，要求计算存储位图需要占用多少个盘块
		- 例如：一个 1TB 的磁盘，盘块大小为 4KB，位图需要多大空间？ 
			-  总盘块数 = $\frac{1 \text{TB}}{4 \text{KB}} = \frac{2^{40}}{2^{12}} = 2^{28}$ 个盘块 
			- 位图大小 = $2^{28}$ bit = $\frac{2^{28}}{8}$ Byte = $2^{25}$ Byte = 32 MB
			-  所需盘块数 = $\lceil \frac{32 \text{MB}}{4 \text{KB}} \rceil = \lceil \frac{2^{25}}{2^{12}} \rceil = \lceil 2^{13} \rceil = 8192$ 个盘块
	- [[磁盘空闲空间管理]] 

![[2015-exam-paper-ocr.pdf#page=3&rect=79,408,531,472|2015-exam-paper-ocr, p.3]]

[[Pasted image 20250930034425.png]]

[[磁盘调度算法]]
-  头也必须继续移动到磁盘的**物理末端**。在这个问题中，最内侧磁道就是199号 
	- 这一阶段的移动路径是 `58 -> 130 -> 180 -> 199`。
	- $移动距离_1 = 199 - 58 = 141$
2.  到达199号磁道后，磁头掉头，开始向外侧（0号磁道）移动。
	1. 移动路径是 `199 -> 42 -> 15`
	2. $移动距离_2 = 199 - 15 = 184$
- 衍生 
	- 其他磁盘调度算法 








![[2015-exam-paper-ocr.pdf#page=3&rect=81,359,445,409|2015-exam-paper-ocr, p.3]]
[[Pasted image 20250930034432.png]]

[[（不）可靠服务]] 
[[邮局协议第3版POP3]]
[[有链接服务与无链接服务]] 
[[TCP IP参考模型(OSI与TCPIP模型的对比）]]
1. #传输层  
	传输层主要提供两种核心服务，由两个主要协议实现：
    *   **TCP (Transmission Control Protocol, 传输控制协议)**：它提供的是 **面向连接的、可靠的** 数据传输服务。
        *   **面向连接 (Connection-oriented)**：在数据传输前，必须先建立一个连接（三次握手），传输结束后再释放连接（四次挥手）。这就像打电话，必须先拨号接通才能通话。
        *   **可靠的 (Reliable)**：TCP 通过序列号、确认应答（ACK）、超时重传、流量控制和拥塞控制等机制，确保数据能够完整、无误、按序地到达目的地。
    *   **UDP (User Datagram Protocol, 用户数据报协议)**：它提供的是 **无连接的、不可靠的** 数据传输服务。
        *   **无连接 (Connectionless)**：发送数据前不需要建立连接，直接把数据包（数据报）发送出去。这就像寄平信，写好地址就投进邮筒，不管对方是否准备好接收。
        *   **不可靠的 (Unreliable)**：UDP 不保证数据包的交付、不保证顺序、也不保证数据的完整性。它追求的是简单、高效、低延迟。
	 **分析 POP3 协议的需求**：POP3 (Post Office Protocol version 3) 是用来从邮件服务器上**接收**电子邮件的。电子邮件的内容必须是完整和准确的，不能丢失任何一个字节，也不能出现乱序，否则邮件将无法阅读或内容错误。因此，POP3 协议对数据传输的**可靠性**有非常高的要求。

- 衍生 
	- [[邮件协议的区别和联系]] **考点**: 可能会问发送邮件用什么协议？或者比较 POP3 和 IMAP 的优缺点
	- [[TCP的可靠性保证]] 
	- #TCP连接管理 
		- [[TCP四次挥手]]  [[TCP三次握手]]    
		- **考点**: 可能会考查握手和挥手过程中各个 #报文段的标志位 （SYN, ACK, FIN）以及状态变迁。
	- #协议与端口号  [[协议与端口号]]  
		-    *   **考点**: 直接考察某个协议使用的默认端口号和传输层协议。


![[2015-exam-paper-ocr.pdf#page=3&rect=80,201,491,357|2015-exam-paper-ocr, p.3]]
[[Pasted image 20250930034439.png]]
[[曼彻斯特编码]]
[[编码方式]]
1. #不归零编码NRZ   高电平代表'1'，低电平代表'0' 
2. #不归零反相编码NRZI    信号电平跳变代表'1'，不跳变代表'0'
3. #曼彻斯特编码  #每一个比特位的时间（码元周期） 被分成前后两个相等的部分。
	**电平跳变**: 在每个 #码元周期 的**中间时刻**，信号电平一定会发生一次跳变。这个跳变既用于表示数据，也用于同步接收方和发送方的时钟。 
	 - **两种约定**: 存在两种相反的编码约定，题目中没有明确指出使用哪一种，因此需要我们根据选项进行尝试。
	    *   **约定一 (IEEE 802.3 标准)**:
	        *   **0**: 由 **高电平** 跳变为 **低电平**
	        *   **1**: 由 **低电平** 跳变为 **高电平**
	    *   **约定二 (G.E. Thomas 提出，有时也用)**:
	        *   **0**: 由 **低电平** 跳变为 **高电平**
	        *   **1**: 由 **高电平** 跳变为 低电平
4. #差分曼彻斯特编码      每个码元周期的**中间时刻**同样有一次电平跳变（用于同步时钟）。
    *   数据的表示依赖于码元周期**开始时**是否存在电平跳变。
    *   **0**: 码元周期**开始时**有电平跳变。
    *   **1**: 码元周期**开始时**无电平跳变。
- 衍生 
	- #波形绘制 
		- 给你一段比特流（如 `10011010`）和一种编码方案（如差分曼彻斯特编码），要求你画出对应的 #信号波形图 。
	- [[编码方式的优缺点比较]]  比较不同编码方案的优缺点，特别是从 **同步能力**、**直流分量** 和 **带宽效率**（或波特率与比特率的关系）三个方面进行比较。
	- [[比特率 波特率 码元]] 
		- 区分 **比特率 (Bit Rate)** 和 **波特率 (Baud Rate)**
	- **其他编码方案**：可能会考察其他编码方案，如 #AMI编码 (Alternate Mark Inversion)  或 #HDB3编码 ，它们是NRZ的改进，旨在解决 #同步和直流分量问题 ，同时保持较高的带宽效率

![[2015-exam-paper-ocr.pdf#page=3&rect=77,141,515,201|2015-exam-paper-ocr, p.3]]
[[Pasted image 20250930034447.png]]
[[差错控制与流量控制]]
[[滑动窗口协议]]
 #滑动窗口协议 
#帧序号的比特数 
#往返时延RTT  
1. 计算发送时延 ($t_t$) 
	1. 发送一个帧所需的时间为：
		$t_t = \frac{L}{C} = \frac{8000 \text{ bits}}{128 \times 10^3 \text{ bps}} = 0.0625 \text{ s} = 62.5 \text{ ms}$
	2. 计算往返时间 ( #往返时延RTT  
		1. 数据从主机甲发送到主机乙，然后确认信息从乙返回到甲，总共需要两次单向传播。
			$RTT = 2 \times t_p = 2 \times 250 \text{ ms} = 500 \text{ ms}$
	3. 根据 #信道利用率 计算所需的 #最小窗口大小 (W) 
		1.  #信道利用率的公式 为：
			$\eta = \frac{W \times t_t}{t_t + RTT}$ 
		2. 根据题目要求，$\eta \ge 0.8$
			1. $\frac{W \times 62.5 \text{ ms}}{62.5 \text{ ms} + 500 \text{ ms}} \ge 0.8$
			2. $\frac{W \times 62.5}{562.5} \ge 0.8$ 
			3. $W \times 62.5 \ge 0.8 \times 562.5$ 
				$W \times 62.5 \ge 450$
				$W \ge \frac{450}{62.5}$
				$W \ge 7.2$
				由于窗口大小 W 必须是整数，所以 W 至少要取 **8**。
	4. 根据窗口大小计算所需的 #最小序号位数 (k)
		1. $W \le 2^k - 1$
		2. $8 \le 2^k - 1$
	 5. 所以，k 的最小值是 **4**。
- 衍生 
	- [[选择重传协议SR]] 
		- SR 协议对窗口大小和序号位数的关系是：发送窗口 + 接收窗口 $\le 2^k$
			- 为了最大化利用序号，会设置发送窗口 = 接收窗口 = $2^{k-1}$
		- 对于 SR 协议，关系式为 $W \le 2^{k-1}$ 
	- [[停等协议]]  这是窗口大小 W=1 的特例。可以计算一下本题中如果用停等协议，信道利用率是多少：
        $\eta = \frac{1 \times 62.5}{62.5 + 500} = \frac{62.5}{562.5} \approx 11.1\%$。可以看到，对于高延迟的卫星链路，停等协议的效率非常低。
	-  #最大信道利用率100 的条件 [[最大信道利用率]]
		- 要使 #最大信道利用率100 ，发送方必须在第一个帧的确认到达之前，能够一直不停地发送数据。这段时间是 $t_t + RTT$。在这段时间内，发送方可以发送的帧数是 $\frac{t_t + RTT}{t_t}$。因此，要达到100%的利用率，窗口大小 W 必须满足：
		    $W \ge \frac{t_t + RTT}{t_t} = 1 + \frac{RTT}{t_t} = 1 + \frac{2 \times t_p}{t_t}$
		    这个比值 $\frac{t_p}{t_t}$ 通常用字母 a 表示，所以 $W \ge 1+2a$
	- 反向计算 
		- 题目也可能反过来问：给定 k 位序号，采用 GBN 协议，能达到的最大信道利用率是多少？ 
			- 例如，如果 k=3，则最大窗口大小 $W = 2^3 - 1 = 7$。
			    最大利用率 $\eta = \frac{7 \times 62.5}{62.5 + 500} = \frac{437.5}{562.5} \approx 77.8\%$。
		

![[2015-exam-paper-ocr.pdf#page=3&rect=78,58,356,140|2015-exam-paper-ocr, p.3]]
[[Pasted image 20250930034455.png]]
[[CSMA-CD协议的工作原理]]


- CSMA/CD 其核心思想就是“先听后发，边发边听”。 
- CSMA/CD 是为 **有线** 以太网设计的 
- #最小帧长限制 是为了确保在帧发送完毕之前，发送方一定能检测到可能发生的冲突。  [[CSMA-CD最小帧长问题]] 
- D. 当信号传播延迟趋近 0 时，信道利用率趋近 100% 
	- 我们定义一个重要参数 $a$，它表示单向传播时延 $\tau$ 与帧发送时间 $T_{fr}$ 的比值：
        $a = \frac{\tau}{T_{fr}}$ 
	- 这个参数 $a$ 的值越小，意味着传播延迟相对于发送一帧的时间来说越短，发生冲突的概率就越低，或者说因冲突浪费的时间占比越小，信道利用率就越高。CSMA/CD 的极限信道利用率 $S_{max}$ 可以表示为：
        $S_{max} = \frac{1}{1+2a}$
    *   当信号传播延迟 $\tau \to 0$ 时，参数 $a \to 0$。此时，
        $S_{max} = \frac{1}{1+2 \times 0} = 1$

-  衍生 
	- [[CSMA-CD协议的工作原理]] 载波侦听  多点接入  冲突检测
	- [[CSMA-CA vs CSMA-CD]]
	- #二进制指数退避算法  **目的:** 发生冲突后，让各站点等待一个随机的时间再重传，以避免再次冲突。[[二进制指数退避算法]]
	- #CSMA/CD性能分析
		- **关键参数:** $a = \frac{\tau}{T_{fr}}$。为了提高性能，应让 $a$ 尽可能小
		-   #提高信道利用率的方法:
		    *   减小 $\tau$：意味着减小网络跨距（电缆长度）。
		    *   增大 $T_{fr}$：意味着发送更长的数据帧。
		*   这解释了为什么在高速以太网（如千兆以太网）中，要么保持最小帧长不变但大大缩短网络跨距，要么采用“载波延伸”和“帧突发”等技术来等效地增加帧的发送时间。



![[2015-exam-paper-ocr.pdf#page=4&rect=75,745,356,820|2015-exam-paper-ocr, p.4]]
[[Pasted image 20250930034503.png]]
[[交换机的工作方式]]  [[冲突域与广播域]]  
#多端口网桥 
#冲突域  
#广播域  
1. [[网桥]]  #交换机与网桥的关系  
	1.  因为交换机在功能和工作原理上与网桥相同（基于MAC地址转发），但提供了更多的端口和更高的转发效率（通常通过专用的ASIC硬件实现），所以说它“本质上是一种多端口网桥”是完全正确的 
2. B. 通过交换机互连的一组工作站构成一个冲突域 (错误) 
	1.  交换机的一个核心功能就是**隔离冲突域**。每个交换机端口本身就是一个独立的冲突域。因此，通过交换机连接的一组工作站**不构成一个**冲突域，而是构成了**多个**冲突域（每个端口一个）。这个选项的描述是错误的。
3.  交换机每个端口所连网络构成一个独立的广播域 (错误)
	1. **什么是广播域？** 网络中可以接收到同一个广播帧（目标MAC地址为 $FF:FF:FF:FF:FF:FF$）的所有设备的集合，构成一个广播域。
	2.  #交换机如何处理广播 作为一个标准的第二层设备，交换机无法识别第三层（网络层）的IP地址。当它收到一个广播帧时，它无法确定具体的目标设备，其默认行为是**将该广播帧转发到除接收端口外的所有其他端口**。
	3. 因此，连接在同一台交换机（未配置VLAN的情况下）上的所有设备都属于**同一个广播域**。能够隔离（或分割）广播域的设备是路由器（Router）或其他第三层设备。所以，“每个端口构成一个独立的广播域”是错误的。
4.  D. 以太网交换机可实现采用不同网络层协议的网络互联 (错误) 
	1.  #设备与层级匹配   [[设备分配的定义]]  [[设备与层级]] 
		1. 交换机（Switch）是**第二层*设备，它处理的是**数据帧（Frame）**，并根据**MAC地址**进行转发 
		2.  实现不同网络（例如不同IP子网）之间的互联，需要处理第三层（网络层）的数据包（Packet），并根据**IP地址**等网络层地址进行寻址和转发。这是路由器（Router）的工作  
		3. **协议的互联：** 要连接采用不同网络层协议（如IP协议和早已淘汰的IPX协议）的网络，必须有一个能够理解并转换这两种协议的设备，这显然是网络层的功能。
		4.    **结论：** 标准的以太网交换机（也称二层交换机）不具备网络层的功能，它对IP地址等网络层信息是“透明”的。因此，它不能实现不同网络层协议的网络互联。这个选项是错误的。

- 衍生 
	- [[冲突域与广播域的分割]] 
	- [[虚拟互联网VLAN]]   这是交换机功能的一个重要扩展。虽然交换机默认不 #分割广播域 ，但通过配置VLAN，可以在一台物理交换机上划分出多个逻辑上的广播域。一个VLAN就是一个独立的广播域。这是非常高频的考点






![[2015-exam-paper-ocr.pdf#page=4&rect=78,622,507,742|2015-exam-paper-ocr, p.4]]
[[Pasted image 20250930034508.png]]

#路由表 
[[IP分组的生命周期]]
 #最长前缀匹配[[最长前缀匹配]]  
**4. 检查路由 `0.0.0.0/0`**
*   **网络前缀**：`/0`，表示匹配任意IP地址。这被称为**默认路由** (Default Route)。
*   **结论**：**匹配**。匹配长度为 **0** 位。
找到了四个匹配的路由，它们的匹配长度分别是 23, 25, 27, 和 0。
根据**最长前缀匹配原则**，路由器会选择前缀最长的那一个。
$max(23, 25, 27, 0) = 27$
所以，路由器最终选择 `169.96.40.0/27` 这条路由
- 衍生 
	- #CIDR无类域间路由  
		- 题目中的 `/23`, `/25`, `/27` 写法就是CIDR表示法。它废除了传统的A、B、C类网络划分，允许使用任意长度的前缀来定义网络，极大地提高了IPv4地址的利用率
		-    **衍生考点**：
		    *   **子网掩码转换**：能够快速地在CIDR前缀（如 `/23`）和点分十进制子网掩码（如 `255.255.254.0`）之间进行转换。
		    *   **计算公式**：对于前缀 `/n`，子网掩码的前 `n` 位为1，后 `32-n` 位为0。
	- #IP地址与子网掩码 的“与”运算 
		- $IP_{destination} \ \& \ SubnetMask = NetworkAddress$ 
	-  #路由聚合   [[路由聚合（路由汇总-超网）]]  
		-  #计算汇总路由 ：给出多个网络地址，要求计算出能包含所有这些地址的最短前缀（最概括）的汇总路由。例如，汇总 `192.168.0.0/24` 和 `192.168.1.0/24`，可以得到 `192.168.0.0/23`。
	- [[默认路由]] 

![[2015-exam-paper-ocr.pdf#page=4&rect=80,544,530,618|2015-exam-paper-ocr, p.4]]
[[Pasted image 20250930034516.png]]
- [[TCP流量控制与拥塞控制]]  
- [[往返时延RTT]]  #接收缓存  #计算机网络入门题目  
1. 计算 #拥塞窗口 (`cwnd`) 的变化
	1. TCP的拥塞控制在开始时处于 #慢启动 (Slow Start)  阶段。在此阶段，`cwnd`的初始值通常为 1 MSS，并且每经过一个RTT，`cwnd`就会翻倍（指数增长），直到`cwnd`达到`ssthresh`。
		*   **连接建立时 (0 RTT)**:
		    $cwnd = 1 \times MSS = 1KB$
		    (此时甲发送1KB数据)
		*   **经过 1 个 RTT后**:
		    收到1KB数据的ACK，`cwnd`翻倍。
		    $cwnd = 2 \times 1KB = 2KB$
		    (此时甲发送2KB数据)
		*   **经过 2 个 RTT后**:
		    收到2KB数据的ACK，`cwnd`翻倍。
		    $cwnd = 2 \times 2KB = 4KB$
		    (此时甲发送4KB数据)
		*   **经过 3 个 RTT后**:
		    收到4KB数据的ACK，`cwnd`翻倍。
		    $cwnd = 2 \times 4KB = 8KB$
		    (此时甲发送8KB数据)
		*   **经过 4 个 RTT后**:
		    收到8KB数据的ACK，`cwnd`翻倍。
		    $cwnd = 2 \times 8KB = 16KB$
		在这个过程中，`cwnd`的值（1, 2, 4, 8, 16 KB）始终小于或等于`ssthresh`（32 KB），所以整个过程都处于慢启动阶段。
		因此，在第4个RTT结束时，甲的**拥塞窗口 `cwnd` 为 16KB**
2. 计算 #接收窗口 (`rwnd`) 的变化 
	1. 题目给出的条件：
		*   乙为该连接分配了 16KB 的接收缓存 (`rcvBuffer`)。
		*   **关键信息**: 乙收到的数据**全部存入缓存，不被取走**。这意味着乙的应用程序没有从缓存中读取数据。
		
		接收窗口`rwnd`的大小等于接收缓存的总大小减去已缓存的数据量。
		$rwnd = rcvBuffer_{total} - rcvBuffer_{used}$
		
		我们来计算乙的缓存被占用了多少：
		*   在第1个RTT内，乙收到了 $1KB$ 数据。
		*   在第2个RTT内，乙收到了 $2KB$ 数据。
		*   在第3个RTT内，乙收到了 $4KB$ 数据。
		*   在第4个RTT内，乙收到了 $8KB$ 数据。
		到第4个RTT结束时，乙的缓存中累计收到的数据总量为：
		$rcvBuffer_{used} = 1KB + 2KB + 4KB + 8KB = 15KB$
		此时，乙的接收缓存剩余空间为：
		$rwnd = 16KB - 15KB = 1KB$
	
		乙会将这个 1KB 的值放在ACK报文中通告给甲。因此，在第4个RTT结束时，甲收到的**接收窗口 `rwnd` 为 1KB**。
1.  3. 计算最终的发送窗口
	根据 #TCP流量控制与拥塞控制核心公式  ，甲的实际发送窗口是`cwnd`和`rwnd`中的较小值。
	$发送窗口 = \min(cwnd, rwnd) = \min(16KB, 1KB) = 1KB$
	所以，经过4个RTT后，甲的发送窗口是 **1KB**。 **答案选 A。**

- 衍生 
	- 进入拥塞避免阶段 #拥塞避免 
		-  **问题变种**: 如果初始`ssthresh`设为8KB，问经过4个RTT后`cwnd`是多少？
	  - **解析**:
        *   前3个RTT同上，`cwnd`分别变为2KB, 4KB, 8KB。
        *   当`cwnd`达到8KB（等于`ssthresh`）后，TCP会从**慢启动**切换到**拥塞避免 (Congestion Avoidance)** 阶段。
        *   在拥塞避免阶段，`cwnd`不再指数增长，而是线性增长，即每个RTT增加 1 MSS。
        *   所以经过第4个RTT后，$cwnd = 8KB + 1MSS = 9KB$。
	* 发生 #网络拥塞
		* **问题变种**: 如果在甲发送8KB数据后（第3个RTT后），发生了**超时 (Timeout)**，那么接下来的`ssthresh`和`cwnd`会变成多少？ 
	    *   **解析**: 超时是严重的拥塞信号。
	        *   `ssthresh`会被更新为当前`cwnd`的一半：$ssthresh = \frac{cwnd}{2} = \frac{8KB}{2} = 4KB$。
	        *   `cwnd`被重置为初始值 1 MSS，即 $cwnd = 1KB$。
	        *   TCP重新进入慢启动阶段。
	- 发生 #快速重传 
		-  **问题变种**: 如果在甲发送8KB数据后，收到了3个重复的ACK（Triple Duplicate ACKs），那么接下来的`ssthresh`和`cwnd`会变成多少？ 
		 - **解析**: 收到3个重复ACK被认为是较轻微的拥塞信号，会触发[[快速重传]]和快速恢复。
		        *   `ssthresh`更新为当前`cwnd`的一半：$ssthresh = \frac{cwnd}{2} = \frac{8KB}{2} = 4KB$。
		        *   `cwnd`也减半，而不是重置为1：$cwnd = ssthresh = 4KB$。
		        *   随后直接进入拥塞避免阶段，而不是慢启动。
	* #接收方应用程序消耗数据  
		*  **问题变种**: 如果乙的应用程序在每个RTT结束时会从缓存中读取2KB数据，问4个RTT后甲的发送窗口是多少？
	    *   **解析**: 这会改变`rwnd`的计算。
	        *   1 RTT后: 缓存占用 1KB。`rwnd`=15KB。应用读取2KB（实际只能读1KB），缓存清空。`rwnd`变为16KB。
	        *   2 RTT后: 缓存占用 2KB。`rwnd`=14KB。应用读取2KB，缓存清空。`rwnd`变为16KB。
	        *   ... 以此类推，如果应用消耗速度大于或等于数据到达速度，`rwnd`将始终保持较大值（16KB）。
	        *   这种情况下，发送窗口将完全由`cwnd`决定，即 $发送窗口 = \min(16KB, 16KB) = 16KB$。
	
		



![[2015-exam-paper-ocr.pdf#page=4&rect=75,424,494,544|2015-exam-paper-ocr, p.4]]
[[Pasted image 20250930034522.png]]

#请求报文   [[HTTP请求报文结构]] 
[[HTTP链接方式]] 
[[Cookie和HTTP的无状态性]] 

我们来逐行解读这个HTTP请求报文：

1.  `GET /index.html HTTP/1.1`
    *   **`GET`**: 这是HTTP请求方法，表示客户端（浏览器）希望从服务器**获取（GET）**一个资源。
    *   **`/index.html`**: 这是请求的资源的路径（URI）。客户端想要获取名为 `index.html` 的文件。
    *   **`HTTP/1.1`**: 这是所使用的HTTP协议的版本号。

2.  `Host: www.test.edu.cn`
    *   **`Host`**: 这是一个必需的请求头字段（自HTTP/1.1起）。它指定了请求的目标服务器的域名。这使得一个服务器（拥有一个IP地址）可以托管多个网站。

3.  `Connection: Close`
    *   **`Connection`**: 这个请求头字段用于控制网络连接在当前事务完成后是否保持打开。
    *   **`Close`**: 这个值明确告诉服务器，在发送完响应后，应该关闭这个TCP连接。这是一种**非持续连接**（Non-persistent Connection）的请求。

4.  `Cookie: 123456`
    *   **`Cookie`**: 这个请求头字段包含了之前由服务器通过 `Set-Cookie` 响应头发送给客户端并由客户端存储的数据。当客户端再次向同一个服务器发送请求时，会附上这个Cookie。
    *   它的存在表明，这个浏览器**之前已经访问过**这个服务器，并且服务器给它设置了一个Cookie。

- 衍生 
	- [[HTTP方法]]   
	- #HTTP状态码 [[HTTP状态码]] 
	- HTTP/1.1 vs HTTP/2.0 [[HTTP 协议版本演进]]
	- [[HTTPS]]  
	- [[Web缓存]] 



![[2015-exam-paper-ocr.pdf#page=4&rect=75,199,536,427|2015-exam-paper-ocr, p.4]]
[[Pasted image 20250930034541.png]]
 #单链表节点 #数据类型定义 #数组
#哈希表 
[[数组]]
1.    创建一个大小为 $n+1$ 的整型数组 `q`，并将其所有元素初始化为 0。
	1.  使用一个指针 `p` 指向链表的头节点 `h`（答案代码中 `p` 指向头结点，实际操作的是 `p->link`，这是一种常见的删除技巧）。
	2.  遍历链表（`while (p->link != NULL)`）：
	    a.  取出当前要检查的节点 `p->link`，计算其数据 `data` 的绝对值，记为 `m`。
	    b.  检查 `q[m]` 的值：
		*   如果 `q[m] == 0`：说明这是绝对值 `m` 第一次出现。我们保留这个节点。将 `q[m]` 设为 1，然后将指针 `p` 后移一位（`p = p->link`）。
		*   如果 `q[m] == 1`：说明绝对值 `m` 是重复的。我们需要删除 `p->link` 这个节点。具体操作是：让 `p` 的 `link` 指针绕过 `p->link`，直接指向 `p->link->link`，然后释放原 `p->link` 节点的内存。注意，此时 `p` **不能后移**，因为 `p` 的下一个节点已经换成了新的，需要继续对这个新的 `p->link` 进行判断。
	3.  遍历结束后，释放辅助数组 `q` 的内存。
 #节点定义 
- 哈希表 
```c++

#include <iostream>
#include <unordered_set> // 包含哈希集合的头文件
#include <cmath>

// #节点定义 (同上)
struct ListNode {
    int data;
    ListNode* next;
    ListNode(int val) : data(val), next(nullptr) {}
};
//- ListNode(int val): 这是一个**构造函数 (constructor)**。构造函数是一个特殊的函数，它的名字和结构体的名字完全一样。当你创建一个新的 ListNode 对象时，这个函数会自动被调用。int val 表示在创建节点时，你必须提供一个整数值。: data(val), next(nullptr): 这部分叫做成员初始化列表 (member initializer list)。这是一种在 C++ 中初始化成员变量的高效且推荐的方式。
    //- data(val): 它的意思是，把传入构造函数的参数 val 的值，赋给成员变量 data。
        
   // - next(nullptr): 它的意思是，将成员变量 next 指针初始化为 nullptr。nullptr 是 C++11 引入的关键字，代表“空指针”，表示这个指针当前不指向任何有效的内存地址。这是一个非常好的默认行为，因为一个新创建的节点，默认情况下就是孤立的，它的后面还没有连接任何其他节点。
	//{}: 这是构造函数的函数体，这里是空的，因为所有的初始化工作都在成员初始化列表里完成了。
/**
 * @brief 使用哈希集合删除单链表中绝对值重复的节点。
 * @param head 指向链表哑元头节点的指针。
 * @note 这个版本不再需要参数 n，因为它不依赖于数据范围。
 */
void removeDuplicateAbsValues_hash(ListNode* head) {
    if (head == nullptr || head->next == nullptr) {
        return;
    }

    // 1. 创建哈希集合来存储已经出现过的绝对值
    std::unordered_set<int> seen;

    // 2. 遍历链表
    ListNode* p = head; // p 是前驱指针

    while (p->next != nullptr) {
        int abs_val = std::abs(p->next->data);

        // 使用 find() 方法检查元素是否存在。
        // 如果 find() 返回 end() 迭代器，说明元素不在集合中。
        if (seen.find(abs_val) == seen.end()) {
            // 如果这个绝对值是第一次出现
            seen.insert(abs_val); // 将其插入到集合中
            p = p->next;          // 保留节点，p 后移
        } else {
            // 如果这个绝对值已经出现过，删除 p->next 节点
            ListNode* node_to_delete = p->next;
            p->next = node_to_delete->next;
            delete node_to_delete;
            // p 不移动
        }
    }
}
```

**代码关键点解释**：
*   **前驱指针 `p`**：代码中使用 `p` 作为待考察节点 `p->link` 的前一个节点。这样做的好处是，当需要删除 `p->link` 时，我们可以方便地修改 `p->link` 的指向来完成删除操作。这是单链表删除操作的常用技巧。
*   **`p` 不移动的情况**：在 `else` 分支（删除节点时），`p` 指针没有后移。这是一个非常重要的细节。因为删除了 `p->link` 之后，`p` 的下一个节点变成了原来 `p->link` 的下一个节点，这个新节点是未经检查的，所以循环需要继续从 `p` 的位置开始，检查新的 `p->link`。

4. 复杂度分析
	*   **时间复杂度**：
	    *   分配和初始化辅助数组 `q` 的时间是 $O(n)$。
	    *   `while` 循环遍历整个链表一次。设链表长度为 $L$，循环体内的操作（取绝对值、数组访问、指针修改）都是 $O(1)$ 的。所以循环部分的时间是 $O(L)$。
	    *   总的时间复杂度是 $O(L+n)$。通常在描述算法复杂度时，如果 $L$ 和 $n$ 是两个独立的变量，我们会写成 $O(L+n)$。如果题目场景暗示 $L$ 远大于 $n$ 或反之，可能会简化。答案给出的 $O(m)$ 是一个笔误，应为 $O(L)$ 或 $O(L+n)$（此处 `m` 可能是想表示链表长度）。
	*   **空间复杂度**：
	    *   算法使用了一个辅助数组 `q`，其大小为 $n+1$。
	    *   因此，额外使用的空间与 `n` 成正比。
	    *   空间复杂度为 $O(n)$。
-  衍生 
	- 取消 `|data| <= n` 的约束 
		- **问题**：如果 `data` 的值没有范围限制，或者范围极大（如 `n` 是 $10^9$），那么创建一个大小为 `n+1` 的数组就会导致内存溢出。
	    *   **解决方案**：此时应该使用**哈希表 (Hash Set)** 来代替数组。将遇到的绝对值存入哈希表中。哈希表平均查找和插入的时间复杂度也是 $O(1)$。 
	    *   **复杂度**：时间复杂度为 $O(L)$，空间复杂度为 $O(k)$，其中 $k$ 是链表中不同绝对值的个数 ($k \le L$)。 
	- 要求 $O(1)$ 的空间复杂度**：
	    *   **问题**：不允许使用辅助数组或哈希表等额外空间。
	    *   **解决方案**：
	        *   **暴力法**：即前面提到的 $O(L^2)$ 的双重循环方法。
			*   #先排序再删除 ：先对链表进行排序（例如，归并排序，时间复杂度 $O(L \log L)$），排序后所有绝对值相同的节点都会相邻。然后再次遍历链表，只需比较相邻节点即可删除重复项，这一步是 $O(L)$。总时间复杂度为 $O(L \log L)$。	
	- #删除规则 改变
		- **保留最后一个出现的节点**：可以先将链表**翻转**，然后应用原题的算法（保留第一个），最后再将结果链表**翻转**回来。
	    *   **删除所有重复的节点**：只要一个数的绝对值出现超过一次，所有该绝对值的节点都删除。例如 `1 -> 2 -> -1 -> 3`，结果为 `2 -> 3`


![[2015-exam-paper-ocr.pdf#page=4&rect=79,35,548,197|2015-exam-paper-ocr, p.4]]
[[Pasted image 20250930034556.png]]
[[Pasted image 20250930034605.png]]
- [[邻接矩阵，邻接表 ，稀疏图，稠密图]] 
	[[矩阵乘法的运算法则]] 
1. $A = \begin{bmatrix} 0 & 1 & 1 & 0 & 1 \\ 1 & 0 & 0 & 1 & 1 \\ 1 & 0 & 0 & 1 & 0 \\ 0 & 1 & 1 & 0 & 1 \\ 1 & 1 & 0 & 1 & 0 \end{bmatrix}$ 
2. (2) 求 $A^2$，并解释矩阵 $A^2$ 中位于0行3列元素的含义 
	1.  $A^2 = A \times A$。
		$A^2 = \begin{bmatrix} 0 & 1 & 1 & 0 & 1 \\ 1 & 0 & 0 & 1 & 1 \\ 1 & 0 & 0 & 1 & 0 \\ 0 & 1 & 1 & 0 & 1 \\ 1 & 1 & 0 & 1 & 0 \end{bmatrix} \times \begin{bmatrix} 0 & 1 & 1 & 0 & 1 \\ 1 & 0 & 0 & 1 & 1 \\ 1 & 0 & 0 & 1 & 0 \\ 0 & 1 & 1 & 0 & 1 \\ 1 & 1 & 0 & 1 & 0 \end{bmatrix}$

		我们重点计算位于0行3列的元素，记为 $(A^2)_{03}$。该元素的值是 $A$ 的第0行与 $A$ 的第3列的点积。
		*   $A$ 的第0行: `[0 1 1 0 1]`  #矩阵乘法法则 
		*   $A$ 的第3列: `[0 1 1 0 1]` #邻接矩阵的幂  [[邻接矩阵的性质]]    

		$(A^2)_{03} = (0 \times 0) + (1 \times 1) + (1 \times 1) + (0 \times 0) + (1 \times 1) = 0 + 1 + 1 + 0 + 1 = 3$
		含义解释:
			根据“知识点介绍”中的第3点，$(A^2)_{03}$ 的值表示从顶点0到顶点3，长度为2的路径数量。
			值为3，意味着共有3条这样的路径。我们可以在图中验证一下：
			1.  `0 -> 1 -> 3`
			2.  `0 -> 2 -> 3`
			3.  `0 -> 4 -> 3`
			确实有3条。因此，答案“0行3列的元素值3表示从顶点0到顶点3之间长度为2的路径共有3条”是完全正确的。
1. (3) 解释 $B^m$ 中非零元素的含义
	1. 普适性的问题。对于一个具有 $n$ 个顶点的图，其邻接矩阵为 $B$
	2. 根据邻接矩阵幂的性质，矩阵 $B^m$ 中位于 $i$ 行 $j$ 列的元素 $(B^m)_{ij}$ 的值，代表了**图中从顶点 $i$ 到顶点 $j$ 长度为 $m$ 的路径的数量**。 
	3. 题目问的是**非零元素**的含义。
		*   如果 $(B^m)_{ij} > 0$，说明从顶点 $i$ 到顶点 $j$ 存在长度为 $m$ 的路径，其具体的数值就是路径的数量。
		*   如果 $(B^m)_{ij} = 0$，说明从顶点 $i$ 到顶点 $j$ 不存在任何长度为 $m$ 的路径。
	4. 所以，一个非零元素的含义就是：**在图中，从顶点 $i$ 到顶点 $j$ 存在长度为 $m$ 的路径，且路径的数量就是该元素的值。**
		答案中的描述“图中从顶点 $i$ 到顶点 $j$ 长度为 $m$ 的路径条数”是这个含义的准确概括。
- 衍生 
	- #顶点的度  [[顶点的度]]
		- 对于 #无向简单图 ，顶点 $i$ 的度是与它相连的边的数量。这个值恰好是 $A^2$ 的对角线元素 $(A^2)_{ii}$。
		-  #图的连通性[[图的连通性]]
			- 一个图是连通的，当且仅当对于任意两个不同的顶点 $i$ 和 $j$，都存在一条从 $i$ 到 $j$ 的路径。
		    *   这等价于说，对于任意 $i \neq j$，在矩阵之和 $S = A + A^2 + \dots + A^{n-1}$ 中，元素 $S_{ij}$ 必须大于0。因为在有 $n$ 个顶点的连通图中，任意两点间的最短路径长度不会超过 $n-1$。
	- #可达矩阵   
		- 通过计算 $R = A \lor A^2 \lor \dots \lor A^{n-1}$（这里 $\lor$ 表示布尔矩阵乘法中的逻辑或运算），可以得到可达性矩阵。$R_{ij}=1$ 表示顶点 $j$ 从顶点 $i$ 可达
	- #计算环路数量  #环路检测 
		- 矩阵 $A^m$ 的迹（主对角线上元素的和），即 $Tr(A^m) = \sum_{i=0}^{n-1} (A^m)_{ii}$，表示图中所有长度为 $m$ 的闭合路径（环路）的总数
		-  例如，$Tr(A^3)$ 记录了所有长度为3的环路数量。在一个简单无向图中，每个长度为3的环（即三角形）会被每个顶点计算两次（如 $0 \to 1 \to 2 \to 0$ 和 $0 \to 2 \to 1 \to 0$），所以图中三角形的数量是 $Tr(A^3) / 6$。

![[2015-exam-paper-ocr.pdf#page=5&rect=68,410,562,823|2015-exam-paper-ocr, p.5]]
[[Pasted image 20250930034616.png]]
[[1.寄存器]]  #计算机体系结构入门题目  
#暂存器      [[微程序控制器和硬布线控制器的区别]]  [[指令寻址方式]]
1，2，3，5，8须连接到控制部件输出端
 - (1) 图中哪些寄存器是程序员可见的？为何要设置暂存器T？ 
 1. 第一部分：程序员可见寄存器 
	 1. **推导**：程序员可见寄存器是指令系统中可以直接引用的寄存器。
        *   **通用寄存器 (R0~R3)**：用于存放操作数、运算结果或地址，是典型的程序员可见寄存器。例如，`ADD R1, R2` 指令直接操作它们。
        *   **程序计数器 (PC)**：存放下一条待执行指令的地址。虽然程序员不常直接给PC赋值，但转移/跳转指令（如 `JMP`、`CALL`）和分支指令（如 `BEQ`）的本质就是修改PC的值，因此PC是程序员可见的。
        *   **其他寄存器**：MAR、MDR、IR、T等是在指令执行周期中由硬件自动使用的，程序员无法通过指令直接读写，故不可见。
    *   **结论**：程序员可见寄存器为通用寄存器（R0~R3）和PC。
2. 第二部分：设置暂存器T的原因 
	1.  **推导**：关键在于理解 #单总线结构 的瓶颈。考虑一个双操作数指令，如 `ADD R1, R0` (执行 `R1 ← (R1) + (R0)`)   [[系统总线结构（数据线，地址线，控制总线）]]
	    1.  ALU需要两个输入：来自R1的数据和来自R0的数据。
        2.  在单总线结构中，同一时刻只能有一个寄存器的数据被放到总线上。
        3.  如果将R0的内容放到总线上，ALU的输入A和输入B（通过T）都会接收到来自总线的数据。这样无法同时提供两个不同的操作数。  
        4.  因此，需要一个临时寄存器T来暂存其中一个操作数。操作流程变为：  [[微操作的例子]]
            *   **微操作1**：将R0的内容送到总线，然后装入暂存器T (`(R0) → Bus → T`)。
            *   **微操作2**：将R1的内容送到总线，直接进入ALU的A输入端 (`(R1) → Bus → ALU_A`)。
            *   **微操作3**：T的内容送入ALU的B输入端 (`(T) → ALU_B`)。
            *   **微操作4**：ALU执行加法，结果输出。
            *   **微操作5**：ALU结果送到总线，装入R1 (`ALU_out → Bus → R1`)。
    *   **结论**：设置暂存器T是为了在 #单总线结构 下，解决ALU两个输入端口不能同时从总线接收两个不同操作数的问题。它用于临时缓存一个操作数。
-  (2) 控制信号ALUop和SRop的位数至少是多少？ 
	1.    **推导**：一个需要表示 $k$ 种不同状态的控制信号，其二进制编码至少需要 $n$ 位，其中 $n$ 必须满足 $2^n \ge k$。用数学公式表示为 $n = \lceil \log_2 k \rceil$   #控制信号的位数 #控制信号 
		*   **ALUop**：题目说明 #ALU 有7种操作（mova, add, sub, and, or, not, inc）。所以 $k=7$。
	        *   我们需要找到最小的 $n$ 使得 $2^n \ge 7$。
	        *   $2^2 = 4 < 7$
	        *   $2^3 = 8 \ge 7$
	        *   所以 `ALUop` 至少需要 **3** 位。 
	    *   **SRop**：题目说明 #移位寄存器SR  有3种操作（mov, left, right）。所以 $k=3$。
	        *   我们需要找到最小的 $n$ 使得 $2^n \ge 3$。
	        *   $2^1 = 2 < 3$
	        *   $2^2 = 4 \ge 3$
	        *   所以 `SRop` 至少需要 **2** 位。
-  (3) 信号SRout所控制的部件的名称或作用是什么？ 
	1. **推导**：观察图中信号`SRout`（在端点①处）的作用。它控制着一个门电路，这个门电路的输入是移位寄存器SR的输出，输出则连接到主总线上 
		1. 在总线结构中，多个部件的输出端连接到同一条总线。为了防止信号冲突（即多个部件同时向总线输出），每个部件的输出端必须通过一个“开关”连接到总线 
		2. 这个“开关”就是 #三态门 （或称 #三态缓冲器 ）。当控制信号（如此处的`SRout`）有效时，三态门导通，将SR的输出数据放到总线上；当`SRout`无效时，三态门处于高阻态，相当于将SR与总线断开 

- （4）
	- 1，2，3，5，8须连接到控制部件输出端
-  (5) 为完善单总线数据通路，需要在端点①～⑨中相应的端点之间添加必要的连线。写出连线的起点和终点，以正确表示数据的流动方向。 
	- [[单总线连接]] 
		- 所有需要交换数据的部件都必须连接到唯一的总线上。这意味着：
		    1.  需要从总线读取数据的部件，其输入端必须与总线相连。
		    2.  需要向总线写入数据的部件，其输出端必须通过三态门与总线相连。
	1. 
-  (6) 为什么二选一选择器 MUX 的一个输入端是 2？ 
	- #程序计数器PC  [[程序计数器PC]]
		- 在顺序执行指令时，每执行完一条指令，PC（程序计数器）的值都需要增加，以指向下一条指令。增加的量等于一条指令的长度（以字节为单位） 
	- 字节编址
		- 指内存中每个字节都有一个唯一的地址
	- PC存放的是当前（或下一条）指令的地址。当CPU要取下一条指令时，新的PC值就应该是当前的PC值加上一条指令的长度，即 $PC_{new} = PC_{current} + 2$。

*   **“所以每条指令占用2个内存单元”**: 这是从上述两个前提得出的直接结论。
    *   一条指令的长度是16位。
    *   一个内存单元（地址）存放8位（1字节）。
    *   那么，存放一条16位的指令需要多少个内存单元呢？
    $存储单元数 = \frac{指令总位数}{每个单元的位数} = \frac{16 \text{ bits}}{8 \text{ bits/单元}} = 2 \text{ 个单元}$
    这意味着一条指令会占据两个连续的字节地址。例如，第一条指令可能存放在地址 `0x0000` 和 `0x0001`，第二条指令就会从 `0x0002` 开始，存放在 `0x0002` 和 `0x0003`，以此类推。

*   **“顺序执行时，下条指令地址为(PC) + 2”**: 这是程序执行流程的核心。
    *   **PC (Program Counter, 程序计数器)** 是一个特殊的寄存器，它总是指向**当前正在执行指令的起始地址**。
    *   当CPU执行完位于地址`PC`的指令后，如果没有遇到跳转或分支指令，它就需要去取下一条指令来执行。
    *   因为我们已经知道每条指令占用2个字节，所以下一条指令的起始地址必然在当前指令地址之后2个字节的位置。
    *   因此，更新PC以指向下一条指令的操作就是：
    $PC_{next} = PC_{current} + 2$

*   **“MUX的一个输入端为2，可便于执行(PC) + 2操作”**: 这是将上述逻辑与给定的电路图联系起来。
    *   在CPU的数据通路（Datapath）设计中，计算下一条指令的地址是一个基本操作。这个操作需要一个加法器，加法器的两个输入分别是当前的`PC`值和一个**增量**。
    *   在这个16位指令系统中，顺序执行时的增量是一个**固定的常数2**。
    *   因此，在电路设计中，会有一个硬编码的常数`2`作为信号源。
    *   图中的MUX（多路选择器）是一个选择门。它的作用是根据控制信号`MUXop`（⑧）来决定从它的多个输入中选择哪一个作为输出（⑦）。
    *   将常数`2`连接到MUX的输入端`0`，意味着当控制信号`MUXop`为`0`时，MUX的输出就是`2`。这个输出`2`随后可以被送入一个加法器，与当前的PC值相加，从而完成`PC+2`的计算。

- 衍生 
	- 存储系统
		- #字节序 对于一个16位的数据存放在两个字节地址中，是大端序（Big-Endian）还是小端序（Little-Endian）？这会影响多字节数据的存取方式。
	    *   #存储器接口 ：MAR、MDR与主存之间的交互，读/写控制信号的作用。

	可能衍生出的考点
	这个知识点是计算机组成原理的核心，可以衍生出许多考点：
	1.  **PC的作用和更新机制**：
	    *   PC的功能是什么？（存放下一条要执行指令的地址）
	    *   PC的值在哪些情况下会改变？
	        *   **顺序执行**：$PC \leftarrow PC + L$（L为指令字长，单位是字节）
	        *   **无条件跳转 (Jump)**：$PC \leftarrow TargetAddress$
	        *   **条件分支 (Branch)**：如果条件满足，$PC \leftarrow BranchTargetAddress$；否则，$PC \leftarrow PC + L$。
	
	2.  **数据通路设计**：
	    *   画出PC更新的简化数据通路图。这通常包括PC寄存器、一个加法器和一个MUX。
	    *   **PC更新逻辑**：PC的输出连接到加法器的一个输入，常数`2`（或`4`）连接到加法器的另一个输入。加法器的输出`PC+2`连接到MUX的一个输入。MUX的另一个输入可能来自跳转/分支地址计算单元。MUX的输出最终会作为下一周期写回PC的新值。
	    *   分析控制信号（如图中的`MUXop`）的作用。它由**控制单元(Control Unit)**根据指令的操作码(Opcode)产生，决定是选择顺序执行的地址还是跳转地址。
	
	3.  **指令字长与寻址方式**：
	    *   给出一个不同的架构设定（例如，指令长度32位，但按字编址，其中1字=32位），让你计算PC的增量。
	        *   **解答**：按字编址意味着每个地址对应一个字（32位）。一条32位指令正好占用一个地址单元。所以PC增量是1。$PC_{next} = PC_{current} + 1$。
	    *   这个问题考察的是对“指令长度”、“编址单位”和“PC增量”三者之间关系的深刻理解。
	
	4.  **分支指令的地址计算**：
	    *   在16位指令系统中，分支指令（如`BEQ`）中的偏移量（offset）字段位数会更少（比如8位）。
	    *   计算分支目标地址的公式仍然类似：$TargetAddress = (PC + 2) + SignExtend(offset)$。注意这里的基址是`PC+2`，而不是MIPS中的`PC+4`。
	    *   有时为了扩大寻址范围，offset可能也是**字偏移量**。如果指令是16位（2字节），那么字偏移量就需要乘以2，即左移1位（`offset << 1`）。这与MIPS中左移2位（`<< 2`）是同样的道理。


![[2015-exam-paper-ocr.pdf#page=6&rect=73,330,562,822|2015-exam-paper-ocr, p.6]]
[[Pasted image 20250930034627.png]]
[[微指令操作控制字段的编码方式]]   
[[指令系统]]    #控制信号 [[指令流水线与冲突]]  #计算机体系结构入门题目  
- 题目条件   [[单总线结构]]
	1.  **CPU结构**：这是一个 #单总线结构 的CPU。这意味着在同一个时钟周期内，只能有一个部件（如寄存器R0、PC、MDR等）将数据输出到总线上。
	2.  **数据通路**：图中的灰色区域是核心运算和暂存单元。
	    *   #算术逻辑单元ALU 的两个输入分别是寄存器 #移位寄存器SR  的输出（A输入）和寄存器 **T** 的输出（B输入）。
	    *   **SR**（移位寄存器）的数据来源是 #多路选择器MUX 的输出。
	    *   **MUX** 的数据来源有两个：ALU的输出（0号输入）和系统总线（1号输入）。
	    *   **T**（暂存寄存器）的数据来源是系统总线。
	3.  **控制信号**：
	    *   `ALUop`: 控制ALU执行7种操作之一（mova, add, sub, and, or, not, inc）。
	    *   `SRop`: 控制SR执行3种操作之一（mov, left, right）。`mov`在这里是“加载”的意思，即将MUX的输出打入SR。
	    *   `MUXop`: 控制MUX选择输入源（0: ALU, 1: 总线）。
	    *   `SRout`: 控制SR将其内容输出到总线。
	    *   `Tin`: 控制T从总线载入数据。
	    *   `Rx_in`/`Rx_out`: 控制通用寄存器Rx的读写。
	4.  **指令格式**（图44b）：
	    *   16位定长指令。
	    *   操作码（OP） + 寻址模式（Md, Ms1, Ms2） + 寄存器编号（Rd, Rs1, Rs2）。
	    *   寻址模式：1位，0=寄存器直接，1=寄存器间接。
	    *   寄存器：R0-R3，共4个，需要2位地址（00, 01, 10, 11）。
- #时钟周期 
1. #指令系统与指令格式     #单周期取值 指令总长度为16位 
	1. 指令由操作码 (Opcode) 和地址码 (Operand) 组成。操作码决定了指令的功能，其位数决定了指令系统的最大指令数量。地址码则指明了操作数的位置，可以包括寻址模式和寄存器编号等字段 
		1. 我们需要根据题目的文字描述，计算出除了OP字段外，其他所有字段占了多少位
-  (1) 该机的指令系统最多可定义多少条指令？ [[指令格式]]
	1. **解题思路**：
		一个指令系统能定义多少条不同的指令，完全取决于 #操作码 (OP)  字段的位数。若操作码有 $n$ 位，则最多可以表示 $2^n$ 种不同的状态，即最多定义 $2^n$ 条指令。
	2. 推导过程  [[寄存器地址字段]] 
		根据图44b，一个 #三地址指令 包含以下字段：
        *   目标寄存器地址 `Rd`：需要 $log_2(4)=2$ 位。
        *   源寄存器1地址 `Rs1`：需要 $log_2(4)=2$ 位。
        *   源寄存器2地址 `Rs2`：需要 $log_2(4)=2$ 位。
        *   目标寻址模式 `Md`：需要1位。
        *   源1寻址模式 `Ms1`：需要1位。
        *   源2寻址模式 `Ms2`：需要1位。
    3.  用于操作数定义的总位数 = $2+2+2+1+1+1=9$ 位。
    4.  指令总长度为16位。
    5.  所以，操作码（OP）字段的位数 = 总长度 - 操作数字段长度 = $16 - 9 = 7$ 位。
    6.  因此，最多可以定义的指令条数是 $2^7=128$ 条
-  (2) 若 `inc`、`shl` 和 `sub` 指令的操作码分别为 `01H`、`02H` 和 `03H`，则以下指令对应的机器码各是什么？  
1. 解题思路  [[指令周期]]
	1. 需要根据图 44b 所示的指令格式，将汇编指令的各个部分（操作码、寻址模式、寄存器号）翻译成二进制，然后拼接成完整的机器码，最后转换为十六进制
	重要前提
	*   **寄存器编号**：R0, R1, R2, R3 分别对应二进制 `00`, `01`, `10`, `11`。
	*   #寻址模式 ：题目中提到了 #寄存器直接寻址  和寄存器 #间接寻址  。我们根据图 44b 的格式，假设寄存器直接寻址模式 (如 `R1`) 编码为 `01`，寄存器间接寻址模式 (如 `(R1)`) 编码为 `10` 或 `11`。从答案给出的 `sub` 指令的二进制码来看，它似乎对寻址模式的编码有特定的规则，
2. 我们采用以下更清晰的推导方式 
	1. 指令 1: `inc R1`
		1. **语义**: `R1 <- R1 + 1`。这是一条单操作数指令 ，操作数是 `R1`，它既是源也是目标。
			1. 操作码 (OP) `01H` = `0000001`
			2. 操作数 目标寄存器 `Rd` 是 `R1`。
			    *   #寻址模式   **Md**: 目标是寄存器 `R1`，是寄存器直接寻址，所以 `Md=0`。
			    *   #寄存器号   **Ms1, Ms2, Rs1, Rs2**: 未使用，按约定填0。`Ms1=0`, `Ms2=0`, `Rs1=00`, `Rs2=00`。
			3.  **组合**: `0000001 | 0 | 0 | 0 | 01 | 00 | 00`  
				1. **二进制码**: `0000 0010 0100 0000`
				2.  **十六进制码**: `0240H` 
	2. 指令 2: `shl R2, R1` 
		1. **语义**: `R2 <- (R1) << 1` (将 R1 的内容左移一位存入 R2)。这是一条 #双操作数指令 
			1. `shl Rd, Rs1` 表示 `(Rs1) << 1 -> Rd`
		2. 操作码 (OP)  `02H` = `0000010` 
		3. 操作数
		    *   目标 `Rd`: `R2` (直接)，`Md=01`, `Rd=10`。
		    *   源 `Rs1`: `R1` (直接)，`Ms1=01`, `Rs1=01`。
		4. 机器码 `0488H` = `0000 0100 1000 1000`
			*   `04...H` 对应于 `0000 010...`，与操作码 `02H` 相关。
		    *   `...88H` 对应于 `...1000 1000`，这部分编码了 `R2` 和 `R1`。
	3. 指令 3: `sub R3, (R1), R2`   
		1. **语义**: `R3 <- (Mem[R1]) - (R2)`。这是一个 #三操作数指令 ，但源操作数 `(R1)` 是寄存器间接寻址，即 R1 的内容是内存地址
		2. 操作码 (OP)`03H` = `0000011`
		3. 操作数
			1. 目标 `Rd`: `R3` (直接)，`Md=01`, `Rd=11`。  
			2. 源 `Rs1`: `(R1)` (间接)，`Ms1=10` (假设), `Rs1=01` 
			3.  源 `Rs2`: `R2` (直接)，`Ms2=01`, `Rs2=10`
		4. 机器码
			1. `06EAH` = `0000 0110 1110 1010`
			2. `...EAH` 对应于 `...1110 1010`，这部分编码了 `R3`, `(R1)`, `R2`
		5. 机器码的高位与 #操作码 紧密相关, 低位编码了寄存器和 #寻址模式
- (3) 假没寄存器 X 的输入和输出控制信号分别为 Xin 和 Xout... 写出图 a 中标号 ①～⑧ 处的控制信号或控制信号的取值。
**解题思路**：
分析图 44a 中每个微操作序列的功能，确定缺失的控制信号。
- ① 和 ② (取指阶段的 PC 更新) 
	1. 这个阶段的目标是将 `PC` 的值加 1，即 `PC <- PC + 1`
	2. 

(4) 指令 `sub R3, (R1), R2` 和 `inc R1` 的执行阶段至少包含几个 #时钟周期 ？

*   **推导思路**：执行阶段的周期数取决于完成该操作需要多少个 #微操作步骤（时钟周期） 。在单总线结构下，每个周期通常只能完成一次 #总线传输
*   **`sub R3, (R1), R2`**
    *   这条指令涉及一次内存读取和一次减法运算。我们参照图44a中为`sub R0, R2, (R1)`设计的流程，该流程是通用的。
    *   **Cycle 1**: `R1out, MARin, MEMop=read` (取地址，启动读内存)。
    *   **Cycle 2**: `MDRout, MUXop=1, SRop=mov` (等待内存数据就绪，并将数据从MDR加载到SR)。
    *   **Cycle 3**: `R2out, Tin` (将R2内容加载到T)。
    *   **Cycle 4**: `ALUop=sub, ..., R3in=1` (执行减法，并将结果写回R3)。
    *   根据这个流程，执行阶段**至少需要4个时钟周期**。

*   **`inc R1`**
    *   指令功能是 `(R1) + 1 -> R1`。ALU有 `inc` 操作，作用于A输入，即 `(SR)+1`。
    *   **Cycle 1**: 将 `(R1)` 送入SR。微操作: `R1out, MUXop=1, SRop=mov`。
    *   **Cycle 2**: 执行 `inc` 并将结果写回R1。
        *   `ALUop=inc` 使ALU计算 `(SR)+1`。
        *   结果需要从ALU输出，经MUX(`MUXop=0`)，通过SR(`SRop=mov` + `SRout`)，上总线，最后写入R1(`R1in`)。
        *   在简单的模型中，从ALU得到结果并写回寄存器可以在一个周期内完成。ALU运算，结果通过数据通路返回，在时钟沿结束时写入目标寄存器。
        *   微操作: `ALUop=inc, MUXop=0, SRop=mov, SRout, R1in`。虽然 `SRout` 和 `SRop=mov` (写入SR) 同时有效看起来有冲突，但在某些设计中，`SRout` 可以输出正在通过SR的数据（即ALU的输出），这被称为“穿透”或“直通”。假设这种高效设计，则此步骤可以在一个周期内完成。
    *   因此，`inc R1` 的执行阶段**至少需要2个时钟周期**。
#暂时放过   #较复杂  #题目连一块了

- 衍生 
	- 指令系统设计
		-  **寻址方式扩展**：增加如立即数寻址、变址寻址等，并分析其对指令格式和执行过程的影响
		-  **指令格式优化**：讨论定长指令和变长指令的优劣，或者设计一种扩展操作码的方案
	- #控制单元设计 
		-   #硬布线控制器 ：可能会让你画出某个控制信号（如`R1in`）的逻辑表达式，其输入是指令操作码、时序信号等。
		- #微程序控制器 这是最重要的衍生考点。可能会让你：
	        *   编写实现某条指令的**微程序**。
	        *   设计微指令的格式（水平型、垂直型、混合型）。
	        *   分析微地址的形成方式（断定方式、增量方式）。
	* #数据通路 修改与扩展
		* 可能会问如何修改数据通路以提高性能，例如增加一个 #旁路 （Bypass）直接将ALU结果送回寄存器或ALU输入，减少周期数。
	    *   可能会要求在现有通路上实现一条新指令，需要你设计其微操作序列。
	    *   **多总线结构**：与单总线对比，分析多总线（如三总线）结构如何在一个周期内完成 `(RA) op (RB) -> RC` 这种操作，从而提高效率。
	-  [[流水线技术]]
		- 可能会问如何将这个CPU改造为流水线结构（如取指、译码、执行、访存、写回五级流水）。
	    *   分析流水线中的**数据冒险**（Data Hazard）和**控制冒险**（Control Hazard），并提出解决方案（如数据前推/旁路、分支预测、延迟槽等）。
		
	
	
	




![[2015-exam-paper-ocr.pdf#page=6&rect=75,110,541,339|2015-exam-paper-ocr, p.6]]
[[Pasted image 20250930034635.png]]
[[Pasted image 20250930034643.png]]


#生产者-消费者问题   
1. 第一步：定义信号量[[信号量]]  
	1. #同步信号量 用于表示资源的数量，解决同步问题。 
	    *   `Full_A`：表示信箱A中**已有的邮件数量**。消费者A需要检查这个值。它的初值是题目给定的 `x`。
	        *   `semaphore Full_A = x;` // Full_A 表示A的信箱中的邮件数量
	    *   `Empty_A`：表示信箱A中**剩余的空位数**。生产者B需要检查这个值。信箱A总容量为`M`，已有`x`个，所以空位是 $M-x$。
	        *   `semaphore Empty_A = M-x;` // Empty_A 表示A的信箱中还可存放的邮件数量
	    *   `Full_B`：表示信箱B中**已有的邮件数量**。消费者B需要检查这个值。初值为 `y`。
	        *   `semaphore Full_B = y;` // Full_B 表示B的信箱中的邮件数量
	    *   `Empty_B`：表示信箱B中**剩余的空位数**。生产者A需要检查这个值。信箱B总容量为`N`，已有`y`个，所以空位是 $N-y$。
	        *   `semaphore Empty_B = N-y;` // Empty_B 表示B的信箱中还可存放的邮件数量
	2. #互斥信号量  通常是二元信号量（值为0或1），用于保护对共享资源的访问，解决互斥问题。
	    *   `mutex_A`：用于保护对信箱A的访问。任何进程访问信箱A前都必须获得这个锁。初值为1，表示信箱A当前无人访问。
	        *   `semaphore mutex_A = 1;` // mutex_A 用于A的信箱互斥
	    *   `mutex_B`：用于保护对信箱B的访问。初值为1。
	        *   `semaphore mutex_B = 1;` // mutex_B 用于B的信箱互斥
2. 第二步：构建进程A和B的逻辑    [[PV操作]]
	1. 用P、V操作来组织每个进程的行为  
		1.  **P操作 (wait)**：申请一个资源。如果信号量的值大于0，则将其减1并继续执行。如果值为0，则进程阻塞，直到信号量的值大于0。
		2.  **V操作 (signal)**：释放一个资源。将信号量的值加1。如果有进程因该信号量而阻塞，则唤醒其中一个。 
	2. 进程A的逻辑分析：
		1. 从信箱A取邮件（作为消费者）
			*   首先，要确保信箱A不为空。所以执行 `P(Full_A)`。如果 `Full_A` 为0（信箱为空），进程A将在此 #阻塞等待 。
		    *   然后，为了保证 #独占访问 ，需要锁住信箱A。执行 `P(mutex_A)`。
		    *   **临界区**：`从A的信箱中取出一个邮件`。
		    *   操作完成后，释放锁。执行 `V(mutex_A)`。
		    *   因为取走了一个邮件，信箱A的空位数增加了一个。需要通知可能在等待空位的生产者（进程B）。所以执行 `V(Empty_A)`。
		2. 回答问题并提出新问题（本地操作，不涉及同步互斥）
		3. 向信箱B放邮件（作为生产者）
			 *   首先，要确保信箱B没有满。所以执行 `P(Empty_B)`。如果 `Empty_B` 为0（信箱已满），进程A将在此阻塞等待。
		    *   然后，为了保证独占访问，需要锁住信箱B。执行 `P(mutex_B)`。
		    *   **临界区**：`将新邮件放入B的信箱`。
		    *   操作完成后，释放锁。执行 `V(mutex_B)`。
		    *   因为放入了一个邮件，信箱B的邮件数增加了一个。需要通知可能在等待邮件的消费者（进程B）。所以执行 `V(Full_B)`。
	3. 进程B的逻辑分析（与进程A对称） 
		1. 从信箱B取邮件（作为消费者）
			*   `P(Full_B)`：等待信箱B有邮件。
		    *   `P(mutex_B)`：锁住信箱B。
		    *   **临界区**：`从B的信箱中取出一个邮件`。
		    *   `V(mutex_B)`：释放信箱B。
		    *   `V(Empty_B)`：通知信箱B多了一个空位。
		2.  **回答问题并提出新问题**
		3.  **向信箱A放邮件（作为生产者）**
		    *   `P(Empty_A)`：等待信箱A有空位。
		    *   `P(mutex_A)`：锁住信箱A。
		    *   **临界区**：`将新邮件放入A的信箱`。
		    *   `V(mutex_A)`：释放信箱A。
		    *   `V(Full_A)`：通知信箱A多了一个邮件。
一个重要的细节
	P操作的顺序。必须先执行同步信号量的P操作，再执行互斥信号量的P操作（例如，先`P(Full_A)`，后`P(mutex_A)`）。如果顺序颠倒，可能会导致**死锁**。

- 衍生   
	- [[进程同步的经典问题]]
	- [[同步机制]] 
	- #进程与线程 
		-  题目中的A和B可以被看作两个进程，也可以是两个线程。如果作为线程，它们共享同一地址空间，共享变量的访问需要更加小心。考题可能会围绕线程同步展开

![[截屏2025-09-30 上午3.47.03.png]][[截屏2025-09-30 上午3.47.39.png]]
- [[页式存储管理]]  #二级页表 [[二级页表]]  
	4. [[编址方式]]
		1. [[虚拟地址到物理地址的转换]] #二级页表 #地址翻译  
	[[二级页表]]
- (1) 页和页框的大小各为多少字节？进程的虚拟地址空间大小为多少页？
1.   [[计算页面的大小]]
	1. 页内偏移量（Page Offset）的位数决定了页的大小。
		1. 因为系统是按字节编址的，12位的偏移量可以表示 $2^{12}$ 个不同的字节位置
		2. 因此，每一页的大小为 $2^{12}$ 字节。
		    *   $2^{12} = 4096$ 字节。因为 $1KB = 1024 = 2^{10}$ 字节，所以 $4096$ 字节 = $4KB$。
		    *   在页式存储中，页框的大小与页的大小是相等的。所以页框大小也为 $4KB$
	2.  [[虚拟地址空间大小]] 
		1. 首先计算总的虚拟地址位数：$10 (\text{目录}) + 10 (\text{索引}) + 12 (\text{偏移}) = 32$ 位
		2.  总的虚拟地址空间大小为 $2^{32}$ 字节 
			1. 要计算有多少页，用总空间大小除以每页的大小：
		        *   总页数 = $\frac{\text{虚拟地址空间总大小}}{\text{每页的大小}} = \frac{2^{32} \text{ B}}{2^{12} \text{ B}} = 2^{(32-12)} = 2^{20}$ 页。
		        *   $2^{20} = (2^{10})^2 = 1024^2 = 1,048,576$ 页，即 $1M$ 页
		**答案 (1):**
		页和页框的大小均为 $2^{12} = 4096$ 字节 (或 $4KB$)。
		进程的虚拟地址空间大小为 $\frac{2^{32}}{2^{12}} = 2^{20}$ 页
-  (2) 假定 #页目录项 和 #页表项 均占4字节，则进程的 #页目录和页表 共占多少页？要求写出计算过程  
- 核心思想  ：访问哪个二级页表是由虚拟地址的 #页目录号 （最高10位）决定的。  #地址变换过程（以二级为例）  [[地址翻译过程（二级页表）]] 
	- 如果两个虚拟地址的 #页目录号 相同，那么它们会通过页目录中的同一个表项，访问到同一个二级页表。[[地址访问流程]]   
	- 如果页目录号不同，则会访问不同的二级页表
1. 分析第一个地址 `0100 0000H` 
	1.    首先将十六进制 (H) 地址转换为32位二进制。
	    *   `0100 0000H` = `0000 0001 0000 0000 0000 0000 0000 0000` (二进制)
	    *   按照 10-10-12 的格式拆分：
		      *   **页目录号 (10位)**: `0000 0001 00`
	        *   **页表索引 (10位)**: `00 0000 0000`
	        *   **页内偏移量 (12位)**: `0000 0000 0000`
	    *   页目录号的二进制 `0000000100` 转换为十进制是 4。
	2. 分析第二个地址 `0111 2048H`  
		1. 转换为32位二进制：
			1. `0111 2048H` = `0000 0001 0001 0001 0010 0000 0100 1000` (二进制)
		2. 按照 10-10-12 的格式拆分：
	        *   **页目录号 (10位)**: `0000 0001 00`
	        *   **页表索引 (10位)**: `01 0001 0010`
	        *   **页内偏移量 (12位)**: `0000 0100 1000`
		*  页目录号的二进制也是 `0000000100`，十进制同样是 4。
	* 结论
	    *   两个虚拟地址的最高10位（页目录号）是完全相同的。
	    *   这意味着在地址转换过程中，CPU会使用相同的页目录号（索引为4）去访问页目录，从而得到同一个页目录项。这个页目录项指向的是同一个二级页表。
	    *   因此，尽管这两个地址的页表索引和页内偏移都不同，但它们共享了同一个二级页表。
-  (3)
	- 共访问 **1** 个二级页表。
		理由：因为两个虚拟地址 `0100 0000H` 和 `0111 2048H` 转换为二进制后，它们的最高10位（即页目录号）都是 `0000000100`，是相同的。相同的页目录号意味着它们会通过页目录的同一个表项索引到同一个二级页表
- 衍生 
	- [[快表TLB]] 
		-  题目可能会增加一个TLB（Translation Lookaside Buffer）的设定，并给出命中率。然后问：访问这两个地址需要访问几次主存？
		- **分析**：
	        *   **TLB命中**：直接从TLB获得物理页框号，只需访问1次主存（取数据）。
	        *   **TLB未命中**：需要访问2次主存（一次访问页目录，一次访问二级页表）来完成地址转换，然后再访问1次主存（取数据），共3次。
	        *   如果两次访问的页目录号和页表索引都不同，且TLB都未命中，则第一次访问需要3次内存访问，第二次访问也需要3次。但如果第二次访问的二级页表已经在第一次访问时被加载到内存，那么访问次数会变化。题目通常会简化这个过程。
	- #物理地址计算   
		-  题目可能会给出页目录和二级页表的部分内容（比如某些表项的值），然后要求计算出给定虚拟地址对应的最终物理地址。
		- **解题步骤**：你需要根据虚拟地址的各部分，一步步查表，将基地址和偏移量结合起来，最终算出物理地址
	- [[页面大小的选择]]
		- 可能会问，如果增大或减小页面大小，会对系统产生什么影响？


![[截屏2025-09-30 上午3.47.10.png]]
[[截屏2025-09-30 上午3.47.54.png]]
- 已知信息  [[计算机网络综合题思考路径]]
	-    **网络地址**：所有设备都在同一个局域网（LAN）内，网络地址为 `111.123.15.0`，子网掩码为 `/24`，即 `255.255.255.0`。
- #DHCP请求  #ARP协议与RARP协议 
- [[MAC地址]]
- [[ARP地址解析协议]]
- (1) DHCP服务器可为主机2～主机N #动态分配IP地址的最大范围   是什么？主机2使用DHCP协议获取IP地址的过程中，发送的封装DHCP Discover报文的IP分组的源IP地址和目的IP地址分别是什么？
	-  [[可用IP地址范围]]
1. DHCP服务器只能分配网络中尚未被使用的IP地址。我们首先要确定整个子网中哪些IP地址已经被静态占用了 
	1. 子网可用主机IP总范围是 `111.123.15.1` 到 `111.123.15.254`
	2. 已被 #静态占用 的IP有：
        *   `111.123.15.1` (路由器)
        *   `111.123.15.2` (DHCP服务器自身)
        *   `111.123.15.3` (WWW服务器)
        *   `111.123.15.4` (主机1)
    *   因此，DHCP服务器可以分配的地址池就是总可用范围中除去这些已被占用的地址。
    *   可分配的起始地址是 `111.123.15.5`，结束地址是 `111.123.15.254`。
2. 第二部分：DHCP Discover 报文的IP地址 
	1. [[DHCP的一切]]  #DHCP工作流程：DORA四步曲   
		1. DHCP的第一个步骤是 **Discover (发现)**。此时，客户端（主机2）还没有IP地址，它的目标是找到网络中任何一个可用的DHCP服务器  
	2. #源IP地址 因为主机2还没有被分配IP地址，所以它在IP包头中使用的源地址是一个表示“未知”或“本机”的特殊地址，即 **`0.0.0.0`**  [[默认路由]] 
	3. #目的IP地址  因为主机2不知道DHCP服务器的具体IP地址，所以它必须在本地网络中进行广播，以确保所有潜在的DHCP服务器都能收到它的请求。这个广播地址是本地网络的受限广播地址，即 **`255.255.255.255`**  
	4.   **结论**: 源IP地址是 `0.0.0.0`，目的IP地址是 `255.255.255.255` 
- (2) 若主机2的ARP表为空，则该主机访问Internet时，发出的第一个以太网帧的目的MAC地址是什么？封装主机2发往Internet的IP分组的以太网帧的目的MAC地址是什么？
 - 第一部分：第一个以太网帧的目的MAC
	 - [[ARP缓存表]]  [[默认网关]]   #默认网关  
	 1. 主机2要访问Internet，意味着它要访问一个不在本地子网 (`111.123.15.0/24`) 的IP地址。
	 2.  根据路由原理，当目标地址不在本地网络时，主机会将数据包发送给**默认网关**，由网关负责转发。本网络中的默认网关是路由器，其IP地址为 `111.123.15.1`
	 3. 为了将IP包封装成 #以太网帧 发送给网关，主机2需要知道网关的MAC地址。 
		 1.  题中明确指出主机2的ARP表为空
			 1. 这意味着它不知道 `111.123.15.1` 对应的MAC地址。
		 2. 因此，主机2在发送去往Internet的数据包之前，必须先发送一个 #ARP请求 来查询网关的MAC地址
	 4.   #广播帧的目的MAC地址 是 **`ff-ff-ff-ff-ff-ff`**。
	 5.   **结论**: 主机2发出的第一个帧是ARP请求帧，其目的MAC地址是 `ff-ff-ff-ff-ff-ff`
- 第二部分：封装去往Internet的IP分组的帧的目的MAC 
	1. #数据封装过程   #逐跳传输[[数据封装过程]]     [[逐跳传输]] 
		1. 这个问题问的是承载着发往Internet的IP数据包的那个 #以太网帧 。这个帧是在ARP解析完成**之后**才发送的。
		2. IP数据包的目的IP地址是Internet上的某个服务器地址（例如 `8.8.8.8`），这个地址在整个传输过程中通常保持不变
		3. 但是，以太网帧的MAC地址是**逐跳变化**的 
			1. 在本地网络这一跳，数据包的目标是 #默认网关
		4. 通过上一步的ARP请求，主机2已经获得了默认网关 `111.123.15.1` 的MAC地址，即 `00-a1-a1-a1-a1-a1`。
		5. 因此，主机2会将IP数据包封装在一个以太网帧里，该帧的 #目的MAC地址 就是 #路由器的MAC地址 
	2.  **结论**: 封装IP分组的以太网帧的目的MAC地址是 **`00-a1-a1-a1-a1-a1`**。 
- (3) 若主机1的子网掩码和默认网关分别配置为 `255.255.255.0` 和 `111.123.15.2`，则该主机是否能访问WWW服务器？是否能访问Internet？请说明理由 
1.  **知识点**: **IP路由判断**、**子网掩码的作用**、**默认网关的作用**。
2.  **分析配置**:
    *   主机1的IP: `111.123.15.4`
    *   子网掩码: `255.255.255.0` (配置正确)
    *   默认网关: `111.123.15.2` (配置**错误**，正确的应为路由器的 `111.123.15.1`)。`111.123.15.2` 是DHCP服务器的地址。
 - 第一部分：能否访问WWW服务器？
	 1. [[判断 IP 地址的合法性]]  #路由判断   当主机1要访问一个目标IP时，它会先用自己的 #子网掩码 判断目标IP是否与自己在同一个子网。
	    *   主机1的网络地址: $111.123.15.4 \text{ AND } 255.255.255.0 = 111.123.15.0$
	    *   WWW服务器的目标IP: `111.123.15.3`
	    *   判断目标网络地址: $111.123.15.3 \text{ AND } 255.255.255.0 = 111.123.15.0$
	2.  **通信过程**: 因为计算出的网络地址相同，主机1认为WWW服务器和它在同一个局域网内。 
	3. **结论**: **对于同一子网内的通信，不需要经过默认网关**。主机1会直接通过ARP协议获取 `111.123.15.3` 的MAC地址，然后通过交换机将数据帧直接发送给WWW服务器。因此，**主机1可以访问WWW服务器**。
- 第二部分：能否访问Internet？ 
	1. #路由判断 : 当主机1要访问Internet上的一个IP（例如 `8.8.8.8`）时，它会进行同样的判断。
    *   主机1的网络地址: `111.123.15.0`
    *   判断目标网络地址: $8.8.8.8 \text{ AND } 255.255.255.0 = 8.8.8.0$
    2.  **通信过程**: 因为计算出的网络地址不同 (`111.123.15.0` ≠ `8.8.8.0`)，主机1认为目标在外部网络，必须将数据包发送给**默认网关**。
	3.  **错误的影响**: 主机1配置的默认网关是 `111.123.15.2`。所以，它会把所有去往Internet的数据包都发送给IP地址为 `111.123.15.2` 的设备，也就是DHCP服务器。
	4.  **结论**: DHCP服务器是一台服务器，而不是路由器。它没有路由功能，收到不属于自己的数据包后，不知道如何转发到Internet，通常会直接丢弃。因此，数据包无法到达真正的网关（路由器），也就无法访问Internet。所以，**主机1不能访问Internet**。


	- **问题(3)** 中，主机1将默认网关错配为DHCP服务器。这意味着，当主机1要访问Internet时，它会把所有发往外网的IP包，都封装进一个目的MAC为DHCP服务器MAC的帧里。DHCP服务器收到后，发现IP包不是给自己的，而且自己又不是路由器，不知道如何转发，只能丢弃。这就是“逐跳传输”在第一跳就失败的典型案例。


- 衍生 
	- [[IP地址与子网掩码]]
	- [[DHCP的一切]]
		-    #DHCP中继  Relay (中继代理)**: 当客户端和DHCP服务器不在同一个广播域时，如何通过路由器配置DHCP中继来完成地址分配。
			- 路由器会将客户端的广播请求以**单播**的形式转发给指定的DHCP服务器，从而实现跨网段的地址分配。
	- [[ARP地址解析协议]]
		- #ARP缓存 ARP表的作用、老化时间、如何查看和清除 (`arp -a`, `arp -d`)。 
		- #免费ARP 用于检测IP地址冲突或在主备切换后更新其他设备ARP缓存的机制。 
		- #代理ARP    路由器代替子网内的主机响应来自外部网络的ARP请求，实现网络隔离或扩展。 、
		- #ARP欺骗  一种常见的局域网攻击方式，其原理和防范措施 
	- 