![[2016-exam-paper-ocr.pdf#page=1&rect=81,531,524,702|2016-exam-paper-ocr, p.1]]
[[Pasted image 20250930041413.png]]

[[链表]]
[[逻辑地址到物理地址的转换]]
- 解题步骤详解 
1. 第一步：根据表格重建原始链表的逻辑顺序 
	1. 从题目给定的表头元素 `c` 开始，沿着“链接地址”追踪  
		1.  表头是 `c`，其物理地址是 `1008H`。`c` 的链接地址是 `1000H`。
		2.  我们找到物理地址为 `1000H` 的节点，它是 `a`。所以 `c` 指向 `a`。
		3.  节点 `a` 的链接地址是 `1010H`。
		4.  我们找到物理地址为 `1010H` 的节点，它是 `e`。所以 `a` 指向 `e`。
		5.  节点 `e` 的链接地址是 `1004H`。
		6.  我们找到物理地址为 `1004H` 的节点，它是 `b`。所以 `e` 指向 `b`。
		7.  节点 `b` 的链接地址是 `100CH`。
		8.  我们找到物理地址为 `100CH` 的节点，它是 `d`。所以 `b` 指向 `d`。
		9.  节点 `d` 的链接地址是 `NULL`，表示链表结束。
		所以，原始链表的**逻辑顺序**是：`c -> a -> e -> b -> d`。
2. 第二步：执行插入操作
	1.  **插入后**的逻辑关系变为：`... -> a -> f -> e -> ...`  
3. 第三步：确定新的链接地址 
	1. 确定题目所问的 `a`, `e`, `f` 三个节点的链接地址
	2. D 
- 衍生 
	- #节点删除操作 
		-  可能会问：如果从原始链表中删除节点 `e`，那么节点 `a` 的新链接地址是什么？
	    *   **解法**：要删除 `e`，需要让 `e` 的前驱节点 `a`直接指向 `e` 的后继节点 `b`。所以 `a` 的新链接地址应为 `b` 的物理地址 $1004H$。
	* #双向链表 
		* 如果这是一个双向链表，每个节点除了 `next` 指针外，还有一个 `prev` 指针指向上一个节点。
		*   **考点**：在 `a` 和 `e` 之间插入 `f` 后，不仅要修改 `a->next` 和 `f->next`，还需要修改 `e->prev` 和 `f->prev`。
	- #循环链表  
		-  链表的最后一个节点不指向 `NULL`，而是指向头节点。
	    *   **考点**：遍历循环链表的终止条件不再是 `p == NULL`，而是 `p->next == head`
	* #查找链表 
		*  可能会问：在链表中查找元素 `b` 需要经过几次指针访问？
	    *   **解法**：从头节点 `c` 开始，`c -> a -> e -> b`，共需 3 次指针跳转
	* #链表时间复杂度分析 
		* **考点**：对比链表和数组在增、删、查、改等操作上的时间复杂度。
        *   按索引访问：数组为 $O(1)$，链表为 $O(n)$。
        *   在已知前驱节点的情况下插入/删除：链表为 $O(1)$。
        *   在任意位置插入/删除（需要先查找）：数组和链表平均都为 $O(n)$




![[2016-exam-paper-ocr.pdf#page=1&rect=76,427,538,532|2016-exam-paper-ocr, p.1]]
[[Pasted image 20250930041417.png]]
#双向链表   
#链表
#节点删除操作   
1. `p` 节点的前驱是 `p->prev`，后继是 `p->next`。  
	*   `p` 的前驱节点的 `next` 指针指向 `p`，即：`p->prev->next == p`
	*   `p` 的后继节点的 `prev` 指针指向 `p`，即：`p->next->prev == p` 
	2. 我们要将 `p` 从链表中“摘除”，让 `p->prev` 和 `p->next` 直接相连
2. 为了达到这个目标，需要进行两步关键的指针修改
	1. **让 `p` 的前驱节点 (`p->prev`) “跳过” `p`，直接指向 `p` 的后继节点 (`p->next`)** 
		*   在代码中，这意味着我们要修改 `p->prev` 节点的 `next` 指针。
	    *   正确的赋值语句是：`p->prev->next = p->next;`
	2. **让 `p` 的后继节点 (`p->next`) “跳过” `p`，直接指向 `p` 的前驱节点 (`p->prev`)**。
	    *   在代码中，这意味着我们要修改 `p->next` 节点的 `prev` 指针。
	    *   正确的赋值语句是：`p->next->prev = p->prev;`
	-    在完成了链表的“重新链接”之后，节点 `p` 就被孤立出来了。此时，它所占用的内存空间已经不再需要，应该被释放，以防内存泄漏。
	*   执行内存释放操作：`free(p);`
	*   **重要**：`free(p)` 必须在两个指针修改操作**之后**执行。如果先执行 `free(p)`，指针 `p` 将成为一个悬挂指针，我们无法再安全地通过 `p->prev` 和 `p->next` 访问它的前驱和后继节点，从而导致链表断裂。
- 衍生 
	- #双向链表的插入操作  
		- 这是删除的逆操作。要在节点 `q` 之后插入一个新节点 `s`，需要修改四个指针：
		    *   `s->next = q->next;`
		    *   `q->next->prev = s;`
		    *   `q->next = s;`
		    *   `s->prev = q;`
		    考点会集中在**操作的正确顺序**上。与删除不同，插入操作的顺序非常重要，错误的顺序会导致链表信息丢失。
	- 边界条件处理 
		- 删除头节点或尾节点
			- 在 #双向循环链表 中，由于头尾相连，删除第一个或最后一个数据节点（紧随头结点或在头结点之前）的逻辑与删除中间节点完全相同，代码具有普适性。但在 #非循环双向链表 中，删除头/尾节点是特殊情况，需要额外处理 `head` 或 `tail` 指针
		- 删除链表中唯一的节点 
			- 删除后链表变为空。需要将头结点的 `next` 和 `prev` 都指向它自己



![[2016-exam-paper-ocr.pdf#page=1&rect=78,301,529,428|2016-exam-paper-ocr, p.1]]
[[Pasted image 20250930041423.png]]

#最长递减子序列 
1.  从 `8` 开始，我们可以找到 `8, 4, 2, 1`。这是一个长度为4的递减子序列。
2.  我们再检查其他的可能性：
    *   `8, 5, 3, 1` (长度为4)
    *   `8, 4, 3, 1` (长度为4)
    *   `4, 2, 1` (长度为3)
    *   `5, 3, 1` (长度为3)

通过检查，我们可以发现最长的递减子序列长度为4。例如 **`8, 4, 2, 1`** 这个子序列。

*   `8` 在原序列第1位。
*   `4` 在原序列第2位。
*   `2` 在原序列第3位。
*   `1` 在原序列第7位。

这四个数字在原序列中依次出现，并且数值上是严格递减的。

根据上述定理，我们需要的最小轨道数 `n` 就等于最长递减子序列的长度。
所以，$n_{至少} = 4$。

- 衍生
	-  #最长递增/递减子序列 
		- **问题:** 给定一个序列，求其最长递增（或递减）子序列的长度。
	    *   **算法:**
	        *   **动态规划 $O(n^2)$:** 定义 $dp[i]$ 为以第 $i$ 个元素结尾的最长递增子序列的长度。状态转移方程为 $dp[i] = \max(dp[j]) + 1$，其中 $0 \le j < i$ 且 $array[j] < array[i]$。
	        *   **贪心 + 二分查找 $O(n \log n)$:** 维护一个数组 `tails`，其中 `tails[i]` 存储长度为 $i+1$ 的所有递增子序列中末尾元素的最小值。遍历原序列，对于每个元素，通过二分查找在 `tails` 中找到它的位置并更新。这是解决此类问题的最高效方法。
	- #栈的输出序列 
		- [[栈]] **问题:** 给定一个入栈序列（如 `1, 2, 3, ..., n`），问哪些出栈序列是合法的。 

![[2016-exam-paper-ocr.pdf#page=1&rect=78,248,527,300|2016-exam-paper-ocr, p.1]]
[[Pasted image 20250930041657.png]]
[[Pasted image 20250930041709.png]]

#下标  [[三对角行列式的递推公式]] 
#三对角行列式  [[压缩存储]] 
1. #按行优先  即将矩阵的非零元素逐行地、从左到右地存放到一个一维数组中。
	根据图示，存储顺序为：
	$a_{1,1}, a_{1,2}, a_{2,1}, a_{2,2}, a_{2,3}, a_{3,2}, a_{3,3}, a_{3,4}, \dots$
2. 方法一： #公式法（计算三角矩阵）  
	1. 一个计算下标的公式：对于元素 $a_{i,j}$，其在一维数组 B (即题目中的 N) 中的下标 $k$ 为：
			$k = 2i + j - 3$ 
	2. $k = 2 \times 30 + 30 - 3$
		$k = 60 + 30 - 3$
		$k = 87$
-  方法二：根据原理手动推导 (原理推导法) 
	1.  步骤1：计算前29行（行号从1到29）的非零元素总数  
		1.   **第1行**：有2个非零元素。
			*   **第2行到第29行**：这些都是中间行，每行有3个非零元素。总共有 $29 - 2 + 1 = 28$ 行。
			*   所以，第2行到第29行的非零元素总数为：$28 \times 3 = 84$ 个。
			*   因此，前29行的非零元素总数为：$2 + 84 = 86$ 个
	2. **步骤2：确定 $m_{30,30}$ 在第30行的位置。**
		*   第30行是中间行，其非零元素按顺序存储为：$m_{30,29}, m_{30,30}, m_{30,31}$。
		*   可见，$m_{30,30}$ 是第30行中的**第2个**非零元素。 
	3. **步骤3：计算最终下标。**
		*   前29行总共有86个元素，由于数组 $N$ 的下标从0开始，这86个元素会占据下标 $0, 1, \dots, 85$。
		*   第30行的第一个非零元素 $m_{30,29}$ 的下标紧随其后，为 $86$。
		*   第30行的第二个非零元素 $m_{30,30}$ 的下标就是 $87$。
- 衍生 
	- 改变下标起始值  
		- 如果题目改为矩阵下标 $i, j$ 从0开始 ($0 \le i, j < 100$)，而数组下标仍从0开始。那么 $m_{30,30}$ 实际是第31行第31列。这时就需要重新推导公式。新的元素是 $m'_{i',j'}$，其中 
		-  $i' = i-1, j' = j-1$。代入原公式 $k = 2(i'+1) + (j'+1) - 3 = 2i' + j' 。$ 对于 $m'_{29,29}$ (即原来的 $m_{30,30}$)，$k=2 \times 29 + 29 = 87$ 
		- 如果数组下标从1开始，那么所有计算出的下标结果都需要加1。原题的答案就变成 $87+1=88$。 
	- #不同的压缩存储方式  [[压缩存储]] 



![[2016-exam-paper-ocr.pdf#page=1&rect=76,218,447,249|2016-exam-paper-ocr, p.1]]
[[Pasted image 20250930041715.png]]
#树的结点总数 [[结点总数与度]]  #森林  [[二叉树的性质]]
1. #树的性质 一个包含 $n$ 个结点（顶点）的树，必然有且仅有 $n-1$ 条边  
	1. 对于任意一棵独立的树，其结点数永远比边数多 1  
2. [[森林的性质]]   
	1. 在一个森林中，树的个数（$k$）等于总结点数（$V$）减去总边数（$E$）
3. $k = 25 - 15 = 10$
 
- 衍生 
	- [[树的等价定义（无向图）]] 
	- [[生成树]]  一个有 $n$ 个结点的连通图，其生成树有多少条边？（答案：永远是 $n-1$ 条） 
		-  如何求一个图的生成树？（例如，通过深度优先搜索(DFS)或广度优先搜索(BFS)遍历可以得到一棵生成树）。
	
	- [[连通分量与强连通分量的求解算法]]
		-  **考点：** 对于任意一个无向图 $G$，它的连通分量个数 $k$ 和结点数 $V$、边数 $E$ 之间有什么关系？
			 关系是 $k \ge V - E$。
	    *   只有当图中没有环路时（即图是一个森林），等号才成立，即 $k = V - E$。这道题就是这个特例。如果图中有环，每增加一个环，至少会使 $V-E$ 的值减1

![[2016-exam-paper-ocr.pdf#page=1&rect=77,111,500,213|2016-exam-paper-ocr, p.1]]
[[Pasted image 20250930041721.png]]
[[深度优先遍历实现步骤（有向图）]]  
D 
- 衍生 
	-  #图的存储结构  [[邻接矩阵，邻接表 ，稀疏图，稠密图]] 
		-    **邻接矩阵**: 用一个二维数组 `G[V][V]` 表示。`G[i][j] = 1` 表示顶点i和j之间有边。
	    *   **邻接表**: 用一个数组，每个元素指向一个链表，链表中存储该顶点的所有邻接点。
	    *   **复杂度影响**: 对于一个有 $V$ 个顶点和 $E$ 条边的图，DFS和BFS使用邻接表的时间复杂度是 $O(V+E)$；使用邻接矩阵的时间复杂度是 $O(V^2)$。
	- [[最短路径算法]] 



![[2016-exam-paper-ocr.pdf#page=1&rect=74,72,507,110|2016-exam-paper-ocr, p.1]]
[[Pasted image 20250930041737.png]]


[[拓扑排序]]
#Kahn算法  
	#Kahn算法和DFS算法的时间复杂度   都是$O(V+E)$。因为每个顶点和每条边都只被访问常数次
- 现在我们来分析每一步的时间复杂度，前提是图使用**邻接表**来存储： 
1. 步骤1：计算所有顶点 的入度 
	1.   我们需要遍历整个图来确定每个顶点的入度。
	    *   使用邻接表时，遍历所有顶点的邻接链表即可。这个过程需要访问每个顶点（共 $n$ 个）和每条边（共 $e$ 条）一次。
	    *   因此，这一步的时间复杂度是 $O(n+e)$。
2. 步骤2：初始化队列
	*   我们需要遍历一次所有 $n$ 个顶点，检查它们的入度是否为0，并将符合条件的顶点入队。
    *   这个过程的时间复杂度是 $O(n)$。
3. 步骤3：主循环 
	1. 每个顶点最多入队一次，出队一次。因此，出队操作（`a`）总共会执行 $n$ 次 
		1. 对于每个出队的顶点 $u$，我们需要遍历它的所有出边。在整个算法的执行过程中，图中的每一条边 $e$ 都会被访问且仅被访问一次（当其起始顶点出队时） 
	2. 因此，更新邻接点入度（`b`, `c`, `d`）的总操作次数与边的数量 $e$ 成正比 
		1.  综合来看，主循环的总时间复杂度是 $O(n+e)$
4. 算法的总时间复杂度是以上各个步骤复杂度的总和：
	$T(n, e) = O(n+e) \text{ (计算入度)} + O(n) \text{ (初始化队列)} + O(n+e) \text{ (主循环)}$  
	根据 #大O表示法的加法法则 ，我们取最高阶的项，所以最终的时间复杂度为 $O(n+e)$。

- 衍生 
	- 不同存储结构下的时间复杂度 
		-   **问题:** 如果图采用**邻接矩阵**存储，拓扑排序的时间复杂度是多少？
	    *   **解析:**
	        *   **计算入度:** 需要遍历整个邻接矩阵的每一列，时间复杂度为 $O(n^2)$。
	        *   **主循环:** 当一个顶点 $u$出队后，需要找到所有从 $u$ 出发的边，这需要遍历邻接矩阵的第 $u$ 行，耗时 $O(n)$。由于有 $n$ 个顶点，主循环总耗时为 $O(n^2)$。
	        *   **总复杂度:** $O(n^2)$。这是一个非常经典的对比考点。
	- #判断图中是否存在环
		- **问题:** 如何使用拓扑排序来判断一个有向图中是否存在环？
	    *   **解析:** 在Kahn算法执行完毕后，检查排好序的顶点个数是否小于图中的总顶点数 $n$。
	        *   如果个数等于 $n$，说明所有顶点都成功出队，图是DAG。
	        *   如果个数小于 $n$，说明队列提前变空，而图中仍有顶点未被访问（这些顶点的入度始终无法变为0），这些顶点必然构成了环。
	- [[关键路径]]   
		-   **问题:** 在项目管理中，拓扑排序和什么概念紧密相关？
		    *   **解析:** 关键路径。在AOE网（Activity on Edge Network）中，通常先进行拓扑排序来确保事件发生的顺序，然后在此基础上计算每个事件的最早和最晚发生时间，从而找出关键路径。关键路径是项目中耗时最长的路径，决定了项目的总工期。这是数据结构在工程应用中的一个重要考点。
			






![[2016-exam-paper-ocr.pdf#page=2&rect=70,703,525,822|2016-exam-paper-ocr, p.2]]
[[Pasted image 20250930041745.png]]
[[Pasted image 20250930041751.png]]

[[Dijkstra 算法]]
 1. A
- #Dijkstra算法的局限性  
	- 该算法不能处理带有**负权边**的图。如果存在负权边，贪心选择可能导致最终结果不是全局最优解。对于存在负权边的情况，需要使用Bellman-Ford算法或SPFA算法。

 



![[2016-exam-paper-ocr.pdf#page=2&rect=75,555,535,701|2016-exam-paper-ocr, p.2]]
[[Pasted image 20250930041757.png]]
送分题 
B


![[2016-exam-paper-ocr.pdf#page=2&rect=75,506,442,554|2016-exam-paper-ocr, p.2]]
[[Pasted image 20250930041822.png]]

[[B树和B+树的区别]] 
A
由于 B+树的所有叶结点中包含了全部的关键字信息，且叶结点本身依关键字从小到大顺序链接，可以进行顺序查找，而 B 树不支持顺序查找（只支持多路查找）

- 衍生 
	- 树的高度与I/O性能 
		-   **考点:** 为什么 B+树比 B 树更适合做数据库索引？ 
	- #B树的阶数计算 [[B树的阶数计算]] 
		- **考点:** 假设磁盘页大小为 $P$ 字节，关键字大小为 $k$ 字节，指针大小为 $ptr$ 字节。计算一个B树（或B+树）的阶数 $m$ 
			- **解答:** 对于B树的内部节点，一个节点需要存储 $m$ 个指向子节点的指针和 $m-1$ 个关键字及对应的数据。假设数据大小为 $d$。则有不等式： 
				-     $(m-1) \times (k+d) + m \times ptr \le P$
		    *   对于B+树的内部节点，不存储数据，因此不等式为：
		        $(m-1) \times k + m \times ptr \le P$
			-  通过解这个不等式，可以得出 $m$ 的最大值。这个计算题是衡量对 B/B+树物理结构理解程度的常见考点。



![[2016-exam-paper-ocr.pdf#page=2&rect=78,471,480,507|2016-exam-paper-ocr, p.2]]
[[Pasted image 20250930041958.png]]

[[排序算法]] [[内部排序和外部排序]]   [[各类内部排序算法的时间复杂与空间复杂度]] 
D
- 衍生 
	- 外部排序的 I/O 成本计算 
		- 可能会让你计算总的磁盘读写次数。
	    *   假设总数据块数为 $B$，内存缓冲块数为 $M$。
	- 特定场景下的算法选择
		- **问题**：当数据量不大，但要求最坏情况下的时间复杂度必须是 $O(n \log n)$ 时，应该选择什么？
	    *   **答案**：堆排序或归并排序（快速排序最坏情况是 $O(n^2)$）。
	    *   **问题**：当待排序序列大部分已有序时，哪种算法效率更高？
	    *   **答案**：插入排序或冒泡排序，它们在这种情况下时间复杂度可以接近 $O(n)$。

![[2016-exam-paper-ocr.pdf#page=2&rect=78,436,484,470|2016-exam-paper-ocr, p.2]]
[[Pasted image 20250930042003.png]]
C
[[程序设计语言的处理过程]] 
 [[高级语言处理的完整流程]] 
 - 衍生 
	 - [[编译与解释的详细对比（动态语言vs静态语言 ）]]  





![[2016-exam-paper-ocr.pdf#page=2&rect=75,360,527,437|2016-exam-paper-ocr, p.2]]
[[Pasted image 20250930042008.png]]
- 这道题目考察的是C语言中整数的内部表示（特别是补码）以及有符号整数（`signed`）和无符号整数（`unsigned`）之间的类型转换规则。 [[数据类型转换]] 
	- 进行**符号扩展 (Sign Extension)**。即在高位补充原数字的符号位。如果原数是正数（符号位为0），则补充0；如果原数是负数（符号位为1），则补充1。这样可以保持原数的数值不变。 #有符号整数到无符号整数的类型转换规则 
1. 第1步：理解数据类型和其在内存中的大小 
	1. **`short`**：是有符号的16位整数。它的表示范围是 $-32768$ 到 $32767$。这个范围可以用公式 $[ -2^{16-1}, 2^{16-1}-1 ]$ 计算得出。
		*   **`unsigned short`**：是无符号的16位整数。它的表示范围是 $0$ 到 $65535$。这个范围可以用公式 $[ 0, 2^{16}-1 ]$ 计算得出。
2. 第2步：理解有符号整数的补码表示
	1.  **取其绝对值的原码**：[[原码，反码的运算和溢出判断]] #原码表示   [[补码]]
	    `32767` 的16位二进制表示（原码）是：
	    `0111 1111 1111 1111`
	    （因为 $32767 = 2^{15} - 1$）
	2. **按位取反（得到反码）**：
	    将二进制的每一位 `0` 变成 `1`，`1` 变成 `0`。
	    `1000 0000 0000 0000`
	3. **加 1（得到补码）**：
	    在反码的基础上加1。
	    `1000 0000 0000 0001`
3. 第3步：理解 `signed` 到 `unsigned` 的转换规则
	1.   对于变量 `usi`（`unsigned short` 类型），`1000 0000 0000 0001` 这个位模式被解释为一个无符号数。在无符号数中，没有符号位的概念，所有16位都用来表示数值的大小。 #有符号整数到无符号整数的类型转换规则 
4. 第4步：计算 `usi` 的值
	1. 我们需要计算二进制数 `1000 0000 0000 0001` 作为无符号16位整数时，它代表的十进制值。
		这个二进制数中，第15位（最高位）是1，第0位（最低位）是1，其他位都是0。其值为：
	$1 \times 2^{15} + 0 \times 2^{14} + \dots + 0 \times 2^1 + 1 \times 2^0$
		$= 2^{15} + 2^0$
		$= 32768 + 1$
		$= 32769$
-  另一种更快的计算方法（ #模运算 ） 
	1. C语言标准规定，将一个有符号数 `v` 转换为N位的无符号数时，如果 `v` 是负数，结果是 $v + 2^N$。
		在本题中，`v = -32767`，`N = 16`。
		所以 `usi` 的值为：
		$usi = -32767 + 2^{16}$
		$= -32767 + 65536$
		$= 32769$
			

- 衍生 
	- **反向转换**：从 `unsigned short` 转换为 `short` 
		-   ```c
    unsigned short a = 65535;
    short b = a;
    // 问 b 的值是多少？
    ```
    *   **解析**：`65535` 的二进制是 `1111 1111 1111 1111`。当这个位模式被解释为 `short` 时，最高位 `1` 是符号位，表示负数。这是一个补码，我们需要求它的原码。补码求原码（负数）：减1，再按位取反。
    *   `1111 1111 1111 1111` - 1 = `1111 1111 1111 1110` (反码)
    *   按位取反 = `0000 0000 0000 0001` (原码，值为1)
    *   所以 `b` 的值是 `-1`。
- 涉及不同位宽的转换
	- 
		-  ```c
    int i = -1;
    unsigned short usi = i;
    // 问 usi 的值是多少？
    ```
    *   **解析**：假设 `int` 是32位。`-1` 的32位补码是 `1111....1111` (32个1)。当赋给16位的 `unsigned short` 时，会发生**截断**，只保留低16位。所以 `usi` 得到 `1111 1111 1111 1111`，其值为 `65535`。
- 混合类型算术运算中的隐式转换
	- ```c
    int i = -1;
    unsigned int u = 0;
    if (i < u) {
        printf("i < u");
    } else {
        printf("i >= u");
    }
    ```
    *   **解析**：当有符号数和无符号数进行比较时，C语言的"寻常算术转换"规则会将有符号数 `i` 隐式地转换为无符号数。
    *   `i` 的值是 `-1`，其32位补码是 `0xFFFFFFFF`。
    *   当 `-1` 被转换为 `unsigned int` 时，它变成了 $2^{32}-1$，一个非常大的正数。
    *   因此，比较变成了 `(一个很大的正数 < 0)`，这个条件为假。程序会输出 `i >= u`。


![[2016-exam-paper-ocr.pdf#page=2&rect=79,296,522,358|2016-exam-paper-ocr, p.2]]
[[Pasted image 20250930042015.png]]
[[Pasted image 20250930042022.png]]
- 这道题的核心是考察计算机中多字节数据（例如`double`类型）在内存中的存储方式，具体来说是**字节序（Endianness）** 的概念
- [[字节序]]
#小端模式 
 1. 根据小端模式的规则，我们需要将数据的字节**倒序**存入内存。

	*   数据的字节顺序（从高到低）：`11`, `22`, `33`, `44`, `55`, `66`, `77`, `88`
	*   内存地址顺序（从低到高）：`8040H`, `8041H`, `8042H`, `8043H`, `8044H`, `8045H`, `8046H`, `8047H`
	
	现在我们将字节逐一映射到内存地址：
	
	| 内存地址 | 存放内容 | 说明 |
	| :--- | :--- | :--- |
	| `0000 8040H` | `88H` | 存放最低位字节 (LSB) |
	| `0000 8041H` | `77H` | |
	| `0000 8042H` | `66H` | |
	| `0000 8043H` | `55H` | |
	| `0000 8044H` | `44H` | |
	| `0000 8045H` | `33H` | |
	| **`0000 8046H`** | **`22H`** | **<-- 题目所问** |
	| `0000 8047H` | `11H` | 存放最高位字节 (MSB) |
	
	从上表可以清晰地看到，地址为`0000 8046H`的存储单元中存放的内容是`22H`。因此，正确答案是 **A. 22H**。

 - 衍生 
	 - 数据对齐 
		 -    **对齐规则：**
	        1.  结构体中每个成员的偏移量（offset）必须是其自身大小的整数倍。
	        2.  结构体的总大小必须是其所有成员中**最大对齐模数**的整数倍。
	    *   **示例：**
	        ```c
	        struct Example {
	            char a;     // 1字节
	            int b;      // 4字节
	            short c;    // 2字节
	        };
	        ```
	        在32位系统中，`sizeof(struct Example)`通常是12字节，而不是 $1+4+2=7$ 字节。
	        *   `a` 存放在偏移量0处 (1字节)。
	        *   `b` 是4字节，需对齐到4的倍数，所以编译器在`a`后面填充3个字节。`b`存放在偏移量4处 (4字节)。
	        *   `c` 是2字节，需对齐到2的倍数，当前偏移量为8，是2的倍数。`c`存放在偏移量8处 (2字节)。
	        *   结构体总大小需是最大对齐模数（`int`的4字节）的倍数。当前大小为10字节，不是4的倍数，所以再填充2个字节，最终总大小为12字节。
	* 计算机字长 
		*    **寻址能力：** 如果地址总线的宽度等于字长，那么一个32位系统的 #最大寻址空间 就是$2^{32}$个地址单元。如果按字节编址，最大可寻址内存就是 $2^{32}$ B = 4 GB。  #可寻址空间 
	    *   **数据类型大小：** 字长会影响`int`, `long`, 指针等数据类型的默认大小。在32位系统中，`int`和指针通常是32位（4字节）；在64位系统中，它们通常是64位（8字节），但`int`也可能保持32位。这个问题需要根据具体的编程环境和规范来确定。 
	    *   **注意：** 在本题中，“32位字长”这个信息与`double`（64位）的存储并不直接冲突，它可能描述的是CPU的通用寄存器大小，而浮点运算单元（FPU）可以有不同大小的寄存器（如80位或128位）来处理`double`类型。所以这个信息在本题中可以看作是一个背景条件，并不影响字节序的判断。
	




![[2016-exam-paper-ocr.pdf#page=2&rect=82,190,525,296|2016-exam-paper-ocr, p.2]]
[[Pasted image 20250930042029.png]]
#Cache命中率 [[Cache命中率]]
#Cache命中率计算  
$命中率_A = \frac{命中次数}{总访问次数}$
[[地址映射方式]]
#直接映射  
- **Cache 配置**:
    *   **类型**: 数据 Cache (Data Cache)
    *   **映射方式**: 直接映射 (Direct Mapped)
    *   **总大小**: 1KB (1024 字节)
    *   **块大小 (Block Size / Line Size)**: 16 字节 (16B)
1. 第一步：分析 #内存访问模式 
	1. 在循环体 `a[k] = a[k] + 32;` 中，对数组 `a` 进行了两次访问：
		1.  **读操作**: 从内存中读取 `a[k]` 的值（在表达式的右侧）。
		2.  **写操作**: 将计算结果 `a[k] + 32` 写回到 `a[k]` 的位置（在表达式的左侧）。
2. 第二步：理解 #Cache块和数据存放关系  
	1. Cache与主存之间的数据交换单位是 **块(Block)**。当发生Cache缺失(Miss)时，CPU会从主存中加载一整个数据块到Cache中，而不是仅仅加载所需要的那一个数据。这是利用了程序的 #空间局部性原理 ，即如果一个存储单元被访问，那么它附近的单元也很有可能在短时间内被访问。 #事件局限性 
		1. $每块存放的整数个数 = \frac{\text{块大小}}{\text{单个整数大小}} = \frac{16B}{4B} = 4 \text{ 个}$ 
3. 第三步：模拟循环过程，分析Cache命中/缺失情况
	1. 每4个元素（即一个Cache块的数据量）为一个分析周期  
	*   **当 k = 0 时:**
	    1.  **读 `a[0]`**: Cache初始为空，所以这必然是一次 **缺失 (Miss)**。
	    2.  **处理缺失**: 系统从主存中将包含 `a[0]` 的整个块（即包含`a[0], a[1], a[2], a[3]`的数据块）加载到Cache中。
	    3.  **写 `a[0]`**: 此时包含 `a[0]` 的数据块已经在Cache里了，所以这次写操作是 **命中 (Hit)**。
	
	*   **当 k = 1 时:**
	    1.  **读 `a[1]`**: 因为上一步已经将包含`a[0]`到`a[3]`的块加载到Cache中，所以`a[1]`已经在Cache里。这是一次 **命中 (Hit)**。
	    2.  **写 `a[1]`**: 同样是 **命中 (Hit)**。
	
	*   **当 k = 2 和 k = 3 时:**
	    *   对 `a[2]` 和 `a[3]` 的读、写操作也都是 **命中 (Hit)**。
	
	*   **当 k = 4 时:**
	    1.  **读 `a[4]`**: `a[4]` 位于一个新的数据块中，这个块当前不在Cache里。因此，这是一次 **缺失 (Miss)**。
	    2.  **处理缺失**: 系统从主存加载包含`a[4], a[5], a[6], a[7]`的新数据块到Cache中。
	    3.  **写 `a[4]`**: 此时新块已在Cache中，所以是 **命中 (Hit)**。
	**规律总结**:
	我们可以看到一个清晰的模式：对于每4个连续的数组元素（`a[0]`-`a[3]`, `a[4]`-`a[7]`, ...），总共会发生 $4 \times 2 = 8$ 次访问。在这8次访问中，只有第一次（即读取 `a[0]`, `a[4]`, `a[8]`...）是缺失，其余7次都是命中。
1. 第四步：计算总缺失率 
	1. $缺失率 = \frac{\text{缺失次数}}{\text{总访问次数}} = \frac{1}{8}$ 
		1. 将这个分数转换为百分比：
			$缺失率 = \frac{1}{8} = 0.125 = 12.5\%$
	2. 关于“直接映射”和“Cache大小为1KB”的说明 
		1. 在本题的特定访问模式（严格的顺序访问）下，这两个条件不会影响最终结果。因为数组是顺序访问的，我们永远不会在访问 `a[i]` 之后回头去访问一个很早之前的元素 `a[j]` (其中 `i-j` 很大)。所以，虽然数组大小 (1000 * 4B = 4KB) 大于Cache大小 (1KB)，可能会导致之前加载的Cache块被覆盖（这称为**冲突缺失**或**容量缺失**），但在本题的顺序访问模式下，被覆盖的块我们刚好不再需要了。因此，本题中所有的缺失都是第一次访问数据块时发生的 **强制性缺失

- 衍生 
	- 改变 #访问步长
		-   **代码**: `a[k] = a[k*4] + 32;` (k从0到249)
		    *   **分析**: 访问的元素是 `a[0], a[4], a[8], ...`。每次访问的地址间隔为 $4 \times 4B = 16B$，正好等于一个Cache块的大小。这意味着每次访问 `a[k*4]` 都是一个新块的开始。
		    *   **结果**:
		        *   读 `a[k*4]`: **Miss** (加载一个新块)。
		        *   写 `a[k*4]`: **Hit** (因为块刚被加载)。
		        *   每次循环2次访问，1次Miss，缺失率为 $1/2 = 50\%$。
	- 二维数组的访问顺序(行主序 vs 列主序)
		-  **代码 (行主序访问)**:
	        ```c
	        int x[100][100];
	        for(i=0; i<100; i++)
	          for(j=0; j<100; j++)
	            x[i][j] = 0;
	        ```
	    *   **分析**: C语言中数组按行主序存储，即 `x[i][j]` 和 `x[i][j+1]` 在内存中是相邻的。这种访问方式与内存布局一致，空间局部性极好，缺失率会很低（类似于本题）。
	    *   **代码 (列主序访问)**:
	        ```c
	        for(j=0; j<100; j++)
	          for(i=0; i<100; i++)
	            x[i][j] = 0;
	        ```
	    *   **分析**: 访问顺序是 `x[0][0], x[1][0], x[2][0], ...`。`x[i][j]` 和 `x[i+1][j]` 在内存中相隔了整整一行（100个`int`，即400字节）。这个步长远大于Cache块大小(16B)，导致每次访问几乎都是一次Cache Miss，缺失率会非常高。
	- 改变 #Cache映射方式  [[地址映射方式]] 
		- 如果题目改为 **全相联映射 (Fully Associative)**，则可以避免冲突缺失。对于本题，结果不变。但对于访问模式复杂的程序，全相联映射的缺失率通常更低。
	    *   如果改为 **组相联映射 (Set-Associative)**，则需要分析数据块会映射到哪个组，以及组内是否会发生冲突。这是直接映射和全相联映射的折中


![[2016-exam-paper-ocr.pdf#page=2&rect=82,142,526,193|2016-exam-paper-ocr, p.2]]
[[Pasted image 20250930042035.png]]

[[计算物理地址位数]]
[[字节，比特，十六进制]]
[[RAM和ROM的区别]] 
[[SRAM与DRAM对比]] 
#SRAM
1. 第一步：计算ROM和RAM的容量 
	1. **计算ROM区的容量**
	    *   ROM的地址范围是 4000H 到 5FFFH（H代表十六进制）。
	    *   计算地址空间大小的公式是：末地址 - 首地址 + 1。
	    *   进行十六进制减法：
	        $5FFF\text{H} - 4000\text{H} = 1FFF\text{H}$
	    *   然后加1：
	        $1FFF\text{H} + 1 = 2000\text{H}$
	    *   所以ROM区共有 $2000\text{H}$ 个地址。因为是按字节编址，所以ROM的容量就是 $2000\text{H}$ 字节。
	    *   现在我们将十六进制的容量转换为我们熟悉的KB单位：[[按字节编址]]   
	        $2000_{16} = 2 \times 16^3 = 2 \times 4096 = 8192$
	    *   因为 $1\text{KB} = 1024\text{B}$，所以：
	        $8192\text{B} / 1024\text{B/KB} = 8\text{KB}$
	    *   因此，ROM区的容量为 **8KB**
	2. **计算RAM区的容量**
	    *   总存储容量为64KB。
	    *   ROM区占用了8KB。
	    *   剩余的部分都是RAM区，所以RAM区的容量为：
	        $64\text{KB} - 8\text{KB} = 56\text{KB}$
	    *   因此，我们需要设计的RAM区的总容量为 **56KB**。
2. 第二步：计算所需的SRAM芯片数量  
	1. 用 8K × 4位 的SRAM芯片来构成一个 56KB 的RAM区。这里涉及到 #存储器的位扩展和字扩展 #位扩展字扩展 [[存储器扩展]]
		- **目标RAM规格**：容量为56KB。由于系统是按字节编址，数据总线的宽度通常是字节的倍数，这里我们默认是按字节存取，即数据宽度为8位。所以目标是构建一个 56K × 8位 的存储空间。
		*   **SRAM芯片规格**：8K × 4位。这表示每个芯片有8K（$8 \times 1024 = 8192$）个存储单元，每个单元可以存储4位数据。
- 方法一：总容量相除法  
	1. 用目标总容量除以单个芯片的容量。为了避免单位混淆，我们都换算成“位”  
		1.  **目标RAM总位数**：
		    $56\text{KB} = 56 \times 1024 \text{ Bytes} = 56 \times 1024 \times 8 \text{ bits}$
		2.  **单个SRAM芯片的总位数**：
		    $8\text{K} \times 4 \text{位} = 8 \times 1024 \times 4 \text{ bits}$
		3.  **计算所需芯片数量**：
		    $\text{芯片数量} = \frac{\text{目标总位数}}{\text{单个芯片总位数}} = \frac{56 \times 1024 \times 8}{8 \times 1024 \times 4}$
		    我们可以消去 $1024$：
		    $\text{芯片数量} = \frac{56 \times 8}{8 \times 4} = \frac{56}{4} = 14$
- 方法二：位扩展和字扩展组合法  
	1. 位扩展（增加数据宽度）：
	    *   我们需要的数据宽度是8位（1字节）。
	    *   每个SRAM芯片的数据宽度是4位。
	    *   为了实现8位的数据宽度，我们需要将2个芯片并联。这样，当CPU访问一个地址时，可以同时从这2个芯片中各读出4位，合并成一个8位的数据。
	    *   所需并联芯片数 = $\frac{\text{目标数据宽度}}{\text{单芯片数据宽度}} = \frac{8\text{位}}{4\text{位}} = 2$ 个。
	    *   这两个芯片构成一个存储组（Bank），这个组的规格是 8K × 8位。

	2.  **字扩展（增加存储单元数）**：
		*   我们需要总共56K个存储单元（地址）。
		*   每个存储组（Bank）提供了8K个存储单元。
		*   为了达到56K的总容量，我们需要多个这样的存储组。
		*   所需存储组数量 = $\frac{\text{目标存储单元数}}{\text{每组的存储单元数}} = \frac{56\text{K}}{8\text{K}} = 7$ 组。
	
	3.  **计算总芯片数**：
		*   我们总共需要7个存储组，每个存储组由2个芯片构成。
		*   总芯片数量 = $(\text{字扩展所需的组数}) \times (\text{位扩展每组的芯片数}) = 7 \times 2 = 14$ 个。
- 衍生 
	- #地址译码器的设计 
		-   可能会问：要实现对上述7个RAM组的选择，需要几条地址线参与译码？应该如何设计译码电路？
	    *   **解答思路**：因为有7个组，我们需要能区分7个不同的对象。$2^2 < 7 < 2^3$，所以至少需要3条地址线来做译码（例如，使用一个3-8译码器，只用其中7个输出即可）
	* 具体的 #地址线分配
		* 可能会问：对于 8K × 4位 的芯片，其内部地址线有多少根？连接到CPU地址总线的哪些线上？哪些CPU地址线用于片选？
	    *   **解答思路**：一个8K容量的芯片，需要 $log_2(8K) = log_2(8 \times 1024) = log_2(2^3 \times 2^{10}) = log_2(2^{13}) = 13$ 根地址线（如A0-A12）。这些线会直接连接到CPU地址总线的低13位。而CPU地址总线中更高位的地址线（如A13, A14, A15等）则会进入地址译码器，用于生成片选信号，以选择不同的芯片组













![[2016-exam-paper-ocr.pdf#page=2&rect=76,64,532,139|2016-exam-paper-ocr, p.2]]
[[Pasted image 20250930042105.png]]
[[指令格式]]  
[[指令寻址方式]]

- #变址寻址的核心    [[变址寻址]] 
	 如果用 `I` 代表变址寄存器，`(I)` 代表变址寄存器的**内容**，`D` 代表形式地址，那么变址寻址的有效地址 `EA` 的计算公式为：
        $EA = (I) + D$
- #间接寻址  
	- 如果 `A` 是指令中的地址字段，那么间接寻址的有效地址 `EA` 计算公式为：
        $EA = (A)$
        这里的 `(A)` 表示取内存地址为 `A` 的单元中的**内容**
#形式地址 
1. 第一步：先变址 
	1. 我们首先执行变址操作。根据变址寻址的定义，我们需要将变址寄存器 `I` 的内容 `(I)` 与形式地址 `D` 相加。
	    *   这一步计算出的结果是一个**中间地址**，我们称之为 `Addr_temp`。
	    *   计算公式为：$Addr\_temp = (I) + D$
	2. 第二步：后间址
		- 对上一步得到的中间地址 `Addr_temp` 执行间接寻址操作
		- 这意味着 `Addr_temp` 并不是最终操作数的地址，而是**存放最终有效地址的那个内存单元的地址**。
		    *   因此，我们需要访问内存地址为 `Addr_temp` 的单元，取出其内容，这个内容才是我们需要的最终有效地址 `EA`。
		    *   用公式表示就是：$EA = (Addr\_temp)$
		    *   将第一步的 `Addr_temp` 代入，我们得到最终的有效地址计算公式：
		        $EA = ((I) + D)$
- 衍生  
	- 先间址后变址
		*   **第一步：先间址 (Indirect First)**
		    *   首先对指令中的形式地址 `D` 进行间接寻址。这意味着 `D` 指向一个内存地址，该地址中存放着一个基地址。
		    *   我们取出这个基地址：$(D)$
		*   **第二步：后变址 (Index Next)**
		    *   然后，将上一步得到的基地址 $(D)$ 与变址寄存器 `I` 的内容 $(I)$ 相加，得到最终的有效地址。
		    *   最终的有效地址公式为：$EA = (D) + (I)$
		
		








![[2016-exam-paper-ocr.pdf#page=3&rect=77,766,520,820|2016-exam-paper-ocr, p.3]]
[[Pasted image 20250930042111.png]]
- 这道题目考察的是 #计算机组成原理 中两个 #核心寄存器 ：**程序计数器 (PC)** 和 **指令寄存器 (IR)** 的作用和位数确定方法
[[程序计数器PC]] #指令寄存器IR  
1. #程序计数器PC  #程序计数器PC位数的计算 
	1. **PC 的功能:** PC (Program Counter) 的作用是存放**下一条待执行指令的地址**。因此，PC 的位数取决于它需要表示多少个不同的指令地址。
	2.  **地址空间分析:**
	    *   计算机是“按字节编址”，意味着内存中的每一个字节（Byte）都有一个唯一的地址。
	    *   主存总容量为 4GB。我们来计算总共有多少个字节：
	        $4GB = 4 \times 2^{30} \text{Bytes} = 2^2 \times 2^{30} \text{Bytes} = 2^{32} \text{Bytes}$
	    *   这意味着，要唯一标识内存中的每一个字节，需要 32 位的地址。例如，地址从 `00...00` (32个0) 到 `11...11` (32个1)。所以，内存地址寄存器 (MAR) 需要 32 位
	3. “指令按字边界对齐存放”
		1. 字长是 32 位，即 4 字节。
		    *   “按字对齐”意味着每条指令的起始地址必须是 4 的倍数。
		    *   例如，第一条指令地址是 0，第二条是 4，第三条是 8，以此类推。地址不可能是 1, 2, 3, 5, 6, 7 等。
		    *   我们观察这些地址的二进制形式：
		        *   地址 0: `000...0000`
		        *   地址 4: `000...0100`
		        *   地址 8: `000...1000`
		        *   地址 12: `000...1100`
		    *   可以发现，这些地址的**最低两位永远是 `00`**。
		    *   既然 PC 存放的是指令地址，而指令地址的最低两位总是固定的 `00`，那么这两位信息就无需在 PC 中存储。硬件可以在将 PC 的内容发送到地址总线之前，自动在末尾补上两个 `0`。
		    *   因此，PC 实际需要存储的只是地址中变化的部分，即高位的地址。
    *   PC 的位数 = 总地址位数 - 固定的低位数 = $32 - 2 = 30$ 位
    * 另一种思路
	    * 这种方法是计算内存中可以存放多少条指令。
	    *   总内存大小 = $2^{32}$ 字节。
	    *   每条指令大小 = 32 位 = 4 字节。
	    *   可存放的指令数量 = (总内存字节数) / (每条指令的字节数) = $2^{32} / 4 = 2^{32} / 2^2 = 2^{30}$ 条。
	    *   PC 的作用是需要能够指向这 $2^{30}$ 条指令中的任意一条。为了给 $2^{30}$ 个不同的位置进行编号，我们至少需要 $N$ 位，满足 $2^N \ge 2^{30}$。
	    *   因此，最小的 $N$ 是 30。所以 PC 至少需要 30 位
2. #指令寄存器IR  #指令寄存器IR位数的计算 
	1. #IR的功能:  IR (Instruction Register) 的作用是存放**从内存中取出（fetch）的指令本身**。当 CPU 从 PC 指示的地址读取指令后，这条指令会被加载到 IR 中，以供后续的译码和执行。
	*   **位数确定:**
	    *   IR 的大小必须足以容纳一条完整的指令。
	    *   题目明确指出，采用“32 位字长指令字格式”，这意味着每条指令的长度都是 32 位。
	    *   因此，为了完整地保存这条指令，IR 的位数至少需要 32 位。
- 衍生 
	- [[PC-MAR-MDR的关系与区别]] 
	- 变长指令集 
		-  本题是定长指令。如果题目是**变长指令集**（例如，指令长度可以是 16 位、32 位或 48 位），那么：
	        *   IR 的位数必须等于**最长指令**的长度，以确保能容纳任何可能的指令。
	        *   PC 的增量逻辑会变得复杂。执行完一条指令后，PC 不再是简单地 $PC+4$，而是需要根据当前指令的长度来增加，例如 $PC+2$、$PC+4$ 或 $PC+6$（假设按半字对齐）。
	- 内存容量的逆向计算 
		-  本题是定长指令。如果题目是**变长指令集**（例如，指令长度可以是 16 位、32 位或 48 位），那么：
	        *   题目可能会反过来问：一个计算机的 MAR 是 24 位，MDR 是 16 位，按字节编址，那么它的最大寻址空间是多少？
		    *   **解答:** MAR 的位数决定了地址总线的宽度，从而决定了最大寻址空间。24 位的 MAR 可以表示 $2^{24}$ 个不同的地址。因为是按字节编址，所以最大寻址空间就是 $2^{24}$ 字节 = 16 MB。MDR 的 16 位表示数据总线的宽度是 16 位，即字长是 16 位，这影响数据传输效率，但不影响寻址空间大小。

![[2016-exam-paper-ocr.pdf#page=3&rect=75,692,526,770|2016-exam-paper-ocr, p.3]]
[[Pasted image 20250930042117.png]]
[[数据冒险的解决方案]]
[[流水线冒险]] 
[[“流水线冒险”与“流水线冲突”的区别]]
#写后读RAW 
1. 


![[2016-exam-paper-ocr.pdf#page=3&rect=80,629,523,692|2016-exam-paper-ocr, p.3]]
[[Pasted image 20250930042123.png]]
[[Pasted image 20250930042131.png]]

#单周期处理器 
[[计算机性能评测的四个指标]] 
#控制信号 
#时钟频率  [[CPU主频]]




![[2016-exam-paper-ocr.pdf#page=3&rect=78,581,513,631|2016-exam-paper-ocr, p.3]]
[[Pasted image 20250930042137.png]]

[[串行和并行总线的区别]]  
2. #线路复用  
	1. 信号线复用（或称时分复用）是指在不同的时间段内，让同一组物理线路传输不同类型的信息。一个典型的例子就是地址/数据总线复用，即同一组线路先用来传输地址信号，稍后再用来传输数据信号。这样做的好处是显著减少了芯片的引脚数量和电路板的布线复杂度，从而节省了空间和成本
3. #突发传输的主要优势 [[突发传输]]
	1.  突发传输（Burst Transfer）是指在总线上，一次只发送一个起始地址，然后连续传输多个位于连续存储地址的数据块。
4. #总线事务  
	1. #分离事务通信 #总线通信协议  
		1. 分离事务（Split Transaction）是一种先进的总线通信协议。在传统的请求-响应模式中，一个设备（主设备）发起请求（如读内存）后，会一直占用总线，直到另一个设备（从设备）准备好数据并返回。
			1. 如果从设备速度很慢，总线就会被长时间闲置。在分离事务中，主设备发起请求后会立即释放总线，让其他设备可以使用。当从设备准备好数据后，它会重新申请总线，将数据返回给主设备 
			2. 这个过程将一个完整的事务分成了“请求”和“响应”两个独立的子事务，极大地提高了总线在等待慢速设备期间的利用率
#信道利用率 [[数据链路层的信道利用率（有效数据传输速率）]]  

- 衍生 
	-  #总线仲裁  
		- 当总线上有多个主设备（如CPU、DMA控制器）都想使用总线时，需要一种机制来决定谁获得使用权，这就是总线仲裁
	- #总线定时  [[总线定时]]
		- 指总线上信号的同步和时序控制 
	- [[常见的总线标准]]  
		- 考试可能会要求你识别哪些是并行总线，哪些是串行总线，并比较它们的特点 
	- [[总线带宽计算]]  
		- 这是非常经典的计算题。例如：一个32位宽，工作频率为133MHz的PCI总线，其理论峰值带宽是多少？
		    *   计算：$带宽 = \frac{32 \text{ bit}}{8 \text{ bit/B}} \times 133 \times 10^6 \text{ Hz} = 4 \text{ B} \times 133 \times 10^6 \text{ /s} = 532 \times 10^6 \text{ B/s} = 532 \text{ MB/s}$


![[2016-exam-paper-ocr.pdf#page=3&rect=74,520,521,581|2016-exam-paper-ocr, p.3]]
[[Pasted image 20250930042144.png]]

[[区分中断、异常和系统调用]]
#存储保护错 
1. 发生于 CPU 执行一条指令，试图访问一个它没有权限访问的内存地址时（例如，用户态程序试图写入内核空间）。这个错误的检测发生在指令执行的地址翻译阶段，是**执行该指令的直接结果**，因此源于处理器**内部**
- 衍生 
	- [[中断开销]] 
	1. 中断处理本身是有开销的，称为中断开销（Interrupt Overhead）。如果中断发生得过于频繁，会显著影响系统性能。


![[2016-exam-paper-ocr.pdf#page=3&rect=78,445,476,519|2016-exam-paper-ocr, p.3]]
[[Pasted image 20250930042159.png]]

#批处理系统  
#多道批处理系统  
A
- 衍生 
	- 操作系统的发展与分类 
		- 批处理系统 (单道 -> 多道) -> 分时系统 -> 实时系统 -> 网络操作系统 -> 分布式操作系统 -> 嵌入式系统 
	- #CPU利用率 的计算 
		- 假设有 $n$ 个程序并发执行，每个程序因 I/O 操作而等待的时间占其总运行时间的比例为 $p$。
	        *   一个程序处于等待状态的概率是 $p$。
	        *   $n$ 个程序**同时**都处于等待状态的概率是 $p^n$ (假设各程序独立)。
	        *   CPU 处于空闲状态的概率就是所有程序都处于等待状态的概率，即 $P_{idle} = p^n$。
	        *   因此，CPU 的利用率（CPU Utilization）为：
	            $U_{CPU} = 1 - P_{idle} = 1 - p^n$
	        *   **示例**：若一个程序有 50% 的时间在等待 I/O (即 $p=0.5$)，当只有 1 个程序时 (单道)，CPU 利用率为 $1 - 0.5^1 = 50\%$. 如果有 4 个程序 (多道)，CPU 利用率将提高到 $1 - 0.5^4 = 1 - 0.0625 = 93.75\%$。
[[进程状态模型]]


![[2016-exam-paper-ocr.pdf#page=3&rect=79,381,518,444|2016-exam-paper-ocr, p.3]]
[[Pasted image 20250930042208.png]]
#甘特图 

为了使总时间最短，我们应该让各个设备尽可能地“忙碌”起来，减少空闲时间。调度原则如下：
1.  按作业1、作业2、作业3的顺序依次投入输入设备。
2.  一个作业的后一阶段，必须在其前一阶段完成后，并且所需设备空闲时，才能开始。

当作业3的输出任务在第17ms结束时，所有三个作业都已完成。因此，执行完3个作业需要的最少时间是 **17ms**。

- 衍生 
	- #抢占式调度 vs. #非抢占式调度
		-    如果题目允许**抢占**（Preemption），例如一个更高优先级的作业可以中断当前正在CPU上计算的作业，那么调度策略会完全不同，通常会结合优先级、时间片轮转等算法。
		-    对于两个设备（例如只有输入和计算）的 #流式调度 问题，可以使用 #约翰逊算法 来找到最优排序。 
		    *   对于三个或以上设备的问题，它是一个NP-hard问题，没有简单的最优解法，通常会考察一些启发式算法或在简单情况下寻找最优解。





![[2016-exam-paper-ocr.pdf#page=3&rect=80,319,521,383|2016-exam-paper-ocr, p.3]]
[[Pasted image 20250930042216.png]]

#死锁   
#画图   [[死锁产生的四个条件]]  
1. **分析3个进程是否会死锁：**  #死锁状态的进程 
    *   我们选择 $p_1, p_2, p_3$ 这三个进程。它们的资源需求呈现出一种“环形”的依赖关系：
        *   $p_1$ 和 $p_2$ 共同需要 $R_2$。
        *   $p_2$ 和 $p_3$ 共同需要 $R_3$。
        *   $p_3$ 和 $p_1$ 共同需要 $R_1$。
    *   这种结构是产生循环等待的“温床”。我们可以构造一个导致死锁的资源分配序列：
        1.  系统将资源 $R_1$ 分配给进程 $p_1$。此时 $p_1$ 持有 $R_1$，等待 $R_2$。
        2.  系统将资源 $R_2$ 分配给进程 $p_2$。此时 $p_2$ 持有 $R_2$，等待 $R_3$。
        3.  系统将资源 $R_3$ 分配给进程 $p_3$。此时 $p_3$ 持有 $R_3$，等待 $R_1$。
    *   现在，我们来分析系统的状态：
        *   $p_1$ 持有 $R_1$，正在等待 $R_2$，而 $R_2$ 正被 $p_2$ 持有。
        *   $p_2$ 持有 $R_2$，正在等待 $R_3$，而 $R_3$ 正被 $p_3$ 持有。
        *   $p_3$ 持有 $R_3$，正在等待 $R_1$，而 $R_1$ 正被 $p_1$ 持有。
    *   这形成了一个完美的循环等待链： $p_1 \rightarrow p_2 \rightarrow p_3 \rightarrow p_1$。
    *   此时，这三个进程都无法继续执行，也无法释放资源，系统陷入死锁。由于我们找到了一个由3个进程构成的死锁场景，并且已经排除了1个和2个进程的可能性，因此**处于死锁状态的进程数至少是3**。
	1.  **分析进程 $p_4$ 的作用：**
	    进程 $p_4$ 只需要一个资源 $R_2$。这样的进程永远不会满足“请求和保持”条件（因为它拿到 $R_2$ 后就可以直接运行结束，不需要再等待其他资源），因此 $p_4$ 本身不会成为死锁循环链中的一环。
- 衍生 
	- #哲学家就餐问题  
		- 考点: 这是一个经典的死锁同步问题模型。可能会要求你分析某种解决方案为何会（或不会）产生死锁，或者让你设计一个无死锁的解决方案 
	- [[死锁检测算法]]
		-  **考点:** 系统允许死锁发生，但能通过算法检测到它，并采取措施进行恢复。
		*   **检测方法:** 通常使用**资源分配图 (Resource-Allocation Graph)** 来检测是否存在循环。如果图中出现环路，则可能存在死锁。
		*   **恢复策略:**
		    *   **进程终止:** 强行终止一个或多个死锁进程。
		    *   **资源剥夺:** 从一个或多个进程中抢占资源分配给其他进程。
		*   **例题:** 给出一张 #资源分配图 ，判断图中是否存在死锁。或者，描述一个系统状态，要求你画出资源分配图。
	- #死锁避免  #死锁避免的核心  
		-  **考点:** 在资源分配过程中，使用某种算法（如**银行家算法 (Banker's Algorithm)**）来判断此次分配是否会导致系统进入不安全状态，从而避免进入可能导致死锁的区域。
		- **例题:** 给出系统的总资源数、各进程的最大需求和当前已分配资源，判断当前系统是否处于安全状态，或者某个进程的新请求是否可以被满足。
	    *   例如，给定一个状态，要求你找出一个**安全序列 (Safe Sequence)**。
![[2016-exam-paper-ocr.pdf#page=3&rect=77,227,526,319|2016-exam-paper-ocr, p.3]]
[[Pasted image 20250930042223.png]]
[[Pasted image 20250930042228.png]]

[[时钟算法CLOCK]]
#CLOCK算法   
1.  #修改与访问   #修改位 
	-  **访问**: 最近未被访问的页面，比最近访问过的页面，未来被再次访问的可能性更低，因此价值更低。
	*   **修改**: 未被修改的“干净页”比被修改过的“脏页”更适合淘汰，因为淘汰“干净页”不需要将其写回磁盘，开销小；而淘汰“脏页”必须先花费I/O时间将其写回磁盘，开销大。
2. **最好的淘汰选择是 $(0, 0)$**，最差的选择是 $(1, 1)$。在 $(0, 1)$ 和 $(1, 0)$ 之间，由于写回磁盘的开销远大于CPU和内存操作，因此通常优先淘汰不需要写回的 $(1, 0)$ 页面，而不是需要写回的 $(0, 1)$ 页面 
	该算法淘汰页面的优先级顺序如下：
	1.  在第一轮扫描中淘汰 **$(0, 0)$**。
	2.  若失败，在第二轮扫描中淘汰 **$(0, 1)$**。
	3.  若再次失败，在第三轮扫描中淘汰**原先是 $(1, 0)$** 的页面。
	4.  若仍然失败，在第四轮扫描中淘汰**原先是 $(1, 1)$** 的页面。
	因此，该算法淘汰页的次序为 $(0, 0), (0, 1), (1, 0), (1, 1)$。这与选项 **A** 完全一致 

- 衍生 
	- 与简单CLOCK算法（或称“二次机会算法”）的比较
		-  简单CLOCK只使用访问位 $A$。它扫描时跳过 $A=1$ 的页（并将其置为 $A=0$），替换第一个遇到的 $A=0$ 的页。改进型CLOCK增加了修改位 $M$ 的判断，使得它能区分“干净页”和“脏页”，从而优先淘汰“干净页”，减少了I/O开销






![[2016-exam-paper-ocr.pdf#page=3&rect=78,35,527,229|2016-exam-paper-ocr, p.3]]
[[Pasted image 20250930042234.png]]



-  #同步准则  [[实现互斥的机制]]   #TSL互斥 
[[TSL指令]] 

1. 进入 #临界区  
	1. P1想要进入临界区，它执行`while(TSL(&lock));` 
		1. `TSL(&lock)`被调用。由于`lock`初始为`FALSE`，TSL指令会返回`FALSE`，同时将`lock`的值原子地设置为`TRUE` 
	2.  `while`循环的条件是`FALSE`，因此循环结束，P1成功进入临界区 
		1. 此时，如果另一个进程P2也想进入临界区，它执行`while(TSL(&lock));` 
	3. `TSL(&lock)`被调用。由于`lock`现在是`TRUE`（被P1设置），TSL指令会返回`TRUE`，同时`lock`的值仍然是`TRUE` 
		1.  `while`循环的条件是`TRUE`，因此P2会卡在这个循环里，不断地执行TSL指令，直到`lock`的值变为`FALSE`。这种情况被称为“ #忙等待”或 “ #自旋”
2. 退出临界区 
	1. 当P1执行完临界区代码后，它执行`lock = FALSE;`，释放了锁。
	    *   这时，正在忙等待的P2在下一次执行`TSL(&lock)`时，会读到`FALSE`，返回`FALSE`，然后将`lock`置为`TRUE`，从而跳出`while`循环，进入临界区
	- 等待进入临界区的进程（如P2）并没有进入**阻塞态 (Blocked State)**。它仍然在**就绪态 (Ready State)**，并会不断地被调度到CPU上运行，只是它运行的指令就是那个`while`循环，在消耗CPU时间。因此，它不是被“阻塞”了，而是在“忙等”。当P1释放锁时，它只是改变了一个共享变量`lock`的值，并没有执行任何“唤醒”操作（如`wakeup`原语）。是等待的进程自己通过不断检测`lock`的状态而“发现”锁被释放了。
	- [[让权等待（同步准则）]] #让权等待 
		- 该实现采用的是“忙等待”，是“让权等待”的反面。它不释放CPU，而是在空转。因此，该伪代码**不满足**“让权等待”准则。该描述是错误的 
- D. `while(TSL(&lock))`语句应在关中断状态下执行 #关中断指令   
	- `TSL`指令**本身**的原子性是由硬件保证的。在单处理器系统中，实现其原子性的一种方式可能是在执行这条**单一指令**的期间禁止中断。但是，选项D说的是整个`while(...)`**语句**（即循环）都应该在关中断状态下执行。这是极其危险且错误的。  
		- 如果一个进程在关中断的状态下进入这个`while`循环进行忙等，那么它将永远无法被外部事件（如时钟中断）打断。这意味着操作系统调度程序无法运行，也就无法切换到其他进程——包括那个持有锁、最终会释放锁的进程。这将导致整个系统死锁或崩溃。
			- 因此，只有`TSL`指令本身需要是原子的，而包含它的`while`循环不能在关中断状态下执行。该描述是错误的。
- 衍生 
- 
	1. [[实现互斥的原子指令]] 
	2. [[忙等待和睡眠等待]]
	3. [[互斥锁必须满足的准则]] 
	- #软件实现互斥的方法 
		Dekker算法 / Peterson算法:纯软件实现的、解决了两个进程互斥问题的经典算法。它们通过巧妙地使用标志变量来避免了硬件原子指令的需要，但实现复杂且在现代乱序执行的CPU上需要内存屏障。
	



![[2016-exam-paper-ocr.pdf#page=4&rect=73,709,488,825|2016-exam-paper-ocr, p.4]]
[[Pasted image 20250930042243.png]]

#段表  [[段页式存储管理]] 
[[逻辑地址到物理地址的转换]]  

1. 分解逻辑地址 
	1. 题目明确给出要访问的逻辑地址是：段号 $S=2$，段内地址 $W=400$。
2. 查找段表
	1. 查看题目给出的段表，找到段号为 2 的那一行 
	2. 

| 段号    | 段长 (C)  | 内存起始地址 (b) | 权限  | 状态  |
| :---- | :------ | :--------- | :-- | :-- |
| ...   | ...     | ...        | ... | ... |
| **2** | **300** | **4000**   | 读写  | 在内存 |
| ...   | ...     | ...        | ... | ... |
- 从表中查到，段 2 的段长 $C=300$，内存起始地址 $b=4000$。
3. 进行合法性检查 
	1.    **越界检查**：我们将段内地址 W 和段长 C进行比较。
        *   $W = 400$
        *   $C = 300$
        *   根据越界检查规则，判断 $W \ge C$ 是否成立。
        *   $400 \ge 300$，该条件**成立**。
	2. 这意味着进程试图访问一个长度只有300的段的第400个位置，这显然超出了该段的边界。因此，硬件会立即捕获这个错误，并产生 #越界异常 

- 衍生  
	- 计算正确的物理地址 
		-  **问题**：如果访问的是段号为 2、段内地址为 150 的逻辑地址，结果是什么？ 
			-   **分析**：
		        1.  $S=2$, $W=150$。
		        2.  查表得：段长 $C=300$，基地址 $b=4000$。
		        3.  越界检查：$150 < 300$，检查通过。
		        4.  权限检查：段 2 权限为“读写”，假设是读或写操作，检查通过。
		        5.  状态检查：段 2 状态为“在内存”，检查通过。
		        6.  计算物理地址：$E = b + W = 4000 + 150 = 4150$。
		    *   **答案**：得到内存地址 4150。
	- 考察 #段缺失异常  
		-    **问题**：如果访问的是段号为 1、段内地址为 50 的逻辑地址，结果是什么？
	    *   **分析**：
	        1.  $S=1$, $W=50$。
	        2.  查表得：段长 $C=200$，状态为“**不在内存**”。
	        3.  越界检查：$50 < 200$，通过。
	        4.  在进行状态检查时，发现该段不在内存中，地址变换中断，产生**段缺失异常**。
	    *   **答案**：段缺失异常 (对应选项 A)。
	- 考察 #越权异常
		-  **问题**：如果一个**写指令**要访问段号为 0、段内地址为 80 的逻辑地址，结果是什么？
	    *   **分析**：
	        1.  $S=0$, $W=80$，操作类型为“写”。
	        2.  查表得：段长 $C=100$，权限为“**只读**”。
	        3.  越界检查：$80 < 100$，通过。
	        4.  权限检查：操作为“写”，但段权限为“只读”，权限不匹配，产生**越权异常**。
	    *   **答案**：越权异常 (对应选项 C)。
				
				








![[Pasted image 20250930042416.png]]
[[Pasted image 20250930042257.png]]
[[工作集模型]] 
计算出的工作集 `{6, 0, 3, 2}` 与选项 A `{6, 0, 3, 2}` 完全匹配
[[缺页率算法PFF]]  
PFF 和工作集模型都是基于 #局部性原理  来动态调整进程的内存分配，以达到高效运行和避免颠簸的目的。




![[2016-exam-paper-ocr.pdf#page=4&rect=64,344,534,528|2016-exam-paper-ocr, p.4]]
[[截屏2025-09-30 上午4.24.42.png]]
[[截屏2025-09-30 上午4.24.48.png]]


#并发执行  
[[并发]]  [[实现互斥的机制]] 
*   **进程 P1**
    *   `int x = 0;`：这是进程P1的全局变量，被`Thread1`和`Thread2`共享。
    *   `Thread1()`：`int a;`是`Thread1`的局部变量。`x += 1;`访问并修改了共享变量`x`。
    *   `Thread2()`：`int a;`是`Thread2`的局部变量。`x += 2;`访问并修改了共享变量`x`。

*   **进程 P2**
    *   `int x = 0;`：这是进程P2的全局变量，与P1中的`x`是**完全不同**的变量，因为它们在不同的进程地址空间中。这个`x`被`Thread3`和`Thread4`共享。
    *   `Thread3()`：`int a;`是`Thread3`的局部变量。`a = x; x += 3;`先读取共享变量`x`，然后修改它。
    *   `Thread4()`：`int b;`是`Thread4`的局部变量。`b = x; x += 4;`先读取共享变量`x`，然后修改它。
- **结论：** 选项C中的两个操作访问了同一个共享资源并对其进行修改，且操作本身 #非原子操作   ，会引发 #竞争条件 ，因此必须进行互斥。[[竞争条件]] 
- 衍生 
	- [[活锁和饥饿]] 



![[2016-exam-paper-ocr.pdf#page=4&rect=76,269,357,344|2016-exam-paper-ocr, p.4]]
[[截屏2025-09-30 上午4.24.54.png]]
[[SPOOLing技术]]
#SPOOLing技术  
D. 由用户作业控制设备与输入/输出井之间的数据传送
	SPOOLing技术对用户作业是**透明的**。用户作业只知道自己在进行输入或输出（例如，发出一个`print`指令），但它并不知道数据是先被送到了磁盘的“井”里，也不知道数据何时、如何从“井”里传送到最终设备。整个数据在“慢速设备 ↔ 输入/输出井”之间的传送过程，是由操作系统中的 #SPOOLing管理进程（守护进程，Daemon） 来控制和调度的，而不是由用户作业直接控制。如果由用户作业来控制，就失去了系统统一管理和提高效率的意义。


![[2016-exam-paper-ocr.pdf#page=4&rect=75,206,516,272|2016-exam-paper-ocr, p.4]]
[[截屏2025-09-30 上午4.25.03.png]]
[[信号量与管程的对比]]
1. [[同步机制]]  [[管程]] 
	1. A. 管程只能用于实现进程的互斥
		1. 管程不仅能实现进程间的互斥，而且能实现进程间的同步
		2. 管程通过其固有的互斥特性和内部的“条件变量”机制，既解决了互斥问题，也解决了同步问题。 
	2. B. 管程是由编程语言支持的进程同步机制
		1. 管程是一种高级同步原语，它不是由操作系统内核直接提供给程序员的系统调用（像 #信号量 那样），而是作为一种语言构件在编程语言层面实现的 
			1. 编译器会自动为管程的过程加上进入和退出的代码（类似加锁和解锁），从而为程序员隐藏了复杂的底层实现。所以这个说法是**正确**的
	3. C. 任何时候只能有一个进程在管程中执行
		1. 这是管程最核心的特性—— #管程的互斥性 。管程的设计保证了在任何一个时刻，最多只有一个进程能在管程内部执行其代码。
	4. D. 管程中定义的变量只能被管程内的过程访问 
		1. #管程的封装性 管程将共享的资源（数据结构）和对这些资源的操作（过程/方法）封装在一起。外部进程无法直接访问管程内部的数据，必须通过调用管程提供的过程来间接访问。
#管程  
- 衍生 
	- #条件变量的操作 ：`wait` 和 `signal` 
		*   `c.wait()`: 当一个进程在管程中执行时，如果它所期望的条件不满足，它可以调用条件变量`c`的`wait`操作。该进程会立即释放管程的互斥访问权，并进入与`c`关联的等待队列中，变为阻塞状态。
		*   `c.signal()`: 当一个进程在管程中改变了某个条件，它可能会唤醒其他等待该条件的进程。它会调用相应条件变量`c`的`signal`操作。如果等待队列中有进程，则唤醒其中一个。
	- [[信号量与管程的对比]]  
	- [[signal操作的两种语义 (Hoare vs. Mesa)]]  

![[2016-exam-paper-ocr.pdf#page=4&rect=74,161,473,211|2016-exam-paper-ocr, p.4]]
![[Pasted image 20251010005537.png]]
[[Pasted image 20250930042548.png]]
1. [[设备与层级]]
	1.  **Hub (集线器):**
    > 	“集线器是一个多端口的中继器，工作在**物理层**。”
	    *   从 OSI 模型图中可以看到，**物理层 (物理层)** 对应的是第 **1** 层。
	
	2.  **Switch (交换机):**
    > 	“以太网交换机是一个多端口的网桥，工作在**数据链路层**。”
	    *   从 OSI 模型图中可以看到，**数据链路层 (数据链路层)** 对应的是第 **2** 层。
	
	3.  **R1 (路由器):**
    > 	“路由器是**网络层**设备，它实现了网络模型的下三层，即物理层、数据链路层和网络层。”
	    *   虽然路由器实现了 1、2、3 层的功能，但题目问的是“最高功能层”。因此，路由器的最高功能层是**网络层 (网络层)**，对应的是第 **3** 层。 [[路由器的核心功能]]  

- 衍生  
	- [[数据单元PDU]]  
		- 考试中经常会问每一层处理的数据单元叫什么
	- [[冲突域与广播域]]  
		- #网关  #默认网关  [[默认网关]]

![[2016-exam-paper-ocr.pdf#page=5&rect=70,553,550,824|2016-exam-paper-ocr, p.5]]
[[Pasted image 20250930042556.png]]
[[数据链路层的信道利用率（有效数据传输速率）]]
[[信噪比]] 
1. 第一步：理解核心理论 - 香农定理 [[香农定理]]  
	1. 定理给出了一个在存在高斯白噪声干扰的信道中，理论上能够达到的、无差错传输的最大数据速率，也称为 #信道容量
		1. $C_{max}=W\log_2{(1+S/N)}$
			*   $C$ 是信道的理论最大数据传输速率，单位是比特/秒 (bps)。
			*   $W$ 是信道的带宽 (Bandwidth)，单位是赫兹 (Hz)。
			*   $S/N$ 是信噪比 (Signal-to-Noise Ratio)，是信号功率与噪声功率的比值，它是一个**没有单位的纯数值**。
		2. **信噪比 (SNR)**: 30 dB。注意，这里的单位是分贝 (dB)，而不是公式中需要的纯数值 $S/N$ 
			1. $SNR_{dB} = 10 \log_{10}(S/N)$
			2. $30 = 10 \log_{10}(S/N)$ 
				1. $3 = \log_{10}(S/N)$
					$S/N = 10^3 = 1000$
		3. $C = 8000 \times \log_2(1 + 1000)$
			$C = 8000 \times \log_2(1001)$
			1. $\log_2(1001)$ 很难直接计算。我们通常使用一个近似值。因为 $1001$ 非常接近 $1024$，而 $1024 = 2^{10}$，所以 $\log_2(1024) = 10$
		4. 将单位换算为 kbps (1 kbps = 1000 bps):  
			$C \approx 80 \text{ kbps}$
		5. 计算 #实际数据传输速率 
			1. 实际速率是理论最大速率的 50%。
				实际速率 = $C \times 50\%$
				实际速率 = $80 \text{ kbps} \times 0.5$
				实际速率 = $40 \text{ kbps}$
- 衍生 
	- [[结合信道带宽（奈奎斯特定理）]]  
		- 一个带宽为 4kHz 的无噪声信道，如果采用 8 相位调制（即 $L=8$），其理论最大数据传输速率是多少？
			**解**：
			$C_{max} = 2 \times 4000 \times \log_2(8) = 8000 \times 3 = 24000 \text{ bps} = 24 \text{ kbps}$。
	- [[香农定理与奈奎斯特定理的综合应用]] 
		- 信道的实际极限速率应取这两个公式计算结果中的**较小值**。


![[2016-exam-paper-ocr.pdf#page=5&rect=75,502,520,552|2016-exam-paper-ocr, p.5]]
![[Pasted image 20251010005537.png]] 
[[Pasted image 20250930042605.png]]
[[Pasted image 20250930042622.png]]


#交换机的学习过程  [[交换机的学习过程]]     
1.  **确认帧的路径**：题目关注的是 H4 发送给 H2 的**确认帧**。所以我们的分析起点是 H4，终点是 H2。

2.  **H4 发送数据帧**： 
    *   H4 连接在一个**集线器 (Hub)** 上。   [[集线器vs交换机]] 
    *   集线器是一个物理层（Layer 1）设备。它的工作方式非常简单：它将从一个端口收到的电信号进行放大和整形，然后**复制并广播**到**所有其他端口**。它不理解也不查看数据帧中的任何地址信息（如 MAC 地址）。
    *   因此，当 H4 发送确认帧时，这个帧首先到达集线器。

3.  **集线器（Hub）的处理**：
    *   集线器接收到来自 H4 的信号后，会将其广播到所有其他连接的端口。
    *   与该集线器相连的设备有：**H3** 和通向**交换机 (Switch)** 的链路。
    *   所以，在这一步，**主机 H3** 的网卡会从物理层上接收到这个信号（也就是这个数据帧）。

4.  **交换机（Switch）的处理**： #交换机 [[交换机]]     [[以太网交换机行为]] 
    *   这个确认帧的目的地是 H2。该帧通过集线器后，也会被发送到交换机。
    *   交换机是一个 数据链路层（Layer 2）设备。它比集线器智能得多。它内部维护着一张 #MAC地址表 ，记录了每个 MAC 地址与其连接的交换机端口的对应关系  #MAC地址表的老化  
    *   当交换机收到一个数据帧时，它会执行以下操作： 
        *   读取帧头中的**目的 MAC 地址**。在这个场景中，目的 MAC 地址是 H2 的 MAC 地址。
        *   查询其 MAC 地址表，找到 H2 所在的端口。
        *   将该数据帧**仅仅**从连接 H2 的那个端口转发出去。它**不会**将这个帧转发到连接 H1 的端口。这种行为被称为**精确转发**或**目标转发**。

5.  **最终接收方**：
    *   **H2**：作为确认帧的最终目的地，它理所当然会收到这个帧。
    *   **H3**：因为它和发送方 H4 连接在同一个集线器上，由于集线器的广播特性，H3 也会在物理层上收到这个帧（尽管它的网卡在检查目的 MAC 地址后会丢弃它，但物理层确实接收到了信号）。
    *   **H1**：因为它连接在交换机上，而交换机只会将帧精确地转发给 H2，所以 H1 所在的端口不会收到这个帧的信号。

- [[冲突域与广播域]] 
	- 这道题主要考察了**冲突域 (Collision Domain)** 的概念，以及不同网络设备对冲突域的隔离能力

| 设备类别 | 工作层次 | 功能 | 隔离冲突域 | 隔离广播域 |
| :--- | :--- | :--- | :--- | :--- |
| 集线器 (Hub) | 物理层 | 信号放大与广播 | 否 | 否 |
| 交换机 (Switch) | 数据链路层 | 基于 MAC 地址的帧转发 | 是 | 否 |
| 路由器 (Router) | 网络层 | 基于 IP 地址的包转发 | 是 | 是 |
- 衍生 
	- #APR协议的工作过程 
		- **问题**：在 H2 首次向 H4 发送数据帧之前，它如何知道 H4 的 MAC 地址？
	    *   **解答**：H2 会发送一个 **ARP 请求**。ARP 请求是一个**广播帧**。
	    *   **路径**：这个广播帧会从 H2 发出，经过交换机，交换机会把它转发到所有其他端口（包括连接 H1 的端口和连接集线器的端口）。然后集线器再将它广播到 H3 和 H4。所以 H1, H3, H4 都会收到这个 ARP 请求。只有 H4 会以一个**单播帧**（ARP 响应）回复给 H2。
	- #单播地址   [[不同通信模式的路径]]  
	- [[跨网段通信]] 
		- **问题**：如果 H1 要访问 `Web服务器 (130.18.10.1)`，数据包会经过哪些设备

![[2016-exam-paper-ocr.pdf#page=5&rect=74,455,524,503|2016-exam-paper-ocr, p.5]]
[[Pasted image 20251010005537.png]]
[[Pasted image 20250930042634.png]]
- 这道题的本质是考察在遵循 #CSMA/CD协议  (载波侦听多路访问/冲突检测) 的以太网中，如何根据各项参数计算一个 #冲突域 (Collision Domain)  的 #最大网络直径

#比特流  
#前导码    #两点间的距离公式 
#传播时延 
#信号传播速度   

- 这个时间关系可以用公式表示为：
	$T_{tx} \ge 2 \times T_p$
	其中：
	- $T_{tx}$ (Transmission Time): 发送一个最短有效帧所需的 #发送时延 
	- $T_p$ (Propagation Delay): 信号在网络两端之间的**单程传播时延**。
	- $2 \times T_p$: 信号的往返传播时延 (Round-Trip Time)。
- 步骤 1: 计算争用期  
	1. [[CSMA-CD最小帧长问题]]  [[以太网帧结构]]   
	2. #看图说话 题目中提到 Hub 是 #100Base-T集线器 ，因此速率为 **100Mbps**  #集线器  
		1. $T_{tx} = \frac{\text{最小帧长}}{\text{数据传输速率}}$
			首先，将单位统一：
			- 最小帧长 = $64 \text{ B} = 64 \times 8 \text{ bit} = 512 \text{ bit}$
			- 数据传输速率 = $100 \text{ Mbps} = 100 \times 10^6 \text{ bit/s}$
			1. $T_{tx} = \frac{512 \text{ bit}}{100 \times 10^6 \text{ bit/s}} = 5.12 \times 10^{-6} \text{ s} = 5.12 \mu s$ 
		2. 这个 $5.12 \mu s$ 就是100Mbps #以太网的争用期
- 步骤 2: 计算最大允许的单程总延迟 
	1.  #核心原则  
		1. 最大单程总延迟 = $\frac{\text{争用期}}{2} = \frac{5.12 \mu s}{2} = 2.56 \mu s$ 
	2. 这个 $2.56 \mu s$ 包括了信号在物理介质（网线）中的传播延迟，以及信号经过网络设备（如本题中的Hub）时产生的处理延迟
- 步骤 3: 计算可用于物理传播的延迟 
	1. 题目中明确指出，Hub在再生比特流的过程中会产生 $1.535 \mu s$ 的延迟
		1. 可用的单程传播延迟 $T_{传播} = \text{最大单程总延迟} - \text{Hub延迟}$
			$T_{传播} = 2.56 \mu s - 1.535 \mu s = 1.025 \mu s$
- 步骤 4: 计算最大距离 
	- 最大距离 = $\text{传播速度} \times \text{可用的单程传播延迟}$
		$D_{max} = 200 \text{ m/μs} \times 1.025 \mu s = 205 \text{ m}$ 
- 衍生 
	- 改变网络速率 
		- **问题示例**: 如果将Hub换成10Base-T (10Mbps) 的集线器，其他条件不变，最大距离是多少？ 
			- **解法**: 重新计算争用期。$T_{tx} = \frac{512 \text{ bit}}{10 \times 10^6 \text{ bit/s}} = 51.2 \mu s$。最大单程延迟变为 $25.6 \mu s$。可用传播延迟为 $25.6 - 1.535 = 24.065 \mu s$。最大距离为 $200 \times 24.065 \approx 4813 \text{ m}$
	- 计算网络中允许的中继器数量  #中继器 
		-  **问题示例**: 在一个100Mbps的以太网中，两台主机相距400m，信号传播速度为 $200 \text{ m/μs}$。如果每个中继器（Hub）产生 $0.8 \mu s$ 的延迟，最多可以串联多少个中继器？ 
			- **解法**: 先计算信号的单程传播时延 $T_{传播} = \frac{400 \text{ m}}{200 \text{ m/μs}} = 2 \mu s$。最大单程总延迟仍为 $2.56 \mu s$。那么可用于设备的总延迟为 $2.56 - 2 = 0.56 \mu s$。允许的中继器数量为 $\frac{0.56 \mu s}{0.8 \mu s/\text{个}} = 0.7$。因此，一个中继器都不能放（必须小于等于0.7）
	- 反求 #最小帧长
		-  **问题示例**: 某网络速率为1Gbps，主机间最大距离为100m，信号传播速度为 $200 \text{ m/μs}$，不考虑设备延迟。为了让CSMA/CD协议有效工作，最小帧长应为多少字节？
		-   **解法**: 先计算争用期。$T_{传播} = \frac{100 \text{ m}}{200 \text{ m/μs}} = 0.5 \mu s$。争用期 = $2 \times T_{传播} = 1 \mu s$。根据 $T_{tx} \ge \text{争用期}$，最小帧长 = $\text{速率} \times \text{争用期} = (1 \times 10^9 \text{ bit/s}) \times (1 \times 10^{-6} \text{ s}) = 1000 \text{ bit}$。换算成字节：$\frac{1000}{8} = 125$ 字节。（这也是为什么千兆以太网在 #半双工模式 下需要引入“ #载波扩展 ”或“ #帧突发 ”技术，因为保持64字节最小帧长会导致网络直径过小）


![[2016-exam-paper-ocr.pdf#page=5&rect=74,405,520,457|2016-exam-paper-ocr, p.5]]
![[Pasted image 20251010005537.png]]
[[Pasted image 20250930042639.png]]
- 初始状态分析   [[路由器的核心功能]]   #学习  #计算机网络入门题目  
	1. **事件**: R3检测到网络 `201.1.2.0/25` 不可达。这通常意味着该网络是与R3直接相连的，或者是通过R3才能访问的。 
		1. - **R3 到网络 201.1.2.0/25**：距离是 **0** (直连)。
		    - 当 R3 把这条路由信息告诉它的**另一个邻居 R1** 时，它会把距离加1。所以 R3 直接告诉 R1：“通过我，你到 201.1.2.0/25 的距离是 **1**”。
			- 当 R1 收到来自 R3 的这条信息时，R1 计算出的总距离是：**R3 告诉我的距离 (1) + 我到 R3 的距离 (1) = 2**。
	2. **关键信息**: “R1到该网络的距离为2” 
		1. R1 — R2 — R3 — 网络(201.1.2.0/25)
		- 路由器 R1 实际上会从它的两个邻居（R2 和 R3）那里都学到去往 201.1.2.0/25 的路由：
			1. **从 R2 学到的路径**：R1 -> R2 -> R3 -> 网络，计算出的距离(Metric)是 **3**。
			2. **从 R3 学到的路径**：R1 -> R3 -> 网络，计算出的距离(Metric)是 **2**。
	3.  #坏消息传得慢    
		1. **R3检测到故障**: R3与网络 `201.1.2.0/25` 的连接中断。R3将该网络的路由距离设置为无穷大。在RIP协议中，距离`16`代表无穷大，即网络不可达。
		2.  **R3发送更新**: R3立即（或在下一个更新周期）向其邻居R2发送路由更新，通告网络 `201.1.2.0/25` 的距离为`16`。
		3.  **R2收到更新并重新计算**:
			1. R2收到了来自R3的“坏消息”，得知通过R3到达目标网络的路径已失效。 [[RIP协议]]  
			    *   **关键点来了**：由于“坏消息传得慢”，R3的更新信息此时只到达了R2，尚未传播到R1。因此，R1的 #路由表 仍然是旧的、错误的——它仍然认为自己可以通过R2以距离2到达目标网络。
			    *   R1会正常地向其邻居（包括R2）发送自己的路由表。所以，R2会收到来自R1的路由更新，内容是：“我（R1）可以到达网络 `201.1.2.0/25`，距离是2”。
			    *   R2现在有两个关于目标网络的信息：
			        *   来自R3：距离为16（不可达）。
			        *   来自R1：距离为2（可达）。
			    *   根据距离矢量算法，R2会选择距离更小（更优）的路径。于是，R2抛弃了来自R3的路径，选择了来自R1的路径。
			    *   R2更新自己的路由表。新的距离计算公式为：
			        $新距离 = 到达下一跳的距离 + 下一跳通告的距离$
			        在这个场景中，就是：
			        $R2的新距离 = R2到R1的距离 + R1通告的距离 = 1 + 2 = 3$
			    *   所以，R2更新后的路由表项变为：目标网络 `201.1.2.0/25`，距离`3`，下一跳`R1`。

	- 问题的本质： #路由环路
		- 这个过程实际上形成了一个暂时的 #路由环路 。R2认为去往目标网络应该找R1，而R1仍然认为应该找R2。数据包会在R1和R2之间来回传递，直到它们的TTL（生存时间）耗尽。这个环路会随着后续的更新逐步被打破（距离会不断增加，直到16），但在此刻，R2计算出的新距离就是3

- 衍生 
	- #RIP协议的防环机制   [[RIP协议]]  
		- 为了解决“计数到无穷”问题，RIP引入了多种机制。题目可能就会考察这些机制如何工作或是否能解决特定场景下的环路问题 


![[2016-exam-paper-ocr.pdf#page=5&rect=75,344,516,406|2016-exam-paper-ocr, p.5]]
![[Pasted image 20251010005537.png]]
[[Pasted image 20250930042644.png]]
- 这道题的核心是考察在IP网络中，数据包在经过路由器转发时，其源IP地址和目的IP地址的变化情况，并结合了 #子网划分 的知识。

[[HTTP请求报文结构]]  
1.  第一步：确定 #目的IP地址 
	1. **问题**: 当主机H3访问Web服务器S时，IP数据包的目的地是哪里？
		*   **分析**: 毫无疑问，通信的目的地是Web服务器S。题目中虽然没有直接给出S的IP地址，但是在选项中都出现了 `130.18.10.1` 作为目的地址（除了选项B），并且在解析中明确指出“Web服务器的IP地址为130.18.10.1”
	2. [[路由器的工作原理与NAT]]   [[路由器的核心功能]] 
		1.  **结论**: 因此，当数据包从H3发出，经过R2转发时，其目的IP地址始终是Web服务器S的地址，即 `130.18.10.1` 
		2.  这一步可以立即排除选项B和C，因为它们的目的IP地址不正确。我们只需要在A和D之间选择
2. 第二步：确定 #源IP地址
	1. 我们需要在 `192.168.3.251` 和 `201.1.3.10` 之间选择正确的源IP地址。这需要我们对题目给出的 `201.1.3.x/30` 这个网络地址进行分析
	2. [[CIDR无类域间路由]] #CIDR和子网掩码 
		1.   地址 `201.1.3.x/30` 使用了无类别域间路由（CIDR）表示法。`/30` 表示IP地址的前30位是网络地址，剩下的`32 - 30 = 2`位是 #主机地址 。 #网络地址的主机位 
		    *   `/30` 对应的子网掩码是 `255.255.255.252`
	3. 分析`/30`子网 
		1.  一个`/30`的子网，其 #主机位 只有2位。根据这两位的组合，总共可以有 $2^2=4$ 个地址
		2. 这两个主机位的可能取值是 `00`, `01`, `10`, `11`。
		    *   **规则**:
		        *   主机位全为 `0` (`00`) 的地址是**网络地址**，不能分配给设备。
		        *   主机位全为 `1` (`11`) 的地址是**广播地址**，不能分配给设备。
			1.  因此，一个`/30`的子网中只有2个可用的主机IP地址，这非常适合用于连接两个设备的点对点链路 
	4. 计算具体的地址范围
		1. R1的一个接口IP是 `201.1.3.9` 
			1. 将 `201.1.3.9` 的最后一部分 `9` 转换为二进制，得到 `00001001`
			2. 子网掩码 `255.255.255.252` 的最后一部分 `252` 的二进制是 `11111100`
			3. 将IP地址和子网掩码进行按位与（AND）运算，可以得到网络地址：  #AND运算  [[IP地址与子网掩码]]
		        `00001001` (9)
		        AND `11111100` (252)
		        = `00001000` (8)
		    *   所以，该子网的网络地址是 `201.1.3.8`
	5. **列出该子网的所有地址**:
	    *   **网络地址**: `201.1.3.8` (主机位为`00`)
	    *   **第一个可用IP**: `201.1.3.9` (主机位为`01`)，题目已告知分配给了R1。
	    *   **第二个可用IP**: `201.1.3.10` (主机位为`10`)。
	    *   **广播地址**: `201.1.3.11` (主机位为`11`)。
	6. 推断 #源IP地址 
		1. R1、R2、R3之间的点对点链路使用这个地址段。这暗示了R1、R2、R3的接口共享这个 `201.1.3.8/30` 子网 
		2. `201.1.3.9` 已经分配给R1，那么在这个点对点链路 上，另一个设备（很可能是H3所在网络的网关路由器，如R2或R3）的接口地址必然是剩下的唯一可用地址 `201.1.3.10` 
- 衍生 
	- #CIDR与子网划分   [[子网划分核心概念]] 
		- **核心概念**: 使用 `IP地址/前缀长度` 的方式来表示网络。例如 `/30` 表示前30位为网络位。
	    *   **计算**:
	        *   子网内地址总数: $2^{(32 - \text{前缀长度})}$
	        *   子网内可用主机数: $2^{(32 - \text{前缀长度})} - 2$
		-  **衍生考点**:
	        *   给你一个IP地址和子网掩码，要求计算出其网络地址、广播地址、可用IP范围和可用主机数。例如，计算 `172.16.10.100/27` 的相关信息。
	        *   给你一个大的地址块（如 `192.168.0.0/24`），要求为多个不同规模的部门（如需要30台、50台、10台主机的部门）进行合理的子网划分 #VLSM可变长子网掩码 
	- #特殊IP地址 
		-  **网络地址**: 标识一个网络本身，主机位全为0。例如本题的 `201.1.3.8`。
	    *   **广播地址**: 向该网络中的所有主机发送数据，主机位全为1。例如本题的 `201.1.3.11`。
	    *   **衍生考点**:
	        *   **私有IP地址范围 (RFC 1918)**: 必须熟记。
	            *   A类: `10.0.0.0` - `10.255.255.255` (`10.0.0.0/8`)
	            *   B类: `172.16.0.0` - `172.31.255.255` (`172.16.0.0/12`)
	            *   C类: `192.168.0.0` - `192.168.255.255` (`192.168.0.0/16`)
	        *   **环回地址**: `127.0.0.0/8`，通常用 `127.0.0.1` 来测试本机网络协议栈。
	        *   **链路本地地址 (APIPA)**: `169.254.0.0/16`，当 #DHCP 失败时，主机会自动配置这个范围的地址。
	* [[路由器的工作原理与NAT]] 
		* 区分路由器和交换机的功能。交换机工作在数据链路层，根据MAC地址转发数据帧；路由器工作在网络层，根据IP地址转发数据包
	
	
	

![[2016-exam-paper-ocr.pdf#page=5&rect=80,268,521,345|2016-exam-paper-ocr, p.5]]
[[Pasted image 20251010005537.png]]
[[Pasted image 20250930042650.png]]
- 这道题目的核心是考察在给定的IP配置下，网络设备之间通信的可达性。要解决这个问题，我们需要运用IP地址、子网掩码、默认网关以及数据包转发的基本原理 
[[IP地址与子网掩码]]
1. 第一步：分析子网划分 
	1. 题目给出了两组设备的 #子网掩码 都是 `255.255.255.128` 
		1. 它用来区分一个IP地址的哪部分是网络号，哪部分是主机号，从而判断两个IP地址是否在同一个子网（网段）内
		    *   `255.255.255.128` 转换为二进制是 `11111111.11111111.11111111.10000000`。
		    *   这表示IP地址的前25位是网络位，后7位是主机位。这种表示法也称为CIDR（无类域间路由）表示法，记作 `/25`。
	2. 计算网络地址
		1. 一个IP地址所在的网络地址可以通过将该IP地址与其子网掩码进行按位与 #AND运算 得到。计算公式为：
			    $网络地址 = IP地址 \ \& \ 子网掩码$
		基于这个子网掩码，`192.168.3.0` 这个C类网络被划分成了两个子网：
    3.  **子网一**:
        *   网络地址: `192.168.3.0` (因为 `192.168.3.1` & `255.255.255.128` = `192.168.3.0`)
        *   可用主机IP范围: `192.168.3.1` 到 `192.168.3.126`
        *   广播地址: `192.168.3.127`
    4.  **子网二**:
        *   网络地址: `192.168.3.128` (因为 `192.168.3.254` & `255.255.255.128` = `192.168.3.128`)
        *   可用主机IP范围: `192.168.3.129` 到 `192.168.3.254`
        *   广播地址: `192.168.3.255`
	5.  **设备归属判断**:
    *   H1和H2的默认网关是 `192.168.3.1`，属于**子网一**。因此，H1和H2被配置在子网一。
    *   H3和H4的默认网关是 `192.168.3.254`，属于**子网二**。因此，H3和H4被配置在子网二。
	**结论**: H1和H2在同一个子网，H3和H4在同一个子网，但(H1, H2)与(H3, H4)分属于两个不同的子网。
2. 第二步：逐一分析选项 
	1. A. H1 不能与 H2 进行正常 IP 通信
		1.   **判断**: 错误。
		    *   **原因**: H1和H2位于同一个子网（子网一）。在同一子网内的设备通信，数据包是直接通过交换机在第二层（数据链路层）转发的，不需要经过路由器（网关）。因此，它们之间可以正常通信。
	2. D. H3 不能与 H4 进行正常 IP 通信
		1.    **判断**: 错误。
		    *   **原因**: 与选项A同理，H3和H4位于同一个子网（子网二），它们之间也可以直接正常通信。
	3. B. H2 与 H4 均不能访问 Internet
		1.    **判断**: 错误。
	    *   **原因**: 访问Internet属于跨网段通信，需要通过默认网关。
	        *   对于H4，它的默认网关配置为 `192.168.3.254`。假设这个网关（路由器）配置正确且连接到Internet，那么H4就可以正常访问Internet。
	        *   对于H2，它的默认网关配置为 `192.168.3.1`。
	        *   因为选项中断言两者“均不能”，但H4是有可能访问Internet的，所以这个论断是错误的。
	4. **C. H1 不能与 H3 进行正常 IP 通信**
	    *   **判断**: 正确。
	    *   **原因**: H1和H3位于不同的子网，它们之间的通信（称为**跨网段通信**）必须通过路由器进行转发。
	    *   **通信流程模拟**:
	        1.  H1（在子网一）想要发送数据包给H3（在子网二）。
	        2.  H1通过子网掩码计算发现H3与自己不在同一个网段。
	        3.  因此，H1会将数据包发送给自己的**默认网关**，即 `192.168.3.1`。
	        4.  这个数据包的目的地是H3，它需要被路由到子网二。子网二的网关（也就是H3的网关）是 `192.168.3.254`。
	        5.  问题就出在这里：H1的网关 `192.168.3.1` 和H3所在网络的网关 `192.168.3.254` 位于两个完全不同的子网。一个正常的网络拓扑中，通常一个路由器会用不同的接口连接这两个子网，例如，一个接口IP是 `192.168.3.1`，另一个接口IP是 `192.168.3.254`。
	        6.  但是，题目给出的配置是两组设备分别配置了**不同的网关**。这暗示了一个严重的**配置错误**。H1发送给网关 `192.168.3.1` 的数据包，这个网关很可能不知道如何将数据包路由到 `192.168.3.128/25` 这个网络，或者这个网关本身就是错误的、不存在的设备。因此，数据包无法被正确转发到H3。
	    *   **结论**: 由于网关配置问题导致路由路径不通，H1无法与H3进行正常的IP通信。
- 衍生 
	- #VLSM可变长子网掩码 
		-   这道题是固定长度子网划分的简单情况。更复杂的场景可能会在一个大网络中根据不同部门的需求划分出大小不一的多个子网，这就需要用到VLSM。例如，一个 `/24` 的网络可以划分为一个 `/26`，一个 `/27` 和几个 `/30` 的子网 
	- #CIDR无类域间路由  也就是 `/` 表示法。考试可能会要求你计算一个CIDR地址块的可用IP数量、网络地址和广播地址。例如，`172.16.10.0/22` 的网络范围是多少？ 
	- #路由表查询
		- 当路由器收到一个数据包时，它是如何决定从哪个接口发出去的？这涉及到路由表的**最长匹配原则**。可能会给出一个路由表和一个目的IP地址，让你判断数据包的下一跳。
	- #网络故障排查
		- 类似本题，给出一种网络故障现象（如无法上网、无法访问特定服务器），让你从IP配置（IP地址、子网掩码、网关、DNS）中找出错误原因。
	- [[ARP地址解析协议]]
		- 可能会考察ARP协议的工作原理，例如ARP请求是广播，ARP响应是单播。以及ARP欺骗攻击的基本概念。


![[2016-exam-paper-ocr.pdf#page=5&rect=81,202,515,270|2016-exam-paper-ocr, p.5]]
[[Pasted image 20251010005537.png]]
[[Pasted image 20250930042658.png]]
[[DNS域名系统]]混合查询模式分析:
#迭代查询方式 
域名 `www.abc.xyz.com` 的层级结构从右到左依次是：
1.  `.` (根域)
2.  `.com` (顶级域, Top-Level Domain, TLD)
3.  `xyz.com` (二级域, Authoritative Domain)
4.  `abc.xyz.com` (子域)
5.  `www.abc.xyz.com` (主机名)
- 最少查询次数的推导
	DNS查询为了提高效率和减少网络负载，设计了**高速缓存 (Cache)** 机制。缓存可以存在于多个地方，包括用户的浏览器、操作系统、本地DNS服务器等。
	
	*   **最佳情况（最少查询）:** 当主机 H4 发起域名解析请求时，系统会首先检查自己的[[DNS高速缓存]]。如果 H4 的本地缓存中**已经存在** `www.abc.xyz.com` 对应的IP地址记录（并且该记录未过期），那么它将直接使用该记录，根本**不需要向任何外部DNS服务器（包括`201.1.1.1`）发起任何查询**。
	
	因此，在最理想的情况下，发出的DNS查询次数为 **0**。
- [[DNS查询方式]]    [[DNS解析流程（无缓存）]]
	1.  **第1次查询:** 本地DNS服务器向**根域名服务器 (Root DNS Server)** 发起查询，询问 `www.abc.xyz.com` 的IP地址。根服务器不知道完整地址，但它知道哪个服务器管理 `.com` 域。于是，它会返回 `.com` 顶级域名服务器的地址。
	
	2.  **第2次查询:** 本地DNS服务器拿到 `.com` 服务器的地址后，向 **`.com` 顶级域名服务器 (TLD DNS Server)** 发起查询。`.com` 服务器也不知道完整地址，但它知道哪个服务器管理 `xyz.com` 域。于是，它返回 `xyz.com` 权限域名服务器的地址。
	
	3.  **第3次查询:** 本地DNS服务器向 **`xyz.com` 权限域名服务器 (Authoritative DNS Server)** 发起查询。这个服务器同样可能不知道 `www.abc.xyz.com` 的地址，但它知道管理子域 `abc.xyz.com` 的服务器地址。于是，它返回 `abc.xyz.com` 权限域名服务器的地址。
	
	4.  **第4次查询:** 本地DNS服务器向 **`abc.xyz.com` 权限域名服务器** 发起查询。这个服务器在其区域文件中查找 `www` 这条主机记录，找到对应的IP地址，并将其返回给本地DNS服务器。
	
	至此，本地DNS服务器 `201.1.1.1` 总共发出了 **4** 次查询才获得最终的IP地址。
- 衍生 
	- #混合查询 模式分析
		- 主机向本地DNS服务器发起**递归查询**，然后本地DNS服务器使用**迭代查询**向其他服务器查询。问题可能会问“整个过程中共发生了几次递归查询和几次迭代查询？”
		-  答案：通常是1次递归查询（主机 -> 本地DNS）和多次迭代查询（本地DNS -> 其他DNS服务器）
	- 考虑缓存命中位置的影响 
		- 题目可能会设置不同的缓存命中场景，让你计算查询次数。
	    *   **例1:** 如果本地DNS服务器缓存了 `.com` TLD服务器的地址，但没有 `xyz.com` 的信息，那么需要几次查询？
	        *   解答：跳过第1步（查询根服务器），直接从第2步开始，总共需要 $4-1=3$ 次查询。
	    *   **例2:** 如果主机缓存为空，但本地DNS服务器缓存中有 `www.abc.xyz.com` 的完整记录，那么主机会发出几次查询？本地DNS服务器会发出几次查询？
	        *   解答：主机发出1次（递归）查询给本地DNS服务器。本地DNS服务器因为缓存命中，不再向外查询，所以它发出的（迭代）查询次数为0。
	- [[DNS记录类型的功能]] 
	- #反向DNS查询 
		-   常规查询是“域名 -> IP”，反向查询是“IP -> 域名”。这通常通过一个特殊的域 `in-addr.arpa` (IPv4) 或 `ip6.arpa` (IPv6) 来实现。题目可能会考查反向查询的过程






![[2016-exam-paper-ocr.pdf#page=6&rect=75,633,522,821|2016-exam-paper-ocr, p.6]]
![[Pasted image 20251010005537.png]]
[[Pasted image 20250930042706.png]]
[[Pasted image 20250930042714.png]]
[[Pasted image 20251010185651.png]]
- 这道关于 #TCP协议 的计算题。这道题综合考察了TCP的三个核心阶段：连接建立（三次握手）、数据传输（拥塞控制与流量控制）和连接释放（四次挥手）。 
- [[TCP的序号和确认序号]]  
	- TCP是面向字节流的协议。序列号指的是数据段中**第一个字节**在整个数据流中的编号。例如，如果一个段包含1000字节的数据，其序列号为101，那么它包含的字节编号就是101到1100。下一个数据段的序列号将是1101
1. #往返时延RTT   (1) TCP连接建立（三次握手） 
	#标志位   #TCP标志位    [[TCP三次握手]] 
	1. **第一次握手 (H3 -> S):** 客户端H3发起连接请求。它发送一个TCP段，其中：
	    *   `SYN`标志位设为1，表示这是一个连接请求。
	    *   选择一个初始序号 (Initial Sequence Number, ISN)，题目中给出H3的初始序号为 $seq_H = 100$。
	    *   这个SYN段本身会消耗一个序号，即使它不携带数据。
	2.   **第二次握手 (S -> H3):** 服务器S收到H3的请求后，如果同意建立连接，会回复一个TCP段。这个段需要完成两件事：确认H3的请求，并发出自己的连接请求。
	    *   `SYN`标志位设为1，表示S也在发起连接。
	    *   `ACK`标志位设为1，表示确认号字段有效。
	    *   S选择自己的初始序号，我们设为 $seq_S = y$。（这个值是随机的，与H3的序号无关）。
	    *   确认序号 (Acknowledgement Number) 是对H3的SYN的确认，其值为H3的序号加1。所以 $ack = seq_H + 1 = 100 + 1 = 101$。
	    *   这个SYN+ACK段同样会消耗S的一个序号。
	3. **第三次握手 (H3 -> S):** H3收到S的回复后，发送最后一个确认段。
	    *   `ACK`标志位设为1。
	    *   序号为H3的下一个序号，即 $seq = seq_H + 1 = 101$。
	    *   确认序号是对S的SYN的确认，即 $ack = seq_S + 1 = y + 1$。
	    *   这个ACK段通常不消耗序号（除非携带数据）。
	- **结论：**
		问题问的是第二次握手（S发送给H3）的报文。根据我们的分析：
		*   SYN标志位为1。
		*   ACK标志位为1。
		*   确认序号 (ack) 是 $101$
- (2) 数据传输（流量控制与拥塞控制） [[TCP流量控制与拥塞控制]]
	- #拥塞窗口   #计算拥塞窗口  
	- TCP拥塞控制 - #慢启动算法
		-  这是TCP在连接建立初期或检测到拥塞后用于快速探测网络可用带宽的算法。
		-  **初始值**: 连接建立后，拥塞窗口`cwnd`通常被初始化为1个MSS（Maximum Segment Size，最大报文段长度）。
	    *   **增长规则**: 在慢开始阶段，每当发送方收到一个对新数据的ACK，`cwnd`就增加1个MSS。这导致`cwnd`在每个往返时间（RTT）内大约翻一番，呈现指数级增长。
	1. #计算接收窗口 `rwnd`: 
	    *   H3的接收缓存为20KB。
	    *   题目说明“数据存入而无数据取出”，意味着每收到一个数据段，H3的可用缓存就减少相应大小。
	    *   每个段大小为MSS = 1KB。
	    *   当H3收到第8个数据段时，总共收到了8 * 1KB = 8KB的数据。
	    *   此时H3的可用缓存（即它在ACK中通告的接收窗口`rwnd`）为：$rwnd = 20KB - 8KB = 12KB$
	2. #计算拥塞窗口 `cwnd` 
		*   **概念**: 在慢开始阶段，`cwnd`初始值为1 MSS，每收到一个ACK，`cwnd`增加1 MSS。
		*   **推导**:
		    *   H3的`cwnd`初始值为 $1\text{KB}$。
		    *   H3总共收到了8个确认段（ACK）。
		    *   根据慢开始算法的增长规则，`cwnd`会增加8次，每次增加1KB。
		    *   最终的`cwnd`大小为：$1\text{KB (初始值)} + 8 \times 1\text{KB} = 9\text{KB}$。
		    *   **结论**: 此时H3的拥塞窗口变为 **9KB**。
	3. #计算发送窗口  `swnd` 
		1. $swnd = \min(cwnd, rwnd) = \min(9KB, 12KB) = 9KB$ 
- (3) 窗口耗尽与传输速率  [[TCP的序号和确认序号]]  
1. 下一个待发送的数据段序号
	-    **概念**: 发送窗口等于0，通常是因为接收窗口`rwnd`降为了0（因为`cwnd`会持续增长，除非发生拥塞）。`rwnd`为0意味着接收方的缓存已被填满。
	*   **推导**:
	    *   S的接收缓存大小为20KB，当它被完全填满时，`rwnd`变为0。
	    *   这意味着H3已经成功发送了20KB的数据给S。
	    *   TCP的序列号是基于字节的。$20\text{KB} = 20 \times 1024 \text{ 字节} = 20480 \text{ 字节}$。
	    *   初始序列号是101，这意味着发送的第一个字节的编号是101。
	    *   发送了20480字节后，这些字节的编号范围是从101到 $101 + 20480 - 1 = 20580$。
	    *   因此，**下一个**待发送的数据段的序列号（即第20581个字节的编号）将是 $101 + 20480 = 20581$。
	    *   **结论**: 下一个待发送的数据段序号是 **20581**。
2.  #平均数据传输速率 [[数据链路层的信道利用率（有效数据传输速率）]]  
	*   **概念**: 平均速率 = 总传输数据量 / 总耗时。我们需要计算发送20KB数据总共花了多长时间。
	*   **推导**:
	    *   时间主要由数据在网络中传输的往返时间（RTT）决定。我们通过模拟慢开始过程来计算总共需要多少个RTT。
	        *   **第1个RTT**: H3发送1个段 (1KB)。累计发送: 1KB。
	        *   **第2个RTT**: 收到1个ACK，`cwnd`变为2KB。H3发送2个段 (2KB)。累计发送: $1+2=3\text{KB}$。
	        *   **第3个RTT**: 收到2个ACK，`cwnd`变为4KB。H3发送4个段 (4KB)。累计发送: $3+4=7\text{KB}$。
	        *   **第4个RTT**: 收到4个ACK，`cwnd`变为8KB。H3发送8个段 (8KB)。累计发送: $7+8=15\text{KB}$。
	        *   **第5个RTT**: 收到8个ACK，`cwnd`变为16KB。此时只需再发送 $20 - 15 = 5\text{KB}$ 的数据。因为 $5\text{KB} < cwnd(16\text{KB})$，H3可以一次性将剩余的5KB全部发出。累计发送: $15+5=20\text{KB}$。
	    *   从发送第一个数据段开始，到发送完最后一个数据段（第5轮），总共经历了5个“传输轮次”。每个轮次的时间约等于一个RTT。
	    *   因此，总耗时为 $5 \times \text{RTT} = 5 \times 200\text{ms} = 1000\text{ms} = 1\text{s}$。
	    *   平均数据传输速率 = $\frac{\text{总数据量}}{\text{总时间}} = \frac{20\text{KB}}{1\text{s}} = 20 \text{ KB/s}$。

	- #字节 #比特率C [[比特率 波特率 码元]] 
- 4. 若H3与S之间通信已经结束，在t时刻H3请求断开该连接，则从t时刻起，S释放该连接的最短时间是多少？ 
	- #释放连接 
1. 四次挥手过程与时间计算
	1. **概念**: 我们需要计算从H3发起断开连接（发送第一个FIN）到S完成连接释放（收到最后一个ACK）所经过的时间
	-   **推导**:
	    1.  **时刻 t**: H3发送第一个连接释放报文段 (FIN)。
	    2.  **时刻 t + 0.5 RTT**: S收到H3的FIN。
	        *   *时间流逝: 100ms*
	    3.  **S的操作**: S收到FIN后，立即回复一个ACK。因为题目说明“S已经没有数据需要传输”，所以S可以立即发送自己的FIN报文段，而无需等待。因此，ACK和FIN可以几乎同时发出。
	    4.  **时刻 (t + 0.5 RTT) + 0.5 RTT = t + 1 RTT**: H3收到S的FIN报文段。
	        *   *时间流逝: 又一个100ms*
	    5.  **H3的操作**: H3收到S的FIN后，立即回复最后一个ACK报文段。
	    6.  **时刻 (t + 1 RTT) + 0.5 RTT = t + 1.5 RTT**: S收到H3的最后一个ACK。此时，S的连接被完全释放。
	        *   时间流逝: 再一个100ms
	*   **总时间**: 从时刻t开始，到S释放连接的时刻 $t + 1.5 \text{ RTT}$，总共经过的时间为 $1.5 \times \text{RTT}$。
	*   **计算**: $1.5 \times 200\text{ms} = 300\text{ms}$。
	*   **结论**: S释放该连接的最短时间是 **300ms**。

- 衍生 
	- 拥塞控制 
		-  #拥塞避免 : 当`cwnd`超过慢开始门限`ssthresh`后，TCP会进入拥塞避免阶段，此时`cwnd`不再指数增长，而是线性增长（每个RTT增加1 MSS）。可能会问在某个时刻`cwnd`和`ssthresh`的值
		- #拥塞发生  
	        *   **超时重传**: 如果发生超时，`ssthresh`会降为当前`cwnd`的一半，`cwnd`重置为1 MSS，重新开始慢启动。
	        *   **快速重传/快速恢复**: 如果收到3个重复的ACK，`ssthresh`降为当前`cwnd`的一半，`cwnd`也设为新的`ssthresh`值，然后进入快速恢复算法，而不是从1开始慢启动。
	- 流量控制与糊涂窗口综合症 
		-  如果接收方应用程序读取数据很慢，可能导致它频繁通告一个很小的接收窗口。如果发送方也发送很小的数据包，就会导致网络效率低下。可能会问Nagle算法和延迟ACK是如何缓解这个问题的 
	- 网络结构相关
		- 网络拓扑图中的 #网络地址转换NAT 是一个重要考点。可能会问H3访问Web服务器S时，数据包在R2处源IP地址如何变化。
	    *   **冲突域与广播域**: 可能会问图中Hub和Switch各自形成了多大的冲突域和广播域。 (Hub下的H3/H4在一个冲突域，Switch的每个端口是一个独立的冲突域；整个192.168.3.0/24网络是一个广播域)。





![[2016-exam-paper-ocr.pdf#page=6&rect=78,568,518,634|2016-exam-paper-ocr, p.6]]
[[Pasted image 20250930042731.png]]

#m叉树   
#正则m叉树 
#树的高度 
- (1) 若 T 有 m 个非叶结点, 则 T 中的叶结点有多少个? 
	- 这个问题的目标是建立叶结点数量和非叶结点数量之间的关系。
	**解题思路：** 我们可以利用树的两个基本性质来建立等式。
	1.  **结点总数关系**：树的总结点数 $n$等于 #叶结点 数 $n_0$ 与 #非叶结点 数 $n_k$ 之和。  #叶子节点  
	2.  **边与结点关系**：对于任何一棵树，边数 $e$ 总比结点数 $n$ 少1。 
1. 定义变量   
	1. 令 $n_0$ 为叶结点的数量。
	    *   令 $n_k$ 为非叶结点的数量。根据题意，所有非叶结点都有 $k$ 个孩子。
	    *   题目给定非叶结点数量为 $m$，所以 $n_k = m$。
	    *   令 $n$ 为树的总结点数，则 $n = n_0 + n_k = n_0 + m$
	2. 方法一：从结点与边的关系入手
		1. 根据 #树的基本性质 ，边数 $e$ 和结点总数 $n$ 的关系为：
	          $e = n - 1$ 
	    2. 总边数 $e$ 等于所有非叶结点的出度之和：
	          $e = m \times k = mk$
	3. 得到了计算边数 $e$ 的两个表达式，让它们相等：
          $n - 1 = mk$
        *   将 $n = n_0 + m$ 代入上式：
          $(n_0 + m) - 1 = mk$
        *   整理方程，求解 $n_0$：
          $n_0 = mk - m + 1$
          $n_0 = (k-1)m + 1$
- (2) 若 T 的高度为 h (单结点的树 h=1), 则 T 的结点数最多为多少个? 最少为多少个?
	1. #最多结点数 ($M_1$) 
		1. 要让结点数最多，在有限的高度 $h$ 内，树需要尽可能地“宽”和“满”。这意味着每一层都应该有最多的结点。
		2. **树的形态：**
			*   第1层到第 $h-1$ 层的每个结点都是非叶结点，并且都拥有 $k$ 个孩子。
			*   第 $h$ 层的所有结点都是叶结点 b。
			*   这构成了我们常说的 #完美k叉树  ，或者说“满”的正则k叉树。
				1. 计算每层的结点数： 
				    *   第1层（根结点）：$1 = k^0$ 个结点。
				    *   第2层：根结点的 $k$ 个孩子，共 $k = k^1$ 个结点。
				    *   第3层：第2层的 $k$ 个结点每个都有 $k$ 个孩子，共 $k \times k = k^2$ 个结点。
				    *   以此类推，第 $j$ 层的结点数为 $k^{j-1}$。
				2. **计算总结点数：**
				    *   总结点数 $M_1$ 是从第1层到第 $h$ 层所有结点数的总和：
				      $M_1 = \sum_{j=1}^{h} k^{j-1} = k^0 + k^1 + k^2 + \dots + k^{h-1}$
				    *   这是一个首项为1，公比为 $k$ 的等比数列求和。根据 #等比数列求和公式 $S_n = \frac{a_1(q^n - 1)}{q-1}$，其中 $a_1=1$, $q=k$, $n=h$： [[数列求和公式]] 
				      $M_1 = \frac{1(k^h - 1)}{k-1} = \frac{k^h - 1}{k-1}$
					1. **结论：** 高度为 $h$ 的正则k叉树，最多有 $\frac{k^h - 1}{k-1}$ 个结点。 
	 2. #最少结点数 ($M_2$) 
		1. 要让结点数最少，在必须达到高度 $h$ 的前提下，树需要尽可能地“瘦”和“长”。这意味着我们只添加必要的结点来延伸树的高度。
		2. **树的形态：**
			*   为了达到高度 $h$，必须有一条从根结点到某个叶结点的路径，其长度为 $h-1$（包含 $h$ 个结点）。
			*   我们将这条最长的路径称为“主干”。
			*   主干上的每个结点（除了最后的叶结点），即第1层到第 $h-1$ 层的结点，都必须是非叶结点。根据正则k叉树的定义，它们都必须有 $k$ 个孩子。
			*   为了使总结点数最少，除了用于延伸主干的那个孩子外，其余的 $k-1$ 个孩子都应该是叶结点，不再向下延伸。
			1. 按层分析结点构成 
			    *   **第1层：** 只有1个根结点。
			    *   **第2层：** 根结点必须有 $k$ 个孩子才能成为非叶结点。这 $k$ 个孩子构成了第2层。
			    *   **第3层：** 为了让树的高度继续增加，我们从第2层的 $k$ 个孩子中选择1个，让它成为非叶结点，并生出 $k$ 个孩子，构成第3层。第2层其余的 $k-1$ 个结点则作为叶结点。
			    *   **...**
			    *   **第 $j$ 层 ($2 \le j \le h$)**：都是由上一层（第 $j-1$ 层）主干上的那个结点生出的 $k$ 个孩子。
			    *   这个过程一直持续到第 $h$ 层，第 $h$ 层的 $k$ 个结点都是叶结点。
			2. **计算总结点数：**
			    *   根结点：1个。
			    *   从第2层到第 $h$ 层，每一层都由上一层的一个主干结点“贡献”了 $k$ 个新结点。这个过程发生了 $h-1$ 次（从第1层到第2层，...，从第 $h-1$ 层到第 $h$ 层）。
			    *   所以，除了根结点外，还新增了 $(h-1)$ 组，每组 $k$ 个结点。
			    *   总结点数 $M_2$ 为：
			      $M_2 = 1 + (h-1) \times k$
				结论： 高度为 $h$ 的正则k叉树，最少有 $1 + k(h-1)$ 个结点
- 衍生 
	- 特殊情况： #正则二叉树 (k=2) 
		- 最常见的考点。此时，问题(1)的结论变为：$n_0 = (2-1)m + 1 = m+1$。即**在任何正则二叉树（满二叉树）中，叶结点的数量比非叶结点多1**。这是一个非常重要的性质 
		- 问题(2)的结论变为：q q w er
	        *   最多结点数：$M_1 = \frac{2^h - 1}{2-1} = 2^h - 1$。
	        *   最少结点数：$M_2 = 1 + 2(h-1) = 2h - 1$。




![[2016-exam-paper-ocr.pdf#page=6&rect=79,479,521,567|2016-exam-paper-ocr, p.6]]
[[Pasted image 20250930042739.png]]
[[Pasted image 20250930042747.png]]
[[Pasted image 20250930042807.png]]

#快速排序 
 -> 一直用 整个数组 中间的偏左的数作为基数
```c++
int  a = n /2  
int left =  int A[i];  int i =1 
int right  = int A[n]; 
for ( left > left[a]  ; leftleft[a] + 1 ; )
```
[[快速排序]]
#空间复杂度  **空间复杂度：$O(1)$**
	该算法是**原地 (in-place)** 进行的，它直接在输入数组a上进行修改。
*   除了pivotkey, low, high等几个固定数量的辅助变量外，没有使用额外的、随输入规模n增长的存储空间。
*   因此，空间复杂度是常数级别的，即$O(1)$。

#时间复杂度 **平均时间复杂度：$O(n)$**  
*   第一次划分操作，需要扫描n个元素，时间是$O(n)$。
*   在理想情况下，每次枢轴都能将数组大致平分。那么下一次我们只需要处理$n/2$规模的子问题。
*   因此，总的操作次数大约是 $n + n/2 + n/4 + ... + 1$。这是一个等比数列求和，其结果收敛于$2n$。
*   所以，平均时间复杂度为$O(n)$。这比先排序再划分的$O(n \log n)$要高效得多。
*   **注意**：在最坏情况下（例如每次选中的枢轴都是当前子数组的最大或最小元素），算法会退化到$O(n^2)$。但通过随机选择枢轴等方法可以极大地避免最坏情况的发生。




![[2016-exam-paper-ocr.pdf#page=6&rect=75,261,527,480|2016-exam-paper-ocr, p.6]]
[[Pasted image 20250930042852.png]]

[[异步通信]]  #异步串行通信        [[IO控制方式]]  
- （1）每传送一个字符，在异步串行通信线路上共需传输多少位？  
	- 异步串行通信的数据帧结构  #数据帧结构   #数据帧长度   #帧格式  
		异步通信以"帧"为单位传输数据，每一帧都包含了额外用于同步和校验的控制位。
	    *   #起始位 (Start Bit): 1位，用于通知接收方一个新字符的开始。
	    *   #数据位 (Data Bits) : 7位，这是实际的有效信息（ASCII字符）。
	    *   #奇偶校验位 (Parity Bit): 1位，用于简单的错误检测。
	    *   #停止位 (Stop Bit) : 1位，用于表示一个字符的结束。
	*   **计算**: 将所有位数相加，得到传输一个字符所需的总位数。  #字符  #位   #字符与位 
	    $Total Bits = Start + Data + Parity + Stop = 1 + 7 + 1 + 1 = 10 \text{ 位}$
	2. 在设备 D 持续工作过程中，每秒钟最多可向 I/O 端口送入多少个字符？ 
		-    **知识点**: #数据传输率 的计算。  
			*   **分析**: 题目明确指出 "从D接收启动命令到字符送入I/O端口需要0.5ms"。这意味着设备D每隔 $0.5 \text{ ms}$ 就能准备好一个字符并触发一次中断。因此，这个时间间隔决定了最大的字符传输速率。
			*   **计算**:
			    *   设备D传送一个字符所需时间: $T_{char} = 0.5 \text{ ms} = 0.5 \times 10^{-3} \text{ s}$
			    *   每秒钟可传送的字符数（速率）: $Rate = 1 / T_{char}$
			    $Rate = 1 / (0.5 \times 10^{-3} \text{ s}) = 2000 \text{ 字符/秒}$
- 第二问：中断方式的性能分析
	进行这一问的计算前，我们首先要计算出CPU的时钟周期，这是所有时间计算的基础。
		[[计算机性能评测的四个指标]]  
	*   **CPU时钟周期 ($T$)**:
	    $T = 1 / f = 1 / (50 \text{ MHz}) = 1 / (50 \times 10^6 \text{ Hz}) = 20 \times 10^{-9} \text{ s} = 20 \text{ ns}$
	1) CPU需从D读取1000个字符，则完成这一任务所需时间大约是多少个时钟周期？ [[单级中断处理流程]]
		1) 这个问的是完成整个任务的 总时间  即从开始处理第一个字符到处理完最后一个字符所经过的总时长。这个过程是串行的，处理完一个字符才能开始处理下一个。我们需要分析处理一个字符的完整周期是怎样的。
		    1.  CPU通过中断服务程序中的指令（第15条）启动设备D。
		    2.  设备D工作 $0.5 \text{ ms}$，将字符送入I/O端口，并发出中断请求。
		    3.  CPU响应中断，花费 $10$ 个时钟周期。
		    4.  CPU开始执行中断服务程序，执行到第15条指令时，再次启动设备D，开始下一个字符的处理周期。
		2. 一个完整的字符处理周期时间 $T_{cycle}$ 包括了**设备工作时间**和CPU为启动下一次工作而进行的**部分处理时间**。
	- **计算**:
	    *   **设备D工作时间**: $0.5 \text{ ms}$。换算成时钟周期数:
	        $T_{device\_cycles} = 0.5 \text{ ms} / 20 \text{ ns} = (0.5 \times 10^{-3}) / (20 \times 10^{-9}) = 25000 \text{ 个时钟周期}$
	    *   **中断响应时间**:
	        $T_{response} = 10 \text{ 个时钟周期}$
	    *   **执行ISR前15条指令的时间**:
	        $T_{ISR\_part} = 15 \text{ 条指令} \times 4 \text{ CPI} = 60 \text{ 个时钟周期}$
		处理一个字符的总周期时间为三者之和：
	    $T_{single\_char} = T_{device\_cycles} + T_{response} + T_{ISR\_part} = 25000 + 10 + 60 = 25070 \text{ 个时钟周期}$
	    
	    完成1000个字符的总时间：
	    $T_{total} = 1000 \times T_{single\_char} = 1000 \times 25070 = 25,070,000 \text{ 个时钟周期}$

	- (2) CPU用于完成这一任务的时间大约是多少个时钟周期？ #中断传输   
		CPU开销计算。
		*   **分析**: 这个问题问的是**CPU时间（CPU Time）**，即CPU为这个I/O任务而花费的总时间。在中断方式下，CPU只在响应中断和执行中断服务程序时为该任务工作，其他时间可以执行别的程序。
		*   **计算**:
		    *   对于每一个字符（每一次中断），CPU的开销包括：
		        *   **中断响应时间**: $T_{response} = 10 \text{ 个时钟周期}$
		        *   **执行完整中断服务程序的时间**: 中断服务程序共20条指令。
		            $T_{ISR\_total} = 20 \text{ 条指令} \times 4 \text{ CPI} = 80 \text{ 个时钟周期}$
		    *   处理一个字符所花费的CPU时间：
		        $T_{CPU\_per\_char} = T_{response} + T_{ISR\_total} = 10 + 80 = 90 \text{ 个时钟周期}$
		    *   处理1000个字符所花费的总CPU时间：
		        $T_{CPU\_total} = 1000 \times T_{CPU\_per\_char} = 1000 \times 90 = 90,000 \text{ 个时钟周期}$ (即 $9 \times 10^4$)
	- (3) 在中断响应阶段CPU进行了哪些操作？ 
		- [[单级中断处理流程]] 
			- **分析**: 中断响应阶段，也称为中断隐指令阶段，是由硬件自动完成的一系列操作，目的是为了安全、正确地切换到中断服务程序。
			-   **回答**:
		    1.  **关中断 (Disable Interrupts)**: CPU在响应中断后，会暂时关闭中断响应功能（例如将中断允许位置0），防止在保存现场的过程中被新的中断打扰，造成状态混乱。
		    2.  **保护断点和程序状态 (Save Context)**: 将当前程序的断点（程序计数器PC的内容）和程序状态字（PSW）等关键寄存器的内容压入堆栈。这是为了在中断处理结束后能准确地返回到原程序被中断的地方继续执行。
		    3.  **识别中断源并传送中断服务程序入口地址 (Identify Source & Vectoring)**: CPU通过中断类型码或中断向量表找到对应中断源的服务程序的起始地址，并将其送入PC。这样，下一条指令就会从中断服务程序的第一条开始执行。
- 衍生 
	-   [[中断屏蔽的规则（处理中断嵌套）]]
		- 如果有多个中断源同时请求，CPU如何根据优先级响应？如果在一个中断服务程序执行期间，来了更高级别的中断请求，会发生什么（中断嵌套）？
			-  题目中的“关中断”就是一个例子。可能会有更复杂的中断屏蔽设置，例如通过中断屏蔽字寄存器可以选择性地屏蔽某些中断源。
	- #CPU利用率 可能会让你计算CPU用于I/O任务的利用率。
        $CPU Utilization = (T_{CPU\_total} / T_{total}) \times 100\% = (90,000 / 25,070,000) \times 100\% \approx 0.36\%$
        这个极低的数值直观地展示了中断方式相比查询方式的巨大优势。


![[2016-exam-paper-ocr.pdf#page=7&rect=79,512,521,819|2016-exam-paper-ocr, p.7]]
[[Pasted image 20250930042904.png]]
[[Pasted image 20250930042930.png]]
[[页式存储管理]] 
[[段页式存储管理]] 
- 详细解析这道计算机组成原理与体系结构的经典题目。这道题综合考察了虚拟存储、页式管理、TLB（快表）和 Cache（高速缓存）等核心概念 
-  (1) 计算各字段位数及 B 的含义 
	- #页内偏移 : 由页大小决定。
		- 页大小 = $8KB = 8 \times 1024 B = 2^3 \times 2^{10} B = 2^{13} B$。
		    因此，页内偏移需要 13 位来表示页内的每一个字节。
		    这个偏移量在虚拟地址和物理地址中是相同的，因为它表示的是在页/页框内的相对位置。
		    *   从图中看，`D` 是物理地址的页内偏移部分。
		    *   所以，**D 的位数 = 13 位**。
	- 虚拟地址划分 (A, D)
		虚拟地址共 32 位，分为 `虚拟页号 (A)` 和 `页内偏移 (D)`。
	    *   `A` (虚拟页号) 的位数 = 总位数 - 页内偏移位数 = $32 - 13 = 19$ 位。
	    *   所以，**A 的位数 = 19 位**。
	- 理地址划分 (C, D)
	    物理地址共 24 位，分为 `物理页框号 (C)` 和 `页内偏移 (D)`。
	    *   `C` (物理页框号) 的位数 = 总位数 - 页内偏移位数 = $24 - 13 = 11$ 位。
	    *   所以，**C 的位数 = 11 位**。
	- TLB 字段 B
	    TLB 是一个用于加速地址转换的硬件。它存储 `虚拟页号 -> 物理页框号` 的映射。
	    *   对于 **全相联** TLB，查找时会将虚拟地址中的**整个虚拟页号** (`A`) 与 TLB 中存储的所有条目的**标记 (Tag)** 进行并行比较。
	    *   因此，TLB 条目中存储的标记就是虚拟页号。
	    *   图中 `B` 是 TLB 条目中的标记字段。
	    *   所以，**B 的内容是虚拟页号**，其位数与 `A` 相同。
	    *   **B 的位数 = 19 位**。
	- Cache 地址划分 (E, F, G) 
		物理地址被送到 Cache，Cache 根据物理地址来确定数据是否在其中。物理地址被划分为 `标记 (E)`、`组索引 (F)` 和 `块内偏移 (G)`。
	    *   **`G` (块内偏移, Block Offset)**: 由块大小决定。
	        块大小 = $64B = 2^6 B$。
	        因此，块内偏移需要 6 位。
	        所以，**G 的位数 = 6 位**。
	    *   **`F` (组索引, Set Index)**: 由 Cache 的组数决定。
	        Cache 组数 = (Cache 总大小 / 块大小) / 路数
	        Cache 块数 = $64KB / 64B = (2^6 \times 2^{10}) / 2^6 = 2^{10} = 1024$ 块。
	        Cache 组数 = $1024 / 2$ (2路) $= 512$ 组。
	        $512 = 2^9$，所以需要 9 位来索引这 512 个组。
	        所以，**F 的位数 = 9 位**。
	    *   **`E` (标记, Tag)**: 物理地址剩下的部分就是标记。
	        `E` 的位数 = 物理地址总位数 - `F` 的位数 - `G` 的位数 = $24 - 9 - 6 = 9$ 位。
	        所以，**E 的位数 = 9 位**。
		**小结 (1):**
		*   A = 19 位
		*   B = 19 位 (内容为虚拟页号)
		*   C = 11 位
		*   D = 13 位
		*   E = 9 位
		*   F = 9 位
		*   G = 6 位

- (2) 主存块 4099 映射到 Cache 
	1. #Cache组号 的确定 [[计算Cache组数]]
		1. Cache 的组号由物理地址的**中间部分**，即组索引字段 (`F`) 决定。物理地址是字节地址，而我们现在有的是**主存块号**
			物理块号（或称主存块地址）可以理解为物理字节地址除以块大小，即物理地址中去掉了块内偏移 (`G`) 的部分。
	    物理块号 = `标记 (E) | 组索引 (F)`
	    组索引 `F` 是物理块号的低 9 位。
	    因此，Cache 组号 = `(主存块号) mod (Cache 组数)`
	    *   主存块号 = 4099
	    *   Cache 组数 = 512
	    *   Cache 组号 = $4099 \pmod{512}$
	    *   $4099 = 8 \times 512 + 3$
	    *   所以，余数是 3，**Cache 组号为 3**。
	    *   用 9 位二进制表示就是 `000000011`
	2. H 字段内容的确定 
		从图中可以看出，`H` 是存放在 Cache 行中的标记字段。当一个主存块被调入 Cache 时，其物理地址中对应的标记部分（即 `E` 字段）会被存入 Cache 行的标记字段 `H` 中。
	    *   `H` 的内容就是物理块号中属于标记的部分。
	    *   物理块号的高位是标记，低位是组索引。
	    *   标记 `H` = `(主存块号) / (Cache 组数)` (整除)
	    *   标记 `H` = $4099 / 512 = 8$。
	    *   `E` 字段有 9 位，所以 8 的 9 位二进制表示为 `000001000`。
	    *   因此，**H 字段内容为 8 (二进制 `000001000`)**。
		小结 (2):
		*   Cache 组号为 3。
		*   H 字段内容为 `000001000` (十进制 8)。
		这与标准答案吻合。（注意：答案中 `4099` 的二进制表示有误，但其计算 Cache 组号和 H 的最终结果是正确的）。
- (3) Cache 缺失与缺页的开销比较 
	- #Cache缺失  [[Cache缺失损失]] 
		*   **触发**: CPU 需要的数据不在 Cache 中。
	    *   **处理**: 由**硬件**控制，暂停 CPU，从**主存 (Main Memory)** 中读取包含所需数据的整个块到 Cache 中。
	    *   **时间开销**: 几十到几百个时钟周期（纳秒级, $ns$），主要是主存的访问延迟。
	* #缺页  [[TLB缺失与缺页的区别]] 
		* **触发**: CPU 访问的虚拟地址对应的页不在主存中（页表项无效）。
	    *   **处理**: 这是一个异常（中断），需要**操作系统 (OS)** 介入。
	        1.  CPU 陷入内核态，保存现场。
	        2.  操作系统查找该页在**磁盘 (Disk)** 上的位置。
	        3.  在主存中找到一个空闲页框，若没有，则执行页面替换算法（可能需要将一个“脏”页写回磁盘）。
	        4.  从磁盘读取所需的页到该页框。
	        5.  更新页表和 TLB。
	        6.  返回用户态，重新执行导致缺页的指令。
	    *   **时间开销**: 磁盘 I/O 是机械操作，非常慢。时间开销在**毫秒级 ($ms$)**，比 Cache 缺失慢几个数量级 (大约 $10^5$ 到 $10^6$ 倍)。
	- **结论**: **缺页处理的时间开销远大于 Cache 缺失的开销**。主要原因是 Cache 缺失访问的是主存，而缺页需要访问慢得多的磁盘，并且还涉及复杂的操作系统软件中断处理流程 
- (4) Cache 与页面修改的写策略   [[写策略]]  
	- 问题问的是为什么 Cache-主存层次可以使用 #写直通策略 ，而主存-磁盘（页面管理）层次总是使用写回策略 
		- Cache-主存层次
			-   **速度差距**: Cache (如 SRAM) 的速度比主存 (DRAM) 快约 10-100 倍。虽然有差距，但仍在同一个数量级（纳秒级）。
		    *   **写直通的可行性**: 当执行写操作时，可以同时向 Cache 和主存写入。为了不让 CPU 等待较慢的主存写操作完成，通常会使用一个**写缓冲 (Write Buffer)**。CPU 将数据写入写缓冲后即可继续执行，由写缓冲负责在后台将数据写入主存。因为主存相对较快，写缓冲不容易被填满。因此，**写直通**是可行的。
		- **主存-磁盘层次 (页面修改)**:
		    *   **速度差距**: 主存 (DRAM) 的速度比磁盘 (HDD/SSD) 快约 $10^5-10^6$ 倍。这个差距是巨大的。
		    *   **写直通的不可行性**: 如果每次修改内存中的一个字节都触发一次磁盘写入操作，那么程序的执行速度将会被磁盘的 I/O 速度严重拖累，系统性能将无法接受。一个简单的赋值语句可能会花费数毫秒，这是灾难性的。
		    *   **必须使用写回**: 因此，页面修改必须采用**写回**策略。当一个页面被修改时，在页表中将对应的“修改位”或“脏位” (Dirty Bit) 置 1。这个页面只有在被替换出主存时，操作系统才会检查其脏位。如果脏位为 1，才将整个页面写回到磁盘。这样，多次写操作被合并为一次磁盘 I/O，极大地提高了效率。
		 **结论**: 核心原因在于**存储层次结构中不同层级间的性能差距**。Cache-主存的速度差距尚可容忍，可以通过写缓冲等技术让写直通变得可行。而主存-磁盘的速度差距过于悬殊，导致写直通完全不可行，只能采用写回策略。
- 衍生 
	- #平均访存时间AMAT  [[访存时间计算]]
		- 可能会结合 TLB 命中率进行多级计算：
	        $AMAT = P_{TLB_{hit}} \times (T_{TLB} + T_{Cache}) + (1 - P_{TLB_{hit}}) \times (T_{TLB} + T_{Mem_{pagetable}} + ...)$
	- #虚拟Cache与物理Cache 
		- 物理地址 Cache: 本题中的模式，最简单但需要在地址转换后才能访问 Cache。
	    * 虚拟地址 Cache : 可以和 TLB 并行查询，速度快，但有歧义性 (aliasing) 和同义性 (synonyms) 问题。


 





![[2016-exam-paper-ocr.pdf#page=7&rect=78,390,524,514|2016-exam-paper-ocr, p.7]]
[[Pasted image 20250930042948.png]]
[[Pasted image 20250930042953.png]]
-  (1) 若调度程序只将 nice 的值作为进程的优先数，为什么可能出现饥饿现象？ 
1. 调度策略是“选择优先数最小的进程运行” 
2. **理解`priority = nice`的含义**：这意味着进程的优先数是**静态的**。一旦一个进程被创建，它的`nice`值就确定了，因此它的`priority`也永远不会改变。
3. **构建饥饿场景**：
    *   假设就绪队列中有一个低优先级的进程P_low，其`nice`值为20 (即`priority = 20`)。
    *   此时，如果系统中不断有新的、高优先级的进程（例如，P_high1, P_high2, P_high3...）进入就绪队列，它们的`nice`值都小于20（比如都是10）。
    *   根据“选择优先数最小的进程运行”的规则，调度程序每次都会从P_high系列进程中选择一个来运行，因为它们的`priority` (10) 始终小于P_low的`priority` (20)。
    *   只要这种高优先级的进程源源不断地到来，P_low的`priority`因为是静态的，永远不会变小，所以它将永远没有机会被选中。
4.  **得出结论**：这种一个或多个进程因优先数固定且较低，而无限期地等待CPU的情况，就是**饥饿现象**。

	- **所以，答案的核心是：** 因为采用了**静态优先数**，当就绪队列中持续存在优先数更小（即优先级更高）的进程时，那些优先数较大（即优先级较低）的进程将永远无法获得CPU，从而导致饥饿。

- (2) 使用 nice、cpuTime 和 waitTime 设计一种动态优先数计算方法，以避免产生饥饿现象，并说明 waitTime 的作用。
1. **目标**：设计一个**动态**的`priority`计算公式，解决饥饿问题。解决饥饿的关键在于让一个等待了很久的进程的优先数能够**动态地提高**（即其`priority`值能够**动态地减小**）。 
2. 分析各个变量的作用 
	1. `nice`: 这是用户指定的**基础优先数**。它应该作为公式的基础部分。一个进程的基础优先级高低由它决定。 
	2.  `cpuTime`: 这是进程已经**占用CPU运行的时间**。一个公平的调度系统通常会“惩罚”那些已经运行了很长时间的进程，以给其他进程机会。要实现“惩罚”，就是要**降低它的优先级**，即**增大它的`priority`值**。因此，`cpuTime`项应该是正向贡献。我们可以用一个正常数$k1$作为其权重。所以公式中应该有`+ k1 * cpuTime`这一项。
	3.   `waitTime`: 这是进程在就绪队列中**等待的时间**。为了解决饥饿问题，我们必须“奖励”那些等待了很久的进程。要实现“奖励”，就是要**提高它的优先级**，即**减小它的`priority`值**。因此，`waitTime`项应该是负向贡献。我们可以用一个正常数$k2$作为其权重。所以公式中应该有`- k2 * waitTime`这一项。
3. 组合成完整公式 
	1. 将以上分析组合起来，一个合理的动态优先数计算公式就诞生了：
    $priority = nice + k1 \times cpuTime - k2 \times waitTime$
    其中，$k1 > 0$, $k2 > 0$，这两个系数用来调整`cpuTime`和`waitTime`在优先数计算中的影响力。
4. 说明`waitTime`的作用 
	1.   从公式可以看出，`waitTime`项的系数是负的。
    *   这意味着，一个进程在就绪队列中**等待的时间越长**，它的`waitTime`值就越大。
    *   `k2 * waitTime`的值也随之变大，导致其最终的`priority`值**变得越小**。
    *   根据调度规则（优先数值越小，优先级越高），这个等待了很久的进程的**优先级就会动态提升**。
    *   即使一个进程的初始`nice`值很大（优先级很低），只要它等待的时间足够长，它的`priority`值终将减小到足以被调度程序选中。
    *   这个机制保证了任何进程都不会被无限期地等待，从而**避免了饥饿现象**。这个技术在操作系统中被称为老化  
    * 所以，`waitTime`的作用是：实现“老化”技术，使长时间等待的进程的优先数能够动态减小（即优先级动态提高），最终确保它能获得CPU执行机会，从而避免饥饿

- 衍生 
	- [[常见进程调度算法与优先级关系]]
	- 


![[Pasted image 20251011151246.png]]
[[Pasted image 20250930043006.png]]
- 这道题的核心知识点是 #文件系统的链接分配方式 [[文件分配方式]]，特别是其在实际系统中的一种实现—— #文件分配表FAT  
1. #链接分配   [[链式分配（链接分配）]]   [[文件分配表FAT]]  
	1. **实现**：每个磁盘块中除了存储数据外，还会有一个指针，指向包含文件下一个部分的磁盘块。
	2.  **目录项**：目录中每个文件的条目（目录项）只需要存储文件名和文件的起始磁盘块号。要访问整个文件，只需从起始块开始，顺着指针链逐个访问即可。
	3. **缺点**：无法高效地实现随机/直接访问（比如，要访问第100个块，必须从第1个块开始依次读过99个指针），并且指针占用了存储空间 
 
- (1) 请给出所有目录文件的内容 
	1. `dir` 目录文件 
		*   从目录树结构图可以看出，`dir` 目录下面只有一个子目录 `dir1`。
	    *   从给定的表格中查到，`dir1` 的起始簇号是 48。
	    *   所以，`dir` 文件的内容就是一个指向 `dir1` 的目录项。
![[Pasted image 20251011150000.png|525]]

-  **`dir1` 目录文件**:
	*   从目录树结构图可以看出，`dir1` 目录下面有两个用户文件：`file1` 和 `file2`。
	*   从表格中查到，`file1` 的起始簇号是 100。（注意：`106`, `108` 是后续的簇，目录项只记录第一个）。
	*   从表格中查到，`file2` 的起始簇号是 200。
	*   所以，`dir1` 文件的内容是两个分别指向 `file1` 和 `file2` 的目录项。
*  (2) 若 FAT 的每个表项仅存放簇号，占 2 字节，则 FAT 的最大长度为多少字节？该文件系统支持的文件长度最大是多少？ 
	1. #FAT最大长度 :  #FAT表项大小  
	    *   一个 FAT 表项占 2 字节，也就是 $2 \times 8 = 16$ 比特 (bit)。
	    *   这意味着每个表项可以用 16 位二进制数来表示一个簇号。
	    *   因此，可以表示的唯一簇号数量为 $2^{16} = 65536$ 个。
	    *   FAT 表需要为每一个可能的簇都准备一个表项，所以 FAT 表中总共就有 $2^{16}$ 个表项。
	    *   FAT 的最大长度 = (最大表项数) × (每个表项的大小)
	    *   计算：$FAT_{max\_size} = 2^{16} \times 2 \text{B} = 65536 \times 2 \text{B} = 131072 \text{B} = 128 \text{KB}$。
	2. #文件最大长度 :
	    *   文件最大长度取决于它最多能占用多少个簇。理论上，一个文件可以占用文件系统所能管理的所有簇。
	    *   系统能管理的最大簇数就是 FAT 能寻址的最大簇数，即 $2^{16}$ 个。
	    *   每个簇的大小为 4KB。
	    *   文件最大长度 = (最大簇数) × (每个簇的大小)
	    *   计算：$File_{max\_size} = 2^{16} \times 4 \text{KB} = 65536 \times 4 \text{KB} = 262144 \text{KB} = 256 \text{MB}$。
- (3) 系统通过目录文件和 FAT 实现对文件的按名存取，说明 file1 的 106、108 两个簇号分别存放在 FAT 的哪个表项中
1. 考察 FAT 工作原理的核心。FAT 表项 `FAT[i]` 存放的是第 `i` 簇的**下一个**簇的编号 
	1. 题目给出 `file1` 占用的簇号及顺序是：`100` -> `106` -> `108`。
		*   这意味着：
		    *   文件从 100 号簇开始。
		    *   100 号簇的下一个簇是 106 号簇。这个“链接”信息就存放在 `FAT[100]` 中。所以 **FAT 的 100 号表项中存放的值是 106**。
		    *   106 号簇的下一个簇是 108 号簇。这个信息存放在 `FAT[106]` 中。所以 **FAT 的 106 号表项中存放的值是 108**。
		    *   108 号簇是最后一个簇，所以 `FAT[108]` 中会存放一个文件结束标记（EOF）。
		* 因此，簇号 106 存放在 FAT 的 100 号表项中，簇号 108 存放在 FAT 的 106 号表项中。
-  (4) 假设仅 FAT 和 dir 目录文件已读入内存，若需将文件 dir/dir1/file 的第 50 个字节读入内存，则要访问哪几个簇？ 
- 这是一个综合应用题，需要模拟文件访问的全过程，并计算磁盘 I/O 次数  [[文件块访问次数（磁盘IO次数）]]
	1.  **初始状态**：`dir` 文件和 `FAT` 表在内存中，不需要读磁盘。
	2.  **解析路径 `/dir1`**：要在 `dir` 文件中查找 `dir1`。因为 `dir` 在内存中，所以直接在内存中查找，得到 `dir1` 的起始簇号是 48。这一步**不访问磁盘**。
	3.  **读取 `dir1` 目录文件**：我们只知道 `dir1` 的起始簇号是 48，但它的内容不在内存中。因此，必须从磁盘读取 48 号簇，才能获得 `dir1` 目录的内容。**第一次磁盘访问：访问 48 号簇**。
	4.  **解析路径 `/file1`**：`dir1` 的内容读入内存后，在其中查找 `file1`，得到 `file1` 的起始簇号是 100。这一步在内存中完成，**不访问磁盘**。
	5.  **定位第 50 字节**：
	    *   我们需要找到包含文件第 50 字节的那个簇。
	    *   簇大小为 4KB = 4096 字节。
	    *   文件的第 0 到 4095 字节都位于文件的第 1 个簇中。
	    *   因为 $50 < 4096$，所以第 50 字节就在 `file1` 的**第一个簇**中。
	6. **定位第 5000 字节**:
	    *   簇大小为 4096 字节。我们使用 0-based 索引，第 5000 个字节的偏移量是 4999。
	    *   它属于哪个逻辑块？计算逻辑块号：$\lfloor \frac{4999}{4096} \rfloor = \lfloor 1.22... \rfloor = 1$。
	    *   这意味着我们需要访问文件的第 2 个逻辑块（逻辑块号从 0 开始）。
	7.  **查找物理簇号**:
	    *   第 1 个逻辑块（块号 0）是起始块，即 **100 号簇**。
	    *   要找第 2 个逻辑块，我们需要查询 FAT 表。`FAT` 表已经在内存中。
	    *   查询 `FAT[100]`，根据第(3)问的分析，其值为 106。所以文件的第 2 个逻辑块对应的物理簇是 **106 号簇**。
	8.  **读取文件数据**：为了读取第 5000 字节，必须从磁盘读取 106 号簇。**第二次磁盘访问：访问 106 号簇**。
	
	**结论 (基于5000字节)**：总共需要访问 **48 号簇** 和 **106 号簇**

- 衍生 
	- [[文件分配方式]]
	- #FAT变种
		- FAT12, FAT16, FAT32 的区别主要在于 #FAT表项大小  （12位, 16位, 32位），这直接决定了它们能管理的最大磁盘容量和最大文件大小。这是一个经典的计算题考点
	- #目录的实现方式   
		- [[目录的实现方式]] 录可以是简单的线性列表（查找慢）或哈希表（查找快）。题目中的目录就是线性列表。可能会问，如果目录非常大，有什么优化方法？ 