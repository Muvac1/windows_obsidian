文件描述符、打开文件表和FCB(inode)的关系![[2014-exam-paper-ocr.pdf#page=1&rect=72,609,547,700|2014-exam-paper-ocr, p.1]]
[[Pasted image 20250909031611.png]]
1. `for (j=1; j<=n; j++)`  [[时间复杂度分析]]
	1. 这个循环从1开始，每次加1，直到`j`大于`n`为止。因此，对于每一次外层循环，这个内层循环都会执行 **n** 次。它的时间复杂度是$O(n)$
2. `for (k=1; k<=n; k*=2)` 
	1. 循环的终止条件是$k>n$。也就是说，循环会一直执行，直到$2^{x-1} > n$。我们可以反过来思考，循环执行的条件是$k \le n$，即：
		$2^{x-1} \le n$ 
		解出$x$，我们对两边取以2为底的对数：
		$\log_2(2^{x-1}) \le \log_2 n$
		$x-1 \le \log_2 n$
		$x \le \log_2 n + 1$
	所以，外层循环的执行次数$x$大约是$\log_2 n$次。因此，外层循环的时间复杂度是$O(\log_2 n)$常写为$O(\log n)$  
	嵌套循环结构，内层循环的执行次数不依赖于外层循环的变量`k`。根据 #时间复杂度的乘法法则  
	$T(n) = O(n\log_2 n)$  
- 对[[数阶复杂度的识别]] ($O(\log n)$) 的识别 
- 衍生
	- 内层循环依赖于外层循环变量 
		- 把内层循环的条件`j<=n`改成`j<=k`：
    ```c
    for (k=1; k<=n; k*=2)
        for (j=1; j<=k; j++)
            count++;
    ```
    这时，总执行次数不再是简单的相乘。我们需要将内层循环的执行次数进行累加：
    当 $k=1$ 时，内层执行1次。
    当 $k=2$ 时，内层执行2次。
    当 $k=4$ 时，内层执行4次。
    ...
    直到 $k$ 的最大值（约为$n$）。
    总执行次数 = $1 + 2 + 4 + 8 + \dots + 2^{\log_2 n}$。这是一个等比数列求和。
    总和 $S = \frac{a_1(1-q^m)}{1-q} = \frac{1(1-2^{\log_2 n + 1})}{1-2} = 2^{\log_2 n + 1} - 1 = 2n - 1$。
    因此，这种变种的时间复杂度是$O(n)$。
- #循环变量步长变化 
	*   **算术级数**：`for (i=1; i<=n; i+=c)`，复杂度为$O(n)$。
    *   **平方根**：`for (i=1; i*i<=n; i++)`，循环在$i \approx \sqrt{n}$时停止，复杂度为$O(\sqrt{n})$。
-  #多个并列循环 
   ```c
    for (i=1; i<=n; i++) { ... } // O(n)
    for (j=1; j<=n; j*=2) { ... } // O(log n)
    ```
    根据**加法法则**，总复杂度为$O(\max(n, \log n)) = O(n)$
 - 递归函数的时间复杂度 
	 - 除了循环，递归也是一个重要的考点。例如，计算 #斐波那契数列的递归算法 ，其时间复杂度是指数级的$O(2^n)$。而 #二分查找的递归实现 ，其时间复杂度是对数级的$O(\log n)$。分析递归通常需要使用主定理（Master Theorem）或递归树


![[2014-exam-paper-ocr.pdf#page=1&rect=74,562,531,609|2014-exam-paper-ocr, p.1]]
1. [[表达式转换（前中后缀）]] 
	1. [[栈]]
**运算符处理规则（关键部分）：**
*   **遇到左括号`(`**：直接压入栈中。
*   **遇到右括号`)`**：将栈顶的运算符依次弹出并输出，直到遇到左括号`(`为止。左括号`(`也从栈中弹出，但**不输出**。
*   **遇到其他运算符**（`+`, `-`, `*`, `/`）：
    *   若栈为空，或栈顶元素为`(`，则直接将该运算符压入栈中。
    *   否则，比较该运算符与栈顶运算符的**优先级**。
        *   若该运算符的优先级**高于**栈顶运算符，则将其压入栈中。
        *   若该运算符的优先级**小于或等于**栈顶运算符，则将栈顶运算符弹出并输出，然后**再次**将当前运算符与新的栈顶运算符比较，重复此过程，直到当前运算符可以被压入栈中。

B
 [[Pasted image 20250909032332.png]]
[[Pasted image 20250909032350.png]]
- #后缀表达式求值 
	这是另一个经典的栈应用。给定一个后缀表达式，如 $ab/cd*ef*-g+$，计算其值。
    *   **算法**：从左到右扫描表达式，使用一个**操作数栈**。
    *   遇到**操作数**，压入栈中。
    *   遇到**运算符**，从栈中弹出两个操作数（注意顺序：先弹出的是右操作数，后弹出的是左操作数），进行运算，并将结果压回栈中。
    *   扫描结束后，栈中唯一剩下的元素就是最终结果。
- #前缀表达式求值 
	与后缀求值类似，但需要**从右到左**扫描。
    *   遇到**操作数**，压入栈中。
    *   遇到**运算符**，从栈中弹出两个操作数（先弹出的是左操作数，后弹出的是右操作数），运算后将结果压回栈中。
- #表达式的等价性 
	- 可能会给出多个不同形式的表达式（中缀、前缀、后缀），判断它们是否代表同一个运算逻辑。解决方法是将它们都转换为同一种形式（通常是后缀或中缀）进行比较
- #运算符的结合性 
	- 在处理 #右结合运算符 时 比如幂运算`^`，中缀转后缀的规则需要微调：当待处理的运算符优先级与栈顶运算符**相同时**，当前运算符直接入栈，而不是弹出栈顶元素  





![[2014-exam-paper-ocr.pdf#page=1&rect=77,455,534,561|2014-exam-paper-ocr, p.1]]
[[Pasted image 20250909032402.png]]
1. 考察的是用一维数组实现循环队列时，如何判断队列为空（队空）和队列为满（队满）的条件。我们来一步步推导 
	1. 队列中最多能容纳 $M-1$ 个元素。这个条件非常关键，它暗示了我们使用“牺牲一个存储单元”的方法来区分队空和队满 
2. 推导队空的条件  [[判别队列空满的状态]]
	*   队列初始状态为空。按照惯例，初始化时队头和队尾指针指向同一个位置，比如下标0。即 $end1 = 0$, $end2 = 0$。
	*   当队列为空时，没有任何元素。此时，队头指针 `end1` 和队尾指针 `end2` 相遇。
	*   因此，**队空的判断条件是：$end1 == end2$**。
	*   根据这个条件，我们可以排除选项 C 和 D。
3.  推导队满的条件 
	1.  题目明确指出，队列最多容纳 $M-1$ 个元素，而数组大小为 $M$。这意味着当队列满时，数组中还有一个空闲的位置。
	2.   我们通过一个具体的例子来推导。假设队列从数组下标0开始入队，一直到队满。
    *   入队第1个元素，存放在 `A[0]`。
    *   ...
    *   入队第 $M-1$ 个元素，存放在 `A[M-2]`。
*   此时，队列已满，包含了 $M-1$ 个元素。我们来看指针的状态：
    *   队头元素在 `A[0]`，所以队头指针 $end1 = 0$
    *   队尾元素在 `A[M-2]`，而 `end2` 指向队尾元素的**后一个位置**，所以队尾指针 $end2 = M-1$。
*   现在我们来验证选项 A 和 B 中队满的条件：
    *   **选项 A 的条件**: $end1 == (end2 + 1) \pmod M$
        *   将 $end1 = 0$ 和 $end2 = M-1$ 代入：
        *   $0 == ((M-1) + 1) \pmod M$
        *   $0 == M \pmod M$
        *   $M \pmod M$ 的结果是 0。所以等式 $0 == 0$ 成立。
    *   **选项 B 的条件**: $end2 == (end1 + 1) \pmod {M-1}$
        *   首先，模数是 $M-1$ 是不正确的，因为数组的循环周期是 $M$（下标从0到$M-1$）。仅凭这一点就可以判断 B 是错误的。
        *   即使我们代入验证：$M-1 == (0 + 1) \pmod {M-1}$
        *   $M-1 == 1 \pmod {M-1}$
        *   $1 \pmod {M-1}$ 的结果是 1 (假设$M>2$)。等式 $M-1 == 1$ 显然不成立。

*   **结论**: 队满的条件是 $end1 == (end2 + 1) \pmod M$。这个条件的几何意义是，在循环的意义下，队尾指针 end2 的下一个位置就是队头指针 `end1`，这表示队列已经满了，只留下一个“隔离”空间。
1. 综合以上两点：
	*   队空条件: $end1 == end2$
	*   队满条件: $end1 == (end2 + 1) \pmod M$ 
A  
- 衍生 
1. [[循环队列]] [[循环队列判别队空与队满的三种方法]] 
	1. #指针定义的变化
		考试中另一个常见的“陷阱”是改变指针的定义。本题的定义是**最常见**的一种：
		*   `front` (即 `end1`): 指向**队头元素**。
		*   `rear` (即 `end2`): 指向**队尾元素的下一个位置**。
		还有一种定义方式：
		*   `front`: 指向**队头元素的前一个位置**。
		*   `rear`: 指向**队尾元素**。
		如果采用这种定义，那么入队和出队的操作以及判空/判满的条件都会相应改变：
		*   **初始化**: `front = rear = 0` (或-1，取决于约定)
		*   **入队**: `rear = (rear + 1) % M; A[rear] = x;`
		*   **出队**: `front = (front + 1) % M; x = A[front];` 
		*   **队空条件**: `front == rear`
		*   **队满条件**: `(rear + 1) \pmod M == front` (牺牲一个单元的情况下)
	* 无论指针如何定义，在使用“ #牺牲一个单元”法时，队空和队满的条件表达式是相同的，但入队和出队操作中指针移动和存取数据的先后顺序会不同。做题时一定要**首先看清指针的定义**。 
* #计算队列长度 
	* 在本题的指针定义下，队列长度 `length` 的计算公式为：
		$length = (end2 - end1 + M) \pmod M$ 
		这个公式可以优雅地处理 `end2` < `end1` 的回环情况。例如，当 $end1=0, end2=M-1$ 时，长度为 $(M-1 - 0 + M) \pmod M = (2M-1) \pmod M = M-1$`，是正确的。当队列为空 `$end1 == end2$ 时，长度为0



![[2014-exam-paper-ocr.pdf#page=1&rect=74,355,500,455|2014-exam-paper-ocr, p.1]]
[[Pasted image 20250909032412.png]]
- [[线索二叉树]]  [[前驱后继，前中后序]] [[中序线索化]] 
	- **左线索**：如果一个结点的左孩子指针为空，则该指针被改造为指向其**中序前驱**的线索。
	- **右线索**：如果一个结点的右孩子指针为空，则该指针被改造为指向其**中序后继**的线索。
1. 二叉树的中序遍历
	1. 左-根-右
2.  线索二叉树
-  解题
1. 第一步：写出该二叉树的中序遍历序列 
	1.  从根结点`a`开始，先访问其左子树（以`b`为根）。
	2.  在`b`结点，先访问其左子树（以`d`为根）。
	3.  在`d`结点，它没有左子树，所以先访问根结点`d`。
	4.  然后访问`d`的右子树（结点`e`）。`e`没有左右子树，直接访问`e`
	5.  `d`的左右子树都访问完毕，`d`子树的遍历结果是 `d, e`。
	6.  回到`b`，左子树（`d`子树）已访问完。现在访问根结点`b`。
	7.  然后访问`b`的右子树（结点`x`）。`x`没有左右子树，直接访问`x`。
	8.  `b`的左右子树都访问完毕，`b`子树的遍历结果是 `d, e, b, x`。
	9.  回到`a`，左子树（`b`子树）已访问完。现在访问根结点`a`。
	10. 最后访问`a`的右子树（结点`c`）。`c`没有左右子树，直接访问`c`。
		1. 完整的中序遍历序列为： d, e, b, x, a, c
2. 第二步：在序列中找到结点x的前驱和后继
	- 在序列中，紧邻`x`**之前**的结点是 `b`。因此，`x`的**中序前驱**是`b`。
	- 在序列中，紧邻`x`**之后**的结点是 `a`。因此，`x`的**中序后继**是`a`。
3. 第三步：确定线索指向并选择答案 
	1. 根据线索二叉树的定义：
	- 结点`x`在原树中没有左孩子，所以它的左指针域是空闲的，将被用作**左线索**，指向其中序前驱`b`。
	- 结点`x`在原树中没有右孩子，所以它的右指针域是空闲的，将被用作**右线索**，指向其中序后继`a`。
D
- 在不生成完整序列的情况下寻找前驱/后继
	- 寻找中序后继
		*   若结点`p`有右子树，则其后继是其**右子树中最左边的结点**。
		*   若结点`p`没有右子树，则其后继是“第一个在`p`的右边的祖先”，即从`p`向上回溯，直到找到一个结点，`p`是这个祖先结点的左子树的一部分。这个祖先结点就是`p`的后继。
		*   *例：* 结点`x`没有右子树，向上回溯到`b`，`x`是`b`的右孩子，继续回溯到`a`，`b`是`a`的左孩子，所以`a`是`x`的后继。
	- 寻找中序前驱 
		*   若结点`p`有左子树，则其前驱是其**左子树中最右边的结点**。
        *   若结点`p`没有左子树，则其前驱是“第一个在`p`的左边的祖先”，即从`p`向上回溯，直到找到一个结点，`p`是这个祖先结点的右子树的一部分。这个祖先结点就是`p`的前驱。
        *   *例：* 结点`x`没有左子树，向上回溯到`b`，`x`是`b`的右孩子，所以`b`是`x`的前驱。
- 线索二叉树的遍历算法 
    *   考察如何在已线索化的二叉树上进行中序遍历。由于有了线索，可以不使用栈或递归，实现一个循环迭代式的遍历算法，空间复杂度为$O(1)$





![[2014-exam-paper-ocr.pdf#page=1&rect=75,303,488,353|2014-exam-paper-ocr, p.1]]
[[截屏2025-09-09 上午3.33.21.png]]
1.   [[树到二叉树的转换规则]] 
	1. 左指针指向第一个孩子，右指针指向下一个兄弟
2. 一个结点如果**没有任何孩子结点**，那么它就是叶结点 
	1. 转换规则的第一条：对于树中的任意一个结点，它在二叉树中的**左孩子**是它在原树中的**第一个孩子**
	2. 如果一个结点在森林 F 中是叶结点，意味着它没有孩子，当然也就没有“第一个孩子”。因此，在转换到二叉树 T 后，这个结点**将没有左孩子** 
	3. 换句话说，它在二叉树 T 中的**左孩子指针为空 (null)**
3. 结论
	1. 森林 F 中有多少个叶结点，转换后的二叉树 T 中就有多少个左孩子指针为空的结点。因此，F 中叶结点的个数等于 T 中左孩子指针为空的结点个数
4. C 
	1. A. T 中叶结点的个数
		1. T 中的叶结点是指既没有左孩子也没有右孩子的结点。
		    - 没有左孩子意味着在 F 中是叶结点。
		    - 没有右孩子意味着在 F 中没有右兄弟。
		    所以，T 中的叶结点对应于 F 中**既是叶结点又是其父结点的最后一个孩子**的那些结点（或者是森林中最后一棵树的根，如果它也是叶结点的话）。这个数量通常小于或等于 F 中叶结点的总数。因此 A 错误。
	2. B. T #中度 为 1 的结点个数 
		T 中度为 1 的结点是指只有一个孩子（要么只有左孩子，要么只有右孩子）。
	    - 只有左孩子：对应 F 中有孩子但没有右兄弟的结点。
	    - 只有右孩子：对应 F 中没有孩子（是叶结点）但有右兄弟的结点。
	    这两种情况的组合与 F 中叶结点的总数没有直接的等价关系。因此 B 错误。
	3. D. T 中右孩子指针为空的结点个数 [[树到二叉树的转换规则]]
		1. T 中右孩子指针为空的结点，根据规则 2，意味着这个结点在 F 中**没有下一个兄弟结点**。这通常是其父结点的**最后一个孩子**，或者是森林中**最后一棵树的根**。这和它是不是叶结点（有没有孩子）是两个独立的概念。因此 D 错误
---
- 衍生
1. 数量关系 
	*   森林中的结点总数等于转换后二叉树的结点总数。设结点数为 $n$。
    *   在有 $n$ 个结点的二叉链表中，总共有 $2n$ 个指针域。其中 $n-1$ 个用于连接结点，所以空指针域的数量总是 $2n - (n-1) = n+1$。这是一个固定的性质。
* 结构关系 
    *   森林中一棵树的根，在二叉树中可能不是根结点（除了第一棵树）。
    *   森林中结点的度（孩子数量）不等于二叉树中对应结点的度。森林中结点 $N$ 的度等于其在二叉树中对应结点 $N$ 的左子树的结点数。
- #遍历的等价性 这是非常重要的考点  [[遍历序列的基本性质]]
	*   对森林进行**先根遍历**，其遍历序列与对转换后的二叉树进行**先序遍历**得到的序列**完全相同**。
    *   对森林进行**中根遍历**，其遍历序列与对转换后的二叉树进行**中序遍历**得到的序列**完全相同**。
    *   （注意：后根遍历不具有这种直接的等价性）
- 逆向转换
	*   给定一个二叉树，如何将其还原为森林？操作是转换规则的逆过程：
        *   一个结点 $N$ 的左子树的根是它的第一个孩子。
        *   这个左孩子的右兄弟是它右子树的根，以此类推，沿着右链找到所有兄弟。
		*   二叉树的根的右链（根、根的右孩子、右孩子的右孩子...）上的所有结点，是还原后森林中各棵树的根。


![[2014-exam-paper-ocr.pdf#page=1&rect=72,255,443,306|2014-exam-paper-ocr, p.1]]
[[截屏2025-09-09 上午3.33.32.png]]
[[前缀编码]] 
- 衍生 #哈夫曼编码  [[哈夫曼编码]]  #克拉夫特不等式  [[克拉夫特不等式]] 
1. #前缀编码核心规则 在一个编码方案中，任何一个字符的编码（码字）都不能是另一个字符编码的前缀
2. A. {01, 0000, 0001, 001, 1}
	1. `1` 不是任何其他码字的前缀。
    *   `01` 不是任何其他码字的前缀。
    *   `001` 不是任何其他码字的前缀。
    *   `0001` 不是 `0000` 的前缀，反之亦然。
    *   结论：选项 A 是前缀编码。
3. B. {011, 000, 001, 010, 1}
    *   `1` 不是任何其他码字的前缀。
    *   `011`, `000`, `001`, `010` 之间互不为前缀。
    *   结论：选项 B 是前缀编码。
4. C. {000, 001, 010, 011, 100} 
    *   这是一个 #定长编码 ，所有码字的长度都是3。在定长编码中，只要所有码字不完全相同，就不可能有一个码字是另一个码字的前缀。
    *   结论：选项 C 是前缀编码。
5. D. {0, 100, 110, 1110, 1100}
	   *   `1100` 的开头部分正好是 `110`。
    *   因此，码字 `110` 是码字 `1100` 的前缀。
    *   这违反了前缀编码的定义。
    *   结论：选项 D **不是**前缀编码。
[[前缀编码与二叉树]] 



![[2014-exam-paper-ocr.pdf#page=1&rect=72,137,512,255|2014-exam-paper-ocr, p.1]]
[[截屏2025-09-09 上午3.33.41.png]]
[[拓扑排序]] D 
- #拓扑实现的算法 [[实现拓扑排序的算法]] 
 - [[Kahn算法]]  (基于入度) 
	*   这是本题所使用的方法。
	    *   **步骤**：
	        1.  计算所有顶点的入度，并将所有入度为0的顶点放入一个队列（或集合）中。
	        2.  当队列不为空时，取出一个顶点 $u$，将其加入到拓扑排序结果序列中。
	        3.  遍历 $u$ 的所有邻接点 $v$，将边 $(u, v)$ “删除”，即把 $v$ 的入度减1。
	        4.  如果 $v$ 的入度减为0，则将 $v$ 加入队列。
	        5.  重复此过程直到队列为空。
	    *   **环路检测**：如果算法结束后，结果序列中的顶点数量少于图中总顶点数，说明图中存在环
* [[广度优先搜索（BFS）和深度优先搜索（DFS）]]  
	* DFS算法 (基于深度优先搜索) 
		1.  创建一个栈（或列表）来存储排序结果。
        2.  创建一个集合来记录已访问的顶点。
        3.  对图中的每一个顶点，如果它没有被访问过，就对它进行DFS。
        4.  在DFS函数中，当一个顶点的所有邻接点都已经被访问（即递归调用已返回）后，将该顶点压入栈中。
        5.  所有顶点都访问完毕后，从栈中依次弹出的顶点序列就是拓扑排序的结果（或者说，将列表反转）。
    *   **环路检测**：在DFS过程中，可以通过维护一个“递归栈”来检测环路。如果在访问一个顶点 $u$ 的邻接点 $v$ 时，发现 $v$ 已经存在于当前的递归路径上，则说明存在环
* 衍生
	* #判断序列合法性
		*   给出一个图和一个序列，判断该序列是否是该图的一个合法拓扑序列。
			*   **解法**：遍历序列，对于序列中的每个顶点 $v$，检查它的所有前驱（指向它的顶点）是否都已经在序列中它之前的位置出现过。如果对所有顶点都满足，则序列合法
	* 拓扑排序的唯一性
		* 题目可能会问：“该图的拓扑排序是否唯一？”
	    *   **解法**：在执行Kahn算法时，检查每一步中入度为0的顶点的队列（或集合）的大小。如果在任何时候，这个队列的大小超过1，那么拓扑排序就不是唯一的。如果从始至终队列大小都最多为1，则排序是唯一的。
	* 算法实现与复杂度
		* 复杂度分析：对于一个有 $V$ 个顶点和 $E$ 条边的图， #Kahn算法和DFS算法的时间复杂度 都是$O(V+E)$。因为每个顶点和每条边都只被访问常数次
	* [[关键路径]] 
![[2014-exam-paper-ocr.pdf#page=1&rect=72,86,525,138|2014-exam-paper-ocr, p.1]]

- [[哈希冲突解决办法和堆积的概念]]  
1. A. 存储效率
	1. 存储效率通常指哈希表中空间利用率。它主要与**装填因子**有关，即表中元素的数量与表总容量的比值。堆积只是改变了元素在表中的**位置分布**，并没有改变元素的总数或表的总容量，因此不直接影响存储效率
2. B. 散列函数
	1. 散列函数是一个预先确定的映射规则，用于计算元素的初始哈希地址，堆积现象本身并不会反过来改变或影响散列函数这个算法 
3. C. [[装填因子]] 
	1. $\alpha = \frac{\text{表中填入的记录数}}{\text{哈希表的长度}}$  这个值只与记录数和表长有关
		1. 装填因子是**导致**冲突和堆积概率增加的**原因**，但不是被堆积**影响**的**结果**
4. D. #平均查找长度ASL
	1. 衡量哈希表查找性能的关键指标，指找到一个元素平均需要进行的比较（探测）次数
	 *   **没有堆积时**：如果一个元素没有冲突，查找它只需要1次比较。
        *   **发生堆积时**：以上述例子为例，现在要查找关键字32。
            1.  计算 `H(32) = 2`。
            2.  比较位置2的元素，是12，不匹配。
            3.  向后探测，比较位置3的元素，是22，不匹配。
            4.  再向后探测，比较位置4的元素，是32，匹配成功。
        *   查找32需要进行3次比较。可见，堆积区域越长，查找位于堆积区域后部的元素所需的比较次数就越多。这会显著增加**平均查找长度**，从而降低查找效率

[[Pasted image 20250909033517.png]]
[[平均查找长度 (ASL)]]  [[常用哈希函数的设计方法]] 


![[2014-exam-paper-ocr.pdf#page=1&rect=78,46,452,87|2014-exam-paper-ocr, p.1]]

[[Pasted image 20250909033523.png]]
- [[B树（B-树）]]  题目的核心是：在**关键字总数固定**的情况下，如何构造一棵B树，使其**结点总数最多**
- 建立一个简单的关系式：
	$总关键字数 = \sum_{i=1}^{结点总数} (第i个结点的关键字数)$ 
	让等式左边的“总关键字数”（15）不变，而等式右边的“结点总数”最大
	我们必须让每一项，即**每个结点包含的关键字数量尽可能少**
2. 有一棵 **4 阶 B 树**，即 $m=4$ 
	1. 确定每个结点的最少关键字数 
		*   对于**根结点**，最少可以有 $1$ 个关键字。
	    *   对于**非根结点**，最少可以有 $\lceil m/2 \rceil - 1$ 个关键字。
	        *   代入 $m=4$，最少关键字数为 $\lceil 4/2 \rceil - 1 = 2 - 1 = 1$
	2. 综合来看，在这棵4阶B树中，任何一个结点（无论是根结点还是非根结点）都最少可以只包含 **1** 个关键字 [[树的种类]]
3. 计算最大结点数
    *   我们的目标是让结点数最多。
    *   策略是让每个结点都只存储最少数量的关键字，即 1 个。
    *   总关键字数是 15。
    *   如果每个结点只放 1 个关键字，那么最多可以构成多少个结点？
        $最大结点数 = \frac{总关键字数}{每个结点的最少关键字数} = \frac{15}{1} = 15$
4. 验证结构是否合法
	1. 一个包含15个结点的B树，如果每个结点只有1个关键字，那么每个结点就会有 $1+1=2$ 个分支  
	2. 这实际上构成了一棵**满二叉树**
		1. 一棵高度为4的满二叉树正好有 $2^4-1=15$ 个结点。这个结构是完全合法的，并且满足4阶B树的所有定义（因为每个结点的关键字数1在允许的范围 $[1, 3]$ 内） 
D 
- 衍生
	- 在一棵具有 15 个关键字的 4 阶 B 树中，含关键字的结点个数最少是多少？  
		- 要使结点数最少，就需要让每个结点包含的 #关键字数量 最多  
		- **计算过程：**
		    1.  根据B树定义，一个 $m$ 阶B树的结点最多可以包含 $m-1$ 个关键字。
		    2.  对于 $m=4$，每个结点最多可以有 $4-1=3$ 个关键字。
		    3.  总关键字数为 15。
		    4.  $最少结点数 = \lceil \frac{总关键字数}{每个结点的最多关键字数} \rceil = \lceil \frac{15}{3} \rceil = 5$
	- 高度与关键字/结点数的关系
		- 一棵高度为 $h$ 的 $m$ 阶B树，最少/最多有多少个关键字？
			- 最少关键字数
				-  假设树的结构最“稀疏”。根结点有1个关键字（2个孩子），其他所有结点都只有 $\lceil m/2 \rceil - 1$ 个关键字（$\lceil m/2 \rceil$ 个孩子）。然后逐层计算结点数并乘以每层的最少关键字数
				-  **最多关键字数：** 假设树的结构最“茂密”。每个结点都填满，即都有 $m-1$ 个关键字（$m$ 个孩子）。然后逐层计算结点数并乘以每层的最多关键字数


![[2014-exam-paper-ocr.pdf#page=2&rect=78,768,527,814|2014-exam-paper-ocr, p.2]]
[[排序算法]]    [[希尔排序]] 
1. B
	*   **子序列1 (下标为 1, 4, 7):** 元素为 `[9, 13, 20]`。这个子序列是升序的。
	*   **子序列2 (下标为 2, 5, 8):** 元素为 `[1, 7, 23]`。这个子序列是升序的。
	*   **子序列3 (下标为 3, 6, 9):** 元素为 `[4, 8, 15]`。这个子序列是升序的。
	*   所有按增量3划分的子序列都是有序的。因此，增量可能是3。
[[Pasted image 20250909033542.png]]
- 时间复杂度 
	- 希尔排序的时间复杂度与所选用的增量序列密切相关 
	    *   **最坏情况**：如果增量序列选择不当（例如$8, 4, 2, 1$），时间复杂度会退化到$O(n^2)$。
	    *   **较优情况**：
	        *   Knuth提出的序列 $h_k = \frac{3^k - 1}{2}$，反向使用（例如$..., 40, 13, 4, 1$），其时间复杂度为$O(n^{3/2})$。
	        *   Sedgewick提出的序列，其时间复杂度可以达到$O(n^{4/3})$甚至$O(n \log^2 n)$。
	    *   至今，最优的增量序列仍然是一个开放的数学问题。
- 空间复杂度 
	- 希尔排序是原地排序算法，只需要一个额外的临时变量用于交换，所以空间复杂度为$O(1)$ 
- 稳定性 
	- 希尔排序是**不稳定**的。在对不同子序列进行排序时，相同元素的相对位置可能会发生改变。
- 衍生 
	- 正向推导 
		- 给定一个初始无序序列和一个增量序列（如$g=\{5, 3, 1\}$），要求写出第一趟或第二趟排序后的结果。 
	- 算法性质考察
		-   **增量序列的重要性**：提问为什么增量序列最后一个必须是1？（答案：为了保证最终整个序列一定是有序的，增量为1的希尔排序等价于一次完整的插入排序）。
	- 算法比较
	    *   与**插入排序**比较：希尔排序是对插入排序的改进，为什么它通常更快？（因为它允许元素进行大跨度的移动，能更快地将元素归位到其大致正确的位置）。
	    *   与**快速排序/归并排序**比较：在什么情况下可能会选择希尔排序？（希尔排序实现简单，且对于中等规模的数据集表现良好。它的空间复杂度为$O(1)$，优于归并排序的$O(n)$）。



![[2014-exam-paper-ocr.pdf#page=2&rect=75,732,507,768|2014-exam-paper-ocr, p.2]]
- [[快速排序]]
1. 在算法题目中，通常将  #完成一次分区操作（一趟） 视为“一 #趟 排序”。因此，题目中的“第 $i$ 趟排序结果”指的是已经完成了 $i$ 次分区操作后的数组状态。 
	1. 在快速排序的第 $i$ 趟排序完成后，数组中必定有至少 $i$ 个元素已经处在它们各自最终的、排序完成后的正确位置上
	2. 为什么是“至少” $i$ 个？ 
		1. 因为一次分区操作可能会将一个已经就位的元素（例如数组的第一个或最后一个元素）再次选为基准，但这并不增加新的已就位元素的数量。但在典型的递归调用中，每一趟（即每一次分区）都会将一个新的基准值放到其最终位置。因此，经过 $i$ 趟，至少有 $i$ 个元素就位了
2. 这意味着我们要寻找那个 #已就位元素数量 小于 2  的选项   
	一个元素 `A[k]` 是否“已就位”（在最终正确位置上），需要满足以下条件：
	*   它左边的所有元素都小于或等于 `A[k]`。
	*   它右边的所有元素都大于或等于 `A[k]`。
3. C
	1. 已就位的元素只有 `9`，共 1 个。因为 $1 < 2$，所以 C **不可能是**第 2 趟排序的结果

[[Pasted image 20250909033806.png]]
-  衍生 
	- 特定基准选择下的排序过程
		- 题目可能会给定一个初始序列，并指定每次都选择**第一个元素**或**最后一个元素**作为基准，要求写出第一趟或第二趟排序后的结果 
			- 对序列 `[6, 1, 2, 7, 9, 3]` 进行快速排序，以第一个元素为基准，第一趟排序后的结果是什么？
	        *   **解答**：基准为 `6`。分区后，比 `6` 小的放左边，大的放右边。结果为 `[3, 1, 2, 6, 9, 7]`。此时 `6` 已就位。
- 快速排序的 #时间复杂度分析  
	*   **最坏情况**：当每次选取的基准都是当前待排序列的最大或最小元素时（例如，对一个已经有序或逆序的序列，每次都选第一个元素为基准），分区会极度不平衡，导致时间复杂度退化为 $O(n^2)$。
    *   **最好情况**：当每次选取的基准都能将序列平分为两个长度几乎相等的子序列时，时间复杂度为 $O(n \log n)$。
    *   **平均情况**：在随机输入下，平均时间复杂度为 $O(n \log n)$
- [[快速排序的优化]] 
-  算法特性比较 
	-    **稳定性**：快速排序是一种**不稳定**的排序算法。因为在分区过程中，与基准相等的元素的相对位置可能会发生改变。
	*   **空间复杂度**：主要取决于递归调用的深度。最好和平均情况下为 $O(\log n)$，最坏情况下为 $O(n)$。
    *   **与其他 $O(n \log n)$ 算法的比较**：
        *   **归并排序**：稳定，时间复杂度稳定在 $O(n \log n)$，但需要 $O(n)$ 的额外空间。
        *   **堆排序**：不稳定，时间复杂度稳定在 $O(n \log n)$，空间复杂度为 $O(1)$（原地排序）。



![[2014-exam-paper-ocr.pdf#page=2&rect=77,684,514,733|2014-exam-paper-ocr, p.2]]
[[计算机性能评测的四个指标]]   [[CPU主频]] 
$时间_{new} = 0.7 \times 1.2 \times (IC_{old} \times CPI_{old} \times T_{clock})$
  $时间_{new} = 16.8秒$  
  - #CPU性能基本公式  
	  - $CPU执行时间 = \frac{指令数 \times CPI}{时钟频率}$ 
	  - $CPU执行时间 = 指令数 \times CPI \times 时钟周期时间$ 
[[Pasted image 20250909033813.png]] 
- 计算性能提升比 
	- 公式：$加速比 = \frac{优化前的执行时间}{优化后的执行时间}$
    *   **例题**：在本题中，加速比为 $20 / 16.8 \approx 1.19$。这意味着编译优化后，程序的执行速度是原来的1.19倍
- #MIPS每秒执行百万条指令数 
	- $MIPS = \frac{指令数}{执行时间 \times 10^6} = \frac{时钟频率}{CPI \times 10^6}$
- #加权平均CPI的计算 
	*   实际程序中包含多种类型的指令，每种指令的CPI可能不同。总的CPI是所有指令类型的加权平均值。
    *   公式：$CPI_{avg} = \sum_{i=1}^{n} (CPI_i \times F_i)$，其中 $CPI_i$ 是第i类指令的CPI，$F_i$ 是第i类指令在程序中所占的比例。
    *   **例题**：一个程序包含40%的算术指令（CPI=1）、40%的访存指令（CPI=2）和20%的分支指令（CPI=3）。优化后，算术指令比例变为50%，访存指令变为30%，分支指令变为20%。求优化前后的平均CPI和性能变化。
* [[阿姆达尔定律]] 
	* 公式：$总加速比 = \frac{1}{(1 - F_{可改进}) + \frac{F_{可改进}}{S_{改进部分}}}$，其中 $F_{可改进}$ 是可改进部分所占的原执行时间比例，$S_{改进部分}$ 是该部分的加速比




![[2014-exam-paper-ocr.pdf#page=2&rect=75,648,513,684|2014-exam-paper-ocr, p.2]]
- [[补码]] [[补码减法]]
1. [[补码加法溢出判断]]  
	1.   溢出是指运算结果超出了机器数所能表示的范围。对于8位补码，范围是 $[-128, 127]$。
C 
[[Pasted image 20250909033820.png]]
- 溢出检测的硬件实现 
	- 在计算机组成原理中，常考如何用逻辑门（特别是异或门）来检测溢出。如前所述，当符号位的进位与最高数值位的进位不同时溢出，这可以用一个异或门 `V = Cs ⊕ C1` 来实现 


![[2014-exam-paper-ocr.pdf#page=2&rect=77,602,526,649|2014-exam-paper-ocr, p.2]]
[[IEEE754单精度浮点数格式]] 
	比较两个以 IEEE 754 单精度浮点格式表示的数的大小 
1. 一个规格化的浮点数的真实值 V 的计算公式为：
	$V = (-1)^S \times (1.M)_2 \times 2^{(E-127)}$ 
- 方法一：按部就班计算法  
1. 分析变量 x (f1 = CC90 0000H)
	1. 转换为二进制
		1. `CC90 0000H` = `1100 1100 1001 0000 0000 0000 0000 0000` 
	2. 分解 S, E, M
        *   **S**: `1` (最高位) -> 这是一个负数。
        *   **E**: `1001 1001` (接下来的8位)
        *   **M**: `001 0000 ... 0000` (剩下的23位)
	3. 计算真实值
		*   符号：负。
		*   阶码 E (十进制): $(10011001)_2 = 128 + 16 + 8 + 1 = 153$。
        *   真实指数 e: $e = E - 127 = 153 - 127 = 26$。
        *   尾数 M: `00100...`，所以有效数字是 $(1.M)_2 = (1.001)_2$。
        *   所以，$x = -1 \times (1.001)_2 \times 2^{26}$
2. 分析变量 y (f2 = B0C0 0000H)
	1. 转换为二进制 
		1. `B0C0 0000H` = `1011 0000 1100 0000 0000 0000 0000 0000`  [[进制转化]] 
	2. 分解 S, E, M 
		*   **S**: `1` (最高位) -> 这是一个负数。
        *   **E**: `0110 0001` (接下来的8位)
        *   **M**: `100 0000 ... 0000` (剩下的23位)
	3. 计算真实值
		*   符号：负。
        *   阶码 E (十进制): $(01100001)_2 = 64 + 32 + 1 = 97$。
        *   真实指数 e: $e = E - 127 = 97 - 127 = -30$。
        *   尾数 M: `10000...`，所以有效数字是 $(1.M)_2 = (1.1)_2$。
        *   所以，$y = -1 \times (1.1)_2 \times 2^{-30}$。
3.  比较 x 和 y
	*   **符号**: 两个数的符号位 S 都是 1，所以它们都是负数，符号相同。因此可以排除选项 B 和 D。
    *   **大小**:
        *   $|x| = (1.001)_2 \times 2^{26}$ 是一个非常大的数。
        *   $|y| = (1.1)_2 \times 2^{-30}$ 是一个非常小的数（接近于0）。
        *   显然，$|x| > |y|$。
	*   对于两个负数，绝对值越大的数反而越小。因为 $|x| > |y|$，所以 $x < y$。
* $x < y$ 且符号相同。所以选择 **A** 
* 方法二：快速比较法 
1. #IEEE754编码的特性 有一个非常巧妙的特性： [[IEEE754单精度浮点数格式]]  [[进制表示法]]
	*   对于**正数**，如果将其 32 位二进制码看作一个无符号整数，那么这个整数的大小关系与它所代表的浮点数的大小关系是一致的。
	*   对于**负数**，情况则相反。如果将其 32 位二进制码看作一个无符号整数，那么整数越大的，其代表的浮点数反而越小（因为绝对值更大，离0更远）。
	*   `f1 = CC90 0000H`，最高位的十六进制数是 `C` (`1100`B)，其最高位是 `1`。所以 x 是负数。
    *   `f2 = B0C0 0000H`，最高位的十六进制数是 `B` (`1011`B)，其最高位是 `1`。所以 y 是负数。
    *   两者符号相同，排除 B 和 D。
2. 判断符号
	1.  `f1 = CC90 0000H`，最高位的十六进制数是 `C` (`1100`B)，其最高位是 `1`。所以 x 是负数
	2. `f2 = B0C0 0000H`，最高位的十六进制数是 `B` (`1011`B)，其最高位是 `1`。所以 y 是负数 
	3. 两者符号相同，排除 B 和 D 
3. 比较整数大小
	*   将 `CC90 0000H` 和 `B0C0 0000H` 直接当作 32 位无符号整数来比较。
    *   显然，`CC900000H > B0C00000H`。
    * 因为都是 负数 。由于 `(f1) > (f2)`，所以 $x < y$  

[[Pasted image 20250909040125.png]]
[[Pasted image 20250909040135.png]]
1. [[IEEE 754 标准 特殊值的表示]]  
2. #双精度浮点数  [[IEEE 754 标准双精度浮点数]]
	 *   64位表示：1位符号位，11位阶码，52位尾数。
    *   阶码偏置值为 1023。
    *   真实值公式：$V = (-1)^S \times (1.M)_2 \times 2^{(E-1023)}$。 
* #浮点数的精度和范围 
	* 单精度浮点数能表示的最大正数、 #最小的规格化正数 等  
	    *   **最大正数**: $S=0$, E 最大但非全1 (即254), M 全1。约 $3.4 \times 10^{38}$。
	    *   **最小规格化正数**: $S=0$, E 最小但非全0 (即1), M 全0。约 $1.18 \times 10^{-38}$。



![[2014-exam-paper-ocr.pdf#page=2&rect=76,550,529,604|2014-exam-paper-ocr, p.2]]
- 目的是计算一个特定规格的DRAM芯片的地址引脚和数据引脚的总数   [[地址总线与存储容量的关系]]  #地址引脚数的计算 
1. 计算 #数据引脚数  #存储器的容量 
	1. 4M x 8 位即一次可以读写8个比特（bit）的数据   
		1. 因此，需要8根线来传输这8位数据
		2. 数据引脚数 = $8$ 
	2.  "4M" 表示该芯片内部有4M个存储单元 
		1.  为了能够唯一地选中这4M个单元中的任意一个，我们需要计算出所需要的地址线条数。
	    *   首先，将 "4M" 转换为以2为底的幂：
	        *   M (Mega) 在计算机中通常表示 $2^{20}$。
	        *   4 表示 $2^2$。
        *   所以，4M = $4 \times M = 2^2 \times 2^{20} = 2^{22}$。、
	* 寻址 $N$ 个单元需要 $\log_2(N)$ 根地址线
	* 因此，总的地址位数 = $\log_2(2^{22}) = 22$ 位 
2. 计算 #地址引脚数   
	1. 这是本题最关键也是最容易出错的一步。题目明确指出芯片是 **DRAM**  
	2. DRAM为了减少芯片的引脚数量、降低成本和封装尺寸，普遍采用 #地址复用技术   [[DRAM地址复用技术]]  
	3. 22位的地址会分为两部分 #行地址   #列地址 
	4. 在寻址时，先通过地址引脚发送11位的行地址，再通过**同一组地址引脚**发送11位的列地址 
	5. 物理上需要的地址引脚数是总地址位数的一半。
    *   地址引脚数 = $\frac{\text{总地址位数}}{2} = \frac{22}{2} = 11$。
总引脚数 = 地址引脚数 + 数据引脚数 = $11 + 8 = 19$ 

[[Pasted image 20250909040144.png]]
- [[存储芯片容量]]  
	-    总容量 = $4M \times 8 \text{ bits} = 32 \text{ Mbits} = 4 \text{ MBytes}$ (因为 1 Byte = 8 bits)。 
- [[系统总线结构（数据线，地址线，控制总线）]] 
	- 数据线 
		- 用于在CPU和存储器之间双向传输数据。数据线的数量决定了数据传输的位宽
	- 地址线 
		- 用于从CPU向存储器发送地址信息，以选择特定的存储单元。它是单向的。地址线的数量 $n$ 决定了可寻址的最大空间，为 $2^n$
- 衍生
	- #存储器扩展 
		- 题目中给出的 "256MB的存储器" 是一个迷惑信息，但在衍生问题中非常重要。
			**问题**: 使用 "4M x 8 位" 的DRAM芯片构成一个 "256MB" 的存储器，需要多少片这样的芯片？
			1.  计算总容量（单位统一为bit）：
			    *   目标存储器容量: $256 \text{MB} = 256 \times 1024 \times 1024 \times 8 \text{ bits} = 2^8 \times 2^{20} \times 2^3 \text{ bits} = 2^{31} \text{ bits}$。
			    *   单片芯片容量: $4\text{M} \times 8 \text{ 位} = 2^{22} \times 8 \text{ bits} = 2^{22} \times 2^3 \text{ bits} = 2^{25} \text{ bits}$。
			2.  计算所需芯片数量：
			    *   芯片数量 = $\frac{\text{总容量}}{\text{单片容量}} = \frac{2^{31}}{2^{25}} = 2^6 = 64$ 片。
	-  如果本题中的芯片是 **SRAM** (Static RAM) 而不是DRAM，那么总引脚数是多少？ 
		-   SRAM**不使用** #地址复用技术 。
		*   数据引脚数仍然是 $8$。
		*   地址引脚数等于总地址位数，即 $22$。
		*   总引脚数 = 地址引脚数 + 数据引脚数 = $22 + 8 = 30$
	- #地址译码设计  
		- 在上述由64片 "4M x 8 位" 芯片构成的256MB存储器中，CPU需要多少根地址线？这些地址线如何分配？ 
			- CPU所需地址线总数 
				*   存储器总容量为256MB，按字节编址。
			    *   $256\text{MB} = 2^8 \times 2^{20} \text{ Bytes} = 2^{28}$ Bytes。
			    *   因此，CPU需要 $28$ 根地址线（A0-A27）来寻址整个256MB空间。
			- 地址线分配
				- 片内地址
					- 每片芯片有4M个单元，需要 $22$ 根地址线（$\log_2(4M) = 22$）来选择芯片内部的地址。通常，CPU地址线的低22位（A0-A21）会连接到**所有**芯片的地址引脚上 
				- 片选地址
					- 我们需要从64片芯片中选出1片。选择64个对象需要 $\log_2(64) = 6$ 根线。因此，CPU地址线的高6位（A22-A27）会连接到一个**地址译码器**（如6-64译码器），译码器的输出信号作为各个芯片的片选信号（Chip Select, CS）

![[2014-exam-paper-ocr.pdf#page=2&rect=78,502,449,549|2014-exam-paper-ocr, p.2]]
- [[指令流水线与冲突]]  #流水线的访存操作 [[高速缓存Cache]]
	-   **IF 阶段**：需要从内存中**读取指令**。
    *   **MEM 阶段**：对于 `load` (加载) 或 `store` (存储) 指令，需要从内存中**读取或写入数据**。
- 不 #分离Cache ( #统一Cache) 的问题
	- 如果指令和数据都存放在同一个 Cache（称为统一 Cache，Unified Cache）中，并且这个 Cache 只有一个读写端口，那么问题就出现了
	- 在某个时钟周期，流水线中的指令 `i` 是一条 `load` 指令，它正处于 `MEM` 阶段，需要访问 Cache 来读取数据。同时，流水线正在为指令 `i+k` (k通常是2或3，取决于流水线深度) 执行 `IF` 阶段，需要访问 Cache 来获取指令 
- 取指令， 取/存数据
	-  这两个操作需要**在同一个时钟周期内同时访问同一个 Cache**。由于 Cache 只有一个端口，它无法同时服务两个请求。这就产生了一种冲突，称为**结构冲突 (Structural Hazard)** 或**资源冲突 (Resource Conflict)**      
	- 为了解决这个冲突，流水线必须暂停 (stall)，让其中一个操作先完成，另一个再进行。这会降低流水线的效率 
	分离 Cache 的解决方案  设计师们提出了将 Cache 分离为两个独立的部分：
    *   #指令Cache (I-Cache)：专门存放指令。
    *   #数据Cache (D-Cache)：专门存放数据。 
*  Cache 是独立的硬件单元，拥有各自的访问端口。这样一来：
    *   `IF` 阶段的取指令操作总是访问 #I-Cache指令Cache 。
    *   `MEM` 阶段的访存操作总是访问 #D-Cache数据Cache 。
	它们是两个不同的物理资源，CPU 就可以在同一个时钟周期内，**同时进行取指令和取/存数据**的操作，从而避免了资源冲突，保证了流水线的流畅运行
指令 Cache 与数据 Cache 分离的**主要和直接目的**就是为了消除因同时访问存储器而引起的指令流水线资源冲突。这与选项 D 的描述完全一致

[[Pasted image 20250909040153.png]]
- [[高速缓存Cache]] 
- [[指令流水线与冲突]] 
- 衍生
	- [[流水线性能分析]] 
		- 例如：一个程序的理想 CPI 为 1，但由于使用了统一 Cache，20% 的指令是访存指令，并且其中 50% 的情况会与取指操作发生冲突，导致流水线暂停 1 个周期。问实际 CPI 是多少？
		- $CPI_{actual} = CPI_{ideal} + Stalls\_per\_instruction = 1 + 0.2 \times 0.5 \times 1 = 1.1$
 - 对比不同 Cache 架构的 AMAT
	 -  给出统一 Cache 和分离 Cache 的参数（总大小、命中率、命中时间等），要求计算并比较它们的 #平均访存时间AMAT
		 -   例如：一个 32KB 的统一 Cache 命中率为 97%。如果将其分为 16KB 的 I-Cache (命中率 98%) 和 16KB 的 D-Cache (命中率 95%)，假设访存指令占所有指令的 30%。计算两种方案的全局平均命中率或 AMAT
			 -  全局命中率 (分离) = $P_{I-Cache\_hit} \times (1 - P_{data\_access}) + P_{D-Cache\_hit} \times P_{data\_access}$
			 - $P_{global\_hit} = 0.98 \times (1 - 0.3) + 0.95 \times 0.3 = 0.686 + 0.285 = 0.971$ 
			 - 例子中，分离后的全局命中率略高于统一 Cache，但实际情况不一定如此
- 识别其他类型的[[指令流水线与冲突]]  
	- 给出一小段汇编代码，要求找出其中存在的数据冲突（RAW, WAR, WAW）或控制冲突，并说明解决方法（如转发/旁路、流水线暂停、分支预测等） #较复杂 




![[2014-exam-paper-ocr.pdf#page=2&rect=74,438,531,502|2014-exam-paper-ocr, p.2]]
- 核心是理解计算机指令是如何在有限的位数（32位）内编码所有必要信息的，包括操作码、寻址方式、寄存器编号和立即数（偏移量） 
1.  分析指令总体结构 [[指令集体系结构]] 
	1.  指令是**32位定长**的
	2.  操作码字段（Opcode）占 **8位**。这个字段告诉CPU要执行什么操作（比如 Store、Add、Load 等），并且题目说明它也包含了[[常见的寻址方式]] 的信息 
	3.   剩下的位数用于指定操作数。可用于操作数地址的位数 = 总位数 - 操作码位数。
        $32 - 8 = 24$ 位。
2. 分析 #源操作数
	1.   寻址方式：**寄存器直接寻址**。这意味着操作数本身就在一个寄存器里
		1. 计算机有 **16个通用寄存器**。为了从16个寄存器中唯一地选择一个，我们需要足够的位数来表示从0到15的编号
		2.   所需位数 $n$ 可以通过公式 $2^n \ge M$ 计算，其中 $M$ 是寄存器数量。这里 $M=16$
		3. $\log_2{16} = 4$ 位
		4. 指令中需要 **4位** 来指定源操作数所在的寄存器
3. 分析 #目的操作数 
    *   寻址方式：**基址寻址**。在这种方式下，最终的内存地址由一个基址寄存器的内容加上一个偏移量（Displacement）得到。
        *   `有效地址 = (基址寄存器内容) + 偏移量`
    *   题目指出，基址寄存器可以是**任一通用寄存器**。因此，和源操作数一样，我们也需要 **4位** 来指定16个通用寄存器中的哪一个作为基址寄存器。
4. 计算 #偏移量 的位数  [[基址寻址偏移量]]
	1. 总共有24位可用于编码两个操作数
	2.   源操作数用掉了4位（用于指定寄存器）
	3. 目的操作数用掉了4位（用于指定基址寄存器） 
	4. 那么，剩下的位数就全部留给了基址寻址中的**偏移量** 
		1. 偏移量的位数 = $24 - 4 - 4 = 16$ 位。
5. 确定 #偏移量的取值范围
   题目明确指出，偏移量用 #补码 (Two's Complement)  表示。
    *   对于一个 $n$ 位的补码整数，其表示的数值范围是 $[-2^{n-1}, 2^{n-1}-1]$。
    *   在这里，$n=16$，所以取值范围是：
        $[-2^{16-1}, 2^{16-1}-1]$
        $[-2^{15}, 2^{15}-1]$
        $[-32768, +32767]$ 
[[Pasted image 20250909040204.png]]

- [[指令格式]]  [[指令寻址方式]]  [[补码]] [[原码，反码的运算和溢出判断]]
- 衍生 
	- 改变寄存器数量
		- 如果题目改为“有32个通用寄存器”，那么指定一个寄存器就需要 $\log_2{32}=5$ 位。偏移量的位数就会减少为 $24 - 5 - 5 = 14$ 位，范围变为 $[-2^{13}, 2^{13}-1]$，即 $[-8192, +8191]$
	- 改变偏移量表示法
		*   如果题目改为“偏移量用**无符号数**表示”，那么16位偏移量的范围将是 $[0, 2^{16}-1]$，即 $[0, 65535]$。
	    *   如果题目改为“偏移量用 #原码表示”，那么16位偏移量的范围将是 $[-(2^{15}-1), 2^{15}-1]$，即 $[-32767, +32767]$
	* 改变寻址方式 
		* 如果目的操作数采用**直接寻址**（地址码直接是内存地址），那么整个24位都将作为内存地址，此时就没有偏移量的概念了。这种情况下，可寻址的内存空间为 $2^{24}$ 个单元
		* 如果指令是**三地址指令**，例如 `ADD R1, R2, D(R3)`（将 R2 的内容与 R3+D 地址处的内容相加，结果存入 R1），那么24位需要分配给三个操作数。比如 R1, R2, R3 各需4位，则偏移量D只剩下 $24 - 4 - 4 - 4 = 12$ 位 
	* #寻址范围计算 [[补码的表示范围]]  [[寻址范围，内存范围]] 
		* 可能会问“该指令能访问的最大内存范围是多少？” 这取决于基址寄存器的位数和偏移量的范围。如果 #基址寄存器 是32位的，那么理论上它可以指向整个 $2^{32}$ 的地址空间。 


![[2014-exam-paper-ocr.pdf#page=2&rect=79,376,521,443|2014-exam-paper-ocr, p.2]]
- 核心是计算 #微程序控制器 中， #控制存储器（控存）的地址空间大小 ，从而确定微指令中“ #下地址字段”所需的位数 
1. 计算执行阶段的微指令总数 
	1. 计算机系统有32条机器指令（或称指令）
	2. 每条机器指令的执行过程都对应一个微程序，这个微程序平均由4条微指令组成
	3.   因此，用于实现所有32条指令执行阶段的微指令总数为：
        $N_{exec} = 32 \text{条指令} \times 4 \text{条微指令/指令} = 128 \text{条微指令}$ 
	4. 计算 #公共微指令数 ：
		1. 题目提到，有一个“公共的取指令微程序”，它包含了2条微指令。这个微程序是所有机器指令在执行前都必须运行的公共部分（即取指周期）
		2. 公共部分的微指令数量为：
	        $N_{fetch} = 2 \text{条微指令}$
	5. 计算 #下地址字段 的位数
		1. 下地址字段需要能够唯一地寻址到这130条微指令中的任何一条
		2. 我们需要找到一个最小的位数 `k`，使得 $2^k$ 能够覆盖130个地址。即求解不等式：
	        $2^k \ge 130$
	    3. 我们可以通过计算2的幂次来找到 `k`：
			*   $2^6 = 64$ （不够）
			*   $2^7 = 128$ （不够）
			*   $2^8 = 256$ （足够）
		    *   因此，`k` 的最小值是8。
	* **结论：** 微指令中的下地址字段至少需要8位。所以答案是 **C** 
* [[微程序控制思想]] 
[[Pasted image 20250909040410.png]]
- 衍生 
	- 计算微指令的字长
		- 题目会给出操作控制字段的编码方式（如水平编码、垂直编码或字段编码）和微命令的数量，以及顺序控制字段的确定方式，要求计算一条微指令的总位数 
		- 假设系统有64个微命令，采用直接控制的水平编码方式（每个微命令占1位），并且采用本题的  #下地址字段法 （已知需要8位），那么微指令的字长至少是 $64 + 8 = 72$ 位
	- 计算 #控制存储器 的总容量 
		- 先计算出微指令的总数（控存深度），再计算出微指令的字长（控存宽度），两者相乘即可得到总容量（单位为bit）
		- 基于本题和上一个例子，控存总容量为 $130 \times 72$ bit
	- 不同下地址确定方法的比较
		- 可能会出选择题或简答题，要求比较[[“下地址字段法”和“μPC计数器法”的优缺点]]  
	- #微程序流程设计  [[指令集体系结构]]  [[指令格式]]  
		-  给出一个简单的机器指令（如 `LDA M`，从内存地址M取数到累加器ACC），要求写出其对应的微指令序列（微操作序列） 
		- `LDA M` 的微操作序列可能为
		    1.  `PC -> MAR` （程序计数器内容送地址寄存器）
	        2.  `1 -> R`, `M(MAR) -> MDR` （读内存，指令读入数据寄存器）
	        3.  `PC + 1 -> PC` （PC自增）
	        4.  `MDR(Addr) -> MAR` （指令的地址部分送地址寄存器）
	        5.  `1 -> R`, `M(MAR) -> MDR` （再次读内存，操作数读入数据寄存器）
	        6.  `MDR -> ACC` （数据送入累加器）
	    *   考试可能会要求将这些微操作分配到具体的微指令中。[[微指令与微命令]] 
![[2014-exam-paper-ocr.pdf#page=2&rect=73,317,528,381|2014-exam-paper-ocr, p.2]]
- [[系统总线结构（数据线，地址线，控制总线）]]
1. [[CPU主频]]  
2. [[总线带宽计算]] 总线带宽 = 总线时钟频率 × 数据线宽度 × 每个时钟周期的数据传输次数 
	*   **总线时钟频率 (Bus Clock Frequency):** 66 MHz
    *   **地址/数据线数量 (Address/Data Bus Width):** 32 根，这意味着数据线宽度是 32 bit
	*  每个时钟周期可以传输 2 次数据 
3. 已知的数据线宽度是 32 bit。我们需要把它转换成字节 (Byte)。因为 1 Byte = 8 bit，所以数据线宽度是 $32 \text{ bit} / 8 = 4 \text{ Byte}$。
    *   时钟频率 66 MHz 表示每秒有 $66 \times 10^6$ 个时钟周期 
    *  总线带宽 = $66 \text{ MHz} \times 4 \text{ Byte} \times 2$  
    *   总线带宽 = $(66 \times 10^6 \text{ 次/秒}) \times 4 \text{ 字节/次} \times 2$ 
	    * 这里的“2”是因为每个时钟周期内有两次传输
	*  总线带宽 = $66 \times 10^6 \times 8 \text{ 字节/秒}$
    *   总线带宽 = $528 \times 10^6 \text{ 字节/秒}$
    *   总线带宽 = $528 \text{ MB/s}$
[[双倍速率传输DDR（上升沿，下降沿）]] 

[[Pasted image 20250909040417.png]]

- [[改变数据传输速率类型]]  
- 反向求解问题 
	-    题目可能给出总线带宽和时钟频率，要求计算总线的数据线宽度。
	    *   例如：一个采用 DDR 技术的同步总线，时钟频率为 100MHz，带宽为 800MB/s，求其数据线宽度是多少位？
    *   推导：$800 = 100 \times (\text{宽度}/8) \times 2 \Rightarrow \text{宽度} = (800 \times 8) / (100 \times 2) = 32 \text{ bit}$。
* 考虑 #总线周期的实际开销 
	* 题目可能会描述一个完整的总线事务（transaction）包含多个时钟周期，例如：1个周期传地址，4个周期传数据。
    *   例如：对于本题，如果一次传输（包含32bit数据）需要1个地址周期和1个数据周期，那么传输4B数据总共需要2个时钟周期。
    *   有效带宽 = $数据量 / 总时间 = 4 \text{ B} / (2 \times \frac{1}{66 \times 10^6} \text{ s}) = 132 \text{ MB/s}$。这种题目考察的是对总线协议和事务过程的理解
- 单位混淆
	- 题目可能在单位上设置陷阱，例如时钟频率用 GHz，数据宽度用 Byte，最终要求结果为 Gbps (Giga-bits per second)。这要求你对 B (Byte) 和 b (bit) 以及 M (Mega, $10^6$) 和 G (Giga, $10^9$) 


![[2014-exam-paper-ocr.pdf#page=2&rect=75,266,531,319|2014-exam-paper-ocr, p.2]]
- 这道题的核心是理解不同总线事务（Bus Transaction）方式的定义  #总线事务 [[突发传输]]  [[总线事务]] 
1. 一次总线事务中 #总线事务 
	1. 这意味着整个操作被视为一个完整的、不可分割的单元
2. 主设备只需给出一个首地址
	1. 最关键的线索。在整个事务中，地址信息只在开始时发送一次 
3. 从设备就能从首地址开始的若干连续单元读出或写入多个数据 
	1. 在接收到那个唯一的首地址后，后续的数据传输自动在连续的地址上进行，无需为每个数据单元再发送新的地址 
- x
1. A. 并行传输
	1. 指的是数据位的传输方式。在并行传输中，一个数据字（例如8位、16位、32位）的所有位在多条并行的导线上同时传输。它描述的是**数据位**的组织形式，而不是**多个数据字**的寻址方式。所以A不正确
2. B. 串行传输
	1. 这也描述数据位的传输方式。在串行传输中，一个数据字的所有位在一条导线上按时间顺序逐位传输。它同样与题干中描述的“一次寻址，多次数据传输”的事务模式无关。所以B不正确
3. C. 突发传输
	1. 这是一种总线事务模式。其定义正是在一次总线事务中，主设备发送一个起始地址，然后连续传输一个数据块（block），这个数据块存储在连续的内存地址中。从设备接收到首地址后，会自动将地址递增，以准备下一次数据传输。这与题干的描述完全吻合 
4. D. 同步传输
	1. 这描述的是总线的**定时方式**。在同步传输中，总线上所有设备共享一个统一的时钟信号，所有的总线操作都由这个时钟信号来同步和协调。虽然突发传输通常在同步总线上实现，但“同步传输”本身描述的是定时机制，而不是寻址和数据流的模式。所以D不正确 
[[Pasted image 20250909040424.png]]
- 衍生 
	- [[总线带宽计算]] 
		- $带宽 = 总线时钟频率 \times (总线宽度 / 8)$
		- 这个公式计算的是理论峰值带宽，假设每个时钟周期都能传输一个数据 
	- 考虑突发传输的实际带宽计算 
		- 在实际计算中，需要考虑地址周期等开销。
		    假设总线时钟频率为 $f$，总线宽度为 $W$ 位，一次突发传输 $N$ 个数据字。
		    完成这次传输需要 $1$ 个地址周期和 $N$ 个数据周期，共 $(N+1)$ 个时钟周期。
		    总时间为 $T = (N+1) / f$。
		    传输的数据总量为 $D = N \times (W / 8)$ 字节。
		    **实际带宽** $B = \frac{D}{T} = \frac{N \times (W/8)}{(N+1)/f} = \frac{N}{N+1} \times f \times \frac{W}{8}$ (字节/秒)
- [[总线仲裁]] 
- [[总线定时]] 
- [[串行和并行总线的区别]] 

![[2014-exam-paper-ocr.pdf#page=2&rect=80,194,373,267|2014-exam-paper-ocr, p.2]]
[[1. IO 结构与控制]]
1. A. 状态端口和控制端口可以合用同一个寄存器
	1. [[IO接口和IO端口]]  
		1. I/O接口通常包含三类端口（寄存器）：数据端口、状态端口和控制端口。状态端口用于CPU读取外设的状态（如忙、闲、就绪），控制端口用于CPU向外设发送命令。在实际设计中，为了节省硬件资源，常常将状态和控制功能集成在同一个寄存器中。例如，一个8位的寄存器，可以用其中几位作为状态位（只读），另外几位作为控制位（只写或读写）。这种设计是常见且可行的 
		2. **结论：** 该陈述正确
2. B. I/O 接口中 CPU 可访问的寄存器称为 I/O 端口 
	1. 这是I/O端口的基本定义。I/O接口是连接CPU和外设的中间电路，它内部包含了一组寄存器。CPU通过读写这些寄存器来与外设进行数据交换和控制。这些可被CPU直接访问的寄存器就被称为I/O端口 
3. C. 采用独立编址方式时，I/O 端口地址和主存地址可能相同  [[编址方式]] 
	1. #独立编址  [[地址空间划分（IO编址方式）]] 
		1. **独立编址**（也称为I/O端口映射I/O）为I/O端口和主存储器设立了两个**独立**的地址空间。CPU通过不同的指令来区分访问的是哪个空间。例如，在x86架构中，`MOV`、`ADD`等指令访问的是内存地址空间，而`IN`、`OUT`等专用指令访问的是I/O地址空间。因为是两个独立的“地图”，所以内存地址`0x1000`和I/O端口地址`0x1000`是两个完全不同的物理位置，它们可以同时存在而不冲突
4. D. 采用 #统一编址 方式时，CPU 不能用访存指令访问 I/O 端口
	1. **统一编址**（也称为内存映射I/O）是将I/O端口看作是主存的一部分，将它们和内存单元进行统一编址，放在同一个地址空间中。这意味着I/O端口也被分配了内存地址。因此，CPU访问I/O端口就和访问一个普通的内存单元完全一样，使用的也是**访存指令**（如`LOAD`, `STORE`, `MOV`等）。该选项说“不能用访存指令访问”，这与统一编址的定义完全相反
	**结论：** 该陈述**错误**

[[截屏2025-09-09 上午4.09.22.png]]  [[两种IO编址方式的优缺点]] 
- [[IO控制方式]] 
	*   **程序查询方式**：CPU通过反复读取状态端口来检测外设是否准备好，CPU利用率低。
    *   **中断方式**：外设准备好后，通过中断信号主动通知CPU，CPU转而执行中断服务程序。提高了CPU利用率。
    *   **DMA（直接存储器存取）方式**：在DMA控制器的主持下，外设与主存之间直接进行数据交换，无需CPU介入（仅在开始和结束时需要CPU干预）。适用于高速、大批量的数据传输。
- 具体指令的识别给出一段汇编代码，判断其采用了哪种I/O编址方式。
    *   如果看到 `IN AL, 0x60` 或 `OUT 0x61, AL`，则必然是**独立编址**。
    *   如果看到 `MOV AL, [0xFFFF0]` 这样的指令，且已知地址`0xFFFF0`对应一个I/O设备，则为**统一编址**。


![[2014-exam-paper-ocr.pdf#page=2&rect=75,130,520,192|2014-exam-paper-ocr, p.2]]
1. 中断请求的响应和处理时间为 100ns #甘特图  
	1. **每 400ns 发出一次中断请求**：这定义了一个固定的时间周期。每隔400ns，设备就会请求一次CPU的服务。我们称之为“中断周期” ($T_{period}$)
	2. 中断响应所允许的 #最长延迟时间 为 50ns 
		1. 是一个 #干扰信息 。它指的是从设备发出中断请求到CPU开始响应（即开始执行中断服务程序）之间的时间不能超过50ns。这个信息对于计算CPU的总I/O时间占比没有影响，因为它只规定了100ns处理时间必须在中断发生后的50ns内开始，但并没有改变处理本身需要100ns这个事实
	3.   $P = \frac{T_{service}}{T_{period}}$ [[CPU时间占比（CPU利用率）]] 
		1.     $P = \frac{100ns}{400ns} = 0.25$

[[截屏2025-09-09 上午4.09.29.png]]
[[截屏2025-09-09 上午4.09.41.png]]
-  #多设备中断处理
	- 如果系统中有多个设备，每个设备都有不同的中断周期和中断服务时间，如何计算CPU的总I/O时间占比？
		- 将每个设备的CPU时间占比分别计算出来，然后相加。例如，设备A的占比为$P_A$，设备B的占比为$P_B$，则CPU总的I/O时间占比为 $P_{total} = P_A + P_B$。如果$P_{total} > 100\%$，则说明CPU无法处理所有设备的中断请求，系统会崩溃
- #中断优先级与中断嵌套 #中断嵌套 
	- 当一个高优先级的中断可以打断一个正在处理的低优先级中断时，系统的行为会怎样？如何计算最坏情况下的中断响应时间？
		- 这涉及到 #实时系统 中的“# #响应时间分析”，需要考虑 #中断阻塞 、 #上下文切换开销 等更复杂的因素
- 中断与DMA
	- 对于大量数据的传输，如果使用中断方式，CPU会频繁参与，占用率很高。题目可能会问：如果改用DMA方式，CPU的占用率会如何变化？
		- 在DMA模式下，CPU只需在数据传输开始前设置好DMA控制器，并在传输结束后处理一次“传输完成”中断。在整个数据传输过程中，CPU是自由的，可以执行其他任务。因此，使用DMA会极大降低CPU在I/O操作上的时间占比。计算时，CPU的占用时间就变成了“DMA设置时间”+“DMA完成中断处理时间”


![[2014-exam-paper-ocr.pdf#page=2&rect=81,73,420,130|2014-exam-paper-ocr, p.2]]
A  [[饥饿]] 
1. 静态优先数调度 [[常见进程调度算法与优先级关系]]
- [[饥饿和死锁的区别]]  
	-   **饥饿 (Starvation):** 进程处于**就绪态**
	-  **死锁 (Deadlock):** 进程处于**阻塞态（等待态）**
- #解决饥饿的方案：老化 [[老化（解决饥饿）]] 
	- 动态地提升那些长时间等待的进程的优先级
[[调度算法性能评价指标]] [[流水线性能分析]]
 
[[Pasted image 20250909040948.png]]

#死锁 ![[2014-exam-paper-ocr.pdf#page=2&rect=72,27,529,74|2014-exam-paper-ocr, p.2]]
1. [[死锁预防 vs 死锁避免vs 死锁检测与解除]]  [[死锁产生的四个条件]] 
	1. 为确保系统 **不发生死锁**，所需的最小设备数n为10。 
**答案：B**
[[截屏2025-09-09 上午4.10.00.png]]
- [[银行家算法核心思想与数据结构]]
	- 通常会给出一个系统在某一时刻的资源分配快照（包括总资源、已分配资源、进程最大需求），然后问：
        *   当前系统是否处于安全状态？
        *   如果此时某个进程发出资源请求，系统是否应该批准？
    *   解题关键是找到一个 #安全序列 ，即一个进程的执行序列，使得每个进程都能顺利完成。
- 反向提问
	- 某系统有12台同类设备，供若干个进程共享，每个进程最多需要3台设备。请问系统最多可以支持多少个这样的进程并发执行而不会发生死锁？
	- 设最多支持 $k$ 个进程。套用公式 $N \ge k \times (R - 1) + 1$。
        $12 \ge k \times (3 - 1) + 1$
        $12 \ge 2k + 1$
        $11 \ge 2k$
        $k \le 5.5$
        因为进程数必须是整数，所以最多支持 $k=5$ 个进程

![[2014-exam-paper-ocr.pdf#page=3&rect=72,779,501,825|2014-exam-paper-ocr, p.3]]
[[Pasted image 20250909041014.png]]
D 
1. [[特权指令与非特权指令的划分]] 
	1. #特权指令 是指那些如果被用户程序随意使用，可能会导致系统崩溃、数据损坏或安全漏洞的指令。这些指令只能在内核态下执行
	2. 当CPU处于用户态时，如果尝试执行一条特权指令，硬件会立即捕获这个行为，并产生一个**陷阱（Trap）**，将控制权交给操作系统内核。内核会处理这个异常，通常是终止这个非法的应用程序。
2. [[trap指令（陷阱指令）]] 
3. [[跳转指令]] 
	1. 跳转指令（如 `JMP`, `CALL`）是改变程序执行流程的基本指令，用于实现分支、循环和函数调用。
4. [[压栈指令]] 
	1. 压栈指令（如 `PUSH`）用于将数据或地址存入程序的调用栈中，是函数调用和局部变量管理的基础。 
		1. 它操作的是应用程序自己的栈空间，不影响操作系统或其他程序，因此是**非特权指令**，可以在用户态执行。
5. [[关中断指令]] 
- 衍生
	1. [[双模式操作]] 
		1. #标志寄存器（程序状态字PSW） 
		2.  其中有一个二进制位（模式位，Mode Bit）用来标识当前是用户态（例如，值为1）还是内核态（例如，值为0）。
	2. [[中断、异常和系统调用的区别与联系]] 
		1.  **共同点**：它们都会打断当前程序的正常执行流程，并强制CPU切换到内核态，跳转到预设的内核处理程序（中断服务例程）去执行 
	3. [[系统调用的过程]]  
	4.   [[特权指令类型]] 
	5. 为什么用户程序不能直接访问I/O设备？
		*   **安全性**：防止恶意程序破坏设备或窃取数据。
	    *   **公平性**：操作系统需要统一协调和调度多个程序对共享设备的访问请求，避免冲突和死锁。如果用户程序可以直接访问，就无法进行有效的管理。
![[2014-exam-paper-ocr.pdf#page=3&rect=73,729,458,783|2014-exam-paper-ocr, p.3]]
- 解题关键在于理解[[进程状态模型]] 以及I/O操作如何影响进程状态 
	- [[进程的五状态模型]] 
- B. 降低进程优先级
	- 事实上，某些调度算法（如多级反馈队列调度）可能会在进程从 #I/O阻塞 中返回后，**提高**其优先级，因为I/O密集型进程通常需要快速响应以保持I/O设备繁忙，从而提高系统整体吞吐量。优先级的调整是调度策略的一部分，而不是一个必然操作
- C. 给进程分配用户内存空间
	- 内存空间通常在进程创建时或进程通过系统调用（如`malloc`）主动申请时分配。读磁盘操作是将数据读入**已经分配好**的内存缓冲区中，而不是为进程分配新的内存空间
- D. 增加进程时间片大小
- A

- 衍生
	- [[CPU密集型 vs. IO密集型进程]] 
	- [[常见进程调度算法与优先级关系]] 

[[Pasted image 20250909041027.png]]



![[2014-exam-paper-ocr.pdf#page=3&rect=71,671,527,736|2014-exam-paper-ocr, p.3]]
- 核心是计算用于管理磁盘空闲空间的“ #位图（Bitmap）”本身需要占用多少磁盘空间 [[位图法]] 
1. 第一步：计算磁盘分区的总簇数
	*   磁盘总容量：$10 \text{GB}$
	*   每个簇的大小：$4 \text{KB}$
	1. $10 \text{GB} = 10 \times 1024 \times 1024 \text{ KB}$ 
	2. $N_{簇} = \frac{10 \text{ GB}}{4 \text{ KB}} = \frac{10 \times 1024 \times 1024 \text{ KB}}{4 \text{ KB}} = 10 \times 1024 \times 256 = 2,621,440$ 个簇
	3. $N_{簇} = \frac{10 \times 2^{10} \times 2^{10} \text{ B}}{4 \times 2^{10} \text{ B}} = \frac{10 \times 2^{20}}{4} = 2.5 \times 2^{20} = 2.5\text{M}$ 个簇。
	
2. 第二步：计算位图的总大小 
	1. 题目说明，用1个位（bit）来标记1个簇。因此，位图所需要的总位数就等于总簇数。
		位图总大小（位数） = 总簇数 = $2.5\text{M}$ 位 (bits)
3. 第三步：将位图大小从“位”转换为“字节”或“KB”
	 $1 \text{ Byte} = 8 \text{ bits}$
	位图总大小（字节） = $\frac{\text{位图总大小（位数）}}{8}$
	$S_{位图} = \frac{2.5\text{M bits}}{8} = \frac{2.5 \times 1024 \times 1024 \text{ bits}}{8} = 327,680 \text{ Bytes}$
	$S_{位图(KB)} = \frac{327,680 \text{ Bytes}}{1024} = 320 \text{ KB}$
4. 第四步：计算存储位图所需的簇数
	*   位图大小：320KB
	*   每个簇的大小：4KB
	存储位图所需的簇数 = $\frac{\text{位图总大小}}{\text{每个簇的大小}}$
	$N_{位图所需簇数} = \frac{320 \text{ KB}}{4 \text{ KB}} = 80$ 个簇

因此，存放该位图需要80个簇。答案是 **A**。
[[Pasted image 20250909041036.png]]
- [[内存碎片]] 
	- 在上述同样的磁盘分区中（簇大小为4KB），如果要存储一个大小为15KB的文件，会产生多少内部碎片？ 
	- $N = \lceil \frac{15 \text{ KB}}{4 \text{ KB}} \rceil = \lceil 3.75 \rceil = 4$ 个簇。
		- $4 \times 4 \text{ KB} = 16 \text{ KB}$
		- 内部碎片 = 占用的总空间 - 文件实际大小 = $16 \text{ KB} - 15 \text{ KB} = 1 \text{ KB}$ 
- [[磁盘空闲空间管理]]
- #空闲链表法 
		*   **优点**：不需要像位图法那样占用一块连续的、可能很大的空间。
        *   **缺点**：查找连续的空闲块效率较低，需要遍历链表。
- [[索引节点 (inode)]] 
	如果一个文件系统使用索引节点来管理文件，每个索引节点大小为128B，其中包含10个直接地址项，1个一级间接地址项，1个二级间接地址项。若磁盘块大小为4KB，每个地址项占4B，那么一个文件最大可以有多大？
	*   **解析**：这是一个更复杂但非常经典的考点，它结合了文件系统结构和磁盘空间管理。
	*   直接地址：$10 \times 4 \text{ KB}$
	*   一级间接地址：一个块能存 $\frac{4 \text{ KB}}{4 \text{ B}} = 1024$ 个地址项，所以大小为 $1024 \times 4 \text{ KB}$。
	*   二级间接地址：$1024 \times 1024 \times 4 \text{ KB}$。
	*   将三者相加即可得到文件的最大大小。






![[2014-exam-paper-ocr.pdf#page=3&rect=76,622,492,670|2014-exam-paper-ocr, p.3]]

- [[虚拟地址到物理地址的转换]] 
1. I. #增大快表容量 (TLB) 
	1. 作用
		1. TLB是页表项的高速缓存。增大TLB的容量意味着它可以缓存更多的页表项
	2. 影响
		1. 由于程序访问内存具有时间局部性和空间局部性，增大TLB容量可以显著提高 #TLB命中率 （Hit Rate）。更高的命中率意味着更多次的地址转换可以直接在高速的TLB中完成，而无需访问慢速的主内存来查询页表
	3. 这直接减少了地址转换的平均时间，因此**能加快虚实地址转换** 
2. II. 让 #页表常驻内存
	1. 作用
		1. 在某些虚拟内存系统中，为了节省内存，页表本身也可能被分页，即页表的一部分可能会被换出到磁盘的交换区
	2. 影响
		1. 如果页表没有常驻内存，当发生TLB Miss时，MMU去内存中查找页表项，可能会发现存放该页表项的“页表页”本身就不在内存中。这会引发一次**缺页中断**，操作系统需要先从磁盘把“页表页”调回内存，然后才能完成最初的地址转换。这个过程称为“二次缺页（double fault）” 
	3. 结论
		1. 让页表常驻内存，可以确保在TLB Miss时，页表查询最多只需要访问主内存，而永远不会因为页表本身被换出而访问更慢的磁盘。这避免了最坏情况的发生，从而**能加快虚实地址转换**
3. #增大交换区swap 
	1. 作用
		1. 交换区是磁盘上的一块空间，用于存放从物理内存中换出的页面。它作为物理内存的逻辑扩展
	2. 影响
		1. 增大交换区的大小，意味着系统可以支持运行更多进程，或者单个进程可以使用更大的虚拟地址空间，因为它有更多的后备存储空间。但这与**地址转换的速度**没有直接关系。地址转换的速度取决于TLB、页表和内存的访问速度。交换区的大小只影响系统能管理多大的虚拟内存，而不影响单次转换操作的快慢 
4. C
[[Pasted image 20250909041049.png]]
- [[有效内存访问时间EAT]] 
- [[页面大小的选择]]  分析不同页面大小对系统性能（空间开销、时间效率）的影响 
- [[反向页表]]  
	- 系统中只有一个页表，每个条目对应一个 #物理页帧 ，而不是 #虚拟页 。条目内容是<进程ID, 虚拟页号>。查找时需要搜索整个表，通常配合哈希表来加速 （优点：极大节省空间；缺点：查找复杂，共享困难） 


![[2014-exam-paper-ocr.pdf#page=3&rect=73,571,515,625|2014-exam-paper-ocr, p.3]]
- [[文件块]]  [[文件控制块FCB]]  [[文件操作流程（打开，读取，写入，关闭）]] 
1.  A将文件内容读到内存中
	1. 这是`读(Read)`操作的核心任务。如果在`打开`时就将文件所有内容读入内存，会非常低效和浪费资源。
	2. 想象一下打开一个几GB大的视频文件，如果系统试图一次性把它全部加载到内存，不仅会消耗大量时间，还可能导致内存不足。因此，文件内容是在进程明确发出`读`请求时，才按需从磁盘读入内存的。所以A是错误的 
2. B (将文件控制块读到内存中)
	1. **这是正确的**。为了管理文件，操作系统为每个文件都维护了一个数据结构，称为  #文件控制块FCB  。FCB 包含了管理文件所需的所有 #元数据
	2. 当进程要`打开`一个文件时，操作系统必须首先找到这个文件的FCB。FCB本身是存储在磁盘上的。为了能快速地访问这些元数据以执行后续操作 
	3. 操作系统会将该文件的FCB从磁盘读入内存中的一个系统级表格（如“打开文件表”）中。这个动作是`打开`操作的核心步骤
3. C (修改文件控制块中的读写权限) 
	1. `打开`操作会检查(check)权限，而不是**修改(modify)**权限。例如，如果一个进程以只读方式打开文件，但文件权限不允许读取，那么`打开`操作会失败。修改权限通常是由一个独立的操作（如`chmod`命令）来完成的，而不是`打开`文件的副作用。所以C是错误的 
4. D (将文件的 #数据缓冲区首指针 返回给用户进程) 
	1. 操作系统为了安全和管理，不会将内核空间的 #数据缓冲区指针 直接暴露给用户进程。当`打开`操作成功后，操作系统会返回给用户进程一个称为 #文件描述符 (File Descriptor) 的小整数。这个文件描述符是该进程后续操作此文件的“句柄”或“代号”。用户进程通过这个文件描述符（而不是 #内存指针 ）来告诉内核它想对哪个已打开的文件进行操作。所以D是错误的 
5. 综上所述，当一个文件被首次打开时，操作系统的核心任务是将描述该文件的元数据结构——文件控制块（FCB）——从磁盘加载到内存中，为后续操作做好准备。因此，选项B是唯一正确的答案。
   
[[Pasted image 20250909041056.png]]
- [[文件描述符、打开文件表和FCB(inode)的关系]]    
	-  关系：文件描述符 -> 进程表项 -> 系统表项 -> 内存inode -> 磁盘inode 
	-  考点：多个进程打开同一个文件时，这些表项如何共享和关联
- [[408/补充资料/操作系统/文件系统/文件实现/文件分配方式]] 
	*   **连续分配**：优点是读写速度快，缺点是外部碎片和文件大小不易扩展。
    *   **链接分配**：优点是无外部碎片，易于扩展，缺点是无法随机访问，可靠性差（指针丢失则文件数据丢失）。
    *   **索引分配**：结合了前两者的优点，支持随机访问，无外部碎片。是现代操作系统（如Linux的ext系列）的主流方式。可能会考各种索引方式（多级索引、混合索引）的寻址和最大文件大小计算。
- [[目录结构]] 
- #文件系统的逻辑结构和物理结构   
	*   逻辑结构：用户视角的文件组织，如流式文件、记录式文件。
    *   物理结构：文件在磁盘等外存上的存放方式和组织，即文件分配方式。



![[2014-exam-paper-ocr.pdf#page=3&rect=78,497,521,574|2014-exam-paper-ocr, p.3]]

核心是理解 #Belady异常  [[Belady异常]] 
[[页面置换算法]] 
1. 在 I, II, III 中，只有 FIFO 算法不是 #栈算法 ，可能会出现 Belady 异常。LRU 和 OPT 都是 #栈算法 ，不会出现 Belady 异常 [[栈算法]] 
[[Pasted image 20250909041104.png]]

- 衍生
	- [[置换算法的性能计算与比较]]  
	- #LRU近似算法   
		- *由于纯粹的 LRU 实现困难，实际操作系统中常用其近似算法。
	    *   #Clock算法 (或称 Second-Chance 算法)：通过给每个页面一个访问位 (Access Bit) 来模拟 LRU。检查页面时，如果访问位是1，就给它“第二次机会”（置为0，指针后移）；如果是0，则置换该页。这是非常重要的考点。
	    *   **增强型 Clock 算法**：同时考虑访问位和修改位 (Modify Bit / Dirty Bit)，形成四种优先级，优先淘汰未访问且未修改的页面。
	* [[全局置换与局部置换]] 
		* 比较两者的优缺点。全局置换能动态调整各进程的内存分配，系统吞吐量可能更高，但一个进程可能会“窃取”另一个进程的页框
	- [[颠簸抖动]]
		- 抖动产生的原因、如何检测（如通过缺页率）以及如何解决（如调整多道程序度、使用工作集模型预先分配足够内存）





![[2014-exam-paper-ocr.pdf#page=3&rect=76,420,371,501|2014-exam-paper-ocr, p.3]]
1. A. 一个管道可实现双向数据传输
	1. **错误**。标准的管道（也称为匿名管道）是半双工（Half-Duplex）的，或者更准确地说是单向（Unidirectional）的。数据只能从管道的“写端”流向“读端”。一旦创建，其数据流方向就固定了。如果两个进程需要进行双向通信，它们必须建立**两个**管道，一个用于进程1到进程2，另一个用于进程2到进程
	2. 题目解析中提到“一个管道可以实现双向的数据传输，而同一个时刻只能最多有一个方向的传输”，这个说法容易引起误解。它可能是在描述半双工的通信模型，但应用在标准管道上是不准确的。最严谨的说法是：一个匿名管道是单向的
2. B. 管道的容量仅受磁盘容量大小限制
	1.  **错误**。管道是存在于**内存**中的一种特殊文件，它本质上是内核管理的一块缓冲区。它不占用任何磁盘空间。因此，管道的容量与磁盘容量无关，而是由操作系统内核决定的一个固定值，通常是内存页大小的整数倍（例如，在Linux中可能是4KB或64KB） 
3. C. 进程对管道进行读操作和写操作都可能被阻塞
	*   **正确**。这是管道作为一种同步通信机制的核心特性。
	    1.  **写操作阻塞**：当一个进程向管道中写入数据时，如果管道的缓冲区已满，那么该写进程将被**阻塞（Block）**，直到管道中的数据被其他进程读取，从而腾出空间。
	    2.  **读操作阻塞**：当一个进程试图从管道中读取数据时，如果管道的缓冲区是空的，那么该读进程将被**阻塞（Block）**，直到有其他进程向管道中写入了数据。
	*   这种阻塞机制实现了进程间的同步，确保了数据的正确传递。题目解析中也说明了这一点：“当管道满时，进程在写管道会被阻塞，而当管道空时，进程在读管道会被阻塞。”
4. D. 一个管道只能有一个读进程或一个写进程对其操作  
	*   **错误**。一个管道可以有**多个读进程**和**多个写进程**。
    *   **多写**：多个进程可以同时向同一个管道写入数据。操作系统会保证每次写入操作的原子性（对于小于`PIPE_BUF`大小的写操作），但来自不同进程的数据可能会交错。
    *   **多读**：多个进程可以同时从同一个管道读取数据。当数据被写入管道后，哪个读进程能读到数据是不确定的，取决于进程调度的时机。一旦一个进程读走了数据，这些数据就从管道中消失了，其他读进程无法再读到。

[[Pasted image 20250909041111.png]]
[[管道]] 
- [[匿名管道与命名管道的区别]] 
	- 主要区别在于：
	    *   **通信范围**：匿名管道用于亲缘进程；命名管道可用于任意进程。
	    *   **存在形式**：匿名管道存在于内存；命名管道在文件系统中有实体。
	    *   **生命周期**：匿名管道随进程；命名管道随文件系统。
- [[管道与消息队列、共享内存的比较]] 
- #PIPE_BUF的作用 
	- 这是一个由POSIX标准定义的常量，表示管道的原子写操作的最大字节数。
    *   当一次`write()`操作写入的数据量**小于或等于**`$PIPE\_BUF$`时，操作系统保证这次写入是**原子**的，即来自多个进程的写入不会相互交错。
    *   如果写入量**大于**`$PIPE\_BUF$`，则数据可能被分割成多个小块写入，可能会与其他进程的写入操作交错。
- [[僵尸进程与管道]] 


![[2014-exam-paper-ocr.pdf#page=3&rect=75,373,469,420|2014-exam-paper-ocr, p.3]]
[[多级页表]]
1. #多级页表 
	* 对于32位系统，如果页表项为4B，一个进程的页表本身可能需要 $2^{20} \times 4B = 4MB$ 的连续空间，这非常巨大。多级页表通过将页表本身进行分页来解决这个问题。
	* D 
- [[多级页表的解决方案]] 
- [[地址变换过程（以二级页表为例）]]
[[Pasted image 20250909041117.png]]
- 衍生
	- [[有效内存访问时间EAT]] 
	- #地址结构计算 
		- 给定虚拟地址位数、物理地址位数、页面大小，要求设计N级页表结构，并画出虚拟地址的划分
			- 一个系统虚拟地址为48位，页面大小为4KB，页表项为8B。请问如果采用三级页表，且各级页表大小不超过一个页面，一个合理的地址划分是怎样的？
		-  **解题思路：**
	        *   页面大小 $4\text{KB} = 2^{12}\text{B}$，所以页内偏移占12位。
	        *   一个页面能存放的页表项数量为 $\frac{4\text{KB}}{8\text{B}} = \frac{2^{12}}{2^3} = 2^9 = 512$ 个。
	        *   这意味着每一级页表的索引需要9位 ($2^9=512$)。
	        *   虚拟页号部分的总位数为 $48 - 12 = 36$ 位。
	        *   用36位做三级索引，每级9位，则 $36 = 9 + 9 + 9 + 9$。需要四级页表。如果题目要求三级，则说明设计不唯一，可以这样划分：$36 = 18 + 9 + 9$ (不合理，顶级页表太大) 或 $36 = 9 + 9 + 18$ (不合理，末级页表太大)。最合理的划分是让每级页表大小都接近一个页面，所以应该是四级：`| 9 | 9 | 9 | 9 | 12 |`。如果题目强制三级，可能是 `| 18 | 9 | 9 | 12 |`，这意味着顶级页表有 $2^{18}$ 项，非常巨大，违背了多级页表的初衷。
	- [[反向页表]] 





![[2014-exam-paper-ocr.pdf#page=3&rect=75,338,473,372|2014-exam-paper-ocr, p.3]]
[[OSI七层模型]] 
C  

[[Pasted image 20250909041125.png]]
- 衍生
	- #层级功能匹配
		- 负责在网络中进行路径选择和逻辑寻址的是 OSI 模型的哪一层？
			- 网络层
	- #设备与层级匹配
		- 路由器（Router）工作在 OSI 模型的哪一层？
			- 网络层（第3层）
		- 交换机（Switch）主要工作在 OSI 模型的哪一层？
			- 数据链路层（第2层）
	- #协议与层级匹配 
		- TCP 协议属于 OSI 模型的哪一层？
			- 传输层
		- HTTP 协议位于 OSI 模型的哪一层？ 
			- 应用层
	- #PDU（协议数据单元）与层级匹配   
		- 在 OSI 模型中，数据包（Packet）是哪一层的数据单元？ 
			- 网络层
		- 传输层处理的 #数据单元 被称为什么？  [[数据单元PDU]] 
			- 数据段（Segment）  
	- [[TCP IP参考模型(OSI与TCPIP模型的对比）]]

![[2014-exam-paper-ocr.pdf#page=3&rect=75,181,525,335|2014-exam-paper-ocr, p.3]]
1. 这道题的核心是考察以太网交换机的两个基本工作原理 #自主学习 #转发/过滤/泛洪 
- 初始状态 
1. 网络拓扑
    *   主机 `00-e1-d5-00-23-a1` (简称 `a1`) 连接到交换机的端口 1。
    *   主机 `00-e1-d5-00-23-b1` (简称 `b1`) 连接到交换机的端口 2。
    *   主机 `00-e1-d5-00-23-c1` (简称 `c1`) 连接到交换机的端口 3。
2. 交换机初始转发表 (MAC地址表) 
    *   表中只有一条记录：`{目的地址: 00-e1-d5-00-23-b1, 端口: 2}`。
    *   这意味着交换机只知道主机 `b1` 在端口 2，不知道 `a1` 和 `c1` 的位置。
- 解题步骤
1. 第一步：主机 `a1` 向主机 `c1` 发送数据帧 
	1. 帧到达交换机
	    *   数据帧从主机 `a1` 发出，通过端口 1 进入交换机。
	    *   帧的 #源MAC地址  是 `a1` (`00-e1-d5-00-23-a1`)。
	    *   帧的 #目的MAC地址  是 `c1` (`00-e1-d5-00-23-c1`)。
	2. 交换机执行 **学习** 操作：将源MAC地址 `a1` 和其进入的端口 1 关联起来，并添加到转发表中。		[[交换机的学习过程]] 
		此时，转发表更新为：
        | 目的地址 | 端口 |
        | :--- | :--- |
        | `00-e1-d5-00-23-b1` | 2 |
        | `00-e1-d5-00-23-a1` | 1 |
	
	3. [[交换机的转发决策]] 
		*   交换机检查帧的 **目的MAC地址** (`c1`)。
	    *   它在转发表中查找 `c1`。发现表中 **没有** 关于 `c1` 的记录。
	    *   当目的MAC地址未知时，交换机执行 #泛洪 (Flooding) 操作。它会将该数据帧从 **除了接收端口（端口 1）之外的所有其他端口** 转发出去。
	    *   因此，交换机会将该帧从端口 2 和端口 3 转发出去。
2. 第二步：主机 `c1` 向主机 `a1` 发送确认帧
	1. 帧到达交换机
	    *   主机 `c1` 收到来自 `a1` 的数据帧后，发送一个确认帧作为回应。
	    *   该确认帧从主机 `c1` 发出，通过端口 3 进入交换机。
	    *   帧的 **源MAC地址** 是 `c1` (`00-e1-d5-00-23-c1`)。
	    *   帧的 **目的MAC地址** 是 `a1` (`00-e1-d5-00-23-a1`)。
	2. 第二步结论
		1. 第二个确认帧的转发端口集合是 `{1}`
	第一个帧的转发端口是 `{2, 3}`。
	第二个帧的转发端口是 `{1}`。
[[Pasted image 20250909041132.png]]
[[交换机的学习过程]]
* [[交换机的工作方式]]  [[MAC地址]]
- [[MAC地址表的老化]]  
	- MAC地址表中的每个条目都有一个老化计时器（例如，默认300秒）。如果在计时器到期之前，没有收到来自该MAC地址的任何帧，该条目就会被从表中删除。
		- 如果在 `c1` 回复 `a1` 之前，`a1` 的条目因为老化而被删除了，那么 `c1` 发给 `a1` 的帧会发生什么？
			-  **答案**: 交换机在转发表中找不到 `a1`，因此也会对这个确认帧进行 **泛洪**（转发到端口 1 和 2）
- [[集线器vs交换机]] 
	- 如果图中的设备是集线器而不是交换机，两次转发会发生什么？
		- **答案**: 集线器是物理层（Layer 1）设备，它不懂MAC地址。它只是简单地将收到的电子信号放大并复制到所有其他端口。因此，`a1` 发送的帧会被转发到端口 2 和 3；`c1` 发送的帧会被转发到端口 1 和 2。集线器始终在“泛洪”
- #VLAN虚拟互联网 [[虚拟互联网VLAN]] 
	- 如果端口 1 和 2 属于 VLAN 10，端口 3 属于 VLAN 20，结果会怎样？
- #环路与生成树协议STP 
	- 如果网络中存在环路（例如，两个交换机之间有两条链路），一个广播帧会发生什么？
	-  **答案**: 如果没有STP，这个广播帧会在环路中被无限次地复制和转发，迅速耗尽网络带宽，导致“广播风暴”。STP通过逻辑上阻塞冗余端口来防止环路的产生






![[2014-exam-paper-ocr.pdf#page=3&rect=75,148,504,184|2014-exam-paper-ocr, p.3]]
1. #数据传输速率（比特率） 指的是单位时间内信道上传输的比特（bit）数量，单位是bps (bits per second)
2. A. #信噪比SNR  [[信噪比]] 
	1. 信噪比是指信号的平均功率与噪声的平均功率之比。噪声是数据传输中的主要干扰因素。根据**香农定理**，在有噪声的信道中，信道的极限数据传输速率$C$与信噪比$S/N$直接相关。信噪比越高，意味着信号越清晰，受干扰越小，信道所能承载的极限数据传输速率就越高。因此，信噪比会影响数据传输速率
3. B. #频率带宽 
	1. 带宽（或称频率带宽）是指信道能够通过的频率范围，单位是赫兹（Hz）。根据**奈氏准则**和**香农定理**，带宽是决定信道极限数据传输速率的两个最基本因素之一。带宽越宽，单位时间内能传输的信号变化就越快，可以承载的数据量就越大。因此，频率带宽会影响数据传输速率。所以B是错误的
4. C. #调制速率  [[比特率 波特率 码元]] 
	1. 调制速率，也称为 #波特率 （Baud Rate），指的是单位时间内信号波形变化的次数，单位是波特（Baud）。数据传输速率（比特率）和调制速率（波特率）的关系是：
	    $数据传输速率 = 调制速率 \times \log_2{M}$
	    其中，$M$是信号的离散状态数量（即一个码元可以携带的比特数）。从这个公式可以看出，调制速率直接决定了数据传输速率。提高调制速率会直接提高数据传输速率。因此，调制速率会影响数据传输速率。所以C是错误的
5. D. #信号传播速度 
	1. 信号传播速度是指电磁波或光信号在传输介质（如铜线、光纤）中传播的速度，它接近光速。这个速度决定的是信号从发送端到达接收端所需要的时间，即 #传播时延 
		1. 计算公式为：
		    $传播时延 = 距离 / 传播速度$ 
		它影响的是“一个比特需要多久才能从A点到B点”，而不是“单位时间内能从A点发送多少个比特” 
D
[[Pasted image 20250909041144.png]]
[[奈氏准则]]   [[香农定理]] 
- 衍生 
	- #奈氏准则应用 
		- 给定带宽和码元状态数$M$，计算极限速率。例如：某无噪声信道的带宽为3kHz，采用4相调制（$M=4$），求其最大数据传输速率
		- 解：$C = 2 \times 3000 \times \log_2{4} = 6000 \times 2 = 12000 \text{ bps} = 12 \text{ kbps}$
	- #香农定理应用 
		- 给定带宽和信噪比，计算信道容量。例如：某信道带宽为3kHz，信噪比为30dB，求其信道容量。
        *   解：首先转换信噪比：$30 = 10\log_{10}{(S/N)}$，所以$\log_{10}{(S/N)} = 3$，即$S/N = 10^3 = 1000$。
			*   然后计算容量：$C = 3000 \times \log_2{(1+1000)} \approx 3000 \times \log_2{1001} \approx 3000 \times 9.967 \approx 29901 \text{ bps} \approx 29.9 \text{ kbps}$
	* 综合应用
		*  给定一个信道的带宽、信噪比和采用的调制技术（$M$值），问实际能达到的 #最大数据传输速率 。这时需要同时计算奈氏准则和香农定理得出的两个速率，然后取**两者中的较小值**作为实际的上限


![[2014-exam-paper-ocr.pdf#page=3&rect=73,64,519,148|2014-exam-paper-ocr, p.3]]
#后退帧GBN协议   #回退N帧协议GBN  
1.  **信道带宽**：物理链路的最高传输能力。 #信道带宽vs协议带宽  
2.  **协议效率**：由滑动窗口大小和往返时延（RTT）决定的协议层面的最高传输能力。
- 推导过程
1. 计算协议允许的最大数据传输速率
	1. #滑动窗口协议 的核心思想是：发送方可以在收到对第一个数据帧的确认之前，连续发送一个窗口大小的数据量  
		*   **发送窗口大小 ($W_S$)**: 题目给出为 $1000$ 个数据帧。
		*   **数据帧长度 ($L$)**: 题目给出为 $1000$ 字节 (Byte)。
	2. 在一个发送周期内，发送方最多可以发送的数据量为：
		$\text{DataInWindow} = W_S \times L = 1000 \times 1000 \text{ Bytes} = 1,000,000 \text{ Bytes} = 1 \text{ MB}$
	 这个“发送周期”是指从发送第一个数据帧开始，到接收到对该 #数据帧的确认（ACK） 为止的时间。这个时间被称为 #往返时延 
   #单向传播时延 ($t_p$)**: 题目给出为 $50 \text{ ms}$。
*   **往返时延 (RTT)**: 是数据从甲传到乙，再加上乙的确认信息从乙传回甲的时间。题目中提到确认帧是一个短帧，可以忽略其传输延迟，因此 RTT 主要由两个单向的传播时延构成。
	$\text{RTT} = 2 \times t_p = 2 \times 50 \text{ ms} = 100 \text{ ms} = 0.1 \text{ s}$
- 现在我们可以计算出，在协议的限制下，发送方甲能达到的最大数据传输速率 ($R_{protocol}$)。它等于在一个 RTT 内最多可以发送的数据量除以 RTT。
	$R_{protocol} = \frac{\text{DataInWindow}}{\text{RTT}} = \frac{1 \text{ MB}}{0.1 \text{ s}} = 10 \text{ MB/s}$  
	题目中的单位是 Mbps (Megabits per second)，我们需要进行单位转换。注意：
	*   1 Byte = 8 bits
	*   1 MB/s = 8 Mbps
	所以：
	$R_{protocol} = 10 \text{ MB/s} \times 8 = 80 \text{ Mbps}$
	*   **协议允许的最大速率 ($R_{protocol}$)**: $80 \text{ Mbps}$
	*   **信道带宽 ($R_{channel}$)**: 题目给出为 $100 \text{ Mbps}$
	发送方甲可以达到的最大平均数据传输速率是这两者中的最小值。
	$\text{MaxRate} = \min(R_{protocol}, R_{channel}) = \min(80 \text{ Mbps}, 100 \text{ Mbps}) = 80 \text{ Mbps}$ 
	C. 80mbps 

[[滑动窗口协议]]  [[后退N帧协议GBN]]    [[关键时延类型和计算]]  [[数据链路层的信道利用率（有效数据传输速率）]]


[[Pasted image 20250909041209.png]]
- 衍生
	- 计算达到 #最大信道利用率 所需的最小窗口大小 
		*   要使信道利用率达到100% ($U=1$)，需要满足 $W_S \times t_t \ge RTT + t_t$。这个不等式描述的是，发送方发送完整个窗口数据的时间，必须足够长，能够覆盖整个RTT，从而让信道始终保持忙碌。
	    *   这个乘积 $R_{channel} \times RTT$ 被称为**带宽时延积 (Bandwidth-Delay Product, BDP)**，它表示在任何时刻，信道中可以容纳的最大比特数，就像一个“管道”的容积。
	    *   要使信道饱和，发送窗口（以比特为单位）必须大于等于带宽时延积。
		*   **例题**: 在本题条件下，要达到100Mbps的速率，最小窗口大小应为多少？
	        *   BDP = $100 \times 10^6 \text{ bps} \times 0.1 \text{ s} = 10^7 \text{ bits}$。
	        *   每个帧的大小 = $1000 \text{ Bytes} = 8000 \text{ bits}$。
	        *   最小窗口大小 $W_S = \lceil \frac{\text{BDP}}{\text{帧大小}} \rceil = \lceil \frac{10^7}{8000} \rceil = \lceil 1250 \rceil = 1250$。
	        *   因为题目给的窗口大小是1000，小于1250，所以无法跑满100Mbps的带宽。
	- 考虑有差错情况下的有效数据速率
	- #选择重传协议SR  对比
	    *   SR协议的接收窗口 $> 1$，它能缓存失序的正确帧。当某个帧丢失时，发送方只需重传那一个丢失的帧。
	    *   在相同的窗口大小和出错率下，SR协议的效率通常高于GBN。题目可能会要求在SR协议下计算吞吐率，并与GBN进行比较。

![[2014-exam-paper-ocr.pdf#page=4&rect=77,754,530,820|2014-exam-paper-ocr, p.4]]
- [[CDMA码分多址]]
	- 是一种允许多个用户在同一时间和同一频段上进行通信的技术。其关键思想是为每个用户分配一个唯一的、相互正交的 #码片序列
	*   **编码**：
	    *   当一个用户（例如站点A）要发送数据比特 **1** 时，它会发送自己的码片序列 $C_A$。
	    *   当它要发送数据比特 **0** 时，它会发送该码片序列的反码 $-C_A$。
	*   **传输**：
	    *   在共享信道上，所有用户发送的信号（码片序列或其反码）会线性叠加。
	*   **解码**：
	    *   接收方（例如站点C）要想解码出站点A发送的数据，需要将接收到的混合信号与站点A的码片序列 $C_A$ 进行**内积（点积）运算**，然后将结果除以码片序列的长度。
	    *   如果结果为 **+1**，则表示A发送了数据 **1**。
	    *   如果结果为 **-1**，则表示A发送了数据 **0**。
	    *   如果结果为 **0**，则表示A没有发送数据。
	- 一个关键特性是码片序列的**正交性**。两个不同的码片序列 $C_i$ 和 $C_j$ 如果是正交的，它们的内积为0，即 $C_i \cdot C_j = 0$。这保证了在解码A的信号时，来自B和C的信号不会产生干扰
	- 我们来验证一下题目中给出的码片序列是否正交：
			*   $C_A = (1, 1, 1, 1)$
			*   $C_B = (1, -1, 1, -1)$
			*   $C_C = (1, 1, -1, -1)$
			
			$C_A \cdot C_B = 1 \cdot 1 + 1 \cdot (-1) + 1 \cdot 1 + 1 \cdot (-1) = 1 - 1 + 1 - 1 = 0$
			$C_A \cdot C_C = 1 \cdot 1 + 1 \cdot 1 + 1 \cdot (-1) + 1 \cdot (-1) = 1 + 1 - 1 - 1 = 0$
			$C_B \cdot C_C = 1 \cdot 1 + (-1) \cdot 1 + 1 \cdot (-1) + (-1) \cdot (-1) = 1 - 1 - 1 + 1 = 0$
			它们两两正交，符合CDMA系统的要求。
1. 第一步：分割接收到的信号 
	题目中给出的码片序列长度为4。这意味着每4个码片代表一个数据比特。接收到的总序列长度为12，因此这代表了3个数据比特的传输周期。我们需要将接收到的序列 $S$ 分成3组，每组4个数字：
	*   $S = (2, 0, 2, 0, 0, -2, 0, -2, 0, 2, 0, 2)$
	*   第一组 (代表第1个比特): $S_1 = (2, 0, 2, 0)$
	*   第二组 (代表第2个比特): $S_2 = (0, -2, 0, -2)$
	*   第三组 (代表第3个比特): $S_3 = (0, 2, 0, 2)$
2. 第二步：解码来自站点A的数据 
	要解码站点A的数据，所以需要使用站点A的码片序列 $C_A = (1, 1, 1, 1)$ 对每一组接收信号进行内积运算，然后除以码片长度4。
	*   **解码第1个比特：**
	    $S_1 \cdot C_A = (2, 0, 2, 0) \cdot (1, 1, 1, 1) = 2 \times 1 + 0 \times 1 + 2 \times 1 + 0 \times 1 = 4$
	    归一化结果：$\frac{4}{4} = 1$
	    结果为+1，说明A发送的第1个数据比特是 **1**。
	*   **解码第2个比特：**
	    $S_2 \cdot C_A = (0, -2, 0, -2) \cdot (1, 1, 1, 1) = 0 \times 1 + (-2) \times 1 + 0 \times 1 + (-2) \times 1 = -4$
	    归一化结果：$\frac{-4}{4} = -1$
	    结果为-1，说明A发送的第2个数据比特是 **0**。
	*   **解码第3个比特：**
	    $S_3 \cdot C_A = (0, 2, 0, 2) \cdot (1, 1, 1, 1) = 0 \times 1 + 2 \times 1 + 0 \times 1 + 2 \times 1 = 4$
	    归一化结果：$\frac{4}{4} = 1$
	    结果为+1，说明A发送的第3个数据比特是 **1**。
第三步： 得到A发送的数据是 **101**  选B

[[Pasted image 20250909041217.png]]
- 反向构造信号 
	- **例**：假设在第一个比特周期，A发送1，B发送0，C发送1。
	    *   A发送的信号是 $C_A = (1, 1, 1, 1)$
	    *   B发送的信号是 $-C_B = -(1, -1, 1, -1) = (-1, 1, -1, 1)$
	    *   C发送的信号是 $C_C = (1, 1, -1, -1)$
	    *   信道上的混合信号 $S_{total} = C_A + (-C_B) + C_C = (1-1+1, 1+1+1, 1-(-1)-1, 1+1-1) = (1, 3, 1, 1)$
- 解码其他站点的数据
	题目可能使用相同的接收信号，但要求解码站点B或C的数据。
    *   **例**：解码站点B发送的数据，使用 $C_B = (1, -1, 1, -1)$。
    *   第1比特: $\frac{S_1 \cdot C_B}{4} = \frac{(2, 0, 2, 0) \cdot (1, -1, 1, -1)}{4} = \frac{2+0+2+0}{4} = 1$ (B发送1)
    *   第2比特: $\frac{S_2 \cdot C_B}{4} = \frac{(0, -2, 0, -2) \cdot (1, -1, 1, -1)}{4} = \frac{0+2+0+2}{4} = 1$ (B发送1)
    *   第3比特: $\frac{S_3 \cdot C_B}{4} = \frac{(0, 2, 0, 2) \cdot (1, -1, 1, -1)}{4} = \frac{0-2+0-2}{4} = -1$ (B发送0)
    *   所以，站点B发送的数据是 **110**。
- #判断码片序列的正交性 
	- 题目可能给出一组码片序列，问它们是否适用于CDMA系统。你需要通过计算它们之间的内积来判断。只有当任意两个不同序列的内积都为0时，它们才是正交的，才适合在理想的CDMA系统中使用
- #码片序列的性质 
	- 一个码片序列与自身的内积等于码片的长度。例如，$C_A \cdot C_A = 1^2+1^2+1^2+1^2 = 4$。这个性质保证了在解码自己发送的信号时，能得到一个非零的、标准化的值（+1或-1）


![[2014-exam-paper-ocr.pdf#page=4&rect=77,678,525,754|2014-exam-paper-ocr, p.4]]
1. 第一步：处理超时事件
	当TCP发送方检测到超时事件时，它会认为网络发生了严重的拥塞。此时会触发以下两个动作：
	1.  **更新慢启动阈值 (ssthresh):** 将`ssthresh`设置为当前拥塞窗口`cwnd`的一半。
	    $ssthresh = \frac{cwnd}{2} = \frac{8KB}{2} = 4KB$
	    (注意：规范中`ssthresh`的值应不小于$2 \times MSS$，这里$4KB > 2KB$，符合要求)。
	2.  **重置拥塞窗口 (cwnd):** 将`cwnd`重置为初始值，即$1 \times MSS$。
	    $cwnd = 1 \times MSS = 1KB$
	3.  **进入慢启动阶段:** 发送方重新开始慢启动过程。
2. 第二步：模拟10个RTT内`cwnd`的增长
	从t时刻之后，`cwnd`开始增长。增长过程分为两个阶段：慢启动（Slow Start）和拥塞避免（Congestion Avoidance）
	*   **慢启动阶段 (cwnd ≤ ssthresh):** 在这个阶段，每经过一个RTT，`cwnd`的大小会翻倍。
	    *   初始状态: $cwnd = 1KB$
	    *   经过第1个RTT: $cwnd = 1KB \times 2 = 2KB$
	    *   经过第2个RTT: $cwnd = 2KB \times 2 = 4KB$
	    *   此时，$cwnd$达到了`ssthresh`的值（$4KB$）。慢启动阶段结束，进入拥塞避免阶段。
	*   **拥塞避免阶段 (cwnd > ssthresh):** 在这个阶段，每经过一个RTT，`cwnd`的大小线性增加$1 \times MSS$。
	    *   经过第3个RTT: $cwnd = 4KB + 1KB = 5KB$
	    *   经过第4个RTT: $cwnd = 5KB + 1KB = 6KB$
	    *   经过第5个RTT: $cwnd = 6KB + 1KB = 7KB$
	    *   经过第6个RTT: $cwnd = 7KB + 1KB = 8KB$
	    *   经过第7个RTT: $cwnd = 8KB + 1KB = 9KB$
	    *   经过第8个RTT: $cwnd = 9KB + 1KB = 10KB$
	    *   经过第9个RTT: $cwnd = 10KB + 1KB = 11KB$
	    *   经过第10个RTT: $cwnd = 11KB + 1KB = 12KB$
经过10个RTT后，拥塞窗口`cwnd`的大小为$12KB$
3. 第三步：计算最终的发送窗口
	TCP的发送方实际能够发送的数据量（即发送窗口）取决于两个因素：拥塞控制（`cwnd`）和流量控制（`rwnd`）。发送窗口是这两者的最小值 
	$SendWindow = 10KB$ 
**结论：** 正确答案是 **A. 10KB**。 

[[TCP流量控制与拥塞控制]]
	#发送窗口  发送方最终的发送能力由拥塞控制和流量控制共同决定。其 #TCP流量控制与拥塞控制核心公式  为：
        $SendWindow = \min(cwnd, rwnd)$ 

[[Pasted image 20250909041228.png]]

- 衍生出的考点
	[[不同的拥塞事件处理方式]] “若甲在t时刻收到了3个冗余ACK，此时cwnd为8KB，则...”，这时答案就会完全不同
	[[TCP的不同版本]] 
 

![[2014-exam-paper-ocr.pdf#page=4&rect=76,630,487,682|2014-exam-paper-ocr, p.4]]
[[UDP (User Datagram Protocol)]]   UDP是TCP/IP协议族中与TCP并列的两个核心传输层协议之一 
[[UDP差错校验]]  UDP的差错校验机制是为了提供对数据完整性的基本检查。 
[[复用与分用]]   这是所有传输层协议的共同职责。 


[[Pasted image 20250909041355.png]]
- 衍生
	- 在UDP之上实现可靠传输既然UDP本身不可靠，应用层如何保证可靠性？
	    *   这是一个更深入的考点。应用层协议可以自己实现序列号、确认（ACK）、超时重传等机制。一个典型的现代例子是**QUIC协议**（被用于HTTP/3），它基于UDP，但在应用层实现了TCP的许多可靠性功能，同时避免了TCP的一些固有问题（如队头阻塞）
![[2014-exam-paper-ocr.pdf#page=4&rect=81,590,474,631|2014-exam-paper-ocr, p.4]]
完整的 #网页访问流程   
  1.  **用户在浏览器输入网址 (例如 `www.pku.edu.cn`)**
    这个操作发生在**应用层**。
2.  **域名解析 (DNS)**
    浏览器首先需要将网址（域名）转换为服务器的 IP 地址。这个过程叫做 DNS 解析。
    *   浏览器会向本地 DNS 服务器发送一个 DNS 查询请求。
    *   DNS 查询通常使用 **UDP (User Datagram Protocol)** 协议。虽然在某些特殊情况下（如区域传送或响应包过大）会使用 TCP，但常规查询默认使用 UDP。
    *   因此，**C. UDP** 是可能用到的。
3.  **建立网络连接**
    *   **数据链路层连接**：用户的计算机需要先连接到互联网。如果用户是通过拨号上网或者某些类型的宽带（如 ADSL），可能会使用 **PPP (Point-to-Point Protocol)** 协议来建立与 ISP (互联网服务提供商) 的连接。
    *   因此，**A. PPP** 是可能用到的。
4.  **数据包在局域网内传输**
    *   当你的计算机知道了目标网站服务器的 IP 地址后，它需要将请求数据包发送出去。在局域网（如家庭 Wi-Fi、校园网）中，数据包的第一站通常是路由器（网关）。
    *   计算机需要知道路由器的 MAC 地址（物理地址）才能将数据帧发送给它。
    *   **ARP (Address Resolution Protocol)** 的作用就是通过 IP 地址查询对应的 MAC 地址。计算机会广播一个 ARP 请求：“谁是 IP 地址为 `192.168.1.1` 的设备？请告诉我你的 MAC 地址。”路由器会响应这个请求。
    *   因此，**B. ARP** 是肯定会用到的（只要是在以太网或 Wi-Fi 环境下）。
5.  **建立传输层连接并发送 HTTP 请求**
    *   获取到 IP 地址后，浏览器会与 Web 服务器之间建立一个 **TCP (Transmission Control Protocol)** 连接。网页内容的传输需要可靠、按序到达，所以使用 TCP。
    *   建立连接后，浏览器会通过这个 TCP 连接发送一个 HTTP (或 HTTPS) 请求，来获取网页主页的内容。
6.  **分析选项 D. SMTP**
    *   **SMTP (Simple Mail Transfer Protocol)**，即简单邮件传输协议。它的唯一作用是**发送电子邮件**。当你使用邮件客户端（如 Outlook, Foxmail）或者网页邮箱点击“发送”按钮时，背后就是 SMTP 协议在工作。
    *   单纯地浏览网页，完全不涉及发送邮件的操作。
* **结论：**
在浏览网页的整个过程中，PPP、ARP、UDP (用于 DNS) 都可能在不同的环节被使用。而 SMTP 是用于发送邮件的，与浏览网页无关。因此，**不可能**使用到的协议是 SMTP。 
正确答案：D  

[[计算机网络TCP-IP模型中的多个层次的协议]]

[[Pasted image 20250909041402.png]]
- 衍生
	- #协议与层次的对应关系    [[记忆协议与层次的对应关系]] 
		- “下列协议中，属于传输层的是？” (A. FTP B. TCP C. IP D. PPP) -> 答案是 B。 
			- 应用层（HTTP, FTP, SMTP, DNS...）、传输层（TCP, UDP）、网络层（IP, ICMP, ARP）、数据链路层（PPP, Ethernet） 
- [[TCP UDP运输层]] 
	*   **TCP：** 面向连接、可靠、开销大、速度慢（适用于文件传输、网页浏览、邮件）。
	*   **UDP：** 无连接、不可靠、开销小、速度快（适用于 DNS 查询、视频直播、在线游戏）。
- [[协议与端口号]]
	“HTTP 协议默认使用的端口号是多少？” -> 答案是 80 
- [[邮件协议的区别和联系]]  
- **网络故障排查：**
    *   **考题示例：** “如果一台计算机可以 `ping` 通某网站的 IP 地址，但无法通过域名访问该网站，最可能的原因是？” -> 答案是 DNS 解析故障。
    *   **分析：** `ping` IP 地址成功，说明从网络层到物理层的连接是通的。无法通过域名访问，说明应用层的 DNS 解析环节出了问题。





![[2014-exam-paper-ocr.pdf#page=4&rect=80,476,531,594|2014-exam-paper-ocr, p.4]]
#带权路径长度  [[带权路径长度]] 
 *   **路径 (Path)**：在树中，从一个节点到另一个节点所经过的节点序列构成一条路径。
*   **路径长度 (Path Length)**：从根节点到某个节点所经过的**边的数量**。通常我们规定根节点的深度（depth）为0，其路径长度也为0。
*   **叶子节点的带权路径长度**：指该叶子节点的**路径长度**与其 #权值 (weight) 的乘积。
*   **树的带权路径长度 (WPL)**：树中**所有叶子节点**的带权路径长度之和。
$WPL = \sum_{i=1}^{n} w_i l_i$
其中，$n$ 是树中叶子节点的总数，$w_i$ 是第 $i$ 个叶子节点的权值，$l_i$ 是第 $i$ 个叶子节点的路径长度（也就是其深度）
1. 根据WPL的定义，要计算它，我们必须遍历到每一个叶子节点，并获取它的两样信息：
	1.  **权值 $w_i$**：题目中已给出，存储在节点的数据域中。
	2.  **路径长度 $l_i$**：即节点的深度，这个信息需要我们在遍历过程中计算和传递。

	因此，问题的关键就变成了：**如何设计一种遍历算法，在访问到每个节点时，都能知道它当前的深度？** 
		这自然引出了两种经典的树遍历方法： #深度优先搜索DFS 和 #广度优先搜索BFS 
 - 解法一： #深度优先遍历（先序遍历）
	DFS非常适合用递归来实现。我们可以设计一个 #递归函数 ，除了接收 #节点指针 外，再额外传递一个参数 `depth` 来记录当前节点的深度
    1.  定义一个递归函数，除了接收指向当前结点的指针外，还需要一个参数 `deep` 来记录当前结点的深度。
    2.  从根结点开始调用该递归函数，初始深度为 0。
    3.  在递归函数内部：
        *   **判断是否为叶子结点**: 如果当前结点的左右子树都为空（`lchild == NULL && rchild == NULL`），那么它就是一个叶子结点。
        *   **累加 WPL**: 如果是叶子结点，则计算它的带权路径长度 `weight * deep`，并将其累加到一个全局或静态变量 `wpl` 中。
        *   **递归深入**: 如果不是叶子结点，就对其非空的左子树和右子树分别进行递归调用，同时将深度参数 `deep` 加 1。
*   **为什么可行**: 先序遍历保证了树中的每个结点都会被访问一次。通过传递深度参数，我们可以在访问到任何一个结点时，都能准确知道它的深度，从而在遇到叶子结点时能够正确计算其对 WPL 的贡献。
  
---  ---
- 解法二：广度优先搜索 (BFS) - 层次遍历法
	*   **核心思想**: 使用一个队列，按层级顺序访问树的每一个结点。
	*   **实现细节**:
	    1.  初始化一个队列，并将根结点入队。
	    2.  我们需要跟踪每个结点的深度。答案中的实现方法比较巧妙，它通过记录**当前层的最后一个结点 (`lastNode`)** 和**下一层的最后一个结点 (`newlastNode`)** 来判断一层的结束。
	    3.  循环处理队列中的结点，直到队列为空：
	        *   一个结点出队。
	        *   **判断是否为叶子结点**: 如果是，则计算 `weight * deep` 并累加到 `wpl`。
	        *   **子结点入队**: 如果该结点有左孩子或右孩子，将它们依次入队，并更新 `newlastNode` 为最新入队的那个孩子。
	        *   **判断层结束**: 检查出队的这个结点是否是 `lastNode`。如果是，说明当前层的所有结点都已处理完毕。此时，需要将深度 `deep` 加 1，并更新 `lastNode = newlastNode`，为下一层的处理做准备。
	*   **为什么可行**: 层次遍历天然地按深度顺序访问结点。通过引入额外的变量来标记每层的结束，我们可以准确地维护当前正在处理的层的深度值 `deep`。
	这个方法同样可以正确计算出WPL，它避免了 #递归 可能导致的 #栈溢出 问题，但通常需要更多的辅助空间（队列）
### (2)二叉树结点的数据类型定义    
用 C 语言的 `struct` 来定义一个标准的二叉树结点。

```c
typedef struct BiTNode {
    int weight;                 // 结点的权值
    struct BiTNode *lchild;     // 指向左孩子的指针
    struct BiTNode *rchild;     // 指向右孩子的指针
} BiTNode, *BiTree;
```

*   `BiTNode` 是结构体类型的名字。
*   `*BiTree` 是一个指针类型，通常用来表示指向树（或子树）根结点的指针。
#### (3) 算法代码分析 
**方法一：先序遍历（递归）**

```c
// 主函数，初始化调用
int WPL(BiTree root) {
    return wpl_PreOrder(root, 0);
}

// 递归辅助函数
int wpl_PreOrder(BiTree root, int deep) {
    static int wpl = 0; // 定义一个 static 变量存储 wpl

    if (root->lchild == NULL && root->rchild == NULL) {
        // 若为叶子结点，累积 wpl
        wpl += deep * root->weight;
    }

    if (root->lchild != NULL) {
        // 若左子树不空，对左子树递归遍历
        wpl_PreOrder(root->lchild, deep + 1);
    }

    if (root->rchild != NULL) {
        // 若右子树不空，对右子树递归遍历
        wpl_PreOrder(root->rchild, deep + 1);
    }

    return wpl;
}
```

*   **代码解读**:
    *   `static int wpl = 0;`：这是代码的一个关键点，也是一个**潜在的陷阱**。`static` 变量在程序的整个生命周期中只被初始化一次。这意味着，如果你在同一个程序中多次调用 `WPL` 函数，`wpl` 不会从 0 重新开始，而是会从上一次计算的结果继续累加，导致后续调用的结果错误。

    ```c
    // 更优的递归实现
    int wpl_PreOrder_better(BiTree root, int deep) {
        // 基准情况：空树的 WPL 为 0
        if (root == NULL) {
            return 0;
        }
        // 基准情况：叶子结点，返回自身的带权路径长
        if (root->lchild == NULL && root->rchild == NULL) {
            return root->weight * deep;
        }
        // 递归步骤：当前子树的 WPL = 左子树的 WPL + 右子树的 WPL
        return wpl_PreOrder_better(root->lchild, deep + 1) + 
               wpl_PreOrder_better(root->rchild, deep + 1);
    }
    ```
    这种方式没有副作用，每次调用都是独立的，是更推荐的函数式编程风格。

**方法二：层次遍历（非递归）**

```c
// 层次遍历算法
int wpl_LevelOrder(BiTree root) {
    BiTree q[MaxSize];      // 定义队列
    int end1 = 0, end2 = 0; // 队头和队尾指针
    int wpl = 0, deep = 0;
    BiTree lastNode = root; // 当前层的最后一个结点
    BiTree newlastNode = NULL; // 下一层的最后一个结点

    end2++;
    q[end2] = root; // 根结点入队

    while (end1 != end2) { // 队列不空
        end1++;
        BiTree t = q[end1]; // 出队

        if (t->lchild == NULL && t->rchild == NULL) {
            // 若为叶子结点，累计 wpl
            wpl += deep * t->weight;
        }

        if (t->lchild != NULL) {
            end2++;
            q[end2] = t->lchild;
            newlastNode = t->lchild; // 更新下一层的最后一个结点
        }

        if (t->rchild != NULL) {
            end2++;
            q[end2] = t->rchild;
            newlastNode = t->rchild; // 更新下一层的最后一个结点
        }
        
        if (t == lastNode) { // 当前层的最后一个结点已访问
            lastNode = newlastNode; // 更新 lastNode
            deep++; // 层数加 1
        }
    }
    return wpl;
}
```

*   **代码解读**:
    *   `q`, `end1`, `end2`: 构成一个简单的循环队列。
    *   `deep`: 当前层的深度。
    *   `lastNode`: 标记当前处理的这一层的终点。
    *   `newlastNode`: 在处理当前层时，动态地记录下一层被入队的最后一个结点。
    *   `if (t == lastNode)`: 这是整个算法最精妙的部分。当出队的结点 `t` 恰好是 `lastNode` 时，我们知道当前层的所有结点都已经处理完毕，并且它们的子结点（即下一层的所有结点）也已经全部入队。此时就可以安全地增加深度 `deep`，并把 `lastNode` 更新为 `newlastNode`，为下一层的遍历做准备。

[[Pasted image 20250909041414.png ]] 
[[Pasted image 20250924175323.png]]
[[Pasted image 20250909042005.png]]
- 衍生 
	- [[哈夫曼树]] 
		-  WPL 最直接和重要的应用就是构造哈夫曼树。对于一组给定的权值，哈夫曼树是具有**最小 WPL** 的二叉树
	- 计算树的 #内部路径长度 (IPL) 或 #外部路径长度 (EPL) 。IPL 是所有内部结点的深度之和，EPL 是所有叶子结点的深度之和。对于任意二叉树，它们之间存在关系 $EPL = IPL + 2n$（其中 n 为内部结点数）



![[2014-exam-paper-ocr.pdf#page=4&rect=76,41,537,481|2014-exam-paper-ocr, p.4]]
[[Pasted image 20250909042018.png]]
[[Pasted image 20250909042026.png]]
[[Pasted image 20250909042038.png]]
1. [[OSPF协议]]  #OSPF [[链路状态信息LSI]]  
	1. 现代网络中最常用的 IGP 之一。它像一个全知的地图绘制者，每个路由器都了解整个网络（AS内部）的拓扑结构，然后独立计算出到所有目的地的最短路径。收敛速度快，非常稳定。     
2. [[Dijkstra 算法]]一种经典的单源最短路径算法，用于计算图中一个节点到所有其他节点的最短路径 
- 1) 本题中的网络可抽象为数据结构中的哪种逻辑结构？ 
- 推导过程
	1.  观察图 42，网络由路由器（R1, R2, R3, R4）和它们之间的连接链路构成。
	2.  我们可以将路由器视为图中的 #顶点 。
	3.  路由器之间的链路可以视为连接顶点的**边（Edge）**。
	4.  每条边都有一个 #费用 （Metric），这可以看作是图中边的 #权重 
	5.  从 R1 到 R2 的费用是 3，从 R2 到 R1 的费用也是 3（可以从表 42 中 R2 的 LSI 查到），这说明连接是双向且对称的。因此，这是一个 #无向带权图 
	6.  图中节点之间存在多条路径（例如从 R1 到 R4 可以走 R1->R2->R4 或 R1->R3->R4），并且存在环路（R1->R2->R4->R3->R1），这种结构通常被称为 #网状结构  （Mesh Topology） 
**答案:**
本题中的网络可以抽象为数据结构中的**图**（更具体地说是**无向带权图**），或称为**网状结构**、**非线性结构**。
-  2) 设计合理的链式存储结构，并画出 R1 对应的链式存储结构示意图。 
- 推导过程
	这是本题的核心，考察的是如何用数据结构来表示图。常用的图表示法有邻接矩阵和邻接表。链式存储结构通常指向**邻接表（Adjacency List）**。
1.  **分析存储需求**：我们需要存储每个路由器的 LSI。一个 LSI 包含两种不同类型的连接：一种是连接到其他路由器（Link），另一种是连接到网络（Net）。这两种连接的信息格式不同。
    *   **Link**: 需要存储邻居路由器的 ID、IP 地址、费用。
    *   **Net**: 需要存储网络前缀、子网掩码、费用。

2.  **设计数据结构**：
    *   为了表示整个网络，我们可以用一个主链表或数组来存放所有的路由器节点，称之为**表头结点（Header Node）**。每个表头结点包含路由器的 ID 和一个指向其邻接边的指针。
    *   从每个表头结点引出一条链表，这条链表上的节点称为**弧结点（Arc Node）**，代表该路由器的一条连接（边）。
    *   由于弧结点需要表示两种不同类型（Link 和 Net），我们可以使用一个标志位 `Flag` 来区分。当 `Flag=1` 表示 Link，`Flag=2` 表示 Net。
    *   为了在同一个结构体中存储两种不同的数据（Link 信息或 Net 信息），可以使用 C 语言中的 `union` 结构。
    *   综合起来，可以设计出类似答案解析中的 `struct` 定义。

3.  **根据 R1 的 LSI 绘制链式存储结构图**：
    *   **表头结点**: 创建一个代表 R1 的表头结点，内容为 R1 的 Router ID `10.1.1.1`。
    *   **弧结点链表**: 从这个表头结点引出一条链表，根据 R1 的 LSI（表 42 第一列）依次创建弧结点：
        *   **第一个弧结点 (Link1)**:
            *   连接到 R2 (ID `10.1.1.2`)。
            *   `Flag=1` (表示 Link)。
            *   存储邻居 ID `10.1.1.2` 和本地 IP `10.1.1.1`。
            *   Metric = `3`。
            *   `next` 指针指向下一个弧结点。
        *   **第二个弧结点 (Link2)**:
            *   连接到 R3 (ID `10.1.1.5`)。
            *   `Flag=1` (表示 Link)。
            *   存储邻居 ID `10.1.1.5` 和本地 IP `10.1.1.9`。
            *   Metric = `2`。
            *   `next` 指针指向下一个弧结点。
        *   **第三个弧结点 (Net1)**:
            *   连接到网络 `192.1.1.0/24`。
            *   `Flag=2` (表示 Net)。
            *   存储网络前缀 `192.1.1.0` 和掩码 `255.255.255.0`。
            *   Metric = `1`。
            *   `next` 指针为 `NULL`，表示链表结束。

**答案:**
（答案解析中给出的图示是该逻辑的完美可视化表达，这里不再重复绘图，其逻辑与上述推导完全一致。）

-  3) 按照迪杰斯特拉(Dijkstra)算法的策略，依次给出 R1 到达图 42 中子网 192.1.x.x 的最短路径及费用。 
- 推导过程
	我们以 R1 为源点，使用 Dijkstra 算法计算到所有其他路由器的最短路径。

#Dijkstra算法步骤 
*   **初始化**:
    *   创建一个集合 `N`，存放已找到最短路径的顶点，初始时 `N = {R1}`。
    *   创建一个距离数组 `D`，`D[v]` 表示从 R1 到顶点 `v` 的当前最短距离。
    *   `D[R1] = 0`。
    *   对于 R1 的邻居 R2 和 R3: `D[R2] = cost(R1, R2) = 3`，`D[R3] = cost(R1, R3) = 2`。
    *   对于其他顶点 R4: `D[R4] = ∞`。
    *   创建一个前驱数组 `P`，`P[v]` 记录最短路径上 `v` 的前一个顶点。`P[R2] = R1`, `P[R3] = R1`。
*   **循环执行**:
    1.  **第 1 轮**:
        *   在 `N` 之外的顶点中，选择距离最小的顶点。当前是 R3 (`D[R3] = 2`)。
        *   将 R3 加入 `N`，现在 `N = {R1, R3}`。
        *   更新 R3 的邻居（R1, R4）的距离：
            *   对于 R4: 经过 R3 的新路径 R1→R3→R4 的距离为 `D[R3] + cost(R3, R4) = 2 + 6 = 8`。
            *   当前 `D[R4] = ∞`。因为 $8 < ∞$，所以更新 `D[R4] = 8`，`P[R4] = R3`。
        *   当前 `N` 之外的顶点距离为: `D[R2] = 3`, `D[R4] = 8`。
    2.  **第 2 轮**:
        *   在 `N` 之外的顶点中，选择距离最小的顶点。当前是 R2 (`D[R2] = 3`)。
        *   将 R2 加入 `N`，现在 `N = {R1, R3, R2}`。
        *   更新 R2 的邻居（R1, R4）的距离：
            *   对于 R4: 经过 R2 的新路径 R1→R2→R4 的距离为 `D[R2] + cost(R2, R4) = 3 + 4 = 7`。
            *   当前 `D[R4] = 8`。因为 $7 < 8$，所以更新 `D[R4] = 7`，`P[R4] = R2`。
        *   当前 `N` 之外的顶点距离为: `D[R4] = 7`。
    3.  **第 3 轮**:
        *   在 `N` 之外的顶点中，选择距离最小的顶点。当前是 R4 (`D[R4] = 7`)。
        *   将 R4 加入 `N`，现在 `N = {R1, R3, R2, R4}`。
        *   所有顶点都已加入 `N`，算法结束。
-  计算到各子网的最终费用:
    *   **到 192.1.1.0/24**: 这是 R1 的直连网络。
        *   路径: 直接到达
        *   费用: $cost(R1, Net) = 1$
    *   **到 192.1.5.0/24**: 这是 R3 的直连网络。
        *   到 R3 的最短路径是 R1→R3，费用为 $D[R3] = 2$。
        *   总费用: $D[R3] + cost(R3, Net) = 2 + 1 = 3$。
    *   **到 192.1.6.0/24**: 这是 R2 的直连网络。
        *   到 R2 的最短路径是 R1→R2，费用为 $D[R2] = 3$。
        *   总费用: $D[R2] + cost(R2, Net) = 3 + 1 = 4$。
    *   **到 192.1.7.0/24**: 这是 R4 的直连网络。
        *   到 R4 的最短路径是 R1→R2→R4，费用为 $D[R4] = 7$。
        *   总费用: $D[R4] + cost(R4, Net) = 7 + 1 = 8$。

**答案:**
将上述结果整理成表格即可：

| 步骤   | 目的网段         | 路径                    | 代价 (费用) |
| :--- | :----------- | :-------------------- | :------ |
| 步骤 1 | 192.1.1.0/24 | 直接到达                  | 1       |
| 步骤 2 | 192.1.5.0/24 | R1→R3→192.1.5.0/24    | 3       |
| 步骤 3 | 192.1.6.0/24 | R1→R2→192.1.6.0/24    | 4       |
| 步骤 4 | 192.1.7.0/24 | R1→R2→R4→192.1.7.0/24 | 8       |

- #邻接矩阵表示法 [[邻接矩阵，邻接表 ，稀疏图，稠密图]] 
	-  要求用邻接矩阵来表示该网络图，并分析其空间复杂度（$O(V^2)$，其中 $V$ 是顶点数）与邻接表（$O(V+E)$，其中 $E$ 是边数）的优劣。对于稀疏图（如本题），邻接表更优
- #Dijkstra算法的复杂度 
	 朴素实现的 Dijkstra 算法时间复杂度为 $O(V^2)$。使用优先队列（最小堆）优化后，复杂度可以降为 $O(E \log V)$。
	*   其他[[最短路径算法]] :
        *   **Bellman-Ford 算法**: 如果图中存在负权边（在实际网络中很少见），Dijkstra 算法会失效，此时需要使用 Bellman-Ford 算法。
        *   **Floyd-Warshall 算法**: 如果要求计算**所有顶点对**之间的最短路径，可以使用 Floyd-Warshall 算法。
    *   **对比链路状态协议和距离矢量协议**: OSPF 是链路状态协议，而 RIP 是距离矢量（Distance-Vector）协议，后者基于 Bellman-Ford 算法。可能会考查两者的区别，如收敛速度、路由环路问题（“无穷计数”问题）等
- #LSA类型   [[链路状态通告LSA]]  每种 LSA 都有其特定的“生产者”和“传播范围”
	- 本题只涉及了最基本的路由器 LSA (Type-1) 和网络 LSA (Type-2)。OSPF 有多种 LSA 类型，用于描述不同网络环境，可能会考查其他 LSA 类型的作用
- #等价多路径负载均衡EMCP 
	-  如果 R1 到某个目的地存在多条费用相同的最短路径，路由器可以同时使用这些路径来转发数据，以实现负载均衡。可能会修改题目中的费用，构造出等价路径的场景。 





![[2014-exam-paper-ocr.pdf#page=5&rect=68,696,531,824|2014-exam-paper-ocr, p.5]]
![[Pasted image 20250924201837.png]]![[Pasted image 20250924202022.png]][[Pasted image 20250909042112.png]] 
- 考察了计算机网络中的三个核心知识点：[[路由聚合（路由汇总-超网）]]（CIDR）、IP分组转发过程（ #最长前缀匹配 和 #TTL ）以及 #默认路由  [[IP分组转发与TTL]]
-  (1) 路由表构建与路由聚合 
	- 为路由器 R1 创建一个路由表，要求包含到达题42图中所有子网 `192.1.x.x` 的路由，并且路由表中的路由项尽可能少。
1. 第一步：根据 LSI 表格构建网络拓扑图
	从表格中可以解读出以下连接信息：
	*   **R1 (10.1.1.1):**
	    *   连接到 R2 (10.1.1.2)，成本为 3。
	    *   连接到 R3 (10.1.1.5)，成本为 2。
	    *   直连网络 `192.1.1.0/24`，成本为 1。
	*   **R2 (10.1.1.2):**
	    *   连接到 R1 (10.1.1.1)，成本为 3。
	    *   连接到 R4 (10.1.1.6)，成本为 4。
	    *   直连网络 `192.1.6.0/24`，成本为 1。
	*   **R3 (10.1.1.5):**
	    *   连接到 R4 (10.1.1.6)，成本为 6。
	    *   连接到 R1 (10.1.1.1)，成本为 2。
	    *   直连网络 `192.1.5.0/24`，成本为 1。
	*   **R4 (10.1.1.6):**
	    *   连接到 R3 (10.1.1.5)，成本为 6。
	    *   连接到 R2 (10.1.1.2)，成本为 4。
	    *   直连网络 `192.1.7.0/24`，成本为 1。
- (1) 生成 R1 的路由表并进行路由聚合
1. 给出 R1 的路由表，要求包括到达所有 `192.1.x.x` 子网的路由，并使路由项尽可能少 
	1. 运行 #Dijkstra算法 计算最短路径 (从 R1 出发) 
		1. 到达 `192.1.1.0/24`这是 R1 的 #直连网络 
			*   路径：直连
	        *   成本 (Metric): 1
	        *   下一跳 (Next Hop): - (或 0.0.0.0)
	        *   接口 (Interface): E0 (根据答案推断的接口名)

	    2.  **到达 `192.1.5.0/24` (连接在 R3 上):**
	        *   路径：R1 -> R3
	        *   总成本: $Cost(R1 \to R3) + Cost(R3 \to Net) = 2 + 1 = 3$
	        *   下一跳: R3 在 R1-R3 链路上的 IP 地址，从 R3 的 LSI 表中 Link2 看到 R3 连接 R1 的本地 IP 是 `10.1.1.10`。所以下一跳是 `10.1.1.10`。
	        *   接口: L1 (根据答案推断的接口名)
	
	    3.  **到达 `192.1.6.0/24` (连接在 R2 上):**
	        *   路径：R1 -> R2
	        *   总成本: $Cost(R1 \to R2) + Cost(R2 \to Net) = 3 + 1 = 4$
	        *   下一跳: R2 在 R1-R2 链路上的 IP 地址，从 R2 的 LSI 表中 Link1 看到 R2 连接 R1 的本地 IP 是 `10.1.1.2`。所以下一跳是 `10.1.1.2`。
	        *   接口: L0 (根据答案推断的接口名)
	
		4.  **到达 `192.1.7.0/24` (连接在 R4 上):**
	        *   需要计算 R1 到 R4 的最短路径。有两条可能路径：
	            *   路径 1: R1 -> R2 -> R4，成本 = $Cost(R1 \to R2) + Cost(R2 \to R4) = 3 + 4 = 7$
	            *   路径 2: R1 -> R3 -> R4，成本 = $Cost(R1 \to R3) + Cost(R3 \to R4) = 2 + 6 = 8$
	        *   选择成本更低的路径 1 (R1 -> R2 -> R4)。
	        *   总成本: $Cost(R1 \to R4) + Cost(R4 \to Net) = 7 + 1 = 8$
	        *   下一跳: 路径的第一跳是 R2，所以下一跳地址是 `10.1.1.2`。
	        *   接口: L0
	2. #路由聚合  [[路由聚合（路由汇总-超网）]]
		问题要求路由项尽可能少。我们观察到去往 `192.1.6.0/24` 和 `192.1.7.0/24` 的下一跳和出接口都相同（都是 `10.1.1.2` 和 L0）。因此，我们可以尝试将这两个网络地址聚合。 [[IP地址 进制转化]]
	    *   `192.1.6.0` 的二进制表示 (只看第三个字节): `00000110`
	    *   `192.1.7.0` 的二进制表示 (只看第三个字节): `00000111`
	    这两个地址的前 23 位是相同的: `11000000.00000001.0000011`。因此，它们可以聚合成一个超网 `192.1.6.0/23`。
	3. 最终路由表 

| 目的网络 | 下一跳 | 接口 |
| :--- | :--- | :--- |
| `192.1.1.0/24` | - | E0 |
| `192.1.6.0/23` | `10.1.1.2` | L0 |
| `192.1.5.0/24` | `10.1.1.10` | L1 |
-  (2) IP 分组转发与 TTL 计算 
	- 主机 `192.1.1.130` 向 `192.1.7.211` 发送 TTL=64 的 IP 分组，R1 从哪个接口转发？最终 TTL 是多少？
1. 确定转发路径 
    *   源主机 `192.1.1.130` 位于 R1 的直连网络 `192.1.1.0/24`。
    *   目的主机 `192.1.7.211` 位于 `192.1.7.0/24` 网络，该网络连接在 R4 上。
    *   分组的路径是：`Host(src) -> R1 -> R2 -> R4 -> Host(dst)`。（此路径是我们在第（1）问中计算出的 R1 到 R4 的最短路径）。
2. R1 的转发决策 
    *   R1 收到分组后，查找其路由表以决定如何转发。
    *   目的地址 `192.1.7.211` 与路由表中的 `192.1.6.0/23` 匹配（因为 `192.1.6.0` <= `192.1.7.211` < `192.1.8.0`）。
    *   根据该路由条目，R1 将从 **L0** 接口将分组转发给下一跳 `10.1.1.2` (R2)。
3. TTL 计算 
    *   IP 分组每经过一个路由器，其 TTL 值减 1。
    *   初始 TTL = 64。
    *   分组经过的路由器有：R1, R2, R4 (共 3 个)。
    *   最终 TTL = 初始 TTL - 经过的路由器数量
    *   $TTL_{final} = 64 - 3 = 61$
    *   分组到达目的主机 `192.1.7.211` 时，TTL 值为 61。
- (3) 增加互联网连接与 LSI 更新
	若 R1 增加一条 Metric 为 10 的链路连接 Internet，则 R1 的 LSI 需要增加哪些信息？  
	1.  **理解互联网连接：** 连接到互联网意味着 R1 现在有了一条路径可以到达任何不在其路由表中的外部网络。在路由协议中，这通常通过一条 #默认路由  来表示。

	2.  **默认路由的表示：** 默认路由使用一个特殊的网络前缀来代表“所有其他网络”，即 `0.0.0.0/0`。

	3.  **更新 LSI：** R1 需要向网络中的其他路由器（R2, R3）通告这个新连接。这是通过更新并广播它自己的 LSI 来实现的。在 LSI 中，需要增加一个新的直连网络信息。
	    *   **网络前缀 (Prefix):** `0.0.0.0/0`
	    *   **费用 (Metric):** 10 (题目给定)

因此，R1 的 LSI 中需要增加一条新的网络信息：**网络前缀为 `0.0.0.0/0`，Metric 为 `10`**。
 - 衍生 
	 - [[距离矢量协议vs链路状态协议]] 
	 - #OSPF  #OSPF协议细节 
		 - 可能会考查 #OSPF区域 的概念、[[不同类型的 LSA]]（ #链路状态通告LSA  ）、 [[DR-BDR]]  
	 - [[边界网关协议BGP]]
		 -   题目中提到连接 Internet，这自然引出了 BGP。可能会考查 BGP 作为域间路由协议的特点、与 OSPF (域内路由协议) 的区别、路径向量属性（如 AS-PATH）
	- #VLSM可变长子网掩码   [[VLSM可变长子网掩码]] 
	- [[NAT (网络地址转换) 详解]] 

![[2014-exam-paper-ocr.pdf#page=5&rect=67,357,539,695|2014-exam-paper-ocr, p.5]]

-  这道计算机组成原理的经典题目。这道题综合考察了[[指令系统]]、[[指令寻址方式]]、[[流水线技术]]中的数据相关和控制冒险等核心概念  [[流水线冒险]] 
1. **C语言代码:** `for (int i = 0; i < n; i++) sum += A[i];`
**寄存器分配:**
*   `sum` 存放在 `R1`
*   `i` 存放在 `R2`
*   数组 `A` 的基地址存放在 `R3`
*   `n` 存放在 `R6`

**汇编代码分析:**
1.  `loop: sll R4, R2, 2`
    *   功能：`R4 = R2 << 2`，即 $R4 = R2 \times 4$。`R2`是循环变量`i`，这步是在计算数组元素`A[i]`相对于 #数组基地址 的 #字节偏移量 
2.  `add R4, R4, R3`
    *   功能：`R4 = R4 + R3`。将基地址`R3`和偏移量`R4`相加，得到`A[i]`的**实际内存地址**。
3.  `load R5, 0(R4)`
    *   功能：`R5 = Memory[R4 + 0]`。从内存地址`R4`处加载数据到寄存器`R5`。也就是把`A[i]`的值取出来。
4.  `add R1, R1, R5`
    *   功能：`R1 = R1 + R5`。执行`sum += A[i]`。
5.  `add R2, R2, 1`
    *   功能：`R2 = R2 + 1`。执行`i++`。
6.  `bne R2, R6, loop`
    *   功能：`if (R2 != R6) goto loop`。如果`i != n`，则跳转回`loop`标签处，继续循环。
- (1) M的存储器编址单位是什么？ 
	- #按字节编址  
	**推导过程:**
	关键在于第一条指令 `sll R4, R2, 2`。
	*   `sll` 是逻辑左移指令，左移2位等价于乘以 $2^2=4$。
	*   `R2` 存放的是数组下标 `i` (例如 0, 1, 2, ...)。
	*   为了得到第 `i` 个元素 `A[i]` 的地址，我们需要计算 `基地址 + i × 每个元素的大小`。
	*   指令 `sll R4, R2, 2` 实现了 `i × 4` 的计算，这意味着数组中每个元素的大小是 **4个字节**。
	*   如果计算机是按字编址（假设1个字=4字节），那么第 `i` 个元素的地址就是 `基地址 + i`，我们就不需要乘以4了。
	*   正因为计算机的最小寻址单位是**字节**，我们才需要将数组下标 `i` 乘以元素大小（4字节）来得到正确的字节偏移量。
	
	因此，存储器的编址单位是字节。
- (2) 已知sll指令实现左移功能，数组A中每个元素占多少位？ 
	-  4B (4个字节)
	**推导过程:**
	这个问题和上一个问题紧密相连。
	*   如上所述，`sll R4, R2, 2` 指令计算了字节偏移量，其值为 $i \times 4$。
	*   这个 `4` 就是数组 `A` 中每个元素所占的字节数。
	*   所以，数组A中每个元素占4个字节 (Byte)。
	*   题目问的是“占多少位”，但答案给的是“4B”，这在考试中通常可以接受。如果严格要求，应该是 $4 \text{ 字节} \times 8 \text{ 位/字节} = 32 \text{ 位}$。
-  (3) 表中bne指令的机器码是多少？...推断出bne指令的转移目标地址计算公式
	**答案:**
	*   `bne`指令的机器码是 `1446FFFAH`。
	*   OFFSET 字段的值为 `FFFAH`，用补码表示为 `-6`。
	*   转移目标地址计算公式为：`目标地址 = (PC) + 4 + OFFSET × 4`。
**推导过程:**
1.  **定位机器码:** 从表格中找到 `bne` 指令，其对应的机器码是 `1446FFFAH`。
2.  **解析OFFSET:**
    *   题目给出的指令格式为 `OP | Rs | Rd | OFFSET`，其中 `OFFSET` 占16位（即4个十六进制位）。
    *   因此，`1446FFFAH` 的后16位 `FFFAH` 就是 `OFFSET` 字段。
    *   `OFFSET` 是用补码表示的。`FFFAH` 是一个16位的数，其最高位是1（因为F是`1111`），所以它是一个负数。
    *   计算其十进制值：`FFFAH` 对应的负数是 $-(2^{16} - \text{FFFAH}) = -(\text{10000H} - \text{FFFAH}) = -6$。所以 `OFFSET` 的值是-6。
3.  **推导目标地址计算公式:**
    *   这是一种典型的**PC相对寻址**。转移的目标地址是相对于当前PC值的一个偏移。
    *   `bne` 指令所在的地址是 `08048114H`。
    *   当CPU执行 `bne` 指令时，PC寄存器的值已经自动更新，指向了下一条指令的地址，即 `$PC = 08048114H + 4H = 08048118H$`。
    *   `bne` 指令的跳转目标是 `loop` 标签，其地址为 `08048100H`。
    *   现在我们有了 `PC_{next}` (`08048118H`)，`OFFSET` (`-6`)，和 `TargetAddress` (`08048100H`)，我们可以推导它们之间的关系。
    *   我们发现，$08048118H + (-6 \times 4) = 08048118H - 24_{10} = 08048118H - 18H = 08048100H$。
    *   这个计算结果与目标地址完全吻合。
    *   **为什么 OFFSET 要乘以4？** 在MIPS这类RISC架构中，所有指令都是定长的（这里是4字节），并且是字对齐的。因此，跳转的目标地址也必须是4的倍数。为了在16位的 `OFFSET` 字段中表示更大的跳转范围，`OFFSET` 存放的是**字偏移量**而不是字节偏移量。硬件在计算时会自动将其乘以4，转换成字节偏移量。
    *   因此，通用的计算公式就是：$TargetAddress = PC_{next} + \text{SignExtended}(\text{OFFSET}) \times 4$，其中 $PC_{next} = PC + 4$。
-  (4) 流水线阻塞（冒险）分析。 #数据冒险
	**答案:**
	*   会发生数据阻塞的指令为第2、3、4、6条。
	*   第6条指令还会发生控制冒险。
	*   指令1的执行不会因为与指令5的数据相关而发生阻塞，是因为指令6（bne）引入的控制冒险导致了流水线停顿，这个停顿恰好给了指令5足够的时间完成写回操作，从而消除了数据冒险。
	推导过程:
	我们分析的是 #数据冒险 (Data Hazard)  中的 #写后读RAW (Read After Write, RAW) 相关。即后一条指令需要读取的寄存器，恰好是前一条指令要写入的。
	
	*   **指令1和指令2:**
	    *   `1: sll R4, R2, 2` (写 `R4`)
	    *   `2: add R4, R4, R3` (读 `R4`)
	    *   **存在RAW相关**。指令2在执行（EXE）阶段就需要 `R4` 的新值，但此时指令1可能还没完成写回（WB）阶段。这会导致数据冒险，需要通过**转发（Forwarding/Bypassing）** 或**插入气泡（Stall/Bubble）** 来解决。
	
	*   **指令2和指令3:**
	    *   `2: add R4, R4, R3` (写 `R4`)
	    *   `3: load R5, 0(R4)` (读 `R4`)
	    *   **存在RAW相关**。与上面类似，指令3需要指令2计算出的地址值。
	
	*   **指令3和指令4:**
	    *   `3: load R5, 0(R4)` (写 `R5`)
	    *   `4: add R1, R1, R5` (读 `R5`)
	    *   **存在RAW相关**。这是一种经典的“**load-use**”冒险。`load`指令在访存（MEM）阶段才能从内存中取到数据，而下一条 `add` 指令在执行（EXE）阶段就需要这个数据。即使有转发，也来不及，因为数据要从MEM阶段的末尾转发到EXE阶段的开头，时间上错后了一个周期。这通常**必须插入一个周期的停顿（气泡）**。
	
	*   **指令5和指令6:**
	    *   `5: add R2, R2, 1` (写 `R2`)
	    *   `6: bne R2, R6, loop` (读 `R2`)
	    *   **存在RAW相关**。`bne`指令需要比较 `R2` 的新值，而这个值由前一条 `add` 指令计算。
	
	*   **指令6的控制冒险 (Control Hazard):**
	    *   `bne` 是一条条件转移指令。流水线在取下一条指令时（IF阶段），并不知道 `bne` 的比较结果（通常在ID或EXE阶段得出）。如果流水线按顺序取了 `bne` 的下一条指令，而 `bne` 最终决定跳转，那么已经进入流水线的指令就是错误的，必须被冲刷掉，造成性能损失。这就是控制冒险。

	*   **指令5 (本轮循环) 和 指令1 (下轮循环) 的关系:**
	    *   `5: add R2, R2, 1` (写 `R2`)
	    *   `1': sll R4, R2, 2` (读 `R2`)
	    *   这之间确实存在RAW数据相关。但是，为什么它不会导致阻塞？
	    *   关键在于它们之间隔着一条 `bne` 指令。`bne` 指令本身会引入**控制冒险**。为了解决控制冒险，流水线需要停顿（stall），等待 `bne` 计算出跳转目标地址。
    *   我们画一个简化的流水线时序图：
        ```
        时钟周期:   1   2   3   4   5   6   7   8   9
        ----------------------------------------------------
        Inst 5 (add): IF  ID  EXE MEM WB
        Inst 6 (bne):     IF  ID  EXE MEM WB
                                |
                                +--> 分支结果在此确定, 产生2个周期的停顿(bubble)
        (bubble) :              IF  ID  EXE... (被冲刷)
        (bubble) :                  IF  ID ... (被冲刷)
        Inst 1' (sll):                  IF  ID  EXE MEM WB
        ```
	    *   从上图可以看出，当指令1' (`sll`) 进入ID阶段需要读取 `R2` 的值时（周期7），指令5 (`add`) 早已在周期5就完成了写回（WB）阶段。`R2` 的新值已经稳定地写入了寄存器堆。
	    *   因此，由 `bne` 指令的**控制冒险**所引起的**停顿**，"掩盖"了指令5和指令1'之间的**数据冒险**。
- 
- [[指令集体系结构]] 
	-  **指令格式:** 如题中的 `OP | Rs | Rd | OFFSET`，理解不同字段的含义
	- 寻址方式
        *   **寄存器寻址:** 操作数在寄存器中，如 `add R1, R1, R5`。
        *   **立即数寻址:** 操作数在指令中，本题未直接体现，但 `load R5, 0(R4)` 中的 `0` 是一个立即数偏移。
        *   **(基址+偏移量)寻址:** 如 `load R5, 0(R4)`，地址为 `(R4)+0`。
        *   **PC相对寻址:** 如 `bne` 指令，转移目标是 `PC + offset`。
[[编址方式]]
-  #CPU流水线技术  #流水线技术  
	*   **流水线阶段:** IF, ID, EXE, MEM, WB 是经典的五级流水线。
    *   **流水线冒险 (Hazard):** [[流水线冒险]] 
        *   **结构冒险:** 硬件资源冲突（本题未涉及）。
        *   **数据冒险:** 指令间存在数据依赖，导致后序指令用到错误的数据。主要是RAW（写后读），还有WAR（读后写）和WAW（写后写）。
        *   **控制冒险:** 由分支、跳转等指令引起，导致PC不确定，取指错误。

[[Pasted image 20250909042201.png]]
[[Pasted image 20250909042138.png]]
- 衍生 
	- [[数据冒险的解决方案]] 
	- [[流水线性能分析]] 


![[Pasted image 20250925024211.png]]![[2014-exam-paper-ocr.pdf#page=5&rect=74,225,534,360|2014-exam-paper-ocr, p.5]]- 
 - C语言描述:  `for(int i = 0; i < N; i++) sum += A[i];`
	这是一个简单的数组求和循环。
- 汇编代码分析:
	*   寄存器分配：`sum` -> `R1`，`i` -> `R2`，`N` -> `R6`，数组 `A` 的基地址 -> `R3`。
	*   初始状态：`R1=0`, `R2=0`, `R6=1000`。
	*   指令逐条分析：
	    1.  `sll R4, R2, 2`: `R4 = R2 << 2`，即 `R4 = i * 4`。计算数组元素 `A[i]` 的字节偏移量（假设每个元素占4字节）。
	    2.  `add R4, R4, R3`: `R4 = R4 + R3`，即 `R4 = &(A[i])`。计算 `A[i]` 的完整内存地址。
	    3.  `load R5, 0(R4)`: `R5 = Memory[R4]`，即 `R5 = A[i]`。从内存加载数组元素的值。
	    4.  `add R1, R1, R5`: `R1 = R1 + R5`，即 `sum = sum + A[i]`。累加。
	    5.  `add R2, R2, 1`: `R2 = R2 + 1`，即 `i++`。循环变量自增。
	    6.  `bne R2, R6, loop`: `if (R2 != R6) goto loop`。循环条件判断，`i != N`。
-  (1) P执行结束时，R2的内容是多少？ 
	- **答案：** 1000
	**推导过程：**
	1.  `R2` 存放的是循环变量 `i`，其初始值为0。
	2.  `R6` 存放的是循环的上限 `N`，其值为1000。
	3.  循环的条件是 `R2 != R6`。这意味着循环会一直执行，直到 `R2` 的值等于 `R6`。
	4.  循环体执行的 `i` 的值是从 0, 1, 2, ..., 999。
	5.  当 `i=999` (即 `R2=999`) 时，循环体最后一次执行。在循环体内部，指令 `add R2, R2, 1` 会将 `R2` 的值变为 1000。
	6.  此时，执行 `bne R2, R6, loop` 指令。比较 `R2` (1000) 和 `R6` (1000)，两者相等，`bne` (Branch if Not Equal) 条件不满足，分支不跳转，循环结束。
	7.  因此，程序P执行结束时，`R2` 的最终内容是 **1000**。
-  (2) M的指令Cache和数据Cache分离。若指令Cache共有16行，Cache和主存交换的块大小为32字节，则其数据区的容量是多少？若仅考虑程序段P的执行，则指令Cache的命中率为多少？ 
	- [[分离Cache]]  [[高速缓存Cache]]
#Cache总容量  
	每个Cache行存储一个 #数据块 ，大小为 32字节 
	这里的“其数据区的容量”中的“其”指代的是前文刚刚描述的**指令Cache**。一个Cache行（Line）通常由`标记(Tag)`、`有效位(Valid bit)`等控制信息和实际存储数据的`数据块(Data Block)`组成。Cache的“容量”通常就指其所有数据块的总大小，即 #数据区的总容量 
	16* 32 = 512字节
	1.  **理解“数据区容量”**：如上所述，这指的是指令Cache中用于实际存储指令内容的总空间大小。它不包括用于地址映射的标记位（Tag）和状态位（如Valid bit）。
	2.  **计算公式**：Cache的容量计算非常直接：
	    $C = N \times B$
	    其中：
	    *   $C$ 是Cache容量 (Capacity)。
	    *   $N$ 是Cache的总行数 (Number of lines)。
	    *   $B$ 是每行中数据块的大小 (Block size)。
	3.  **代入数值**：
	    *   题目给定指令Cache共有 $N = 16$ 行。
	    *   题目给定块大小为 $B = 32$ 字节。
	4.  **计算结果**：
	    指令Cache容量 = $16 \times 32 \text{ 字节} = 512 \text{ 字节}$。
- #指令Cache命中率  
	1.  **分析指令地址和大小：**
	    *   程序P的起始地址是 `08048100H`。
	    *   共有6条指令，每条指令是32位，即4字节。
	    *   6条指令占用的总空间为 $6 \times 4 = 24$ 字节。
	    *   指令地址范围为 `08048100H` 到 `08048114H`。
	2.  **分析Cache块和指令存放：**
	    *   Cache块大小为32字节。
	    *   程序的24字节代码（从 `08048100H` 到 `08048117H`）完全可以被一个32字节的Cache块容纳。例如，一个从 `08048100H` 开始的Cache块可以覆盖到 `0804811FH` 的地址范围。
	3.  **分析Cache访问过程：**
	    *   **首次执行（i=0）：**
	        *   CPU取第一条指令 `sll` (地址 `08048100H`)。此时指令Cache为空，发生**强制性失效 (Compulsory Miss)**。
	        *   系统从主存中将包含该指令的整个32字节块调入指令Cache的某一行。由于所有6条指令都在这个块中，所以整个循环体的代码此时都已装入Cache。
	        *   CPU取后续的5条指令（`add`, `load`, `add`, `add`, `bne`）。由于它们刚刚被调入Cache，这5次访问全部**命中 (Hit)**。
	    *   **后续执行（i=1 到 i=999）：**
	        *   循环跳转回 `loop` 处，重新取第一条指令。
	        *   由于指令Cache有16行，而我们的程序只占用1行，且没有其他程序干扰，所以不会发生冲突失效或容量失效。
	        *   因此，从第二次循环开始，每一次取指令都会在Cache中找到，全部命中。
	4.  **计算命中率：**
	    *   循环总共执行1000次（从 `i=0` 到 `i=999`）。
	    *   每次循环执行6条指令。
	    *   总的指令访问次数 = $1000 \times 6 = 6000$ 次。
	    *   总的失效次数 = 1 次（仅在最开始取第一条指令时）。
	    *   总的命中次数 = 总访问次数 - 总失效次数 = $6000 - 1 = 5999$ 次。
	    *   命中率 $H = \frac{\text{总命中次数}}{\text{总访问次数}} = \frac{5999}{6000} \approx 0.999833...$
	    *   换算成百分比为 **99.98%**。
- (3) P在执行过程中，哪条指令的执行可能发生 #溢出异常 ？哪条指令的执行可能产生 #缺页异常 ？对于数组A的访问，需要读 #磁盘 和 #快表TLB 至少各多少次？ 
	1. [[溢出异常]]  发生在算术运算中，当结果超出了寄存器能表示的范围时 
		1. 分析程序中的算术指令：
		    *   指令1 (`sll`): `R2` 最大为1000，`1000 << 2 = 4000`，远小于32位寄存器的表示范围，不会溢出。
		    *   指令2 (`add`): 地址相加，一般不会设计导致地址计算溢出。
		    *   指令4 (`add R1, R1, R5`): 这是 `sum += A[i]`。如果数组 `A` 中的元素值很大，它们的累加和 `sum` 完全有可能超过一个32位有符号或无符号整数的表示范围，从而导致溢出。
		    *   指令5 (`add`): `R2` 从0加到1000，不会溢出。
				*   因此，最可能发生溢出异常的是**指令4**。
	 2. [[缺页中断与缺页异常]] 发生在当CPU试图访问一个虚拟地址，而该地址所在的页(Page)当前不在主存中时 
		*   题目明确指出“数组A未调入主存”。
		*   程序中访问数组A的指令是 `load R5, 0(R4)`，它需要从内存中读取 `A[i]` 的值。
		*   当第一次执行这条指令（即访问 `A[0]`）时，由于包含 `A[0]` 的页不在主存中，必然会触发**缺页异常**。
		*   因此，可能产生缺页异常的是**指令3**。
	3. #读磁盘和访问TLB次数  
		-   **读磁盘次数：**  [[缺页中断（缺页异常）的处理流程]]
		    1.  #缺页异常 发生后，操作系统需要从磁盘将缺失的页调入主存。
		    2.  题目说明“所有数组元素在同一页，并存储在磁盘同一个扇区”。
		    3.  这意味着，处理第一次访问 `A[0]` 时发生的 #缺页异常 ，只需要从磁盘读取**1次**（读取包含整个数组A的那个页/扇区）。
		    4.  一旦该页被调入主存，后续访问 `A[1]` 到 `A[999]` 时，页都在主存中，不会再发生缺页异常，也就不再需要读磁盘。
		    5.  所以，总共需要读磁盘 **1** 次。
		-   **访问TLB次数：**
		    1.  TLB (Translation Lookaside Buffer) 是页表的Cache，每次通过虚拟地址访问内存前，CPU都会先查询TLB。 [[TLB(快表)的结合]]
		    2.  **访问 `A[0]` 的过程：**
		        *   `load` 指令执行，CPU生成 `A[0]` 的虚拟地址。
		        *   **第1次TLB访问：** 查询TLB，因为是第一次访问该页，TLB未命中 (TLB Miss)。
		        *   硬件接着查询主存中的页表，发现页表项表明该页不在主存中，于是触发 #缺页异常 。
		        *   操作系统处理缺页异常（包括了上面说的1次磁盘读取），将页调入主存，更新页表，并将该页的“虚拟页号 -> 物理页帧号”的映射关系填入TLB。
		        *   异常处理结束后，**导致异常的指令 (`load A[0]`) 会被重新执行**。
		        *   **第2次TLB访问：** 再次查询TLB，此时因为映射关系已被填入，TLB命中 (TLB Hit)。
		        *   所以，仅访问 `A[0]` 就导致了2次TLB访问。
		    3.  **访问 `A[1]` 到 `A[999]` 的过程：**
		        *   这999次访问，由于所有元素都在同一个页，它们的虚拟页号都相同。
		        *   每次访问时，CPU都会先查询TLB。因为 `A[0]` 的访问已经将该页的映射关系载入了TLB，所以这999次访问都会**TLB命中**。
		        *   这会产生 **999** 次TLB访问。
		    4.  **总TLB访问次数：**
		        *   总次数 = 访问 `A[0]` 的次数 + 访问 `A[1...999]` 的次数 = $2 + 999 = 1001$ 次。
		        *   所以，至少需要访问TLB **1001** 次。
[[Pasted image 20250909042353.png]]
[[Pasted image 20250909042400.png]] 
- 衍生 
	- Cache扩展问题
		- 不同映射方式
			- 如果题目改为直接映射（Direct Mapped）或组相联（Set-Associative），可能会引入**冲突失效 (Conflict Miss)**。例如，如果数据访问和指令访问的地址映射到同一个Cache行，就会发生冲突 [[地址映射方式]]
		- [[页面置换算法]] 
			- 如果Cache容量不足以容纳整个循环体（**容量失效 Capacity Miss**），则需要考虑替换算法的影响。
	- [[多级页表]] 对于更大的虚拟地址空间，计算访问一次内存需要几次访存（先访问多级页表，再访问数据） 
	- #页面大小的影响  #页面大小的选择  改变 #页面大小 （Page Size）会如何影响 #页表大小 、缺页率和 #内部碎片

![[2014-exam-paper-ocr.pdf#page=5&rect=70,107,535,229|2014-exam-paper-ocr, p.5]]
- 考察两种不同的 #文件物理结构（分配方式）—— #连续分配 和 #链接分配 ——在执行文件记录插入操作时的性能差异，以及链接分配中文件大小的计算 [[文件分配方式（文件物理结构） 文件分配方式的对比]] [[408/补充资料/连续分配]]
1. (1) 若文件系统采用连续分配方式，每个磁盘块存放一条记录，文件 F 存储区域前后均有足够的空闲磁盘空间，则完成上述插入操作最少需要访问多少次磁盘块？F 的文件控制块内容会发生哪些改变？ 
	1.  **确定移动策略**：要在第 30 个位置插入新记录，意味着原来的第 30 到第 200 条记录都需要向后移动一个位置。但题目给了一个关键条件：“存储区域**前后**均有足够的 #空闲磁盘空间 ”，并且要求“**最少**需要访问多少次磁盘块”。
	    *   **方案一（向后移动）**：移动第 30 至 200 条记录（共 $200 - 30 + 1 = 171$ 条）。
	    *   **方案二（向前移动）**：移动第 1 至 29 条记录（共 29 条）。
	    *   为了最小化磁盘访问次数，我们选择移动记录数较少的方案，即**向前移动第 1 至 29 条记录**。
	2.  **计算磁盘访问次数**：移动一条记录的操作包含两个步骤：
	    *   **读出**：将该记录所在的磁盘块读入内存（1 次磁盘访问）。
	    *   **写入**：将内存中的记录写入到新的磁盘块位置（1 次磁盘访问）。
	    *   因此，移动一条记录需要 2 次磁盘访问。
	    计算总访问次数：
	    *   移动 29 条记录：$29 \times 2 = 58$ 次访盘。
	    *   将新的记录写入到空出来的第 30 个位置：1 次访盘。
	    *   总访问次数 = $58 + 1 = 59$ 次。
	    * $N_{access} = N_{move} \times 2 + N_{insert} = 29 \times 2 + 1 = 59$  
	3.  #文件控制块FCB  变化：
	    文件控制块（File Control Block, FCB）是操作系统为了管理文件而设置的数据结构，包含了文件名、物理地址、文件长度、创建日期等元数据。
	    *   **起始块号**：由于我们将第 1 至 29 条记录向前移动了一个块的位置，整个文件的起始物理地址发生了改变。例如，如果原来从 100 号块开始，现在就从 99 号块开始。
	    *   **文件长度**：文件原来有 200 条记录，插入一条后变为 201 条记录。因此，文件长度（或记录数）增加了。
- (2) 若文件系统采用 #链接分配 方式  ，每个磁盘块存放一条记录和一个链接指针，则完成上述插入操作需要访问多少次磁盘块？若每个存储块大小为 1KB，其中 4 字节存放链接指针，则该文件系统支持的文件最大长度是多少？ 
	1.  **计算磁盘访问次数**：
	    *   **定位插入点**：要在第 30 个位置插入，需要先找到第 29 个记录块，以便修改它的指针。由于是链接结构，必须从文件的第一个块开始，顺着指针链逐个读取，直到读到第 29 个块。这个过程需要 **29 次读**操作。
	    *   **执行插入操作**：
	        1.  从第 29 个块中读出它原来指向下一个块（即原第 30 块）的指针地址。
	        2.  将新记录和这个指针地址写入一个新分配的空闲磁盘块中。这需要 **1 次写**操作。
	        3.  修改内存中第 29 个块的指针，使其指向这个新分配的块。
	        4.  将修改后的第 29 个块写回磁盘。这需要 **1 次写**操作。
	    *   总访问次数 = 定位次数 + 写入新块次数 + 更新旧块次数 = $29 + 1 + 1 = 31$ 次。
	    * $N_{access} = (\text{插入位置} - 1) + 1_{\text{写新块}} + 1_{\text{更新前驱块}} = (30 - 1) + 1 + 1 = 31$ 
	2.  **计算文件最大长度**：
	    *   **指针寻址能力**：链接指针大小为 4 字节。
	        *   1 字节 (Byte) = 8 位 (bit)。
	        *   4 字节 = $4 \times 8 = 32$ 位。
	        *   一个 32 位的指针可以指向 $2^{32}$ 个不同的地址。这意味着该文件系统最多可以管理 $2^{32}$ 个磁盘块。
	    *   **每个块的有效数据大小**：
			*   存储块总大小：1 KB = 1024 字节。
			*   指针占用空间：4 字节。
			*   每个块中用于存储数据的有效空间 = $1024 \text{ B} - 4 \text{ B} = 1020 \text{ B}$。
		*   **文件最大长度**：
	        *   最大长度 = (可寻址的最大块数) × (每块的有效数据大小)
	        *   $\text{MaxFileSize} = 2^{32} \times 1020 \text{ B}$
	        *   为了方便表示，我们进行单位换算：
	            *   $2^{10} = \text{K}$ (Kilo)
	            *   $2^{20} = \text{M}$ (Mega)
	            *   $2^{30} = \text{G}$ (Giga)
	        *   $2^{32} = 2^2 \times 2^{30} = 4 \times \text{G}$
	        *   所以，$\text{MaxFileSize} = 4\text{G} \times 1020 \text{ B} = 4080 \text{ GB}$ (因为 $1 \text{ G} \times 1 \text{ B} = 1 \text{ GB}$)。
	    $\text{MaxFileSize} = 2^{\text{指针位数}} \times (\text{块大小} - \text{指针大小})$
	    $\text{MaxFileSize} = 2^{32} \times (1024 - 4) \text{ B} = 4080 \text{ GB}$

[[Pasted image 20250909042411.png]]
- 衍生  #FAT
	- [[索引分配]] 这是第三种主流的分配方式。题目可能会改成使用索引分配，然后提问类似的问题 
	- [[文件分配表FAT]] 这改善了链接分配的随机访问性能，因为查找指针链只需要在内存中的 FAT 表里进行，而不需要访问每个数据块 


![[2014-exam-paper-ocr.pdf#page=5&rect=70,32,523,112|2014-exam-paper-ocr, p.5]]
1. 经典的操作系统题目。这道题是 #生产者-消费者问题 的一个变体，理解了它的推导过程，对掌握进程同步与互斥的核心思想非常有帮助。 
	1.  **共享资源**：一个大小为1000的环形缓冲区。
	2.  **两类进程**：多个生产者进程和多个消费者进程。
	3.  **生产者行为**：一次生产一个产品放入缓冲区。如果缓冲区满了，必须等待。
	4.  **消费者行为**：如果缓冲区空了，必须等待。
	5.  **核心约束 (The Twist)**：**一个消费者**进程必须**连续取出10个**产品后，其他消费者进程才能开始取产品。
前4点是经典的生产者-消费者问题。第5点是本题的关键，增加了一个新的互斥/同步条件 
[[信号量]] [[PV操作]] 
#信号量的两种用途   
-  解题思路推导
1. 第1步：构建标准的生产者-消费者模型 
	先忽略“连续取10个”的特殊要求，只解决前4个基本要求。
	
	1.  **缓冲区互斥访问**：生产者放入产品和消费者取出产品都需要修改缓冲区（如指针、计数器等），这些操作是临界区，必须互斥。因此，我们需要一个互斥信号量。
	    *   `semaphore mutex2 = 1;` // 用于缓冲区访问互斥，初值为1
	
	2.  **生产者与消费者的同步**：
	    *   生产者需要知道缓冲区是否有空位。我们可以用一个信号量来统计空位数。
	        *   `semaphore empty = 1000;` // 记录空闲缓冲区的数量，初值为1000
	    *   消费者需要知道缓冲区是否有产品。我们可以用一个信号量来统计产品数。
	        *   `semaphore full = 0;` // 记录缓冲区中产品的数量，初值为0
基于这三个信号量，标准的生产者-消费者代码框架如下： 

```c
// 标准生产者
producer() {
    while(1) {
        生产一个产品;
        P(empty);       // 申请一个空位，若无则等待
        P(mutex2);      // 锁住缓冲区
        把产品放入缓冲区;
        V(mutex2);      // 释放缓冲区锁
        V(full);        // 通知消费者，产品数+1
    }
}

// 标准消费者
consumer() {
    while(1) {
        P(full);        // 申请一个产品，若无则等待
        P(mutex2);      // 锁住缓冲区
        从缓冲区取出一个产品;
        V(mutex2);      // 释放缓冲区锁
        V(empty);       // 通知生产者，空位数+1
        消费该产品;
    }
}
```
**注意**：`P(empty)`和`P(full)`必须在`P(mutex2)`**之前**。如果`P(mutex2)`在前面，可能会导致死锁。例如，一个生产者锁住缓冲区后发现缓冲区已满，于是它在持有锁的情况下等待`empty`信号量，但能释放`empty`信号量的消费者却因为无法获得缓冲区锁而无法进入临界区。

2. 第2步：加入“连续取10个”的约束 
	现在我们来处理这个核心约束。这个约束的本质是：**消费者之间的互斥**。当一个消费者开始其“取10个”的流程时，其他消费者必须等待。这又是一个典型的互斥问题。
	
	因此，我们需要引入**第四个信号量**，专门用于控制消费者之间的互斥。
	
	*   `semaphore mutex1 = 1;` // 用于消费者之间互斥，保证一次只有一个消费者在执行“取10个”的循环
	
	现在，我们把这个新的互斥锁加入到消费者的逻辑中。
	
	*   一个消费者在**开始它的10次循环之前**，必须先获得这个锁 `P(mutex1)`。
	*   在它**完成了10次循环之后**，必须释放这个锁 `V(mutex1)`，以便其他消费者可以开始。
 2. 第3步：整合最终代码
	将第1步和第2步的逻辑结合起来，我们就得到了题目给出的最终解法。
**信号量定义与初始化：**

*   `semaphore mutex1 = 1;` // **消费者互斥锁**：保证任一时刻只有一个消费者在执行取10个产品的操作。
*   `semaphore mutex2 = 1;` // **缓冲区互斥锁**：保证任一时刻只有一个进程（生产者或消费者）在访问缓冲区。
*   `semaphore empty = 1000;` // **资源计数器**：记录缓冲区空槽位数。
*   `semaphore full = 0;` // **资源计数器**：记录缓冲区产品数。

**生产者进程 `producer()`** (与标准模型相同)

```c
void producer() {
    while (1) {
        生产一个产品;
        P(empty);       // 1. 等待并获取一个空槽位
        P(mutex2);      // 2. 锁住缓冲区，准备写入
        把产品放入缓冲区;
        V(mutex2);      // 3. 释放缓冲区锁
        V(full);        // 4. 通知消费者产品数+1
    }
}
```

**消费者进程 `consumer()`** (加入新约束)

```c
void consumer() {
    while (1) {
        P(mutex1);      // 1. 获取消费者之间的互斥锁，准备开始我的“10次”回合
        
        for (int i = 0; i < 10; ++i) {
            P(full);        // 2. 等待并获取一个产品
            P(mutex2);      // 3. 锁住缓冲区，准备读取
            从缓冲区取出一个产品;
            V(mutex2);      // 4. 释放缓冲区锁
            V(empty);       // 5. 通知生产者空槽位数+1
        }
        
        V(mutex1);      // 6. 10个产品已取完，释放消费者互斥锁，让其他消费者有机会
        
        消费这10个产品;
    }
}
```
*   **代码解读**：`P(mutex1)` 和 `V(mutex1)` 形成了一个更大的“临界区”，这个临界区保护的不是缓冲区，而是“连续取10个产品的权利”。一旦一个消费者进入这个区域，其他消费者就会在 `P(mutex1)` 处阻塞，直到当前消费者完成10次循环并执行 `V(mutex1)`。在for循环内部，每次取产品时，依然遵循标准的生产者-消费者同步和互斥逻辑。

**注意**：题目答案中的 `while(1)` 循环位置有些不清晰，可能会引起误解。正确的模型是每个消费者进程都在一个
大的 `while(1)` 循环中运行，而 `P(mutex1)` 和 `V(mutex1)` 应该在这个循环的内部，包围住 `for` 循环。


[[Pasted image 20250909042419.png]]
[[Pasted image 20250909042427.png]]
- 衍生 
1. 生产者一次生产M个产品
	*   这与消费者一次消费10个类似。生产者需要先申请M个空位，即连续执行M次 `P(empty)`，然后再锁住缓冲区放入M个产品，最后连续执行M次 `V(full)`。
    *   代码框架：`for(i=0; i<M; i++) P(empty);` `P(mutex);` `...add M items...` `V(mutex);` `for(i=0; i<M; i++) V(full);`
2.  **缓冲区中产品数达到K个后，才允许消费者取**：
    *   这是一个同步问题。消费者不能像之前那样只要 `full > 0` 就取。
    *   **解法一（简单但不高效）**：消费者在循环外执行K次 `P(full)`，然后再进入循环取走K个产品。这要求生产者必须生产了K个产品后，第一个消费者才能被唤醒。
    *   **解法二（更复杂）**：引入一个新的信号量，如 `semaphore can_consume = 0;`。当生产者执行 `V(full)` 后，检查 `full` 的值是否等于K，如果是，则执行 `V(can_consume)`。消费者则首先等待 `P(can_consume)`。这种方法需要小心处理，避免引入新的竞争条件。评分说明中的第⑤条就是指这种考点。
3.  **允许多个消费者同时从缓冲区取产品（但一次只能取一个）**：
    *   这就是经典的读者-写者问题变体。生产者是“写者”，消费者是“读者”。需要允许多个“读者”同时进入。
    *   需要引入一个计数器 `read_count` 和一个保护计数器的互斥锁 `mutex_rc`。第一个进入的读者需要锁住缓冲区（对写者互斥），后续读者只需增加计数器。最后一个离开的读者负责释放缓冲区锁。
4.  **死锁问题分析**：
    *   考察对P操作顺序的理解。如前所述，如果将 `P(mutex2)` 放在 `P(empty)` 或 `P(full)` 之前，就可能导致死锁，并要求考生分析死锁产生的原因和条件。







