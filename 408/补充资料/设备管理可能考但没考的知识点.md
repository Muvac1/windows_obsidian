![[Pasted image 20251216205525.png]]
### 知识点一：单缓冲区与双缓冲区的问题（具体计算）

**考点核心：**
计算处理一批数据所需的总时间。
设 $T$ 为将一个数据块输入缓冲区的时间，$M$ 为将缓冲区数据传送到用户工作区的时间，$C$ 为CPU处理数据的时间。

*   **单缓冲公式：** 每块处理时间 $Time = \max(C, T) + M$
*   **双缓冲公式：** 每块处理时间 $Time = \max(C+M, T)$

#### 【习题 1】
某文件占 10 个磁盘块，现要把该文件磁盘块逐个读入主存缓冲区，并送入用户区进行分析。假设一个缓冲区与磁盘块大小相同，将一个磁盘块读入缓冲区（输入）的时间 $T = 100\mu s$，将缓冲区数据传送到用户区（传送）的时间 $M = 50\mu s$，CPU分析一块数据（计算）的时间 $C = 90\mu s$。
请计算：
1.  在单缓冲区结构下，处理完这 10 个数据块所需的最少时间。
2.  在双缓冲区结构下，处理完这 10 个数据块所需的最少时间。

#### 【解答】

**1. 单缓冲区：**
*   **分析：** 在单缓冲下，磁盘输入（T）和CPU计算（C）可以并行，但传送（M）必须串行（因为传送时缓冲区被占用，不能输入也不能计算）。
*   **处理一块的时间：** $Max(C, T) + M = Max(90, 100) + 50 = 150\mu s$。
*   **总时间计算：**
    *   前 9 块可以流水线处理，时间为 $9 \times 150\mu s$。
    *   第 10 块需要完整执行 T -> M -> C（最后一块处理完才算结束）。
    *   **公式法（近似）：** $n \times (Max(C, T) + M)$。
    *   **精确法（考虑流水线收尾）：**
        *   前一块的输入+传送结束，才能开始下一块的输入。
        *   单块时间 $150\mu s$。
        *   总时间 = $10 \times 150\mu s = 1500\mu s$。
        *   *注：如果题目问“CPU处理完”的时间，最后一块的C不能被掩盖。单缓冲的并行度主要是C和下一块的T并行。由于 $T > C$，瓶颈在T。*
        *   精确流程：$T_1(100) \to M_1(50) \to [C_1(90) \parallel T_2(100)]$ (此时$C_1$先做完，等$T_2$做完才能$M_2$)。所以每块的间隔确实是 $T+M = 150$。
        *   **答案：** $1500\mu s$（或者 $1500 + C$ 的剩余部分，但在标准计算题中通常直接用 $n \times (\max(C, T) + M)$，如果 $C$ 被 $T$ 掩盖）。此处 $T=100, M=50, C=90$，由于 $T+M > C$，且单缓冲 $T$ 和 $M$ 串行，每一轮周期其实是由 $T$ 和 $M$ 决定的（如果 $T>C$）。准确说是 $10 \times (100+50) + 90 \text{(最后一次C)} - \text{重叠部分}$。
        *   **最简通用公式结果：** $10 \times 150 = 1500\mu s$。

**2. 双缓冲区：**
*   **分析：** 双缓冲允许输入 $T$ 和 (传送 $M$ + 计算 $C$) 并行进行。
*   **处理一块的时间：** $Max(C+M, T) = Max(90+50, 100) = 140\mu s$。
*   **总时间计算：**
    *   第一块输入需 $100\mu s$。
    *   之后可以并行。瓶颈在于 $C+M = 140\mu s$。
    *   总时间 $\approx 100 \text{(第一块T)} + 10 \times 140 = 1500$？ 不对。
    *   **精确逻辑：**
        *   第一块数据准备好需要 $T$。
        *   之后的处理受限于慢的一方。这里 $C+M=140 > T=100$。所以系统受限于CPU侧的处理速度。
        *   总时间 = 第一块的输入 $T$ + $10 \times (C+M)$？不，最后一块处理完即可。
        *   通用公式：$T + n \times \max(C+M, T)$ (近似)。
        *   更精确：$T + (n-1) \times \max(T, C+M) + (C+M) = 100 + 9 \times 140 + 140 = 1500\mu s$。
        *   **对比单缓冲：** 此题数据 $C+M > T$，双缓冲优势不明显，因为CPU处理太慢。
    *   **修正数据以便体现双缓冲优势（考试常见套路）：**
        *   若 $T=100, M=10, C=80$。
        *   单缓冲：$\max(100, 80)+10 = 110$。
        *   双缓冲：$\max(100, 80+10) = 100$。

---

### 知识点二：磁盘调度算法（寻道距离、磁臂黏着）

**考点核心：**
1.  **磁臂黏着 (Arm Stickiness)**：指在SSTF（最短寻道时间优先）等算法中，如果新到来的请求总是落在当前磁头附近，磁头会一直在一个小区域移动，导致远处的请求“饥饿”。
2.  **解决算法**：图片明确指出 **FCFS, n-step-SCAN, FSCAN** 没有磁臂黏着。
3.  **计算**：标准的寻道长度计算。

#### 【习题 2】
假设磁盘磁头当前位于 100 号柱面，磁头移动方向为磁道号增加方向。磁盘请求队列如下：
`55, 58, 39, 18, 90, 160, 150, 38, 184`
请回答：
1.  使用 **SSTF** (最短寻道时间优先) 算法，计算磁头移动的总道数。
2.  什么是“磁臂黏着”现象？上述队列中，如果源源不断有 `99, 101, 100` 这样的请求加入，SSTF 会发生什么？
3.  简述 **n-step-SCAN** 算法是如何解决磁臂黏着问题的。

#### 【解答】

**1. SSTF 计算：**
*   当前由 100 开始：
    *   -> 90 (距离10)
    *   -> 58 (距离32)
    *   -> 55 (距离3)
    *   -> 39 (距离16)
    *   -> 38 (距离1)
    *   -> 18 (距离20)
    *   (此时较小的处理完了，去大的) -> 150 (距离 150-18=132)
    *   -> 160 (距离10)
    *   -> 184 (距离24)
*   **总距离** = $10+32+3+16+1+20+132+10+24 = 248$。

**2. 磁臂黏着现象：**
*   **现象：** 当系统不断有新的I/O请求到达，且这些新请求的磁道位置非常接近当前磁头位置时，SSTF算法会优先服务这些新请求。导致磁头长时间在一个小范围内徘徊，那些此时距离磁头较远的请求（如队列中的160, 184）可能长时间得不到服务，产生“饥饿”现象。
*   **后果：** 系统的公平性下降。

**3. n-step-SCAN 解决方法：**
*   **原理：** n-step-SCAN 将磁盘请求队列分成若干个长度为 $N$ 的子队列。磁盘调度按 FCFS 依次处理这些子队列。而在处理每一个子队列内部时，使用 SCAN 算法。
*   **为何解决：** 即使有大量新请求密集到达，它们会被放入下一个或后续的子队列中，而不会插入当前正在处理的子队列。因此，磁头必须处理完当前这一批（包括远处的）之后，才会去处理新来的，从而避免了原地打转。

---

### 知识点三：I/O 方式的特点（结合组成原理）

**考点核心：**
程序查询、中断驱动、DMA、通道控制的区别。重点在于CPU干预频率和数据传输单位。

#### 【习题 3】
下列关于I/O控制方式的描述中，正确的是（多选/简答）：
A. 在中断驱动方式下，CPU以字节（或字）为单位干预I/O。
B. DMA方式下，CPU只需要在数据块传输开始和结束时参与，中间无需干预。
C. 通道控制方式比DMA方式的并行程度更高，一个通道可以控制多台设备。
D. DMA方式的数据传送方向是在内存和CPU之间。

#### 【解答】

*   **A 正确。** 中断方式每输入/输出一个数据（字或字节），设备控制器就向CPU发送中断请求，CPU处理中断进行数据传送。
*   **B 正确。** 这是DMA的核心特点，以“块”为单位，仅在开始（初始化DMA控制器）和结束（DMA发中断）时需要CPU。
*   **C 正确。** 通道是专门的I/O处理器，执行通道程序，可以管理多台设备，进一步减少CPU负担。
*   **D 错误。** DMA（Direct Memory Access）的数据传送是直接在**设备（I/O接口）和内存**之间进行的，不经过CPU。

**总结（结合组原）：**
*   **干预频率（由高到低）：** 程序查询 > 中断 > DMA > 通道。
*   **数据传输路径：** 前两者经过CPU，后两者直接“内存 <-> 设备”。

---

### 知识点四：FBR (Frequency-based Replacement) 算法

**考点核心：**
图片中提到“短周期用 RLU (应为LRU)，长周期用 LFU”。
**纠正：** 图片中的 RLU 应为 LRU (Least Recently Used)。
FBR 试图结合 LRU 和 LFU 的优点。
*   **LRU优点**：利用局部性原理，处理最近访问。
*   **LFU优点**：保留频率高的数据。
*   **FBR机制**：通过分区（New, Middle, Old）来解决 LFU 的“缓存污染”和 LRU 不能反映频率的问题。

#### 【习题 4】
1.  FBR（基于频率的置换）算法主要为了解决 LFU 算法的什么缺陷？
2.  根据图片提示，FBR 是如何结合“短周期”和“长周期”特性的？

#### 【解答】

**1. 解决 LFU 的缺陷：**
*   LFU (Least Frequently Used) 容易受到**短期密集访问**的误导。例如，一个数据在短时间内被访问了100次（计数器猛增），之后再也不用了。但由于计数值很高，它会长期驻留在缓存中，挤占有用空间。这被称为“缓存污染”或未能适应访问模式的变化。

**2. 结合机制（解析图片观点）：**
*   **“短周期用 LRU”：** FBR 将LRU队列分为不同区域（如 New Section, Middle Section, Old Section）。当数据块在 **New Section（代表近期刚被访问，即短周期）** 被再次访问时，**不增加**其频率计数。这模拟了 LRU 的特性——刚刚被访问的数据通常还在“热度”中，不需要通过增加频率来证明它的价值，避免短期的密集访问“刷高”频率。
*   **“长周期用 LFU”：** 当数据块从 New Section 移出进入 Middle/Old Section 后，如果再次被访问，则**增加**其频率计数，并移回头部。只有在长周期内真正被多次访问的数据，其频率值才会高。
*   **置换策略：** 当需要置换时，选择 Old Section 中频率计数最低的块（类似 LFU），但要排除最近刚被访问过的（通过 New Section 保护）。
*   **总结：** 图片的意思是，对于刚刚进入或刚被访问的数据（短周期），我们关注它的“新旧”（LRU属性），不急着记频；对于存在较久的数据（长周期），我们通过计数（LFU属性）来决定去留。