[[826历年真题解析-数据结构篇（包括算法题）-12.15.pdf#page=39&rect=23,711,581,805|826历年真题解析-数据结构篇（包括算法题）-12.15, p.39]]
![[Pasted image 20251215195032.png]]

- 这道题目考察的是数据结构中 #二叉堆 的性能分析，特别是对于**插入操作**在平均情况下的时间复杂度
1. 输入随机的情况下，完全二叉堆的插入平均时间是常数。即$O(1)$  
2. 推导逻辑如下：
	1. **插入操作的机制**：在二叉堆中插入一个新元素时，我们将新元素放在堆的末尾（数组的最后位置），然后执行 #上滤操作 。如果新元素比父节点更符合堆序（例如在最小堆中比父节点小），就交换位置，直到满足堆序或到达根节点。  
	2.  **最坏情况**：新插入的元素是整个堆中最小（或最大）的，它需要从最底层一直交换到根节点。完全二叉堆的高度为$h=\lfloor\log_2 n\rfloor$，所以最坏时间复杂度是$O(\log n)$。
	3.  **平均情况（随机输入）**：
	    *   我们要问的是：一个随机插入的元素，平均需要向上爬多少层？   
	    *   在一个[[完全二叉堆]]中，底层的节点数量大约占总节点数的一半（$n/2$），倒数第二层占$1/4$，以此类推。
	    *   从概率角度看，一个随机的数在插入后，它是其所在路径上最小值的概率并不大。
	    *   数学上可以证明，对于随机排列的输入，新插入元素向上移动的层数的期望值是常数。虽然树高是$\log n$，但新元素大约有$50\%$的概率不需要移动（或只移动1层），有$25\%$的概率移动2层...
	    *   这就形成了一个收敛的级数。新元素上移层数的期望值小于$\sum_{i=1}^{\infty} \frac{i}{2^i} = 2$。
	    *   因此， #平均交换次数 是一个常数，平均时间复杂度为$O(1)$。   #二叉堆堆插入平均时间复杂度    
3. 衍生  
	1. #多叉堆  
		1. 题目标题提到了“多叉堆”。如果把二叉堆改成$d$叉堆（每个节点有$d$个孩子）： #多叉堆的时间复杂度（插入，删除） 
			*   **树的高度**：变为$\log_d n$。
			*   **插入操作（Sift Up）**：只需比较父节点，最坏情况交换$\log_d n$次。时间复杂度为$O(\log_d n)$。
			*   **删除操作（Sift Down）**：下滤时，需要从$d$个孩子中找到最小的一个进行交换，每次比较需要$d-1$次。总时间复杂度为$O(d \log_d n)$。
			*   **考点**：$d$增大时，树变矮，插入变快，但删除（下滤）变慢。
	2. #堆排序  
		1. **时间复杂度**：建堆$O(n)$ + 删除$n$次堆顶（每次$\log n$）。总时间为$O(n \log n)$。
			*   **空间复杂度**：$O(1)$（原地排序）。
			*   **稳定性**：堆排序是**不稳定**的排序算法。
	3. #堆应用-TOP-K问题  
		1. 如何在$n$个元素中找到前$K$大（或小）的元素？
			*   **方法**：维护一个大小为$K$的小顶堆。
			*   **复杂度**：遍历数据，插入/更新堆。总时间复杂度为$O(n \log K)$。
			*   **对比**：如果用快速排序（Quick Select）的思路，平均时间是$O(n)$，但最坏是$O(n^2)$，而堆方法稳定为$O(n \log K)$。
	4. #优先队列的应用  
		1. 考察堆在**Huffman编码**（每次取两个最小频次）、**Dijkstra算法**（最短路径）、**Prim算法**（最小生成树）中的应用，这些算法的核心都是利用堆来快速获取最小值。
总结公式表

| 操作                | 二叉堆最坏情况     | 二叉堆平均情况     | $d$叉堆最坏情况       |
| :---------------- | :---------- | :---------- | :-------------- |
| **插入 (Insert)**   | $O(\log n)$ | $O(1)$      | $O(\log_d n)$   |
| **删除堆顶 (Delete)** | $O(\log n)$ | $O(\log n)$ | $O(d \log_d n)$ |
| **线性建堆 (Build)**  | $O(n)$      | $O(n)$      | $O(n)$          |
![[Pasted image 20251215195110.png]]
[[Pasted image 20251119162146.png]]

- 为什么完全二叉堆插入操作的平均时间复杂度是$O(1)$  
1. 二叉堆是一个 #完全二叉树 
	1. #堆的插入操作 的流程是：先把新元素放在数组的末尾（即树的最后一个叶子节点位置），然后执行 #上滤操作 ，即如果该节点比父节点大（在最大堆中）或小（在最小堆中），就与父节点交换，直到满足堆的性质 
2. 复杂度分析  
	1. 最坏情况$O(\log n)$  
		1. 如果新插入的元素是整个堆中最大（或最小）的，它需要从最底层的叶子节点一路交换到根节点。完全二叉树的高度是$\log_2 n$，所以最坏需要交换约$\log_2 n$次。
	2. 平均情况$O(1)$（题目重点 
		1. 这是一个统计学概率问题。
		    *   在一个含有$n$个元素的堆中，树的结构是底层节点多，顶层节点少。
		    *   第1层有$1$个节点，第2层有$2$个，...，第$k$层有$2^{k-1}$个。
		    *   这意味着，**绝大多数节点都分布在树的底层**。大约$50\%$的节点是叶子节点，$25\%$的节点在倒数第二层。
		    *   在“理想随机”的情况下，新插入的数值大小也是随机的。统计表明，新插入的元素通常不需要向上移动很多层就能找到它的位置。
		    *   数学推导上，新元素向上移动$i$层的概率大约随着$i$的增加呈指数级下降（即移动1层的概率很大，移动到根的概率极小）。其移动层数的期望值是一个收敛的常数级数。
		    *   因此，平均交换次数是一个常数，即平均时间复杂度为$O(1)$。
-  衍生 
	- 删除堆顶元素的复杂度  
		- 题目解析中提到了这个，这是与插入对应的考点。
		*   **操作流程**：将堆顶元素（根）与最后一个元素交换，删除最后一个元素，然后将新的堆顶元素**下滤（Sift Down）**。
		*   **复杂度**：无论是平均情况还是最坏情况，删除操作的时间复杂度都是$O(\log n)$。
		    *   *原因*：被换到堆顶的那个元素通常是原堆中较小（或较大）的边缘元素，它几乎必然需要沉底或沉到很深的位置，因此平均路径长度接近树高。
	- 建堆的复杂度  
		- 这是二叉堆最经典的考点之一，常用于考察对$O(n)$与$O(n\log n)$的辨析。
			*   **方法1：逐个插入法**。
			    如果从空堆开始，执行$n$次插入操作。
			    *   最坏时间复杂度：$O(n\log n)$（$\log 1 + \log 2 + \dots + \log n$）。
			    *   平均时间复杂度：基于上述$O(1)$的结论，平均是$O(n)$。
			*   **方法2：筛选法（Floyd建堆算法）**。
			    这是标准库（如C++ `std::make_heap`）采用的方法。将数组直接看作完全二叉树，从**最后一个非叶子节点**开始，依次向前执行**下滤**操作。
			    *   时间复杂度：**严格的$O(n)$**。
			    *   *数学原理*：$\sum_{h=0}^{\log n} \frac{n}{2^{h+1}} \cdot h = O(n)$。因为大部分节点在底层，不需要下滤或下滤路径很短；只有极少数节点（根附近）需要下滤很深。
	- #堆排序  
		- **复杂度**：堆排序的时间复杂度在最好、最坏、平均情况下极其稳定，均为$O(n\log n)$。
		*   **空间复杂度**：$O(1)$，因为是原地排序。
		*   **稳定性**：堆排序是**不稳定**的排序算法。
- 总结公式

| 操作 | 平均时间复杂度 | 最坏时间复杂度 |
| :--- | :--- | :--- |
| **插入 (Insert)** | $O(1)$ | $O(\log n)$ |
| **删除堆顶 (Delete)** | $O(\log n)$ | $O(\log n)$ |
| **筛选法建堆 (Build)** | $O(n)$ | $O(n)$ |
| **堆排序 (Sort)** | $O(n\log n)$ | $O(n\log n)$ |





![[Pasted image 20251215195121.png]]
[[Pasted image 20251119162252.png]]

- #Dijkstra算法 在不同图密度下的堆优化策略  #调整叉数堆平衡（提取最小值，减小键值）    [[Dijkstra 算法]]  
	- 核心在于如何通过调整堆的叉数（$d$）来平衡“Extract-Min（ #提取最小值 ）”和“Decrease-Key（ #减小键值 ）”这两大操作的开销  
1. Dijkstra算法的操作统计  
	1. 在Dijkstra算法运行过程中（也就是图中的PFS - Priority First Search过程）： 
		1.  **Extract-Min（提取最小节点）：** 执行$n$次（每个节点出队一次）。
		2.  **Decrease-Key（更新邻居距离）：** 执行$e$次（每一条边都可能触发一次松弛操作）。
2.  $d$叉堆的操作复杂度    
	1. 对于一个包含$n$个元素的$d$叉堆（完全$d$叉树）：
		*   树的高度：约为$\log_d n$。
		*   **Decrease-Key（向上调整）：** 只需要与父节点比较，最坏情况是上浮到根节点。
		    *   复杂度：$O(\log_d n)$。
		*   **Extract-Min（向下调整）：** 删除根节点后，将末尾元素放至根部并下沉。下沉时，需要从$d$个孩子中找到最小的一个进行交换。
		    *   复杂度：需要比较$d$个孩子，并重复树高次，即$O(d \cdot \log_d n)$。
3. 总时间复杂度公式   
	1. 将上述两步结合，总时间复杂度$T$为：
		$T \approx n \times (\text{Extract-Min代价}) + e \times (\text{Decrease-Key代价})$
		$T \approx n \cdot (d \log_d n) + e \cdot (\log_d n)$
		提取公因式$\log_d n$，得到图片右侧的公式：
		$T \approx (n \cdot d + e) \log_d n$
4. 针对稠密图的优化 ($d$的确定)    [[堆]]
	1. **二叉堆的情况 ($d=2$)：**
    复杂度为$O((2n+e)\log_2 n)$。对于稠密图，边数$e$接近$n^2$。此时复杂度约为$O(n^2 \log n)$。
    而如果不使用堆，直接用数组（朴素Dijkstra），复杂度是$O(n^2)$。显然，**二叉堆在稠密图中反而更慢**。
	*   #多叉堆的优化策略 
	    观察公式$(n \cdot d + e) \log_d n$。
	    在稠密图中，$e \gg n$，$e$项占主导地位。我们需要通过增加$d$来降低树的高度$\log_d n$，从而加快执行次数最多的Decrease-Key操作。虽然这会增加Extract-Min中比较孩子的代价（$n \cdot d$），但只要$n \cdot d$不超过$e$，整体就是划算的。
	
	    **取值推导：**
	    为了让$n \cdot d$与$e$的数量级平衡，我们取$n \cdot d \approx e$，即：
	    $d \approx \frac{e}{n}$
	    考虑到稀疏图的情况以及为了保证$d \ge 2$，通常取$d = \frac{e}{n} + 2$  
	*   **代入验证：**
	    当$d \approx n$（极度稠密图，$e \approx n^2$）时：
	    复杂度变为$O((n \cdot n + n^2) \log_n n) = O(2n^2 \cdot 1) = O(n^2)$。
	    这使得基于堆的Dijkstra算法在稠密图中退化为与朴素算法相同的$O(n^2)$，避免了$\log n$的额外开销。
- 衍生 
	-  (斐波那契堆) 的对比  
		- **考点：** 理论上Dijkstra的最优解是使用 #斐波那契堆 。
	    *   **原理：** 斐波那契堆的Decrease-Key均摊复杂度为$O(1)$，Extract-Min为$O(\log n)$。
	    *   **总复杂度：** $O(e + n \log n)$。这在理论上优于多叉堆，但在实际应用中因为常数因子大且实现复杂，往往不如$d$叉堆高效。
	- #Prim算法的复杂度    
		- **考点：** Prim算法（用于最小生成树）的逻辑与Dijkstra几乎完全一致（也是PFS框架）。
	    *   **结论：** 上述关于$d$叉堆的优化推导完全适用于Prim算法。  
	* #多叉堆的数组索引计算  
		* **考点：** 在数组中实现$d$叉堆，给定索引$i$（从0开始），如何计算父节点和子节点？
	    *   **公式：**
	        *   父节点：$\lfloor \frac{i-1}{d} \rfloor$
	        *   第$k$个子节点（$k \in [1, d]$）：$i \cdot d + k$
	- 空间复杂度与缓存优化  
		- **考点：** 为什么有时候$d$叉堆比二叉堆快，即使在理论复杂度相似时？
	    *   **解释：** $d$叉堆的节点在数组中更紧凑，访问孩子节点时内存跳转更少，具有更好的**缓存局部性 (Cache Locality)**
	* 不同图密度下的算法选择 (选择题/简答题)  
		*  如果$e \approx n$，选什么？答：二叉堆优化的Dijkstra，复杂度$O(n \log n)$。
	    *   如果$e \approx n^2$，选什么？答：朴素Dijkstra（无堆）或$d \approx n$的多叉堆，复杂度$O(n^2)$。
	    *   如果边权全为1，选什么？答：BFS（广度优先搜索），复杂度$O(n+e)$。


![[Pasted image 20251215195129.png]]
[[Pasted image 20251119162422.png]]

核心考点在于 #完全二叉堆的基本操作时间复杂度 ，特别是**最坏情况**与**平均情况**的区别 
1.  #堆的删除操作 （通常指删除堆顶元素/Extract-Min or Max）：
    *   **操作流程：** 为了保持完全二叉树的结构，删除堆顶元素（根节点）后，我们需要把堆中**最后一个元素**（通常是层级最深的叶子节点）移动到根节点的位置。
    *   **下沉（Sift Down/Percolate Down）：** 此时根节点的值很可能破坏了堆的性质（例如在小顶堆中，原来的叶子节点通常比根节点的子节点大得多）。因此，需要不断将该节点与子节点比较并交换，直到它“下沉”到合适的位置。
    *   **复杂度分析：** 堆的高度是$O(\log n)$。在删除操作中，被移动到堆顶的那个元素，大概率是一个比较“边缘”的值，它通常需要一路下沉到树的底部或接近底部的位置才能重新满足堆性质。因此，无论是**最坏情况**还是**平均情况**，下沉操作的路径长度都与树高成正比，即时间复杂度均为$O(\log n)$。

**结论：** 题目说删除的平均情况是$O(1)$，这与事实不符，所以选错

- 衍生考点（必背） 
	- #建堆的时间复杂度
		- **自顶向下建堆（插入法）：** 相当于对$n$个元素依次执行插入操作。最坏时间复杂度是$O(n\log n)$。
		*   **自底向上建堆（筛选法/Heapify）：** 从最后一个非叶子节点开始，依次向下调整。
		    *   公式推导涉及错位相减法，最终结果是线性的。
		    *   **结论：** 这种建堆方式的时间复杂度是$O(n)$。这是高频考点。
	- #堆排序  
		-  **时间复杂度：** 无论是最好、最坏还是平均，堆排序都需要建堆$O(n)$加上$n$次删除堆顶调整$O(n\log n)$，所以总复杂度稳定在$O(n\log n)$。
		*   **空间复杂度：** 原地排序，仅需常数辅助空间，为$O(1)$。
		*   **稳定性：** 由于交换操作可能改变相同元素的相对位置，堆排序是**不稳定**的排序算法。
	- #堆应用-TOP-K问题 
		-   如果需要在$n$个元素中找到前$k$大（或小）的元素：
			*   **方法：** 建立一个大小为$k$的堆。
			*   **复杂度：** 时间复杂度为$O(n\log k)$。当$k$远小于$n$时，这比全排序$O(n\log n)$要快得多
	- #数组下标计算  
		- 完全二叉堆通常用数组存储。对于下标为$i$的节点（假设下标从1开始）：
			*   父节点下标：$\lfloor i/2 \rfloor$
			*   左孩子下标：$2i$
			*   右孩子下标：$2i+1$
			*   *(注：如果下标从0开始，左孩子为$2i+1$，右孩子为$2i+2$)
- 总结表

| 操作                  | 最坏时间复杂度     | 平均时间复杂度       |
| :------------------ | :---------- | :------------ |
| **插入 (Insert)**     | $O(\log n)$ | $O(1)$        |
| **删除 (Delete)**     | $O(\log n)$ | $O(\log n)$   |
| **建堆 (Build Heap)** | N/A         | $O(n)$ (自底向上) |





![[Pasted image 20251215195136.png]]
[[Pasted image 20251119162604.png]]

- 核心考点在于区分 **“逐个插入建堆”** 和 **“整体调整建堆（Floyd建堆算法）”** 的时间复杂度区别。  

1. 推导逻辑：  
	1. 在数据结构中，建立二叉堆（Build Heap）通常指从一个无序数组出发，将其转化为满足堆性质的数组。  
		1.  **方法一：逐个插入**  
		    如果你从空堆开始，依次将数组中的$n$个元素执行插入操作（`push`），每次插入需要向上调整（Swim/Sift Up），最坏情况下的时间复杂度是$O(\log i)$。总时间复杂度为$\sum_{i=1}^{n}\log i=\log(n!)$，根据[[斯特林公式]]，这确实是$O(n\log n)$。
		2.  **方法二：下沉调整**
		    这是**标准**的“建堆”算法（如 C++ STL 中的 `std::make_heap`）。它的做法是将整个数组直接看作一棵完全二叉树，然后从**最后一个非叶子节点**开始，依次向前对每个节点执行“下沉”（Sink/Sift Down/Heapify）操作。
		    通过数学级数求和证明，这种方法的时间复杂度是线性时间，即$O(n)$。
2. **结论：**
	既然存在$O(n)$的更优算法，且该算法是工业界和教材中的标准“ #建堆”方法，那么说 #建堆的时间复杂度 是$O(n\log n)$就是不准确的（或者说是指代了效率较低的方法）。因此题目判断为 **错**。

3. [[Floyd建堆算法的时间复杂度证明]]  
- 衍生  
	- #建堆vs堆排序  
		- **建堆 (Build Heap)：** 时间复杂度$O(n)$。
		*   **堆排序 (Heap Sort)：** 包含“建堆”和“依次删除堆顶”两个步骤。
		    *   第一步建堆：$O(n)$
		    *   第二步删除$n$次，每次$O(\log n)$：总计$O(n\log n)$
		    *   **总时间复杂度：** $O(n)+O(n\log n)=O(n\log n)$。
		    *   易错点：不要因为堆排序是$O(n\log n)$就误以为建堆也是$O(n\log n)$
	* #堆应用-TOP-K问题 
		* 从$n$个元素中找出最大（或最小）的$k$个元素。
			*   **方法：** 建立一个大小为$k$的堆。
			*   **复杂度：** $O(n\log k)$。如果$k$很小（远小于$n$），这优于全排序的$O(n\log n)$。
			*   或者使用$O(n)$建堆，然后弹出$k$次，复杂度为$O(n+k\log n)$。
	- 插入与删除的代价   
		- 插入一个元素：$O(\log n)$
		*   删除堆顶元素：$O(\log n)$  
	* #数组下标计算        
		* 对于完全二叉堆（数组下标从1开始）：
			*   父节点索引：$\lfloor i/2 \rfloor$
			*   左孩子索引：$2i$
			*   右孩子索引：$2i+1$
			*   最后一个非叶子节点索引：$\lfloor n/2 \rfloor$ （这是Floyd建堆算法的起点）。
	- 稳定性  
		- 堆排序是**不稳定**的排序算法。
	    *   *原因：* 堆顶元素与堆尾元素交换时，可能会破坏相同元素的相对顺序。


![[Pasted image 20251215195144.png]]
[[Pasted image 20251119162553.png]]
[[Pasted image 20251119162618.png]]

- 这是一道非常经典的数据结构题目，考察的是**二叉堆  的构建算法**，特别是 #Floyd建堆算法  [[建堆]]
- **题目背景：**
	*   **目标**：将向量转换为 #大顶堆 （Max Heap，即父节点的值 $\ge$ 子节点的值）。 #最大堆   
	*   **初始向量**：`[3, 8, 0, 6, 1, 13, 11, 2, 9, 5, 4, 14, 7, 10, 12]`
	*   **节点总数**：$n=15$。
	*   **索引范围**：$0$ 到 $14$
1. Floyd算法逻辑
	算法的核心思想是从**最后一个非叶子节点**开始，从后往前（索引从大到小），依次对每个节点执行 `percolateDown`（下滤/下沉）操作。  
	- #完全二叉树的数组表示      #完全二叉树的编号性质 
		- 堆通常是用数组实现的完全二叉树。对于数组中索引为 $i$ 的节点（从0开始）：
		    *   父节点索引：$\lfloor \frac{i-1}{2} \rfloor$
		    *   左孩子索引：$2i + 1$
		    *   右孩子索引：$2i + 2$
	*   对于索引为 $i$ 的节点：  
	    *   左孩子索引：$2i + 1$
	    *   右孩子索引：$2i + 2$
	*   **最后一个非叶子节点索引**：$\lfloor \frac{n}{2} \rfloor - 1 = \lfloor \frac{15}{2} \rfloor - 1 = 6$。
	    *   这意味着索引 $7$ 到 $14$ 都是叶子节点，不需要处理。
	    *   我们需要依次处理的节点索引顺序为：$6 \rightarrow 5 \rightarrow 4 \rightarrow 3 \rightarrow 2 \rightarrow 1 \rightarrow 0$。
2. 下滤
	观察表格变化规律，这里的“第 X 次下滤”是将**树的同一深度的所有节点**作为一个批次处理完毕后的结果：
	*   **第1次下滤后**：处理最底层的非叶子节点（索引 $6, 5, 4, 3$）。
	*   **第2次下滤后**：处理倒数第二层的非叶子节点（索引 $2, 1$）。
	*   **第3次下滤后**：处理根节点（索引 $0$）。

3. 初始状态 
	1. 数组：`[3, 8, 0, 6, 1, 13, 11, 2, 9, 5, 4, 14, 7, 10, 12]`
		1.  第1次下滤（处理索引 6, 5, 4, 3）  
			1. 这一轮处理的是直接连接叶子节点的父节点。  
			*   **Index 6 ($A[6]=11$)**:
			    *   子节点：$13(A[13]=10)$, $14(A[14]=12)$。
			    *   最大子节点是 $12$。
			    *   $11 < 12$，交换。
			    *   **结果**：$A[6]=12, A[14]=11$。
			*   **Index 5 ($A[5]=13$)**:
			    *   子节点：$11(A[11]=14)$, $12(A[12]=7)$。
			    *   最大子节点是 $14$。
			    *   $13 < 14$，交换。
			    *   **结果**：$A[5]=14, A[11]=13$。
			*   **Index 4 ($A[4]=1$)**:
			    *   子节点：$9(A[9]=5)$, $10(A[10]=4)$。
			    *   最大子节点是 $5$。
			    *   $1 < 5$，交换。
			    *   **结果**：$A[4]=5, A[9]=1$。
			*   **Index 3 ($A[3]=6$)**:
			    *   子节点：$7(A[7]=2)$, $8(A[8]=9)$。
			    *   最大子节点是 $9$。
			    *   $6 < 9$，交换。
			    *   **结果**：$A[3]=9, A[8]=6$。
		**此时数组状态（对应表格“第1次下滤后”）**：
		`[3, 8, 0,` **`9`**, **`5`**, **`14`**, **`12`**, `2, 6, 1, 4, 13, 7, 10, 11]`
		*(对比原题表格，完全一致)*
		2. 第2次下滤（处理索引 2, 1） 
			1. 这一轮处理再上一层的节点，可能会引发连锁下沉。 
			*   **Index 2 ($A[2]=0$)**:
			    *   子节点：$5(14)$, $6(12)$。（注意用上一步更新后的值）
			    *   最大子节点是 $14$。
			    *   $0 < 14$，交换 $A[2]$ 和 $A[5]$。
			    *   此时 $A[5]$ 变成了 $0$。检查 $A[5]$ 是否满足堆性质。
			    *   **$A[5]$ 的连锁调整**：$A[5]=0$，其子节点为 $11(13)$, $12(7)$。最大是 $13$。
			    *   $0 < 13$，交换 $A[5]$ 和 $A[11]$。此时 $A[11]=0$，是叶子，停止。
			    *   **结果**：$A[2]=14, A[5]=13, A[11]=0$。
			*   **Index 1 ($A[1]=8$)**:
			    *   子节点：$3(9)$, $4(5)$。
			    *   最大子节点是 $9$。
			    *   $8 < 9$，交换 $A[1]$ 和 $A[3]$。
			    *   此时 $A[3]$ 变成了 $8$。检查 $A[3]$ 是否满足堆性质。
			    *   **$A[3]$ 的连锁调整**：$A[3]=8$，其子节点为 $7(2)$, $8(6)$。
			    *   $8$ 大于两个子节点，无需继续交换。
			    *   **结果**：$A[1]=9, A[3]=8$。
		**此时数组状态（对应表格“第2次下滤后”）**：
		`[3,` **`9`**, **`14`**, **`8`**, `5,` **`13`**, `12, 2, 6, 1, 4,` **`0`**, `7, 10, 11]`
		*(对比原题表格，完全一致)*
		3. 第3次下滤（处理索引 0）
			处理根节点，这通常会引发最长的连锁交换路径。
			*   **Index 0 ($A[0]=3$)**:
			    *   子节点：$1(9)$, $2(14)$。
			    *   最大子节点是 $14$。
			    *   $3 < 14$，交换 $A[0]$ 和 $A[2]$。
			    *   **结果**：$A[0]=14$，现在 $A[2]=3$。
			    *   **$A[2]$ 的连锁调整**：
			        *   $A[2]=3$。子节点：$5(13)$, $6(12)$。
			        *   最大子节点是 $13$。
			        *   $3 < 13$，交换 $A[2]$ 和 $A[5]$。
			        *   **结果**：$A[2]=13$，现在 $A[5]=3$。
			    *   **$A[5]$ 的连锁调整**：
			        *   $A[5]=3$。子节点：$11(0)$, $12(7)$。
			        *   最大子节点是 $7$。
			        *   $3 < 7$，交换 $A[5]$ 和 $A[12]$。
			        *   **结果**：$A[5]=7$，现在 $A[12]=3$。
			        *   $A[12]$ 是叶子节点，停止。
		**最终数组状态（对应表格“第3次下滤后”）**：
		`[`**`14`**, `9,` **`13`**, `8, 5,` **`7`**, `12, 2, 6, 1, 4, 0,` **`3`**, `10, 11]`
		*(对比原题表格，完全一致)*
- 衍生 
	- 时间复杂度对比  
		-    #自下而上建堆（Floyd） ：$O(n)$。
	    *   #自上而下建堆（依次Insert） ：每次插入是 $O(\log n)$，插入 $n$ 个元素总耗时 $O(n \log n)$。
	    *   *考题形式*：给出两种建堆代码，问哪个效率高，或者计算具体的操作次数差异。
	1. 最小堆 vs 最大堆 
		1. 题目可能要求建立**小顶堆**（Min-Heap）。逻辑完全一样，只是在下滤时，是和**较小**的子节点交换，且当父节点 $\le$ 子节点时停止
	2. #堆排序  
		- 建堆只是堆排序的第一步。
	    *   **排序过程**：将堆顶（最大值）与数组末尾元素交换，数组长度减1，然后对新的堆顶执行一次下滤。重复此过程。
	    *   *考题形式*：给出建好堆后的数组，问经过两次“排序/输出堆顶”操作后的数组状态。
	3.  **稳定性**：
	    *   堆排序是**不稳定**的排序算法。
	    *   *考题形式*：给出一个包含重复元素的序列，问堆排序后这两个重复元素的相对位置是否改变。
	*  #数组与树的映射 ：
	    *   给定一个数组索引，问它在树中的层数，或者问它的兄弟节点索引是多少。
	    *   例如：索引 $i$ 的兄弟是 $i-1$（如果 $i$ 是偶数）或 $i+1$（如果 $i$ 是奇数），且需要 #判断是否越界  
![[Pasted image 20251215195201.png]]
[[Pasted image 20251119162626.png]]

- 这个问题涉及数据结构中用于外部排序的核心算法结构：胜者树与败者树  
3. #锦标赛树（胜者树）的调整过程  
	1. 当从胜者树中取出一个元素（通常是根节点，即当前的最小/最大值）后，需要填入下一个元素并重新调整树以选出新的胜者。
		*   **操作：** 新元素必须沿着路径向上，每一层都要和它的**兄弟节点**（Sibling）进行比较。
		*   **劣势：** 在计算机存储中，访问“兄弟节点”意味着需要计算兄弟节点的下标并进行一次额外的内存访问。如果兄弟节点不在Cache（缓存）中，会增加访存开销。
4. #败者树的调整过程
	1. 败者树的内部节点记录的是左右子树比较后的“败者”（Loser），而“胜者”（Winner）则继续向上参与更上一层的比较。
		*   **操作：** 当叶子节点更新后，新元素作为“挑战者”往上走。它只需要和**父节点**（Parent）中记录的败者进行比较。
		    *   如果新元素赢了（比如比父节点记录的败者还小），那么新元素继续往上找爷爷节点比较，原来的败者留在父节点。
		    *   如果新元素输了（比如比父节点记录的败者大），那么新元素留在该父节点变成新的败者，而父节点原先记录的那个元素（它是上一轮的胜者）“复活”成为新的挑战者继续往上比较。
		*   **优势：** **不需要访问兄弟节点**。因为父节点已经记录了另一边的“最强者”（即上一轮的败者，其实是那棵子树的优胜者），所以只需和父节点比较即可。

**结论（即图中解析的意思）：**
败者树简化了重构时的比较路径。在胜者树中，你需要“读兄弟，比兄弟，写父亲”；而在败者树中，你只需要“读父亲，比父亲，（可能）写父亲”。减少了访存次数，因此在常数系数上优于胜者树。

- **应用场景：** 主要用于 #k路归并排序 当需要将$k$个有序段归并成一个有序序列时，使用选择树可以高效地找到这$k$个元素中的极值 
*   **时间复杂度：** 无论是胜者树还是败者树，调整一次的时间复杂度都是$O(\log k)$。  

[[胜者树（锦标赛树）]]

- 衍生 
	- 比较次数与复杂度计算
		*   **建树过程：**
		    对于$k$个归并段，建立败者树或胜者树需要进行的比较次数为$k-1$次。时间复杂度为$O(k)$。
		*   **调整（归并）过程：**
		    每取出一个元素，填入新元素后，重新调整树的深度为$\lceil\log_2k\rceil$（或$\lfloor\log_2k\rfloor+1$）。因此，每次调整的比较次数约为$\lceil\log_2k\rceil$。
		*   **总时间复杂度：**
		    若有$n$个元素进行$k$路归并，总的时间复杂度为$O(n\log k)$。
	- 空间复杂度
		-    需要额外的存储空间来存放树的内部节点。对于$k$路归并，需要大小为$k$的数组作为辅助空间（胜者树和败者树节点数与归并路数$k$相关），空间复杂度为$O(k)$。   #k路归并排序  
	- 为什么 $k$ 路归并中 $k$ 不能无限大？  
		- 随着$k$增大，归并趟数$\lceil\log_k m\rceil$（其中$m$是初始归并段数量）会减少，从而减少磁盘I/O次数。
		*   但是，内部归并时，每次选出最小值的比较次数$\lceil\log_2 k\rceil$会增加。
		*   如果$k$过大，CPU内部比较的时间开销会抵消掉磁盘I/O减少带来的收益。
		*   **衍生：** 这也是引入**置换-选择排序**（生成初始归并段）和**最佳归并树**（Huffman树思想）的原因。
	- 代码实现细节（数组下标）  
		-  败者树通常用数组实现。
		*   对于节点$i$，其父节点下标通常为$\lfloor i/2 \rfloor$。
		*   考题可能会让你手动模拟败者树的建立过程（画图），特别是“败者留，胜者上”的逻辑。
- 总结 LaTeX 公式速记
	- $k$路归并的调整时间复杂度：$O(\log k)$
	*   $n$个元素$k$路归并的总复杂度：$O(n\log k)$
	*   树的高度（比较次数上限）：$\lceil\log_2 k\rceil$

![[Pasted image 20251215195209.png]]
[[Pasted image 20251119162634.png]]
- 基于这道题目，我来为你详细解析为什么“败者树删除（调整）的时间复杂度在常系数上优于胜者树”，并介绍相关的知识点及可能的考点  
1. 为什么 #败者树常系数 更优？ 
	1. 这道题的核心在于**胜者树**和**败者树**在进行“重构/调整”（即删除堆顶元素并插入新元素后的重新筛选过程）时的访问模式不同。虽然两者的理论时间复杂度都是$O(\log k)$，但在具体的计算机指令执行和内存访问上，败者树更高效。  
2. [[胜者树（锦标赛树）]]
	*   **结构：** 每个非叶子节点存储的是其两个子节点中的“胜者”（较小值或较大值）。
    *   **调整过程：** 当一个叶子节点的值改变（比如取出了最小值，读入下一个值）时，我们需要自底向上调整。在每一层，新的节点值必须与它的**兄弟节点**（Sibling）进行比较，选出新的胜者上升到父节点。
    *   **劣势（题目中的“迂回”）：** 为了找到兄弟节点，程序通常需要计算兄弟节点的下标（例如，若当前是$i$，兄弟可能是$i+1$或$i-1$），然后**访问兄弟节点的内存地址**读取数据。这意味着每次比较都要访问当前路径之外的节点（兄弟节点），增加了访存次数和缓存未命中的概率。
3. [[败者树]]  
	1. **结构：** 每个非叶子节点存储的是其两个子节点比较后的“败者”。而胜者则继续向上参与更上一层的比赛。最终的胜者存储在根节点之上的一个额外单元（通常记为$ls[0]$）。
	    *   **调整过程：** 当叶子节点值改变时，新的值作为一个“挑战者”自底向上升。在每一层，它直接与**父节点**中存储的“败者”进行比较。
	        *   如果新值“赢”了（比父节点存的败者更优），新值继续向上，父节点保留原来的败者。
	        *   如果新值“输”了（不如父节点存的败者），新值留在父节点变成新的败者，原父节点里的值作为胜者继续向上。
	    *   **优势（题目中的“避免迂回”）：** 调整时，我们只需要访问**父节点**的内容即可。父节点本身就在回溯的路径上。我们**不需要去访问兄弟节点**。这减少了内存地址的计算和访存跳转，因此在常数系数上，败者树比胜者树更快。
**总结：**
胜者树比较的是**兄弟**（Off-path），败者树比较的是**父节点**（On-path）。败者树简化了寻址和访存，因此常系数更优。

- 衍生 
	- 关于败者树和胜者树的高频考点  
		- 时间复杂度与空间复杂度 
			- 无论是胜者树还是败者树，对于$k$路归并： #k路归并排序的时间复杂度和空间复杂度（胜者树，败者树）  
				*   **树的高度：** $h=\lceil\log_2k\rceil$。
				*   **建树时间：** $O(k)$。
				*   **调整（删除/插入）时间：** $O(\log k)$。
				*   **总排序时间（n个元素）：** $O(n\log k)$。
				*   **空间复杂度：** 都需要$O(k)$的辅助空间来存储内部节点。
		- #败者树的重构逻辑   
			- 考题可能会给你一组数，让你画出败者树，或者模拟一次输出后的调整过程。
			*   **规则：** 父节点存败者，胜者往上走。
				*   **最终结果：** $ls[0]$存储最终冠军的索引。
		- #置换-选择排序   
			- 败者树常用于生成外部排序的初始归并段（Run）。
				*   **考点：** 生成的归并段长度不是固定的，平均长度是内存工作区大小的$2$倍。
				*   **公式：** 设内存工作区可容纳$m$个记录，则生成的初始归并段平均长度为$2m$。
		- I/O次数的计算  [[文件块访问次数（磁盘IO次数）]]   
			- 这是 #外部排序计算题的核心 。
				*   **公式：** 设共有$m$个初始归并段，进行$k$路归并。
				    *   #归并趟数 ： $S=\lceil\log_k m\rceil$。
				    *   **增加k的影响：** 增大$k$可以减少归并趟数$S$，从而减少磁盘I/O次数。但是$k$过大，内部归并比较次数$O(n\log k)$会增加（虽然败者树缓解了比较开销，但I/O读写变得离散，未必总是越快越好）。
		- 对比总结  
			- **胜者树：** 调整时看兄弟，适合并行计算（因为子树之间独立）。
			*   **败者树：** 调整时看父节点，减少访存，常系数小，是单线程外部排序的首选。 
- 简单记忆 LaTeX 公式：
	*   调整复杂度：$O(\log k)$
	*   归并趟数：$S=\lceil\log_k m\rceil$

![[Pasted image 20251215195215.png]]
[[Pasted image 20251119162639.png]]

- “使用胜者树可以在$O(n\log n)$时间内完成排序，**但败者树不行**”。这个后半句的表述是错误的。
1.  **本质相同：**  #胜者树 （Winner Tree）和 #败者树 （Loser Tree）本质上都是 #多路选择树 （Tournament Tree），它们都是 #完全二叉树 结构 
2. **功能一致：** 它们的作用都是为了从$n$个元素（或$k$个归并段）中快速选出最大或最小的元素。
3.  **时间复杂度一致：**
    *   **建树：** 无论是胜者树还是败者树，初始化的时间复杂度通常为$O(n)$。
    *   **调整（重构）：** 当取走根节点（当前最值）并读入下一个元素后，都需要沿着从叶子到根的路径进行调整。树的高度为$\lceil\log_2 n\rceil$，因此单次调整的时间复杂度均为$O(\log n)$。
    *   **排序总耗时：** 对$n$个元素进行排序，需要执行$n$次“取值+调整”的操作。因此，总的时间复杂度为$n\times O(\log n)=O(n\log n)$。

因此，败者树完全可以在$O(n\log n)$的时间内完成排序 ，题目中的否定描述是错误的  

- 这道题目涉及的数据结构通常出现在**外部排序**的**多路归并**章节，也可以作为一种 #内部排序算法（锦标赛排序） 。  
- 衍生  
	- 外部排序中的 k 路归并  
		- **考点：** 在将$k$个有序段归并成一个有序段时，如果使用普通的比较法，每次选出最小值需要$k-1$次比较，总复杂度为$O(N\cdot k)$（$N$为总记录数）。而使用败者树（或胜者树），可以将比较次数降低。
		*   **公式：** 使用败者树进行$k$路归并，选出一个最小值的比较次数约为$\lceil\log_2 k\rceil$。归并$N$个元素的总时间复杂度优化为$O(N\log k)$。 
	* 空间复杂度与堆排序的对比  
		*   **考点：** 堆（Heap）、胜者树、败者树都可以用于$O(n\log n)$的排序，区别在哪里？
		*   **区别：**
		    *   **堆排序**是原地排序，辅助空间复杂度为$O(1)$。
		    *   **胜者树/败者树**需要额外的存储空间来维护树的结构（内部节点），辅助空间复杂度为$O(n)$（归并时为$O(k)$）。
		    *   因此，在单纯的内部排序（内存足够）场景下，通常首选堆排序；而在外部排序（需要减少I/O和内存访问）场景下，败者树更常见。
	* 败者树的调整细节 
		* **考点：** 可能会考察败者树具体的重构过程。
		*   **细节：** 当一个新的胜者“浮”上来时，它与父节点记录的元素（上次的败者）比较。
		    *   如果新胜者比父节点记录的值更“强”（如更小），则新胜者继续上升，父节点内容保持不变（因为父节点记录的败者确实比新胜者弱）。
		    *   **注意（易错点）：** 如果新胜者比父节点记录的值“弱”，则**新胜者变为败者留在该父节点**，而原父节点记录的值（之前的败者，但在当前比较中是胜者）代替它继续上升。
	- 树的高度  
		- **考点：** 对于$k$路归并或$n$个元素的排序，树的高度（比较路径长度）是多少？
		*   **公式：** 深度（或比较次数）通常为$h=\lceil\log_2 k\rceil$或$\lceil\log_2 n\rceil$。 



![[Pasted image 20251215195222.png]]
[[Pasted image 20251119162648.png]]

- 左式堆的一个核心性质：节点数量与右侧路径长度的关系  
1. 答案选择 (B)：至少；$2^{k+1}-1$   
	1. [[左式堆]]  
		1. #左式堆
			1. 对于堆中的任意节点$x$，其左子节点的**零路径长度（NPL, Null Path Length）**必须大于等于右子节点的零路径长度。即$npl(left(x))\ge npl(right(x))$。
			    *   这意味着：从根节点出发，**向右走的路径**总是通往空节点（或叶子节点）的**最短路径**。 
2. 寻找“至少”包含多少节点  
	1. 题目问的是在右侧路径长度固定为$k$的情况下，节点数量**最少**是多少。
	    *   为了使节点数量最少，我们需要让树尽可能的“瘦”。
	    *   但是，受限于左式堆的性质（左边必须比右边“重”或相等），最“瘦”的情况就是**左子树的NPL刚好等于右子树的NPL**。
	    *   当每一个节点的左右子树NPL都相等时，这就构成了一棵**满二叉树（Perfect Binary Tree）**。
3. 数学计算：  
	1. 如果右侧路径长度为$k$（这意味着树的层数或者是高度关联到$k$），在最少节点的情况下，这就形成了一棵高度为$k$的满二叉树。
	    *   一棵高度为$k$的满二叉树，其节点总数由几何级数求和得出：
	        第0层有$2^0$个，第1层有$2^1$个，...，第$k$层有$2^k$个。
	    *   总节点数$N=\sum_{i=0}^{k}2^i$。
	    *   根据等比数列求和公式，结果为$2^{k+1}-1$。
4. 关于图片中“外部节点”的补充解释  
	1. 图片解析中提到了“$2^k-1$个内部节点”和“$2^{k+1}-1$个节点”。这通常是在 #扩充二叉树  的语境下讨论的，其中把空指针看作“外部节点”。但在常规的数据结构考题中（如本题），通常直接问的是树中实际存在的节点总数，即满二叉树的节点总数$2^{k+1}-1$
- 衍生 
	- 左式堆，考试通常会从以下几个角度进行考察：
		- 考点一：最大右路径长度（树的高度） 
			- 本题的逆向思维。如果一个左式堆有$n$个节点，它的右侧路径长度$r$最大是多少？
				*   根据本题结论，$n\ge2^{r+1}-1$。
				*   两边取对数，可以得出右路径长度$r$是$O(\log n)$级别的。
				*   **公式：** 右路径长度$r\le\lfloor\log_2(n+1)\rfloor-1$。
				*   **意义：** 这保证了左式堆的基本操作（特别是合并）的时间复杂度与$O(\log n)$成正比。
	- #左式堆合并操作的时间复杂度       
		-   左式堆的插入（Insert）和删除最小值（Delete Min）本质上都是合并操作。
		*   合并两个左式堆是沿着**右侧路径**进行的。
		*   因为右侧路径长度不超过$O(\log n)$，所以合并操作的时间复杂度是$O(\log n)$。
		*   **对比：** 普通二叉堆（Binary Heap）合并通常需要$O(n)$，这是左式堆的主要优势
	- 左式堆的构建与调整  
		- 考察在合并过程中，如果某节点的左孩子NPL小于右孩子NPL，必须**交换左右子树**以维护左式性质。
		*   **题目形式：** 给定两个具体的左式堆，画出合并后的结果。  
	*  #左式堆vs斜堆 
		* #斜堆 是左式堆的自调节版本（类似于Splay Tree之于AVL Tree）。 
		*   斜堆**不记录NPL**，也不要求严格的左式性质，而是通过无条件交换左右子树来达到摊还复杂度$O(\log n)$。考题可能会问二者的区别（左式堆是严格的最坏情况$O(\log n)$，斜堆是摊还$O(\log n)$）




![[Pasted image 20251215195228.png]]
[[Pasted image 20251119163335.png]]
数据结构中 #左式堆 （题目中提到的“ #crane算法”应指代左式堆的合并操作或特定教材中的叫法，其核心即为标准的左式堆合 并算法）及其性质的判断题  

- **推导过程：**
	1.  **合并过程**： #左式堆的合并操作 确实是沿着两个堆的**右侧路径**进行的。我们将两个堆的右路径类似于归并排序那样合并成一个新的路径。  [[左式堆]]
	2.  **性质维护（关键点）**：左式堆必须满足**左式性质**，即对于任意节点$x$，其左子节点的零路径长（NPL）必须大于等于右子节点的零路径长，即$npl(x.left)\ge npl(x.right)$。
	3.  **交换操作**：当合并操作递归返回时，新的右子树可能因为合并了另一个堆而变得“更重”（NPL变大）。如果此时根节点的右子节点的NPL变得比左子节点还大（违反了左式性质），算法会**交换**该根节点的左右子节点。
	4.  **结论**：一旦发生交换，原本位于**左侧**的子节点就会变成**右侧**子节点，从而出现在最终堆$H$的右侧路径上。因此，$H$右侧链上的节点不一定全来自$A$或$B$原本的右侧链，也可能来自它们原本的左子树。
- 结合图片中的实例（j）到（k）
	- 注意看图中(j)部分，节点17的左子树（以15为根）和右子树（以13为根）发生了**swapped（交换）**。交换后，原本在左边的节点15及其子树变成了右子树。这就直接证明了题目中的观点。   
- 衍生 
	- #左式堆的时间复杂度   
		*   **考点**：问你左式堆的合并、插入、删除最小元的时间复杂度。
		*   **解答**：由于左式堆的右路径长度最多为$O(\log N)$，而所有操作都主要沿着右路径进行，因此合并、插入（看作与单节点堆合并）、删除最小元（合并左右子树）的复杂度均为$O(\log N)$。
	- #左式堆NPL的计算  
		- **考点**：给出一棵具体的树，让你计算根节点或某个特定节点的NPL值。
		*   **解答**：记住$npl(null)=-1$，叶子节点的$npl=0$，非叶子节点$npl=1+\min(left,right)$。如果是合法的左式堆，直接看右子树深度即可。
	* 最大节点数量与右路径的关系  
		* **考点**：如果一个左式堆的右路径上有$r$个节点，那么该堆至少包含多少个节点？
		*   **解答**：这不仅是考察左式堆，也是考察满二叉树的性质。因为右路径是最短路径，如果右路径长为$r$，则这就意味着该树包含了一棵高度为$r$的满二叉树（Perfect Binary Tree）。
		    公式：至少有$2^r-1$个节点。
	- #左式堆vs斜堆    
		- **考点**：斜堆是左式堆的自调节版本（类似于Splay Tree之于AVL Tree）。可能会问二者的区别。
		*   **解答**：
		    *   左式堆需要维护$npl$，只有在违反性质时才交换左右子树。
		    *   斜堆**不需要**维护$npl$，在每次合并后**无条件交换**左右子树（除了右路径上最大的那个节点可能例外）。
		    *   斜堆的最坏情况是$O(N)$，但摊还复杂度（Amortized Complexity）是$O(\log N)$。
	- #建堆（左式堆）过程模拟   
		-  **考点**：给出一组序列，要求画出逐步插入（即不断合并）后的左式堆形态。
		*   **技巧**：严格执行“先沿右路合并，再回溯检查NPL并交换”的步骤。这道题里的图片就是这类题目的分解动作。




![[Pasted image 20251215195235.png]]
[[Pasted image 20251119163344.png]]

 **核心定义：** 左式堆的定义是基于[[零路径长]]简称$npl$的，而不是基于树的高度。
*   **左式堆性质：** 对于堆中的任意节点$x$，其左孩子的$npl$必须大于或等于右孩子的$npl$。
    公式表示为：$npl(left\_child(x))\ge npl(right\_child(x))$。
*   **为什么题目是错的？**
    *   **高度（Height）**：节点到最远叶子节点的距离。
    *   **零路径长（NPL）**：节点到最近的“空节点”（或外部节点）的距离。
    *   虽然左式堆倾向于让左子树更“重”，但这仅仅是指到达空节点的路径长。右子树完全可以是一个非常“瘦高”的树（例如，右子树只有左孩子一直延伸下去，而右孩子的右孩子为空），此时右子树的$npl$很小（因为很快遇到空节点），但$height$很大。
    *   **反例（结合图片解析）：**
        看图中红色的节点（标号为2）。它的左孩子$npl=1$，右孩子$npl=1$。满足左式堆性质$1\ge 1$。但是，我们观察该节点的右子树，虽然它的“最近空节点距离”很短，但它可能有一条非常长的路径（比如它的左分支延伸很长），导致右子树的实际高度高于左子树。

**结论：** 左式堆限制的是$npl$，而不是$height$。因此$L.height\ge R.height$不是左式堆的必要条件。

- 衍生   
	- #npl的计算与验证（左式堆）     
		- 题目可能会给出一棵树，让你计算根节点的$npl$，或者判断它是否为左式堆。
		*   **解题技巧：** 自底向上计算。叶子节点的$npl$通常为1（如果定义NULL为0）。非叶子节点的$npl$等于其$min(npl(左),npl(右))+1$。如果发现任何节点$npl(左)<npl(右)$，则它不是左式堆。
	- #最右路径长度    
		-   **问题：** 一个包含$N$个节点的左式堆，其最右路径长度（Right Path Length）最多是多少？
		*   **公式：** 右路径长度$r$与节点数$N$满足关系：$N\ge 2^r-1$。
		*   **结论：** 右路径长度最多为$\lfloor\log_2(N+1)\rfloor$。这是左式堆操作高效（$O(\log N)$）的基础。
	- #合并操作—— 核心考点  
		- 左式堆最著名的操作是合并，也是相比于二叉堆（Binary Heap）的优势所在。
		*   **过程：**
		    1.  比较两个堆根节点的大小，将根节点较小的堆作为主堆，较大的堆与主堆的**右子树**进行合并。
		    2.  递归合并后，如果发现新生成的右子树的$npl$大于左子树的$npl$（破坏了左式性质），则**交换左右子树**。
		    3.  更新当前节点的$npl$。
		*   **时间复杂度：** $O(\log N)$。
	- #左式堆vs斜堆  
		*   **解析：** 斜堆是左式堆的自调节形式（类似于Splay树之于AVL树）。斜堆**不需要**维护$npl$信息，在合并后无条件交换左右子树。斜堆具有均摊$O(\log N)$的时间复杂度，而左式堆是最坏情况$O(\log N)$。  
	* 辨析题   
		*   判断：左式堆一定是一棵完全二叉树吗？  -> **False**（左式堆通常非常不平衡，极度向左倾斜，完全二叉树是二叉堆的特性）。
		*   题目： 左式堆根节点的左子树节点数（Size）一定大于右子树吗？
			*   **答案：** **False (❌)**。
			*   **修正后的解析：** $npl$ 只限制了“通往空节点的距离”，并不限制节点总数。**右子树完全可以包含大量的节点**（例如：右子树本身是一棵极度向其自身左侧发展的树，虽然它没有右孩子导致 $npl$ 很小，但它的左分支可以拥有无数节点）。因此，右子树的节点数完全可能超过左子树。


![[Pasted image 20251215195243.png]]
[[Pasted image 20251119163352.png]]
题目考察的是 #左式堆 （也称为左偏树）的性质，特别是关于[[零路径长]] 与节点数量关系的计算。    
1. 答案 **2019** 是基于左式堆的性质以及“使得右子堆最大化”这一目标推导出来的。核心逻辑在于：为了让右子堆尽可能大，必须让左子堆尽可能小，但左子堆的NPL必须满足左式堆的约束条件
2. 定义回顾 
	1. NPL（零路径长） 一个节点到其后代中最近的“空节点”（external node）的路径长度。  
	2. #左式堆的性质  [[左式堆]]
		1. 对于任意节点 $x$，其左孩子的NPL必须大于等于右孩子的NPL，即 $NPL(Left) \ge NPL(Right)$。 
	3. #节点数与NPL的关系   
		1. 一个NPL为 $k$ 的左式堆，至少包含 $2^{k+1}-1$ 个节点（有些定义中NPL从-1或0开始，这里根据题目答案2019推断，采用的是“NPL=1时，最少需要3个节点”的定义，即满二叉树的性质）。  
3. 目标设定   
    *   总节点数 $N=2023$。
    *   根节点占用 $1$ 个。
    *   剩余 $2022$ 个节点分配给左子树（$L$）和右子树（$R$）。
    *   目标：最大化 $|R|$。
    *   手段：最小化 $|L|$。
4. 约束分析  
	-  根据性质：$NPL(L) \ge NPL(R)$。
    *   为了让 $|L|$ 最小，我们应当选取满足条件的 #最小合法左式堆 
    *   **关键点**：根据题目给出的答案 2019，我们可以反推题目所隐含的“最小非平凡情况”或特定定义下的NPL层级。
    *   如果 $NPL(R)$ 能够取最小值（比如对应“叶子节点”层级），通常左子树最少只需要1个节点。但答案不是 2021 ($2023-1-1$)，而是 2019 ($2023-1-3$)。
    *   这说明题目设定右子堆的结构使得 $NPL(R)$ 处于一个层级，该层级要求左子树至少有 **3个节点**。
    *   3个节点是**NPL=1**（假设空节点NPL=-1，叶子NPL=0）或对应高度为1的满二叉树的最小节点数。
    *   **推导逻辑**：假设右子堆是一个具有一定结构的堆（例如，$NPL(R)$至少为某个值，或者题目隐含了根节点的NPL属性），为了维持 $NPL(L) \ge NPL(R)$，且已知 $NPL(R)$ 的某种状态导致左子树最少需要是一棵满的“根+左+右”的小树（大小为3）。
	* 计算：
        $|R|_{max} = Total - 1 - |L|_{min}$
        $|R|_{max} = 2023 - 1 - 3 = 2019$
**结论**：答案 2019 是在假设**左子树必须至少包含3个节点**（即满足 $NPL(L) \ge 1$ 的最小满树结构）的情况下得出的。这通常发生在右子树的NPL被假定为 1 时。

- 衍生 
	- #右路径长度的最大值   
		- **考点**：给定 $N$ 个节点，右路径（Right Spine）最多有多少个节点？
	    *   **公式**：$r \le \lfloor \log_2(N+1) \rfloor$。
	    *   **例子**：2023个节点，右路径最多有 $\lfloor \log_2(2024) \rfloor = 10$ 或 $11$ 个节点（取决于是否包含根的计数方式）。
	- 合并操作 (Merge) 的复杂度  [[左式堆的合并算法]] 
		- **考点**：左式堆的核心优势在于合并。
	    *   **知识**：合并两个左式堆的时间复杂度是 $O(\log N)$，因为合并操作只沿着右路径进行。
	- 最小节点数与dist的关系   
		- **考点**：给定一个 $dist$ 值（或NPL），问子树最少有多少个节点？ #NPl（dist） [[dist (左式堆）]] 
	    *   **公式**：$MinNodes(d) = 2^{d} - 1$ （具体指数取决于 $dist$ 对空节点的定义是0还是-1）。这是本题答案推导的核心依据。
	- 构建与调整  
		- **考点**：给出一组数，画出插入或合并后的左式堆。
	    *   **注意**：在合并后，如果某节点的左孩子 $dist$ 小于右孩子 $dist$，需要**交换左右孩子**并更新 $dist$ 值。
- 总结
	这道题是一道典型的利用**数据结构极值性质**的反向推导题。它考察的不是直接计算，而是对“左式堆为了维持性质，左子树有最小节点数限制”这一点的理解。答案 2019 对应了左子树取最小非叶子结构（大小为3）的情况。 


![[Pasted image 20251215195250.png]]
[[Pasted image 20251119163357.png]]

- 该题目主要考察的是  左式堆   这种数据结构的特性，特别是其核心操作的时间复杂度  
1. 核心逻辑：右侧路径长度决定时间复杂度  
	1. 图片左上角的示意图中明确指出：“所需时间 $\propto$ 右侧藤总长”。左式堆的特殊性质保证了其**右侧路径**（从根节点一直往右孩子走的路径）的长度非常短，对于$n$个节点的左式堆，右路径长度最多为$O(\log n)$。 
2. Merge (合并) 操作
	1. 左式堆的所有操作基础都是 **Merge**。合并两个左式堆时，实际上是沿着两个堆的“右侧路径”进行递归合并。由于右侧路径长度限制在$O(\log n)$，因此 `merge` 操作的时间复杂度为$O(\log n)$。
3. Insert (插入) 操作  
	1. 图片左下角的代码显示，`insert` 被实现为：将新节点看作一个只有一个节点的堆，然后与原堆进行 `merge`。
	    代码：`_root = merge( _root, new BinNode<T>( e, NULL ) );`
	    因为 `merge` 是$O(\log n)$，所以 `insert` 也是$O(\log n)$。
4. DelMax (删除最大/最小) 操作  
	1. 图片右上角的代码显示，`delMax` 的过程是：删除根节点，然后将其**左子树**和**右子树**进行 `merge`。
	    代码：`_root = merge( lHeap, rHeap );`
	    同样，因为 `merge` 是$O(\log n)$，所以 `delMax` 也是$O(\log n)$。
- **结论：** 正是因为左式堆巧妙地利用 `merge` 操作统一了插入和删除，且 `merge` 的复杂度被右路径长度限制在$O(\log n)$，所以题目所述“三者时间复杂度同时优化到$O(\log n)$”是正确的。  
	[[左式堆]] 
- **关键推论：**
	正是因为左边总是比右边“厚实”，所以树的“右路径”是最短的通路。数学上可以证明，如果一个左式堆有$n$个节点，其右侧路径的长度$r$满足：
	$r \le \lfloor \log_2(n+1) \rfloor$
	即右路径长度是$O(\log n)$级别的。
- 衍生  
	-   #左式堆vs普通二叉堆 
		- **普通二叉堆：** 基于数组实现的完全二叉树。
		    *   `insert`: $O(\log n)$（均摊可以是$O(1)$）。
		    *   `delMax`: $O(\log n)$。
		    *   `merge`: **$O(n)$**（这是普通堆的弱点，合并需要把所有数据重新建堆）。
		* **左式堆：**
		    *   `merge`: **$O(\log n)$**（优势所在）。
		    *   代价是需要额外的空间存储$npl$值，且不再是完全二叉树，不能用数组简单存储，指针操作带来少量额外开销。
	* #斜堆  
		* **考点：** 斜堆是左式堆的自调节版本（类似于Splay Tree之于AVL Tree）。
		*   **区别：** 斜堆不需要维护$npl$值。在 `merge` 后，它无条件交换左右子树。
		*   **复杂度：** 斜堆的所有操作（merge, insert, delete）的**摊还复杂度 (Amortized Complexity)** 为$O(\log n)$，但最坏情况可能是$O(n)$。
	- #维护左式性质（调整操作）  
		- **考题形式：** 给出两个左式堆，画出合并过程。
		*   **步骤：**
		    1.  假设两个堆根节点为$A$和$B$，且$A.data < B.data$（小顶堆为例）。
		    2.  保留$A$作为根，递归合并$A$的右子树和$B$。
		    3.  **关键点：** 合并返回后，检查$A$的左右孩子是否满足$npl(left) \ge npl(right)$。如果不满足，**交换左右孩子**，并更新$A$的$npl$。
	- #节点数与路径长度的关系（左式堆）    
		- **公式题：** 右路径长度为$r$的左式堆，至少包含多少个节点？
		*   **答案：** 至少包含$2^r - 1$个节点。这是证明右路径长度为$O(\log n)$的基础。

[[优先级队列可能考但没考的知识点]] 

![[Pasted image 20251119163407.png]]