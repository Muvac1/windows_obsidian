![[912历年真题解析-组成原理篇（2024.12.2）.pdf#page=10&rect=17,377,579,808|912历年真题解析-组成原理篇（2024.12.2）, p.10]]

1. 这道题主要考察计算机组成原理中的[[流水线技术]]   [[流水线]]   [[流水线性能分析]]  
	1. 流水线时钟周期$T_{clk}$   
		1. 公式为：$T_{clk} = \max(T_{stage\_i}) + T_{reg}$
			1. 其中，$T_{stage\_i}$ 是第 $i$ 个流水段的组合逻辑延迟 ，$T_{reg}$ 是 #流水线寄存器 （题目中的“寄存器”或“锁存器”）的延迟  
	2. #流水线延迟    
		1. 指单条指令从进入流水线到执行完成所需要的总时间。对于一个 $k$ 级的流水线，其延迟为：
		    公式为：$Latency = k \times T_{clk}$   
	3. #流水线吞吐率   
		1. 指单位时间内流水线能够完成的指令数量，是衡量流水线性能的重要指标。理想情况下，当流水线“充满”后，每个时钟周期都能完成一条指令。
		    公式为：$Throughput = \frac{1}{T_{clk}}$
		    吞吐率的单位通常是 GIPS 
2. 我们整理一下已知条件：
	*   组合逻辑部件延迟：A=40ps, B=20ps, C=35ps, D=15ps, E=15ps, F=25ps。
	*   总逻辑延迟 = $40+20+35+15+15+25 = 150ps$。
	*   寄存器延迟 $T_{reg} = 10ps$。
-  (1) 4级流水线设计
1. **目标**：构建一个4级流水线，需要插入 $4-1=3$ 个寄存器。为了使流水线性能最好（即时钟周期最短），我们应该尽量让每个流水段的逻辑延迟大致相等。  
	1. 分析  
		1. 总逻辑延迟为150ps，分成4段，理想情况下每段的逻辑延迟为 $150/4 = 37.5ps$。我们根据这个理想值来划分逻辑部件：
			*   A (40ps) 本身就接近37.5ps，可以单独作为一段。
			*   B (20ps) + C (35ps) = 55ps。
			*   D (15ps) + E (15ps) = 30ps。
			*   F (25ps)。
2. 只是一个粗略的划分，我们需要尝试不同的组合。题解中给出的方案是：在AB之间、BC之间、DE之间插入寄存器。我们来分析这种划分方式：
	*   **段1**: 逻辑部件 A。逻辑延迟 $T_{stage1} = 40ps$。
	*   **段2**: 逻辑部件 B。逻辑延迟 $T_{stage2} = 20ps$。
	*   **段3**: 逻辑部件 C + D。逻辑延迟 $T_{stage3} = 35ps + 15ps = 50ps$。
	*   **段4**: 逻辑部件 E + F。逻辑延迟 $T_{stage4} = 15ps + 25ps = 40ps$。
3. 计算时钟周期  
	1. 时钟周期由最长的逻辑段决定。
		$T_{clk} = \max(40, 20, 50, 40) + T_{reg} = 50ps + 10ps = 60ps$
		这个最长的段就是由C和D组成的逻辑段，与题解“最长的流水段为C+D+锁存器=60ps”的描述一致。  
4. 计算延迟和吞吐率  
	1. 延迟  
		1. $Latency = k \times T_{clk} = 4 \times 60ps = 240ps$
	2. 最大吞吐率
	    $Throughput = \frac{1}{T_{clk}} = \frac{1}{60ps} = \frac{1}{60 \times 10^{-12}s} \approx 16.67 \times 10^9 \text{ Instructions/s} = 16.67 \text{GIPS}$
- (2) 达到最大吞吐率的设计  
1. 目标  ：要达到最大吞吐率，根据公式 $Throughput = 1/T_{clk}$，就是要使**时钟周期 $T_{clk}$ 最小化**。  
	1. 时钟周期 $T_{clk} = \max(T_{stage\_i}) + T_{reg}$。要使其最小，就必须使最长的逻辑段延迟 $\max(T_{stage\_i})$ 最小。
		#逻辑部件 是不可再分的，其中延迟最长的单个部件是A（40ps）。因此，任何流水段的逻辑延迟都不可能小于40ps（除非A本身被分成一段）。所以，$\max(T_{stage\_i})$ 的理论最小值就是最长的那个不可分部件的延迟，即40ps    
2. 设计流水线  
	1. 以40ps为上限来划分逻辑段，只要一个组合的延迟超过40ps，就必须插入寄存器。
		*   **段1**: A (40ps)。延迟为40ps，达到上限，必须在此之后插入寄存器。
		*   **段2**: B (20ps)。延迟为20ps。
		*   **段3**: C (35ps)。延迟为35ps。
		*   **段4**: D (15ps)。延迟为15ps。
		*   **段5**: E (15ps) + F (25ps) = 40ps。延迟为40ps。
	2. 这样，我们得到了一个5级流水线，各段的逻辑延迟分别为 {40ps, 20ps, 35ps, 15ps, 40ps}。寄存器被插在了A之后(AB之间)、B之后(BC之间)、C之后(CD之间)、D之后(DE之间)。
3. 计算时钟周期  
	1. $T_{clk} = \max(40, 20, 35, 15, 40) + T_{reg} = 40ps + 10ps = 50ps$
		这个最长的段是由A或者E+F组成的逻辑段，与题解“最长的流水段为A+锁存器=50ps”的描述一致。 
4. 计算延迟和吞吐率  
	1. 延迟   
		1. $Latency = k \times T_{clk} = 5 \times 50ps = 250ps$  
	2. 最大吞吐率  
		1. $Throughput = \frac{1}{T_{clk}} = \frac{1}{50ps} = \frac{1}{50 \times 10^{-12}s} = 20 \times 10^9 \text{ Instructions/s} = 20 \text{GIPS}$  
- 衍生    
	- #流水线加速比 
		- 考题可能会问，相比于不使用流水线的单周期处理器，该流水线的加速比是多少？
		    *   单周期处理器执行一条指令的时间 $T_{non-pipeline} = \text{总逻辑延迟} + \text{寄存器延迟} = 150ps + 10ps = 160ps$。
		    *   流水线处理 $n$ 条指令的时间 $T_{pipeline} = (k + n - 1) \times T_{clk}$。
		    *   当 $n$ 很大时，加速比 $S \approx \frac{T_{non-pipeline}}{T_{clk}}$。
		    *   例如，对于问题(2)中的5级流水线，其理想加速比为 $S \approx \frac{160ps}{50ps} = 3.2$
	- 流水线冲突 
		- 考题可能会给出一个指令序列，让你找出其中存在的冲突，并说明如何通过**暂停（Stall）**、数据前推（Forwarding）或分支预测（Branch Prediction）等技术来解决 
	- 流水线效率和开销
		-  **开销 (Overhead)**: 主要是指流水线寄存器的延迟。如果将流水线分得过细（例如，每1ps就插入一个寄存器），寄存器延迟的占比会越来越大，反而可能降低性能。考题可能让你分析流水线级数和性能的非线性关系。


![[Pasted image 20251117105754.png]]
[[Pasted image 20251117105801.png]]
[[MIPS处理器微架构(单周期,多周期,流水线)]]    
[[mips指令集简写]] 
-  这道题考察  #三种经典的处理器设计思想 ：单周期（Single-Cycle）、多周期（Multi-Cycle）和流水线（Pipelined）设计  
1. 单周期处理器  
	1.   **核心思想**: 每条指令都在一个时钟周期内完成。
	    *   **时钟周期**: 必须设置为**最长指令**的执行时间，因为时钟周期要能容纳下最复杂、路径最长的那条指令（通常是`lw`指令）。
	    *   **性能**: CPI (Cycles Per Instruction) 恒为1，但时钟频率很低，因为周期太长。
2. 多周期处理器
	1. **核心思想**: 将一条指令的执行过程划分为多个（通常是3-5个）基本步骤，每个步骤在一个时钟周期内完成。不同指令执行所需的步骤数可以不同  
		1. 时钟周期  
			1. 由**最长的功能单元/步骤**的延迟决定。例如，如果内存访问最慢，时钟周期就由内存访问时间决定  
		2. 性能  
			1. 时钟频率比单周期高，但CPI大于1。不同指令的CPI不同，例如`lw`需要5个周期，`j`可能只需要2个周期 
3. 流水线处理器 
	1. 核心思想  
		1.  将指令执行过程划分为多个阶段（Stage），让多条指令的不同阶段在同一时刻重叠执行，像工厂流水线一样  
	2. 时钟周期  
		1. 由**最长的流水线阶段**的延迟决定。为了让流水线顺畅流动，所有阶段的耗时必须统一，这个统一的时间就是时钟周期 
	3. 性能 
		1.  理想情况下，CPI趋近于1，并且时钟频率较高（取决于最长阶段），因此吞吐率（Throughput）极高。但会遇到数据冒险、控制冒险等问题  
- 题目参数梳理  
	*   内存（指令/数据）读/写延迟: $t_{mem}=10ns$
	*   ALU延迟: $t_{ALU}=6ns$
	*   寄存器堆（Register File）读延迟: $t_{RFread}=3ns$
	*   寄存器堆（Register File）写延迟: $t_{RFwrite}=1ns$
	*   流水线寄存器/PC 输出延迟: $t_{latch}=2ns$
-  (1) 按单周期设计，计算指令延迟  
	1. `lw`指令的执行路径如下：
	2.  **取指 (IF)**: 从PC寄存器输出地址，到指令存储器读取指令。
	    *   路径：PC -> 指令存储器
	    *   延迟：$t_{PCout} + t_{mem} = 2ns + 10ns = 12ns$
	3.  **译码/读寄存器 (ID)**: 读取基址寄存器（rs）。
	    *   路径：寄存器堆读
	    *   延迟：$t_{RFread} = 3ns$
	4.  **执行 (EX)**: ALU计算有效地址（基址 + 立即数偏移量）。
	    *   路径：ALU
	    *   延迟：$t_{ALU} = 6ns$
	5.  **访存 (MEM)**: 从ALU计算出的地址去数据存储器读取数据。
	    *   路径：数据存储器
	    *   延迟：$t_{mem} = 10ns$
	6.  **写回 (WB)**: 将从内存读出的数据写入目标寄存器（rt）。
	    *   路径：寄存器堆写
	    *   延迟：$t_{RFwrite} = 1ns$
	将这些串行路径的延迟相加，得到`lw`指令的总延迟：
	$T_{single-cycle} = t_{PCout} + t_{mem\_IF} + t_{RFread} + t_{ALU} + t_{mem\_MEM} + t_{RFwrite}$
	$T_{single-cycle} = 2ns + 10ns + 3ns + 6ns + 10ns + 1ns = 32ns$
- **结论**: 在单周期设计中，时钟周期为32ns。由于所有指令都占用一个完整的时钟周期，所以**任何指令的延迟都是32ns**。
- (2) 按多周期设计，最长和最短的指令延迟分别是多少？  
1. 最长的操作是内存访问，需要10ns 
	1.  但是，答案的解析采用了一种更接近流水线阶段划分的思路来计算时钟周期，即把**一个阶段内所有串行操作的延迟**（包括锁存器延迟）加起来，取最大值。我们按照这个思路来推导：
		1. IF阶段  
			1. PC输出 -> 读指令存储器 -> 锁存到下一级。延迟 = $t_{PCout} + t_{mem} + t_{latch} = 2ns + 10ns + 2ns = 14ns$
		2. ID阶段  
			1. 读寄存器 -> 锁存。延迟 = $t_{RFread} + t_{latch} = 3ns + 2ns = 5ns$  
		3. EX阶段  
			1. ALU计算 -> 锁存。延迟 = $t_{ALU} + t_{latch} = 6ns + 2ns = 8ns$  
		4. MEM阶段  
			1. 读/写数据存储器 -> 锁存。延迟 = $t_{mem} + t_{latch} = 10ns + 2ns = 12ns$  
		5. WB阶段  
			1. 写寄存器 -> 锁存。延迟 = $t_{RFwrite} + t_{latch} = 1ns + 2ns = 3ns$
 2. 最长的阶段是IF阶段，为14ns。所以多周期设计的时钟周期 $T_{multi-cycle} = 14ns$
	1. 最长指令  
		1. `lw`指令，需要经历IF, ID, EX, MEM, WB共5个阶段  
			1. 所需时钟周期数: 5
		    *   指令延迟: $5 \times T_{multi-cycle} = 5 \times 14ns = 70ns$ 
	2. 最短指令  
		1. `j` (jump) 指令。它只需要两个阶段：  
			1.  **IF**: 取指令。
		    2.  **ID**: 译码并直接计算出跳转地址更新PC。
			    *   所需时钟周期数: 2
			    *   指令延迟: $2 \times T_{multi-cycle} = 2 \times 14ns = 28ns$
	-  关于`j`指令周期的说明 
		- 为什么是2个周期而不是3个？在标准的 #多周期MIPS 实现中，`j`和`beq`指令的 #目标地址 计算和PC更新都在ID/Control阶段完成，不需要经过 #算术逻辑单元ALU  。因此`j`指令在第2个周期结束时就能更新PC，下一条指令就可以从新地址开始取指。所以2个周期是标准答案。答案中提到的“按三个周期算是42ns”是考虑到了某些简化的模型可能会把PC更新放到EX阶段，这是一种保守或非优化的实现  
	- **结论**: 最长指令是`lw`，延迟为**70ns**。最短指令是`j`，延迟为**28ns**。
- (3) 按五级流水线设计，处理器频率最高能到多少？  
1. 流水线设计中，时钟周期由**最长的流水线阶段**的延迟决定。这个计算我们在问题(2)中已经完成了  
	*   IF阶段延迟: 14ns
	*   ID阶段延迟: 5ns
	*   EX阶段延迟: 8ns
	*   MEM阶段延迟: 12ns
	*   WB阶段延迟: 3ns
2. 最长的阶段是IF阶段，其延迟为14ns。为了保证流水线能同步工作，时钟周期必须至少为14ns。
	$T_{pipeline} = \max(14, 5, 8, 12, 3) = 14ns$  
	1. 处理器最高频率是时钟周期的倒数：
		$f_{max} = \frac{1}{T_{pipeline}} = \frac{1}{14ns} = \frac{1}{14 \times 10^{-9} s}$
		$f_{max} = \frac{10^9}{14} Hz \approx 71.43 \times 10^6 Hz = 71.43 MHz$
	2. **结论**: 处理器频率最高能达到约**71.4MHz**。
- 衍生 
	- 性能分析与比较  
		-  计算执行一段包含多种指令的程序的总时间。公式为：$T_{total} = N_{instructions} \times CPI_{avg} \times T_{clock}$。你需要能计算出在单周期、多周期和流水线设计下，各自的平均CPI和总执行时间，并进行比较  
		- 加速比计算：例如，流水线相对于单周期的加速比是多少？  
	- #流水线冒险   [[流水线冒险]] 
	- #数据通路与控制  
		-  要求你画出单周期、多周期或流水线的数据通路图。
	    *   分析在执行某条特定指令时，数据通路中哪些线路是有效的，各个控制信号（如`RegWrite`, `ALUSrc`, `MemRead`等）的值是什么。



![[Pasted image 20251117105811.png]]
- 其核心在于**增加流水线段数不一定能提高CPU频率**。CPU的频率取决于流水线 中最慢的那个段（stage）的执行时间  [[CPU主频]]
1. 前提条件：    [[流水线性能分析]]    [[计算机性能评测的四个指标]]   #CPU频率  #时钟频率  [[MIPS处理器微架构(单周期,多周期,流水线)]]    
	1. 有五个子操作 A, B, C, D, E，它们的执行时间分别为： 
    *   A = 30ps
    *   B = 10ps
    *   C = 40ps
    *   D = 40ps
    *   E = 40ps
		*   流水线段与段之间的锁存器（latch）延迟为 5ps
2. #流水线时钟周期的计算公式 为
	$T_{clk} = \max(\text{各段的执行时间}) + \text{锁存器延迟}$
	
	**CPU频率的计算公式为：**
	$f = 1/T_{clk}$
3. 情况 (1): 将 A 和 B 合并为一段，C, D, E 各自为一段，总共4段流水线  
	1. 第一段 (A+B) 的时间 = $30\text{ps} + 10\text{ps} = 40\text{ps}$
		*   第二段 (C) 的时间 = $40\text{ps}$
		*   第三段 (D) 的时间 = $40\text{ps}$
		*   第四段 (E) 的时间 = $40\text{ps}$
		*   所有段中，最长的时间（瓶颈）是 $40\text{ps}$。
		*   因此，时钟周期 $T_{clk} = 40\text{ps} + 5\text{ps} = 45\text{ps}$。
		*   CPU 频率 $f = 1/45\text{ps} = 1/(45 \times 10^{-12} \text{s}) \approx 22.22 \text{GHz}$。
4. 情况 (2): 将 A, B, C, D, E 各自划分为一段，总共5段流水线  
	1. 第一段 (A) 的时间 = $30\text{ps}$
		*   第二段 (B) 的时间 = $10\text{ps}$
		*   第三段 (C) 的时间 = $40\text{ps}$
		*   第四段 (D) 的时间 = $40\text{ps}$
		*   第五段 (E) 的时间 = $40\text{ps}$
		*   所有段中，最长的时间（瓶颈）依然是 $40\text{ps}$（由C, D, E段决定）。
		*   因此，时钟周期 $T_{clk} = 40\text{ps} + 5\text{ps} = 45\text{ps}$。
		*   CPU 频率 $f = 1/45\text{ps} \approx 22.22 \text{GHz}$。
5. 结论 
	1. 从4段流水线增加到5段流水线，CPU的频率并没有改变。这是因为增加的划分（将A+B拆开）并没有解决真正的瓶颈——最慢的C, D, E段。因此，“提高流水线的段数**可**提高CPU的频率”这个说法不是绝对的，只有当增加段数能够**有效缩短最长段的执行时间**时，才能提高CPU频率。所以原命题为假  
- 衍生 
	- 流水线性能计算  
		- 吞吐率计算
			- 计算在 $k$ 段流水线上执行 $n$ 条指令的实际吞TP。总时间为 $T_{pipeline}=(k+n-1) \times T_{clk}$，吞吐率为 $TP=n/T_{pipeline}$。
		*  加速比计算
		    * 衡量流水线相对于非流水线执行的性能提升。
		        $S=\frac{T_{non-pipeline}}{T_{pipeline}}$
		        其中，非流水线执行总时间 $T_{non-pipeline} = n \times (\sum_{i=1}^{k} \Delta t_i)$
	- #流水线划分的原则   
		- 段划分的平衡性  
			- 理想的流水线设计应使每个段的执行时间尽可能相等。如果各段执行时间相差悬殊，则最长段会成为整个流水线的瓶颈，导致其他较快的段处于等待状态，造成硬件资源浪费 
		- 如何有效提高频率 
			- 考题可能会问，在上述例子中，如何修改才能有效提高CPU频率？答案是：需要将最长的段（C, D或E，40ps）进一步细分。例如，如果C可以被拆分为两个20ps的子段C1和C2，那么最长段就变成了30ps（A段），CPU频率就会得到提升。   
	- 流水线冒险 
		- 这是流水线技术中的核心难点，也是高频考点。指因流水线中指令的重叠执行而可能出现的错误结果。
		    *   **结构冒险：** 因硬件资源冲突（如只有一个存储器端口）导致指令无法按时执行。
		    *   **数据冒险：** 后续指令需要用到前面尚未完成指令的计算结果（如 `ADD R1, R2, R3` 后紧跟 `SUB R4, R1, R5`）。
		    *   **控制冒险：** 由分支、跳转等指令引起，导致流水线无法确定下一条要取指的指令地址。

![[Pasted image 20251117105819.png]]
![[Pasted image 20251117105827.png]]
- 我们先分析题目给出的数据：  \   [[MIPS处理器微架构(单周期,多周期,流水线)]]     
	*   各阶段延迟: IF=250ps, ID=180ps, EX=150ps, MEM=300ps, WB=200ps。
	*   寄存器延迟: 输入(写)10ps, 输出(读)10ps。   
- (1) 按照单周期、多周期、流水线设计，时钟周期最短为？请给出你的计算过程  
	- (1) 单周期   
		- **时钟周期**：由最长指令的完整执行时间决定。在`addu`, `lw`, `j`中，`lw`（加载指令）会用到所有5个阶段，所以它是最长的  
			- 计算  
				- 时钟周期等于`lw`指令顺序执行所有阶段的时间总和。
				    $T_{single} = T_{IF} + T_{ID} + T_{EX} + T_{MEM} + T_{WB}$
				    $T_{single} = 250 + 180 + 150 + 300 + 200 = 1080ps$
			- **结论**：单周期设计的时钟周期为 **1080ps**。图片中的分析是正确的，并且指出了PC不是通用寄存器，其延迟不应额外计算，这也是对的
	- (2) 多周期  
		- 时钟周期  
			- 由最耗时的单个功能阶段决定。我们需要在IF, ID, EX, MEM, WB中找到最长的一个。  
		- **计算**：
		    $T_{multi} = \max(T_{IF}, T_{ID}, T_{EX}, T_{MEM}, T_{WB})$
		    $T_{multi} = \max(250, 180, 150, 300, 200) = 300ps$
		- **结论**：多周期设计的时钟周期为 **320ps**  
	- (3) 流水线
		- **时钟周期**：与多周期设计类似，由最长的流水线阶段延迟决定（同样可能需要加上锁存器延迟）
			- $T_{pipeline} = \max(\text{各阶段延迟}) + T_{latch\_delay}$
			    $T_{pipeline} = \max(250, 180, 150, 300, 200) + 10 = 300 + 10 = 310ps$ 
			- **结论**：流水线设计的时钟周期为 **320ps** (同样，采纳图片结论以便后续推导)。  
- (2) 按照单周期、多周期、流水线设计，最短的指令延迟为？  
	- (1) 单周期  
		- 指令延迟：所有指令的延迟都等于时钟周期，因为每条指令都占用一整个长周期。
			*   **计算**：$Latency_{min} = T_{single} = 1080ps$
			*   **结论**：最短指令延迟为 **1080ps**。
	-  (2) 多周期 
		- 指令延迟  
			- 需要找到执行周期数最少的指令。
		    *   `lw`：需要5个周期 (IF, ID, EX, MEM, WB)。
		    *   `addu`：需要4个周期 (IF, ID, EX, WB)，跳过MEM阶段。
		    *   `j`：需要2个周期 (IF, ID)。在ID阶段计算出跳转地址并更新PC，指令执行即结束。
		*   **计算**：最短的指令是`j`，需要2个时钟周期。
			$Latency_{j} = CPI_{j} \times T_{multi}$
			$Latency_{j} = 2 \times 320ps = 640ps$	
		- **结论**：多周期设计下，最短指令延迟为 **640ps**。
	- (3) 流水线  
		- **指令延迟**：在理想流水线（无冲突）中，**任何一条**指令从进入流水线（IF阶段）到离开流水线（WB阶段结束），都需要经过所有5个阶段
		- 计算  
		    $Latency_{any\_instruction} = \text{流水线级数} \times T_{pipeline}$
		    $Latency_{any\_instruction} = 5 \times 320ps = 1600ps$
		- **结论**：流水线设计下，（最短）指令延迟为 **1600ps**。这对应了图片中蓝色框的答案。要注意区分延迟（Latency）和吞吐率。流水线的优势在于其高吞吐率（理想情况下每个周期产出一条指令），而不是缩短单条指令的延迟  	
- 衍生 
	- 流水线冲突  
	- 性能评估  
		- 加速比  衡量流水线相对于非流水线性能提升的指标。
	        $S = \frac{T_{non-pipeline}}{T_{pipeline}}$
	- [[流水线优化]]   
![[Pasted image 20251204174901.png]]
[[Pasted image 20251117105834.png]]
- 题的目的是找出与`lw`指令功能实现**无关**的信息传递路径。`lw`指令的作用是从数据存储器（内存）中读取一个字（word）的数据，并将其加载到指定的寄存器中  
1. [[mips指令集简写]]   [[指令流水线与冲突]]
	`lw`指令的格式通常是 `lw rt, offset(rs)`，其执行过程可以分解为：
	1.  计算内存地址：将寄存器`rs`中的值与指令中的立即数`offset`（经过符号扩展后）相加，得到有效的内存地址。这个计算由ALU（算术逻辑单元）完成。
	2.  读取内存：根据ALU计算出的地址，从数据存储器中读取数据。
	3.  写入寄存器：将从内存中读取的数据写入目标寄存器`rt`。`lw` (Load Word) 是MIPS指令集中的一种I-type（立即数类型）指令。它定义了操作码、源寄存器（rs）、目标寄存器（rt）和立即数（offset）。理解指令的功能是分析数据通路的基础
*   **(A) PC 寄存器 -> 指令内存 (PC register -> Instruction Memory)**
    *   这是 #取指IF （Instruction Fetch, IF）**阶段。任何指令（包括`lw`）在执行前都必须先从指令内存中被取出来。程序计数器（PC）存放着当前指令的地址，CPU使用这个地址去指令内存中获取指令。所以，这个信息传递是**必须的**。

*   **(B) 寄存器 -> ALU (Register -> ALU)**
    *   这是 #执行EXE （Execute, EXE）**阶段的一部分。为了计算访存地址，需要将基址寄存器`rs`中的值送到ALU的一个输入端。所以，这个信息传递是**必须的**。其地址计算公式为：$Address = Reg[rs] + \text{sign\_ext}(offset)$。

*   **(D) ALU -> 到数据内存 (ALU -> to Data Memory)**
    *   这是 #访存MEM （Memory Access, MEM）**阶段。在EXE阶段，ALU计算出的结果是访存的有效地址。这个地址必须被送到数据内存的地址端口，才能根据该地址读取数据。所以，这个信息传递是**必须的**。

*   **(C) ALU -> 寄存器 (ALU -> Register)**
    *   这个路径表示将ALU的计算结果直接写回寄存器堆（Register File）。对于`lw`指令，ALU的计算结果是**内存地址**，而不是最终要写入寄存器的数据。最终要写入寄存器的数据是**从数据内存中读取出来的值**。因此，`lw`指令的数据通路是 `数据内存 -> 寄存器`，而不是 `ALU -> 寄存器`。`ALU -> 寄存器` 这个路径是算术/逻辑运算指令（如`add`, `sub`, `and`等R-type指令）所使用的。
    *   因此，这个信息传递与`lw`指令的最终功能实现是**无关的**。
**结论**：正确答案是 **(C)**。  

- 衍生 
	- MIPS指令集架构  
		- `lw` (Load Word) 是MIPS指令集中的一种I-type（立即数类型）指令。它定义了操作码、源寄存器（rs）、目标寄存器（rt）和立即数（offset）。理解指令的功能是分析数据通路的基础  
	- #CPU数据通路   
		- #数据通路 是CPU中数据流经的路径，由各种硬件单元（如寄存器、ALU、存储器、多路选择器等）和连接它们的总线构成。分析一道指令的执行过程，本质上就是追踪数据在该指令对应的数据通路上的流动过程  
	-     对于`lw`指令，其核心操作发生在EXE, MEM, WB三个阶段：
	    *   EXE: $Address = Reg[rs] + \text{offset}$
	    *   MEM: $Data = Mem[Address]$
	    *   WB: $Reg[rt] \leftarrow Data$
	- 不同指令的数据通路分析 
		-  #sw指令(Store Word) 指令：`sw rt, offset(rs)`。它的数据通路与`lw`类似，但在MEM阶段是**写**内存而不是读。数据从寄存器`rt`流向数据内存，因此会有一条 `寄存器 -> 数据内存` 的路径。
	    *   #R-type指令 (如 `add rd, rs, rt`)：这类指令不访问数据内存。其数据从寄存器`rs`和`rt`流向ALU，计算结果再从ALU直接写回到目标寄存器`rd`。这正是选项(C) `ALU -> 寄存器` 所描述的路径。
	    *   #分支指令beq-rs_rt_label (如 `beq rs, rt, label`)：这类指令需要比较两个寄存器的值（通过ALU做减法并检查零标志位），然后根据结果决定是否更新PC。
	- 流水线中的数据冒险   [[流水线冒险]] 


![[Pasted image 20251204174908.png]]
[[Pasted image 20251117105844.png]]
- #流水线阶段寄存器 （Pipeline Stage Registers），也叫流水线锁存器（Latches），是**微体系结构层**的组件。它们的作用是在流水线的各个阶段之间（如“取指”和“译码”之间，“译码”和“执行”之间）暂存指令和相关数据。它们由CPU的控制单元自动管理，确保指令在各个阶段能够正确、同步地流动 
1. **什么是“透明”？**
    在计算机科学中，当一个较低层次的复杂实现细节对于较高层次的用户（这里指程序员）来说是不可见、无需关心、也无法直接操作时，我们就说这个细节是“透明的”。程序员可以像它不存在一样进行编程。
#程序员可见寄存器 
[[CPU寄存器]]


![[Pasted image 20251204174916.png]]
[[Pasted image 20251117105851.png]]
*   题目给出了一个5级流水线，各个功能段的时间分别为：60ns, 50ns, 40ns, 60ns, 30ns。
*   我们需要找出这些时间中的最大值，即流水线的“瓶颈”所在。
*   计算最大值：$\max(60, 50, 40, 60, 30) = 60\text{ns}$。
*   因此，为了让这个最长的段（60ns）有足够的时间完成操作，处理器的时钟周期至少必须是60ns。  
本题中明确指出“忽略流水线寄存器的延迟”，所以 $\Delta t = 0$，公式简化为：
$T_{clk} \ge \max(t_i)$
  
![[Pasted image 20251204174931.png]]
[[Pasted image 20251117105859.png]]
[[Pasted image 20251117105935.png]]
- 题目解析与推导     [[mips指令集简写]]
	1.  `I1: MOV 100, %edx` (将立即数100移入寄存器`%edx`)
	2.  `I2: MOV 200, %edy` (将立即数200移入寄存器`%edy`)
	3.  `I3: ADD %edx, %edy` (将`%edx`和`%edy`相加，结果存入`%edy`)
- **依赖分析:**
	`I3`指令的执行（E阶段）需要`%edx`和`%edy`的值。而这两个值分别由`I1`和`I2`产生。这是一个典型的RAW数据冲突。 
- 推导过程  
	- 获得最大吞吐率，我们优先考虑使用数据旁路技术。
		*   `I1`的结果 (`%edx`的值) 在其**E阶段结束时**就准备好了。
		*   `I2`的结果 (`%edy`的值) 在其**E阶段结束时**也准备好了。
		*   `I3`需要这两个值用于自己的**E阶段**。
画出时空图来分析：

| 时钟周期(CC) | 1 | 2 | 3 | 4 | 5 | 6 | 7 |
| :--- | :-: | :-: | :-: | :-: | :-: | :-: | :-: |
| **I1: MOV** | F | D | **E** | M | W | | |
| **I2: MOV** | | F | D | **E** | M | W | |
| **I3: ADD** | | | F | D | **E** | M | W |

1.  **CC4**: `I3`处于D阶段（译码和取数），`I2`处于E阶段，`I1`处于M阶段。
2.  **CC5**: `I3`准备进入E阶段。此时它需要`%edx`和`%edy`。
    *   `%edx`的值：由`I1`产生。`I1`的E阶段在**CC3结束时**完成。这个结果可以通过旁路，从`I1`的E-M流水线寄存器直接传给`I3`的E阶段输入。
    *   `%edy`的值：由`I2`产生。`I2`的E阶段在**CC4结束时**完成。这个结果也可以通过旁路，从`I2`的E-M流水线寄存器直接传给`I3`的E阶段输入。

由于数据旁路的存在，`I3`可以在CC5顺利进入E阶段，无需等待`I1`和`I2`完成W阶段。整个过程非常流畅，没有任何暂停（Stall）。

**结论:**
最后一条指令`I3`在第7个时钟周期（CC7）完成其W阶段。因此，三条指令共用时 **7个时钟周期**。
- - 问题 (4): 四条指令的情况  
- **关键信息:** 解答中提到了“**load-use数据冲突**”，这暗示了`I1`和`I2`很可能是`LOAD`指令（从内存加载数据到寄存器），而不是`MOV`立即数。这是`LOAD`指令和普通运算指令的一个关键区别。
	**`LOAD`指令的特殊性:**
	对于`LOAD`指令（如 `LOAD R1, address`），数据是在**M（访存）阶段**从内存中取出的。这意味着数据要到**M阶段结束时**才准备好。
	[[特殊指令]] 
	我们构建一个符合描述的指令序列：
	1.  `I1: LOAD R1, addr1`
	2.  `I2: LOAD R2, addr2`
	3.  `I3: ADD R3, R1, R2`
	4.  `I4: STORE R3, addr3`

**推导过程 (考虑load-use冲突):**
我们来分析`I2`和`I3`之间的依赖，因为`I2`的结果比`I1`晚一个周期才可用。

| 时钟周期(CC) | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
| :--- | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |
| **I1: LOAD** | F | D | E | **M** | W | | | | |
| **I2: LOAD** | | F | D | E | **M** | W | | | |
| **I3: ADD** | | | F | D | **Stall** | **E** | M | W | |
| **I4: STORE**| | | | F | D | Stall | **E** | M | W |
1.  **CC5**: `I3`准备进入E阶段。它需要`R2`的值。
2.  `R2`的值由`I2` (`LOAD`)产生。`I2`在CC5时正处于**M阶段**，数据要到**CC5结束时**才能从内存中读出。
3.  但是，`I3`的E阶段在**CC5开始时**就需要`R2`的值作为输入。数据来不及通过旁路从M阶段的末尾传到同一周期E阶段的开头。
4.  **冲突发生！** 流水线必须暂停。硬件检测到这种“load-use”冲突，会在`I3`的执行阶段前插入一个“气泡”（Bubble），也就是一个Stall周期。
5.  因此，`I3`的D阶段在CC4完成后，需要等待一个周期（CC5），直到CC6才能进入E阶段。此时，`I2`在CC5结束时产生的数据已经可以通过旁路（M -> E）顺利传递给`I3`了。
6.  **分析`I3`和`I4`的依赖**：`I4`需要`I3`的结果`R3`。`I3`是`ADD`指令，其结果在**E阶段结束时**（CC6结束时）就可用了。`I4`的E阶段在CC7开始，可以通过旁路（E -> E）获得数据，**无需暂停**。
7.  **修正时空图**：由于`I3`被暂停了一个周期，它后面的`I4`也必须顺延。
- **结论:**
	- 最后一条指令`I4`在第9个时钟周期（CC9）完成。因此，四条指令共用时 **9个时钟周期**。  
		这个结果可以通过公式 `理想周期 + 暂停周期` 计算。
			理想情况下4条指令耗时 $5 + (4-1) = 8$ 个周期。因为有1个load-use冲突导致了1个周期的暂停，所以总时间是 $8 + 1 = 9$ 个周期。 
- 衍生 
	- 控制冲突处理  [[流水线冒险]]
		- 分支预测  
			- 猜测分支会不会跳转，并提前取指令。如果猜错，则产生分支惩罚（Branch Penalty），需要冲刷（flush）流水线中已取的错误指令  
		- 延迟槽  
			- 在分支指令后紧跟一条或多条指令，无论分支是否跳转，这些指令都会被执行。由编译器负责找到安全的指令来填充延迟槽。题目可能会让你计算使用延迟槽技术后的执行时间。
	- 指令重排  
		- 由编译器或硬件（乱序执行处理器）调整指令顺序，以避免或减少流水线暂停。例如，在`LOAD R1`和`ADD R2, R1`之间插入一条不相关的指令，就可以消除load-use暂停  

![[Pasted image 20251204174953.png]]
[[Pasted image 20251117105945.png]]
- [[流水线冒险]]  [[“流水线冒险”与“流水线冲突”的区别]]   #流水线冲突  




![[Pasted image 20251204175003.png]]
[[Pasted image 20251117105951.png]]
- #流水线的核心思想 是**并行处理**：在同一个时钟周期内，让不同指令处于不同的处理阶段，从而提高处理器的吞吐率。  
1. (A) 多个处理器不会发生结构冲突  
	1. 这个说法是**错误**的。首先，选项中的“多个处理器”应理解为流水线中的“多个处理阶段”或“功能单元”。 #结构冲突 (Structural Hazard) 是指因硬件资源不足，导致多条指令在同一时钟周期内竞争同一个硬件部件。一个经典的例子就是内存访问：  
		1.    指令1处于 **IF** 阶段，需要访问内存来**取指令**。
		    *   同时，指令3（比指令1早两个周期进入流水线）可能处于 **MEM** 阶段，需要访问内存来**读/写数据**。
		    *   如果处理器只有一个单一端口的存储器（即不能同时进行读指令和读/写数据），那么这两个阶段就会争用内存资源，从而产生结构冲突。
	2. 因此，“不会发生结构冲突”的说法是错误的  
2. (B) 每个周期执行一个功能  
	1. 这个说法也是**错误**的。流水线处理器的特点是在**同一个时钟周期内，同时执行多个功能**。例如，在某个周期T，可能有五条不同的指令分别处于IF, ID, EX, MEM, WB五个阶段。这意味着处理器同时在执行“取指”、“译码”、“计算”、“访存”和“写回”这五个不同的功能  
		1. 从**单条指令**的角度看，它在每个周期只完成一个阶段的功能。
		    *   但从**整个处理器**的角度看，它在每个周期并行地执行了多个功能。
		2.  **结论**：题干的表述“每个周期执行一个功能”是片面的，忽略了流水线的并行性，因此是错误的
3. (C) 可以采用微程序或者硬连线设计   #微程序
	1. 这是**正确**的。处理器的**控制器 (Control Unit)** 负责产生控制信号，指挥各个部件工作。控制器的实现方式主要有两种  
		1.  **硬连线 (Hardwired)**：用纯逻辑门电路实现，速度快，但设计复杂，不易修改
		2.  **微程序 (Microprogrammed)**：将控制信号编成微指令存储在控制存储器中，执行时按顺序取出。设计规整，易于修改，但速度较慢。
	2. 无论是流水线处理器还是非流水线处理器，其控制器都可以选择这两种设计方法之一。
	*   **结论**：该说法正确。
4. (D) 不同的指令执行时间相同  
	1. 在**理想的、基础的**五段流水线模型中，这个说法是**正确**的。这里“执行时间”指的是一条指令从进入流水线到最终完成所花费的总时间  
		1. 为了保证流水线能顺畅地流动，通常会将每个阶段的时间设计为相同的长度（一个时钟周期）。因此，任何指令都需要经过全部五个阶段，花费5个时钟周期才能完成  
		2. 在标准模型下，该说法正确。（注：在更复杂的处理器中，不同指令的执行阶段可能需要不同数量的周期，但这超出了基础模型的范畴。）
- 衍生  
	- #超标量与超流水线   #超标量  [[超标量技术]]  #超流水线  
	    *   **超标量 (Superscalar)**：在一个时钟周期内可以发射多条指令，通过复制多套功能部件实现空间上的并行。
	    *   **超流水线 (Super-pipelining)**：将流水线段划分得更细，使得时钟频率可以更高，在一个时钟周期内可以完成多个微操作。
	

![[Pasted image 20251204175011.png]]
[[Pasted image 20251117105957.png]]
[[数据冒险的解决方案]] 
 暂停流水线、调整指令顺序和数据旁路都是用来解决**数据冲突**的，而分支预测是用来解决**控制冲突**的。因此，(B) 分支预测不可以解决数据冲突。   

- 衍生 
	- “加载-使用”冲突  [[特殊指令]] 
		- 这是一个特殊的数据冲突，即使有数据旁路也无法完全解决，通常仍需要一个周期的暂停。
    *   例子：
        ```assembly
        LW R1, 0(R2)   ; Load word from memory into R1
        ADD R3, R1, R4 ; Use R1
        ```
	    `LW`指令在访存（MEM）阶段才能从内存中读出数据，而`ADD`指令在执行（EX）阶段就需要这个数据。即使从MEM阶段的输出直接旁路到EX阶段的输入，时间上也晚了一个周期，因此需要暂停一个周期。

	- #分支预测的准确率对性能的影响     
		- #分支开销
			- 当分支预测错误时，清空流水线并重新取指所造成的时钟周期损失。
			- 计算包含分支指令时的平均CPI：
		        $CPI = CPI_{理想} + P_{分支} \times (1 - A_{预测}) \times \text{分支开销}$
		        其中，$P_{分支}$是分支指令在所有指令中所占的比例，$A_{预测}$是分支预测的准确率。
		- 不同 #分支预测策略的对比  
			- 1位预测器 vs 2位预测器  
				- 2位预测器（通常使用饱和计数器）能够容忍一次错误的行为模式（例如循环结束时的那一次不跳转），因此在循环等场景下表现更好  

![[Pasted image 20251204175021.png]]
[[Pasted image 20251117110010.png]]

 1. 计算时钟周期  [[流水线技术]]  
	首先，确定流水线的时钟周期。
	$T_{cycle} = \text{流水线模块延迟} + \text{流水线寄存器延迟} = 10ns + 5ns = 15ns$
	后续所有的时间计算都基于这个周期
2. 不采用 #旁路技术  
	1. 在这种情况下，指令必须等待前一条指令完成 **WB（写回）** 阶段后，才能在自己的 **ID（读寄存器）** 阶段读到正确的数据。  
		1. 指令依赖分析 
		    *   `lw R1, 0(R2)` 在第5个时钟周期（CC5）的WB阶段才会将数据写入寄存器 `R1`。
		    *   `sub R3, R1, R4` 需要在它的ID阶段读取 `R1`。
		2. 流水线时序图分析  
			1.  **`lw` 指令**: 正常执行，在 CC1-CC5 分别处于 IF, ID, EXE, MEM, WB 阶段。`R1` 的值在 **CC5结束时** 才稳定有效。
			2.  **`sub` 指令**: 在 CC2 开始执行IF。在 CC3，它准备进入ID阶段，但此时 `lw` 尚未写回 `R1`。因此，`sub` 指令必须**停顿**。
			3.  **停顿多久？** 题目中有一个关键细节：“在CC5前半个周期WB段写，后半个周期ID段读”。这意味着，`sub` 可以在 `lw` 写回的同一个周期（CC5）进行ID操作。
			4.  因此，`sub` 的ID阶段必须被推迟到 CC5。它在 CC2 执行了IF，那么在 CC3 和 CC4 就必须插入**两个周期的停顿（气泡）**。
			5.  一旦 `lw` 的数据冒险被解决，后续依赖 `R1` 的指令（`add`, `or`, `add`）就不再有冒险，因为它们可以按部就班地在 `sub` 之后执行，此时 `R1` 的值已经是正确的了。
3. 时序图（如题目所示）  

| 指令 | CC1 | CC2 | CC3 | CC4 | CC5 | CC6 | CC7 | CC8 | CC9 | CC10 | CC11 |
| :--- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- |
| `lw` | IF | ID | EXE | MEM | WB | | | | | | |
| `sub`| | IF | - | - | ID | EXE | MEM | WB | | | |
| `add`| | | IF | - | - | ID | EXE | MEM | WB | | |
| `or` | | | | IF | - | - | ID | EXE | MEM | WB | |
| `add`| | | | | IF | - | - | ID | EXE | MEM | WB |

*   从图中可以看到，最后一条 `add` 指令在 **CC11** 完成WB阶段。
*   总时间 = 总周期数 × 时钟周期 = $11 \times 15ns = 165ns$
4. 采用旁路技术  
	1. 这种情况下，数据可以从 `lw` 指令的 **MEM阶段之后** 直接转发给后续指令的 **EXE阶段**    
		1. 指令依赖分析 
			1.  `lw` 指令在 **CC4结束时**，其MEM阶段完成，此时要加载的数据已经从内存中读出，位于MEM/WB流水线寄存器中。
			    *   `sub` 指令需要在其 **EXE阶段** 使用 `R1` 的值 
		2. 流水线时序图分析  
		    1.  **`lw` 指令**: 正常执行，在 CC4 结束时，数据准备就绪。
		    2.  **`sub` 指令**: 在 CC2 执行IF，CC3 执行ID。在 CC4，它准备进入EXE阶段。
		    3.  **是否需要停顿？** `sub` 在 **CC4开始时** 需要数据，但 `lw` 在 **CC4结束时** 数据才准备好。数据来不及从 `lw` 的MEM阶段结束时转发给 `sub` 的EXE阶段开始时。这被称为 **“Load-Use”冒险**，是旁路技术无法完全消除的一种特殊情况。
		    4.  因此，`sub` 指令必须**停顿一个周期**，等待 `lw` 完成MEM阶段。
		    5.  `sub` 的EXE阶段被推迟到 CC5。在 CC5，`lw` 在MEM阶段的结果（来自CC4的输出）可以被成功转发给 `sub` 的EXE阶段。
		时序图（如题目所示）

| 指令 | CC1 | CC2 | CC3 | CC4 | CC5 | CC6 | CC7 | CC8 | CC9 | CC10 |
| :--- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- |
| `lw` | IF | ID | EXE | MEM | WB | | | | | |
| `sub`| | IF | ID | - | EXE | MEM | WB | | | |
| `add`| | | IF | ID | - | EXE | MEM | WB | | |
| `or` | | | | IF | ID | - | EXE | MEM | WB | |
| `add`| | | | | IF | ID | - | EXE | MEM | WB |

*   从图中可以看到，最后一条 `add` 指令在 **CC10** 完成WB阶段。
*   总时间 = 总周期数 × 时钟周期 = $10 \times 15ns = 150ns$

- 衍生 
	- 不同类型的数据冒险  
		- ALU-ALU冒险 
			- 如果第一条指令是 `add R1, ...`，那么它的结果在EXE阶段结束时（CC3）就可用了。通过旁路，后续指令无需停顿（EXE -> EXE 转发）。这是最常见的转发路径 
		- Load-Use冒险  
			- 正如本题所示，`lw` 指令后的第一条指令即使有旁路也需要停顿1个周期  
	- 更复杂的流水线  
	    *   **超标量（Superscalar）**: 每个时钟周期可以发射多条指令。
	    *   #乱序执行: 允许后一条不相关的指令先于被阻塞的前一条指令执行。

![[Pasted image 20251204175128.png]]
[[Pasted image 20251117110108.png]]
 
[[结构冒险的解决方案]]  
- **冲突场景**：假设有一条`lw`指令正在执行MEM阶段，它需要访问存储器。同时，流水线中另一条晚3个周期的指令正在执行IF阶段，它也需要访问存储器来取指令。如果处理器只有一个统一的存储器端口（即指令和数据共享一个访问通道），那么这两条指令就会争用这个唯一的资源，导致结构冲突。 
	- 解决方案就是将统一的存储器分离成两个独立的“功能单元”：一个用于取指令的指令存储器（或指令缓存I-Cache），另一个用于读写数据的数据存储器（或数据缓存D-Cache）。这样，IF阶段和MEM阶段就可以在同一周期内并行访问各自的存储器，冲突就消除了。
    *   这正是“充分设置功能单元”的体现——通过增加或分离硬件资源来满足流水线并行执行的需求。

![[Pasted image 20251204175135.png]]
[[Pasted image 20251117110114.png]]

[[数据冒险的解决方案]] 

[[编译器优化]] 



![[Pasted image 20251204175143.png]]
[[Pasted image 20251117110120.png]]
[[数据冒险的解决方案]]   
- **生活比喻：** 第1辆车正在“安装引擎”（EX阶段），而紧接着的第2辆车的工作是“连接引擎的点火线”（也发生在EX阶段）。显然，第2辆车必须等到第1辆车的引擎安装完毕，才能去连接点火线。如果它不等，要么无事可做，要么就会去连接一个还不存在的引擎，导致错误。
- **计算机实例 (RAW - 写后读)：** 这是最常见、最重要的数据冒险。
    
    ```assembly
    1ADD R1, R2, R3   ; 指令1: R1 = R2 + R32SUB R4, R1, R5   ; 指令2: R4 = R1 - R5
    ```
    
    - **冒险分析：** `SUB`指令需要读取`R1`的值，但这个值是由`ADD`指令计算并写入的。在流水线中，当`SUB`指令进入“执行”（EX）阶段需要`R1`时，`ADD`指令可能还在“执行”或“访存”阶段，还没把结果写回（WB）到`R1`寄存器中。此时`SUB`如果直接去读`R1`，读到的是旧的、错误的数据。
- **其他类型（在复杂乱序执行流水线中更关键）：**
    - **WAR (Write After Read / 读后写):** 指令J想写入一个寄存器，但它前面的指令I还没从这个寄存器读完旧值。这是一种“伪依赖”或“名字依赖”。
    - **WAW (Write After Write / 写后写):** 指令J和它前面的指令I都要写入同一个寄存器。必须保证指令I先写，指令J后写，否则最终结果就错了。

	-  **(A) RAR (Read After Read, 读后读)**: 指令 `j` 在指令 `i` 之后读取同一个寄存器。这 **不是冲突**，因为读取操作不会改变寄存器的值，两条指令读取到的都是正确的值。 
    *   **(C) WAW (Write After Write, 写后写)**: 指令 `j` 和前序指令 `i` 写入同一个目标寄存器。
        *   **在流水线中**: MIPS 五级流水线是 **按序流出 (in-order completion)** 的。所有指令都经过相同的五个阶段，因此它们到达 WB 阶段的顺序与它们进入流水线的顺序完全相同。前序指令 `i` 总是比后序指令 `j` 先到达 WB 阶段并完成写入。所以 `j` 的写操作不可能发生在 `i` 之前。**因此，WAW 冲突在标准的 MIPS 五级流水线中不会发生。** (注：WAW 冲突通常发生在乱序执行或不同指令执行时间不同的复杂流水线中)。

    *   **(D) WAR (Write After Read, 读后写)**: 指令 `j` 要写入的寄存器，正好是前序指令 `i` 要读取的。
        *   **在流水线中**: 指令 `i` 在第 2 阶段 (ID) 就已经完成了读取操作。而指令 `j` 最早也要在第 5 阶段 (WB) 才能进行写入操作。当 `j` 准备写入时，`i` 早已读取完毕。`j` 的写操作永远不会发生在 `i` 的读操作之前。**因此，WAR 冲突在 MIPS 五级流水线中也不会发生。** (注：WAR 冲突是乱序执行 (out-of-order execution) 处理器需要解决的关键问题之一)。


![[Pasted image 20251204175151.png]]
[[Pasted image 20251117110126.png]]

[[数据冒险的解决方案]] 

- 冲突解决方法 
	-   **数据前传 (Data Forwarding)**：通过硬件设计，将计算结果从其产生的功能单元（如ALU）直接送到需要它的其他功能单元的输入端，而无需等待数据被写回寄存器。这是解决RAW冲突最高效的方法。
    *   **流水线暂停 (Pipeline Stall)**：如果数据前传无法完全解决冲突（例如，`LOAD`指令后紧跟一条使用该数据的指令，`lw R1, 0(R2)` -> `add R3, R1, R4`，数据需要从内存中读取，无法立即前传），则必须暂停流水线，插入一个或多个“气泡”（NOP指令），等待数据就绪。
    *   **分支预测 (Branch Prediction)**：解决控制冲突。通过预测分支的结果来避免流水线暂停。
        *   **静态预测**：总是预测跳转或总不跳转。
        *   **动态预测**：根据历史执行情况来预测。使用分支历史表(BHT)等硬件来提高预测准确率。
    *   **动态调度 (Dynamic Scheduling)**：允许指令乱序执行，以提高指令级并行度。通过寄存器重命名等技术可以消除WAR和WAW冲突，并通过保留站等机制让指令在操作数就绪后立即执行，从而有效处理RAW冲突


![[Pasted image 20251204175158.png]]
[[Pasted image 20251117110130.png]]
[[流水线技术]]
[[流水线冒险]] 



![[Pasted image 20251204175206.png]]
[[Pasted image 20251117110150.png]]
- 核心是围绕**MIPS五级流水线**中的**数据冲突 (Data Hazard)** 以及其两种解决方法：**暂停 (Stall)** 和**数据转发 (Data Forwarding)**  
1.  (1) 指出发生数据冲突的指令和寄存器  
    1.  `LW R4, 0(R5)`: 将内存地址为 `(R5)+0` 的数据加载到寄存器 `R4`。这条指令会**写入 R4**。
    2.  `ADD R6, R4, R7`: 将 `R4` 和 `R7` 的值相加，结果存入 `R6`。这条指令会**读取 R4**。
    3.  `SUB R8, R5, R9`: 将 `R5` 和 `R9` 的值相减，结果存入 `R8`。
		1. 冲突识别  
			1. `ADD` 指令需要读取 `R4` 的值，而这个值是由它紧邻的前一条 `LW` 指令计算并写入的。在流水线中，当 `ADD` 指令进入 ID 阶段需要读取 `R4` 时，`LW` 指令还远未完成其 WB (写回) 阶段，因此 `R4` 的新值还不可用。这就构成了 RAW 数据冲突  
		2. 结论 
			1. 发生数据冲突的指令是 `LW R4, 0(R5)` 和 `ADD R6, R4, R7`，冲突的寄存器是 R4 
2. (2) 如果没有数据转发，则需要暂停几个时钟？  
	1. 没有数据转发的情况下，一条指令必须等到前一条指令完成 **WB 阶段**后，才能在其 **ID 阶段**读取到正确的值  
		1. 看流水线时序图：

| 时钟周期 | CC1 | CC2 | CC3 | CC4 | CC5 | CC6 | CC7 | CC8 | CC9 |
| :--- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- |
| `LW R4, ...` | IF | ID | EXE | MEM | **WB** | | | | |
| `ADD R6, ...` | | IF | **ID** | | | | | | |

*   在 **CC3**，`ADD` 指令进入 ID 阶段，需要读取 `R4`。
*   但是，`LW` 指令要到 **CC5 的末尾**才会将结果写入 `R4`。
*   因此，`ADD` 指令的 ID 阶段必须被暂停，直到 CC6 才能成功读取 `R4` 的新值。
	- 实现这一点，流水线需要在 `ADD` 指令后面插入“气泡”(stall)  

带暂停的流水线时序图








![[Pasted image 20251204175215.png]]
[[Pasted image 20251117153556.png]]


![[Pasted image 20251204175227.png]]
[[Pasted image 20251117154301.png]]



![[Pasted image 20251204175236.png]]
[[Pasted image 20251117154305.png]]
[[Pasted image 20251117154319.png]]
[[Pasted image 20251117154327.png]]
[[Pasted image 20251117154335.png]]


![[Pasted image 20251204175300.png]]
[[Pasted image 20251117154344.png]]



![[Pasted image 20251204175311.png]]
[[Pasted image 20251117154526.png]]


![[Pasted image 20251204175503.png]]
[[Pasted image 20251117154537.png]]
[[Pasted image 20251117154546.png]]





![[Pasted image 20251204175520.png]]
[[Pasted image 20251117154554.png]]
![[Pasted image 20251204175913.png]]、








![[912历年真题解析-组成原理篇（2024.12.2）.pdf#page=19&rect=9,493,593,748|912历年真题解析-组成原理篇（2024.12.2）, p.19]]
[[Pasted image 20251117154611.png]]
[[Pasted image 20251117154639.png]]
[[Pasted image 20251117155947.png]]
[[Pasted image 20251117155955.png]]
[[Pasted image 20251117160003.png]]
[[Pasted image 20251117160011.png]]
[[Pasted image 20251117160018.png]]

-  (1) 和 (2): 计算时钟周期  
- (1) 如果实现了全部的转发，则该处理器的时钟周期不短于 150ps  
1. 当实现转发时，EXE段的逻辑会变得更复杂（需要加入选择器MUX和控制逻辑），因此延迟会增加。
	*   根据题意，各阶段延迟为：IF(130ps), ID(100ps), **EXE(带转发, 150ps)**, MEM(140ps), WB(100ps)。
	*   时钟周期 $T_c$ 必须满足：$T_c \ge \max(130, 100, 150, 140, 100) = 150\text{ps}$。
	*   因此，最短时钟周期为 **150ps**
- (2) 如果实现中不使用转发，则该处理器的时钟周期不短于 130ps  
	*   当不使用转发时，EXE段逻辑相对简单。
	*   各阶段延迟为：IF(130ps), ID(100ps), EXE(无转发, 120ps), **MEM(140ps)**, WB(100ps)。
	*   时钟周期 $T_c$ 必须满足：$T_c \ge \max(130, 100, 120, 140, 100) = 140\text{ps}$。
	*   因此，最短时钟周期为 **140ps**。
* (3): 指令序列执行分析   
	* 我们找出指令间的**写后读（RAW）数据依赖**：
		1.  `add r5, r2, r1` -> `lw r3, 4(r5)` (依赖 `r5`)
		2.  `add r5, r2, r1` -> `or r3, r5, r3` (依赖 `r5`)
		3.  `add r5, r2, r1` -> `sw r3, 0(r5)` (依赖 `r5`)
		4.  `lw r3, 4(r5)` -> `or r3, r5, r3` (依赖 `r3`)
		5.  `or r3, r5, r3` -> `sw r3, 0(r5)` (依赖 `r3`)
	场景一：实现全部转发，需要 9 个时钟周期
	- 在这种情况下，所有数据冒险都可以通过转发解决，除了一个特殊的“加载-使用”冒险（Load-Use Hazard），但我们先分析  
		- 
	




![[Pasted image 20251204180446.png]]
[[Pasted image 20251117160032.png]]
[[Pasted image 20251117160050.png]]


![[Pasted image 20251204180513.png]]
[[Pasted image 20251117160058.png]]


![[Pasted image 20251204180523.png]]
[[Pasted image 20251117160104.png]]



![[Pasted image 20251117160109.png]]



![[Pasted image 20251117160115.png]]



![[Pasted image 20251117160121.png]]



![[Pasted image 20251117160127.png]]



![[Pasted image 20251117160134.png]]



![[Pasted image 20251117160142.png]]